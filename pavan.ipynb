{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8dc8396-93e6-4a15-9980-d6094328c47c",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "## Part 1\n",
    "### Task 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35869c21-7f7e-487a-a572-575a437575a2",
   "metadata": {},
   "source": [
    "#### a) \n",
    "computation of mean and standard deviation of the input data set to obtain the standardized data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7baeb67e-50d1-48d7-80a1-d101cf84270f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: [ 10.    800.      6.696]\n",
      "standard deviation: [ 16.32993162 335.41019662   1.82242037]\n",
      "standardized input data:\n",
      " [[-1.22474487e+00 -1.34164079e+00 -1.22474487e+00]\n",
      " [-1.22474487e+00 -4.47213595e-01 -1.22474487e+00]\n",
      " [-1.22474487e+00  4.47213595e-01 -1.22474487e+00]\n",
      " [-1.22474487e+00  1.34164079e+00 -1.22474487e+00]\n",
      " [ 0.00000000e+00 -1.34164079e+00 -1.22474487e+00]\n",
      " [ 0.00000000e+00 -4.47213595e-01 -1.22474487e+00]\n",
      " [ 0.00000000e+00  4.47213595e-01 -1.22474487e+00]\n",
      " [ 0.00000000e+00  1.34164079e+00 -1.22474487e+00]\n",
      " [ 1.22474487e+00 -1.34164079e+00 -1.22474487e+00]\n",
      " [ 1.22474487e+00 -4.47213595e-01 -1.22474487e+00]\n",
      " [ 1.22474487e+00  4.47213595e-01 -1.22474487e+00]\n",
      " [ 1.22474487e+00  1.34164079e+00 -1.22474487e+00]\n",
      " [-1.22474487e+00 -1.34164079e+00  4.87361991e-16]\n",
      " [-1.22474487e+00 -4.47213595e-01  4.87361991e-16]\n",
      " [-1.22474487e+00  4.47213595e-01  4.87361991e-16]\n",
      " [-1.22474487e+00  1.34164079e+00  4.87361991e-16]\n",
      " [ 0.00000000e+00 -1.34164079e+00  4.87361991e-16]\n",
      " [ 0.00000000e+00 -4.47213595e-01  4.87361991e-16]\n",
      " [ 0.00000000e+00  4.47213595e-01  4.87361991e-16]\n",
      " [ 0.00000000e+00  1.34164079e+00  4.87361991e-16]\n",
      " [ 1.22474487e+00 -1.34164079e+00  4.87361991e-16]\n",
      " [ 1.22474487e+00 -4.47213595e-01  4.87361991e-16]\n",
      " [ 1.22474487e+00  4.47213595e-01  4.87361991e-16]\n",
      " [ 1.22474487e+00  1.34164079e+00  4.87361991e-16]\n",
      " [-1.22474487e+00 -1.34164079e+00  1.22474487e+00]\n",
      " [-1.22474487e+00 -4.47213595e-01  1.22474487e+00]\n",
      " [-1.22474487e+00  4.47213595e-01  1.22474487e+00]\n",
      " [-1.22474487e+00  1.34164079e+00  1.22474487e+00]\n",
      " [ 0.00000000e+00 -1.34164079e+00  1.22474487e+00]\n",
      " [ 0.00000000e+00 -4.47213595e-01  1.22474487e+00]\n",
      " [ 0.00000000e+00  4.47213595e-01  1.22474487e+00]\n",
      " [ 0.00000000e+00  1.34164079e+00  1.22474487e+00]\n",
      " [ 1.22474487e+00 -1.34164079e+00  1.22474487e+00]\n",
      " [ 1.22474487e+00 -4.47213595e-01  1.22474487e+00]\n",
      " [ 1.22474487e+00  4.47213595e-01  1.22474487e+00]\n",
      " [ 1.22474487e+00  1.34164079e+00  1.22474487e+00]]\n",
      "output data:\n",
      " [[ 18.9  80.3]\n",
      " [ 23.5 124.6]\n",
      " [ 24.8 138.6]\n",
      " [ 25.6 146.9]\n",
      " [ 19.2  83.1]\n",
      " [ 25.  140.5]\n",
      " [ 26.5 157.6]\n",
      " [ 27.3 167.5]\n",
      " [ 19.4  84.7]\n",
      " [ 26.4 156.7]\n",
      " [ 28.1 177.7]\n",
      " [ 29.  189.4]\n",
      " [ 22.4  75.2]\n",
      " [ 24.8  92.2]\n",
      " [ 25.8  99.7]\n",
      " [ 26.4 104.6]\n",
      " [ 23.6  83.7]\n",
      " [ 26.5 104.9]\n",
      " [ 27.6 113.8]\n",
      " [ 28.3 119.6]\n",
      " [ 24.8  92. ]\n",
      " [ 28.1 118.2]\n",
      " [ 29.3 128.8]\n",
      " [ 30.1 135.5]\n",
      " [ 23.5  62.2]\n",
      " [ 25.4  72.5]\n",
      " [ 26.3  77.6]\n",
      " [ 26.9  81.1]\n",
      " [ 25.   70.3]\n",
      " [ 27.1  82.7]\n",
      " [ 28.1  88.7]\n",
      " [ 28.7  92.8]\n",
      " [ 26.5  78.6]\n",
      " [ 28.8  93.5]\n",
      " [ 29.9 100.5]\n",
      " [ 30.6 105.2]]\n",
      "Stored 'mean' (ndarray)\n",
      "Stored 'std' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "#Part 1 input data: Air temp [T](degC), ID [ID](W/sqm), load resistance [R](ohms)\n",
    "xdata = [[-10.0, 350, 4.464], \n",
    "  [-10.0, 650, 4.464], \n",
    "  [-10.0, 950, 4.464], \n",
    "  [-10.0, 1250, 4.464], \n",
    "  [10.0, 350, 4.464], \n",
    "  [10.0, 650, 4.464], \n",
    "  [10.0, 950, 4.464], \n",
    "  [10.0, 1250, 4.464], \n",
    "  [30.0, 350, 4.464], \n",
    "  [30.0, 650, 4.464], \n",
    "  [30.0, 950, 4.464], \n",
    "  [30.0, 1250, 4.464], \n",
    "  [-10.0, 350, 6.696], \n",
    "  [-10.0, 650, 6.696], \n",
    "  [-10.0, 950, 6.696], \n",
    "  [-10.0, 1250, 6.696], \n",
    "  [10.0, 350, 6.696], \n",
    "  [10.0, 650, 6.696], \n",
    "  [10.0, 950, 6.696], \n",
    "  [10.0, 1250, 6.696], \n",
    "  [30.0, 350, 6.696], \n",
    "  [30.0, 650, 6.696], \n",
    "  [30.0, 950, 6.696], \n",
    "  [30.0, 1250, 6.696], \n",
    "  [-10.0, 350, 8.928], \n",
    "  [-10.0, 650, 8.928], \n",
    "  [-10.0, 950, 8.928], \n",
    "  [-10.0, 1250, 8.928], \n",
    "  [10.0, 350, 8.928], \n",
    "  [10.0, 650, 8.928], \n",
    "  [10.0, 950, 8.928], \n",
    "  [10.0, 1250, 8.928], \n",
    "  [30.0, 350, 8.928], \n",
    "  [30.0, 650, 8.928], \n",
    "  [30.0, 950, 8.928], \n",
    "  [30.0, 1250, 8.928]] \n",
    "\n",
    "\n",
    "#Part 1 output data: VL (V) and Power out (W)\n",
    "ydata = [[18.9, 80.3], \n",
    " [23.5, 124.6], \n",
    " [24.8, 138.6], \n",
    " [25.6, 146.9], \n",
    " [19.2, 83.1], \n",
    " [25.0, 140.5], \n",
    " [26.5, 157.6], \n",
    " [27.3, 167.5],  \n",
    " [19.4, 84.7], \n",
    " [26.4, 156.7], \n",
    " [28.1, 177.7], \n",
    " [29.0, 189.4],\n",
    " [22.4, 75.2], \n",
    " [24.8, 92.2], \n",
    " [25.8, 99.7], \n",
    " [26.4, 104.6], \n",
    " [23.6, 83.7], \n",
    " [26.5, 104.9], \n",
    " [27.6, 113.8], \n",
    " [28.3, 119.6], \n",
    " [24.8, 92.0], \n",
    " [28.1, 118.2], \n",
    " [29.3, 128.8], \n",
    " [30.1, 135.5],  \n",
    " [23.5, 62.2], \n",
    " [25.4, 72.5], \n",
    " [26.3, 77.6], \n",
    " [26.9, 81.1],  \n",
    " [25.0, 70.3], \n",
    " [27.1, 82.7], \n",
    " [28.1, 88.7], \n",
    " [28.7, 92.8],  \n",
    " [26.5, 78.6], \n",
    " [28.8, 93.5], \n",
    " [29.9, 100.5], \n",
    " [30.6, 105.2]] \n",
    "\n",
    "# calculating the mean and standard deviation using numpy\n",
    "mean=np.mean(xdata, axis=0)\n",
    "std=np.std(xdata, axis=0)\n",
    "print('mean:', mean)\n",
    "print('standard deviation:', std)\n",
    "#standardize the data\n",
    "Nx = []\n",
    "for i in range(len(xdata)):\n",
    "    Nx.append([ (xdata[i][0]-mean[0])/std[0] , (xdata[i][1]-mean[1])/std[1] , (xdata[i][2]-mean[2])/std[2] ])\n",
    "xdata = Nx\n",
    "\n",
    "xarray= np.array(xdata)\n",
    "yarray= np.array(ydata)\n",
    "print('standardized input data:\\n', xarray)\n",
    "print('output data:\\n', yarray)\n",
    "%store mean\n",
    "%store std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6757ee58-ba1f-45ce-9352-dd50194cbbba",
   "metadata": {},
   "source": [
    "#### b)\n",
    "Determining the eigen values and eigen vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a2511e86-d22a-487f-a784-5f04f6d92176",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#P3pcaExampleF22\n",
    "#PCA example modified to project 3 part 1\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fab66835-2d01-4848-8837-108deeffe3f4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.          0.4375      0.66666667]\n",
      " [-1.          0.4375      0.66666667]\n",
      " [-1.          0.8125      0.66666667]\n",
      " [-1.          0.4375      0.66666667]\n",
      " [-1.          1.5625      0.66666667]\n",
      " [ 1.          0.8125      0.66666667]\n",
      " [-1.          1.1875      0.66666667]\n",
      " [-1.          1.5625      0.66666667]\n",
      " [-1.          1.1875      0.66666667]\n",
      " [-1.          1.1875      0.66666667]\n",
      " [-1.          1.5625      0.66666667]\n",
      " [ 3.          1.1875      0.66666667]\n",
      " [-1.          0.4375      1.        ]\n",
      " [ 1.          1.1875      0.66666667]\n",
      " [ 1.          0.8125      0.66666667]\n",
      " [ 1.          1.5625      0.66666667]\n",
      " [-1.          0.8125      1.        ]\n",
      " [-1.          0.4375      0.66666667]\n",
      " [ 3.          1.5625      0.66666667]\n",
      " [ 1.          0.4375      0.66666667]\n",
      " [ 3.          0.4375      0.66666667]\n",
      " [ 1.          0.4375      0.66666667]\n",
      " [-1.          1.5625      1.        ]\n",
      " [-1.          0.8125      0.66666667]\n",
      " [-1.          0.4375      1.        ]\n",
      " [ 3.          1.1875      0.66666667]\n",
      " [ 1.          1.5625      0.66666667]\n",
      " [-1.          1.1875      1.        ]\n",
      " [-1.          0.4375      1.33333333]\n",
      " [-1.          1.5625      1.33333333]\n",
      " [ 1.          1.1875      1.33333333]\n",
      " [ 1.          0.8125      1.        ]\n",
      " [-1.          0.4375      0.66666667]\n",
      " [-1.          0.4375      1.        ]\n",
      " [ 3.          1.1875      0.66666667]\n",
      " [-1.          0.4375      1.        ]]\n",
      "[[-1.         -1.         -1.         -1.         -1.          1.\n",
      "  -1.         -1.         -1.         -1.         -1.          3.\n",
      "  -1.          1.          1.          1.         -1.         -1.\n",
      "   3.          1.          3.          1.         -1.         -1.\n",
      "  -1.          3.          1.         -1.         -1.         -1.\n",
      "   1.          1.         -1.         -1.          3.         -1.        ]\n",
      " [ 0.4375      0.4375      0.8125      0.4375      1.5625      0.8125\n",
      "   1.1875      1.5625      1.1875      1.1875      1.5625      1.1875\n",
      "   0.4375      1.1875      0.8125      1.5625      0.8125      0.4375\n",
      "   1.5625      0.4375      0.4375      0.4375      1.5625      0.8125\n",
      "   0.4375      1.1875      1.5625      1.1875      0.4375      1.5625\n",
      "   1.1875      0.8125      0.4375      0.4375      1.1875      0.4375    ]\n",
      " [ 0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667\n",
      "   0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667\n",
      "   1.          0.66666667  0.66666667  0.66666667  1.          0.66666667\n",
      "   0.66666667  0.66666667  0.66666667  0.66666667  1.          0.66666667\n",
      "   1.          0.66666667  0.66666667  1.          1.33333333  1.33333333\n",
      "   1.33333333  1.          0.66666667  1.          0.66666667  1.        ]]\n",
      "[0.05555556 0.9375     0.7962963 ]\n"
     ]
    }
   ],
   "source": [
    "X = (xarray)#define array\n",
    "print (X)\n",
    "print (X.T)  #print the transpose\n",
    "Xmean = np.mean(X,0)  # compute mean vector\n",
    "print (Xmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e25fb563-aab7-41af-985c-015063fd0b5d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.16825397  0.12142857 -0.08359788]\n",
      " [ 0.12142857  0.20089286 -0.00595238]\n",
      " [-0.08359788 -0.00595238  0.04620811]]\n"
     ]
    }
   ],
   "source": [
    "C = np.cov(X.T)  #transpose is matrix we want to work with - compute covariance matrix\n",
    "print (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0b1699a5-89e3-466f-bdf8-3ab6e993c771",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.17901342 0.19343079 0.04291073]\n",
      "[[ 0.99734431  0.06159826  0.0388584 ]\n",
      " [ 0.06134096 -0.99808654  0.00778053]\n",
      " [-0.03926331  0.00537626  0.99921444]]\n"
     ]
    }
   ],
   "source": [
    "w, v = LA.eig(C)  # get the eigenvalues w and the eigenvectors \n",
    "print (w)\n",
    "print (v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37903520-fc53-4419-8a30-acb5694e0ea6",
   "metadata": {},
   "source": [
    "#### d)\n",
    "creating the scatter plot of the standardized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cc773626-5427-4abc-96ef-53c0c925ee19",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1332x756 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# imports\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "X =(xarray)#define array\n",
    "x=X[:,0]\n",
    "y=X[:,1]\n",
    "z=X[:,2]\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x,y,z, c='red', s=60)\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z');\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcd8666-92c1-43b2-9b14-be92fbd5f690",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45377c5-e651-4277-bbf8-b4f0a5d95930",
   "metadata": {},
   "source": [
    "#### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1981fcf1-2020-4247-bd65-065493b807d4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.    800.      6.696]\n",
      "xdata: [[-1.          0.4375      0.66666667]\n",
      " [-1.          0.8125      0.66666667]\n",
      " [-1.          1.1875      0.66666667]\n",
      " [-1.          1.5625      0.66666667]\n",
      " [ 1.          0.4375      0.66666667]\n",
      " [ 1.          0.8125      0.66666667]\n",
      " [ 1.          1.1875      0.66666667]\n",
      " [ 1.          1.5625      0.66666667]\n",
      " [ 3.          0.4375      0.66666667]\n",
      " [ 3.          0.8125      0.66666667]\n",
      " [ 3.          1.1875      0.66666667]\n",
      " [ 3.          1.5625      0.66666667]\n",
      " [-1.          0.4375      1.        ]\n",
      " [-1.          0.8125      1.        ]\n",
      " [-1.          1.1875      1.        ]\n",
      " [-1.          1.5625      1.        ]\n",
      " [ 1.          0.4375      1.        ]\n",
      " [ 1.          0.8125      1.        ]\n",
      " [ 1.          1.1875      1.        ]\n",
      " [ 1.          1.5625      1.        ]\n",
      " [ 3.          0.4375      1.        ]\n",
      " [ 3.          0.8125      1.        ]\n",
      " [ 3.          1.1875      1.        ]\n",
      " [ 3.          1.5625      1.        ]\n",
      " [-1.          0.4375      1.33333333]\n",
      " [-1.          0.8125      1.33333333]\n",
      " [-1.          1.1875      1.33333333]\n",
      " [-1.          1.5625      1.33333333]\n",
      " [ 1.          0.4375      1.33333333]\n",
      " [ 1.          0.8125      1.33333333]\n",
      " [ 1.          1.1875      1.33333333]\n",
      " [ 1.          1.5625      1.33333333]\n",
      " [ 3.          0.4375      1.33333333]\n",
      " [ 3.          0.8125      1.33333333]\n",
      " [ 3.          1.1875      1.33333333]\n",
      " [ 3.          1.5625      1.33333333]]\n",
      "[ 26.45 100.1 ]\n",
      "ydata: [[0.71455577 0.8021978 ]\n",
      " [0.88846881 1.24475524]\n",
      " [0.93761815 1.38461538]\n",
      " [0.96786389 1.46753247]\n",
      " [0.72589792 0.83016983]\n",
      " [0.94517958 1.4035964 ]\n",
      " [1.00189036 1.57442557]\n",
      " [1.03213611 1.67332667]\n",
      " [0.73345936 0.84615385]\n",
      " [0.99810964 1.56543457]\n",
      " [1.06238185 1.77522478]\n",
      " [1.09640832 1.89210789]\n",
      " [0.84688091 0.75124875]\n",
      " [0.93761815 0.92107892]\n",
      " [0.97542533 0.996004  ]\n",
      " [0.99810964 1.04495504]\n",
      " [0.89224953 0.83616384]\n",
      " [1.00189036 1.04795205]\n",
      " [1.04347826 1.13686314]\n",
      " [1.06994329 1.19480519]\n",
      " [0.93761815 0.91908092]\n",
      " [1.06238185 1.18081918]\n",
      " [1.10775047 1.28671329]\n",
      " [1.13799622 1.35364635]\n",
      " [0.88846881 0.62137862]\n",
      " [0.96030246 0.72427572]\n",
      " [0.99432892 0.77522478]\n",
      " [1.01701323 0.81018981]\n",
      " [0.94517958 0.7022977 ]\n",
      " [1.02457467 0.82617383]\n",
      " [1.06238185 0.88611389]\n",
      " [1.08506616 0.92707293]\n",
      " [1.00189036 0.78521479]\n",
      " [1.08884688 0.93406593]\n",
      " [1.13043478 1.003996  ]\n",
      " [1.15689981 1.05094905]]\n",
      "Stored 'xarray' (ndarray)\n",
      "Stored 'yarray' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "'''>>>>> start CodeP3.1.2F22\n",
    "    V.P. Carey ME249, Fall 2022\n",
    "\n",
    "Intro to Neural Network Modeling \n",
    "Keras model for PV power system'''\n",
    "\n",
    "#import useful packages\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import keras.backend as kb\n",
    "import tensorflow as tf\n",
    "#the follwoing 2 lines are only needed for Mac OS machines\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# define meadian values of input variables - add your values here\n",
    "#Tamed = 10  #make sure Tamed does not = 0\n",
    "#IDmed = 800\n",
    "#RLmed = 6\n",
    "\n",
    "#create input data array\n",
    "xdata = []\n",
    "\n",
    "#Part 1 input data: Air temp (degC), ID (W/sqm), load resistance (ohms)\n",
    "xdata = [[-10.0, 350, 4.464], \n",
    "  [-10.0, 650, 4.464], \n",
    "  [-10.0, 950, 4.464], \n",
    "  [-10.0, 1250, 4.464], \n",
    "  [10.0, 350, 4.464], \n",
    "  [10.0, 650, 4.464], \n",
    "  [10.0, 950, 4.464], \n",
    "  [10.0, 1250, 4.464], \n",
    "  [30.0, 350, 4.464], \n",
    "  [30.0, 650, 4.464], \n",
    "  [30.0, 950, 4.464], \n",
    "  [30.0, 1250, 4.464], \n",
    "  [-10.0, 350, 6.696], \n",
    "  [-10.0, 650, 6.696], \n",
    "  [-10.0, 950, 6.696], \n",
    "  [-10.0, 1250, 6.696], \n",
    "  [10.0, 350, 6.696], \n",
    "  [10.0, 650, 6.696], \n",
    "  [10.0, 950, 6.696], \n",
    "  [10.0, 1250, 6.696], \n",
    "  [30.0, 350, 6.696], \n",
    "  [30.0, 650, 6.696], \n",
    "  [30.0, 950, 6.696], \n",
    "  [30.0, 1250, 6.696], \n",
    "  [-10.0, 350, 8.928], \n",
    "  [-10.0, 650, 8.928], \n",
    "  [-10.0, 950, 8.928], \n",
    "  [-10.0, 1250, 8.928], \n",
    "  [10.0, 350, 8.928], \n",
    "  [10.0, 650, 8.928], \n",
    "  [10.0, 950, 8.928], \n",
    "  [10.0, 1250, 8.928], \n",
    "  [30.0, 350, 8.928], \n",
    "  [30.0, 650, 8.928], \n",
    "  [30.0, 950, 8.928], \n",
    "  [30.0, 1250, 8.928]] \n",
    "\n",
    "#normalizing the xdata using the median value.\n",
    "medianx=np.median(xdata,axis=0)\n",
    "print(medianx)\n",
    "Tmed=medianx[0]\n",
    "IDmed=medianx[1]\n",
    "Rmed=medianx[2]\n",
    "Nx = []\n",
    "for i in range(len(xdata)):\n",
    "    Nx.append([ xdata[i][0]/Tmed , xdata[i][1]/IDmed , xdata[i][2]/Rmed ])\n",
    "xdata = Nx\n",
    "\n",
    "xarray= np.array(xdata)\n",
    "#print (xdata)\n",
    "print ('xdata:', xarray)\n",
    "\n",
    "# define meadian values of output variables - add your values here\n",
    "#VLmed = 25\n",
    "#Wdmed = 100\n",
    "\n",
    "#Part 1 output data: VL (V) and Power out Wd (W)\n",
    "ydata = [[18.9, 80.3], \n",
    " [23.5, 124.6], \n",
    " [24.8, 138.6], \n",
    " [25.6, 146.9], \n",
    " [19.2, 83.1], \n",
    " [25.0, 140.5], \n",
    " [26.5, 157.6], \n",
    " [27.3, 167.5],  \n",
    " [19.4, 84.7], \n",
    " [26.4, 156.7], \n",
    " [28.1, 177.7], \n",
    " [29.0, 189.4],\n",
    " [22.4, 75.2], \n",
    " [24.8, 92.2], \n",
    " [25.8, 99.7], \n",
    " [26.4, 104.6], \n",
    " [23.6, 83.7], \n",
    " [26.5, 104.9], \n",
    " [27.6, 113.8], \n",
    " [28.3, 119.6], \n",
    " [24.8, 92.0], \n",
    " [28.1, 118.2], \n",
    " [29.3, 128.8], \n",
    " [30.1, 135.5],  \n",
    " [23.5, 62.2], \n",
    " [25.4, 72.5], \n",
    " [26.3, 77.6], \n",
    " [26.9, 81.1],  \n",
    " [25.0, 70.3], \n",
    " [27.1, 82.7], \n",
    " [28.1, 88.7], \n",
    " [28.7, 92.8],  \n",
    " [26.5, 78.6], \n",
    " [28.8, 93.5], \n",
    " [29.9, 100.5], \n",
    " [30.6, 105.2]] \n",
    "\n",
    "#narmalizing the ydata using the median value.\n",
    "mediany=np.median(ydata,axis=0)\n",
    "print(mediany)\n",
    "VLmed=mediany[0]\n",
    "Wdmed=mediany[1]\n",
    "Ny=[]\n",
    "for i in range(len(ydata)):\n",
    "    Ny.append([ ydata[i][0]/VLmed , ydata[i][1]/Wdmed ])\n",
    "ydata=Ny\n",
    "yarray= np.array(ydata)\n",
    "#print (ydata)\n",
    "print ('ydata:', yarray)\n",
    "%store xarray\n",
    "%store yarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8111e4-f319-4919-9f44-d792f6cfe771",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "071d8d0c-5c38-458c-b1f3-169d69ee0c26",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.          0.4375      0.66666667]\n",
      " [-1.          0.8125      0.66666667]\n",
      " [-1.          1.1875      0.66666667]\n",
      " [-1.          1.5625      0.66666667]\n",
      " [ 1.          0.4375      0.66666667]\n",
      " [ 1.          0.8125      0.66666667]\n",
      " [ 1.          1.1875      0.66666667]\n",
      " [ 1.          1.5625      0.66666667]\n",
      " [ 3.          0.4375      0.66666667]\n",
      " [ 3.          0.8125      0.66666667]\n",
      " [ 3.          1.1875      0.66666667]\n",
      " [ 3.          1.5625      0.66666667]\n",
      " [-1.          0.4375      1.        ]\n",
      " [-1.          0.8125      1.        ]\n",
      " [-1.          1.1875      1.        ]\n",
      " [-1.          1.5625      1.        ]\n",
      " [ 1.          0.4375      1.        ]\n",
      " [ 1.          0.8125      1.        ]\n",
      " [ 1.          1.1875      1.        ]\n",
      " [ 1.          1.5625      1.        ]\n",
      " [ 3.          0.4375      1.        ]\n",
      " [ 3.          0.8125      1.        ]\n",
      " [ 3.          1.1875      1.        ]\n",
      " [ 3.          1.5625      1.        ]]\n",
      "[[-1.          0.4375      1.33333333]\n",
      " [-1.          0.8125      1.33333333]\n",
      " [-1.          1.1875      1.33333333]\n",
      " [-1.          1.5625      1.33333333]\n",
      " [ 1.          0.4375      1.33333333]\n",
      " [ 1.          0.8125      1.33333333]\n",
      " [ 1.          1.1875      1.33333333]\n",
      " [ 1.          1.5625      1.33333333]\n",
      " [ 3.          0.4375      1.33333333]\n",
      " [ 3.          0.8125      1.33333333]\n",
      " [ 3.          1.1875      1.33333333]\n",
      " [ 3.          1.5625      1.33333333]]\n",
      "[[0.71455577 0.8021978 ]\n",
      " [0.88846881 1.24475524]\n",
      " [0.93761815 1.38461538]\n",
      " [0.96786389 1.46753247]\n",
      " [0.72589792 0.83016983]\n",
      " [0.94517958 1.4035964 ]\n",
      " [1.00189036 1.57442557]\n",
      " [1.03213611 1.67332667]\n",
      " [0.73345936 0.84615385]\n",
      " [0.99810964 1.56543457]\n",
      " [1.06238185 1.77522478]\n",
      " [1.09640832 1.89210789]\n",
      " [0.84688091 0.75124875]\n",
      " [0.93761815 0.92107892]\n",
      " [0.97542533 0.996004  ]\n",
      " [0.99810964 1.04495504]\n",
      " [0.89224953 0.83616384]\n",
      " [1.00189036 1.04795205]\n",
      " [1.04347826 1.13686314]\n",
      " [1.06994329 1.19480519]\n",
      " [0.93761815 0.91908092]\n",
      " [1.06238185 1.18081918]\n",
      " [1.10775047 1.28671329]\n",
      " [1.13799622 1.35364635]]\n",
      "[[0.88846881 0.62137862]\n",
      " [0.96030246 0.72427572]\n",
      " [0.99432892 0.77522478]\n",
      " [1.01701323 0.81018981]\n",
      " [0.94517958 0.7022977 ]\n",
      " [1.02457467 0.82617383]\n",
      " [1.06238185 0.88611389]\n",
      " [1.08506616 0.92707293]\n",
      " [1.00189036 0.78521479]\n",
      " [1.08884688 0.93406593]\n",
      " [1.13043478 1.003996  ]\n",
      " [1.15689981 1.05094905]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "#dividing the input data array randomly into training and validation set\n",
    "#random.shuffle(xarray)\n",
    "train_xarray=xarray[:24]\n",
    "valid_xarray=xarray[24:]\n",
    "print(train_xarray)\n",
    "print(valid_xarray)\n",
    "\n",
    "#dividing the input data array randomly into training and validation set\n",
    "#random.shuffle(yarray)\n",
    "train_yarray=yarray[:24]\n",
    "valid_yarray=yarray[24:]\n",
    "print(train_yarray)\n",
    "print(valid_yarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d89cf30-5544-421a-8742-4220ce29819a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ea5a1ec4-e98c-4f88-8b07-0c6d6b934ce6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define neural network model\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "#As seen below, we have created four dense layers. \n",
    "#A dense layer is a layer in neural network thats fully connected. \n",
    "#In other words, all the neurons in one layer are connected to all other neurons in the next layer.\n",
    "#In the first layer, we need to provide the input shape, which is 1 in our case. \n",
    "#The activation function we have chosen is elu, which stands for exponential linear unit. .\n",
    "\n",
    "from keras import backend as K\n",
    "#initialize weights with values between -0.2 and 0.5\n",
    "initializer = keras.initializers.RandomUniform(minval= -0.2, maxval=0.5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(6, activation=K.elu, input_shape=[3],  kernel_initializer=initializer),\n",
    "    \n",
    "    keras.layers.Dense(8, activation=K.elu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(16, activation=K.elu, kernel_initializer=initializer),\n",
    "    keras.layers.Dense(8, activation=K.elu, kernel_initializer=initializer),\n",
    "\n",
    "    keras.layers.Dense(2,  kernel_initializer=initializer)\n",
    "  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6b4653dd-237b-43c4-ab74-cbc561b55902",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Were using RMSprop as our optimizer here. RMSprop stands for Root Mean Square Propagation. \n",
    "#Its one of the most popular gradient descent optimization algorithms for deep learning networks. \n",
    "#RMSprop is an optimizer thats reliable and fast.\n",
    "#Were compiling the mode using the model.compile function. The loss function used here \n",
    "#is mean squared error. After the compilation of the model, well use the fit method with ~500 epochs.\n",
    "#Number of epochs can be varied.\n",
    "\n",
    "#from tf.keras import optimizers\n",
    "rms = keras.optimizers.RMSprop(0.020)\n",
    "model.compile(loss='mean_absolute_error',optimizer=rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cab1e3-ee83-451f-85fe-2cbe29c971c4",
   "metadata": {},
   "source": [
    "#### d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a2a7601e-85c2-4f89-bfc8-40837ae21422",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "24/24 [==============================] - 0s 226us/step - loss: 0.0524\n",
      "Epoch 2/800\n",
      "24/24 [==============================] - 0s 87us/step - loss: 0.0730\n",
      "Epoch 3/800\n",
      "24/24 [==============================] - 0s 83us/step - loss: 0.0454\n",
      "Epoch 4/800\n",
      "24/24 [==============================] - 0s 70us/step - loss: 0.0509\n",
      "Epoch 5/800\n",
      "24/24 [==============================] - 0s 87us/step - loss: 0.0602\n",
      "Epoch 6/800\n",
      "24/24 [==============================] - 0s 84us/step - loss: 0.0718\n",
      "Epoch 7/800\n",
      "24/24 [==============================] - 0s 72us/step - loss: 0.0520\n",
      "Epoch 8/800\n",
      "24/24 [==============================] - 0s 68us/step - loss: 0.0513\n",
      "Epoch 9/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0306\n",
      "Epoch 10/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0463\n",
      "Epoch 11/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0642\n",
      "Epoch 12/800\n",
      "24/24 [==============================] - 0s 70us/step - loss: 0.0706\n",
      "Epoch 13/800\n",
      "24/24 [==============================] - 0s 72us/step - loss: 0.0456\n",
      "Epoch 14/800\n",
      "24/24 [==============================] - 0s 81us/step - loss: 0.0497\n",
      "Epoch 15/800\n",
      "24/24 [==============================] - 0s 77us/step - loss: 0.0476\n",
      "Epoch 16/800\n",
      "24/24 [==============================] - 0s 83us/step - loss: 0.0854\n",
      "Epoch 17/800\n",
      "24/24 [==============================] - 0s 73us/step - loss: 0.0393\n",
      "Epoch 18/800\n",
      "24/24 [==============================] - 0s 83us/step - loss: 0.0377\n",
      "Epoch 19/800\n",
      "24/24 [==============================] - 0s 73us/step - loss: 0.0305\n",
      "Epoch 20/800\n",
      "24/24 [==============================] - 0s 72us/step - loss: 0.0656\n",
      "Epoch 21/800\n",
      "24/24 [==============================] - 0s 73us/step - loss: 0.0528\n",
      "Epoch 22/800\n",
      "24/24 [==============================] - 0s 71us/step - loss: 0.0552\n",
      "Epoch 23/800\n",
      "24/24 [==============================] - 0s 72us/step - loss: 0.0501\n",
      "Epoch 24/800\n",
      "24/24 [==============================] - 0s 81us/step - loss: 0.0666\n",
      "Epoch 25/800\n",
      "24/24 [==============================] - 0s 68us/step - loss: 0.0562\n",
      "Epoch 26/800\n",
      "24/24 [==============================] - 0s 69us/step - loss: 0.0765\n",
      "Epoch 27/800\n",
      "24/24 [==============================] - 0s 69us/step - loss: 0.0479\n",
      "Epoch 28/800\n",
      "24/24 [==============================] - 0s 82us/step - loss: 0.0864\n",
      "Epoch 29/800\n",
      "24/24 [==============================] - 0s 78us/step - loss: 0.0304\n",
      "Epoch 30/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0656\n",
      "Epoch 31/800\n",
      "24/24 [==============================] - 0s 70us/step - loss: 0.0574\n",
      "Epoch 32/800\n",
      "24/24 [==============================] - 0s 78us/step - loss: 0.0783\n",
      "Epoch 33/800\n",
      "24/24 [==============================] - 0s 86us/step - loss: 0.0449\n",
      "Epoch 34/800\n",
      "24/24 [==============================] - 0s 70us/step - loss: 0.0679\n",
      "Epoch 35/800\n",
      "24/24 [==============================] - 0s 69us/step - loss: 0.0355\n",
      "Epoch 36/800\n",
      "24/24 [==============================] - 0s 76us/step - loss: 0.0440\n",
      "Epoch 37/800\n",
      "24/24 [==============================] - 0s 68us/step - loss: 0.0303\n",
      "Epoch 38/800\n",
      "24/24 [==============================] - 0s 72us/step - loss: 0.0409\n",
      "Epoch 39/800\n",
      "24/24 [==============================] - 0s 72us/step - loss: 0.0890\n",
      "Epoch 40/800\n",
      "24/24 [==============================] - 0s 67us/step - loss: 0.0339\n",
      "Epoch 41/800\n",
      "24/24 [==============================] - 0s 67us/step - loss: 0.0300\n",
      "Epoch 42/800\n",
      "24/24 [==============================] - 0s 65us/step - loss: 0.0922\n",
      "Epoch 43/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0570\n",
      "Epoch 44/800\n",
      "24/24 [==============================] - 0s 65us/step - loss: 0.0551\n",
      "Epoch 45/800\n",
      "24/24 [==============================] - 0s 77us/step - loss: 0.0783\n",
      "Epoch 46/800\n",
      "24/24 [==============================] - 0s 73us/step - loss: 0.0372\n",
      "Epoch 47/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0738\n",
      "Epoch 48/800\n",
      "24/24 [==============================] - 0s 87us/step - loss: 0.0481\n",
      "Epoch 49/800\n",
      "24/24 [==============================] - 0s 83us/step - loss: 0.0457\n",
      "Epoch 50/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0252\n",
      "Epoch 51/800\n",
      "24/24 [==============================] - 0s 70us/step - loss: 0.0333\n",
      "Epoch 52/800\n",
      "24/24 [==============================] - 0s 72us/step - loss: 0.0941\n",
      "Epoch 53/800\n",
      "24/24 [==============================] - 0s 76us/step - loss: 0.0561\n",
      "Epoch 54/800\n",
      "24/24 [==============================] - 0s 69us/step - loss: 0.0440\n",
      "Epoch 55/800\n",
      "24/24 [==============================] - 0s 77us/step - loss: 0.0951\n",
      "Epoch 56/800\n",
      "24/24 [==============================] - 0s 83us/step - loss: 0.0237\n",
      "Epoch 57/800\n",
      "24/24 [==============================] - 0s 86us/step - loss: 0.0258\n",
      "Epoch 58/800\n",
      "24/24 [==============================] - 0s 76us/step - loss: 0.0517\n",
      "Epoch 59/800\n",
      "24/24 [==============================] - 0s 78us/step - loss: 0.0513\n",
      "Epoch 60/800\n",
      "24/24 [==============================] - 0s 72us/step - loss: 0.0701\n",
      "Epoch 61/800\n",
      "24/24 [==============================] - 0s 67us/step - loss: 0.0615\n",
      "Epoch 62/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0492\n",
      "Epoch 63/800\n",
      "24/24 [==============================] - 0s 66us/step - loss: 0.0476\n",
      "Epoch 64/800\n",
      "24/24 [==============================] - 0s 78us/step - loss: 0.0800\n",
      "Epoch 65/800\n",
      "24/24 [==============================] - 0s 84us/step - loss: 0.0342\n",
      "Epoch 66/800\n",
      "24/24 [==============================] - 0s 82us/step - loss: 0.0542\n",
      "Epoch 67/800\n",
      "24/24 [==============================] - 0s 86us/step - loss: 0.0544\n",
      "Epoch 68/800\n",
      "24/24 [==============================] - 0s 70us/step - loss: 0.0763\n",
      "Epoch 69/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0411\n",
      "Epoch 70/800\n",
      "24/24 [==============================] - 0s 89us/step - loss: 0.0780\n",
      "Epoch 71/800\n",
      "24/24 [==============================] - 0s 90us/step - loss: 0.0507\n",
      "Epoch 72/800\n",
      "24/24 [==============================] - 0s 67us/step - loss: 0.0438\n",
      "Epoch 73/800\n",
      "24/24 [==============================] - 0s 71us/step - loss: 0.0704\n",
      "Epoch 74/800\n",
      "24/24 [==============================] - 0s 78us/step - loss: 0.0439\n",
      "Epoch 75/800\n",
      "24/24 [==============================] - 0s 68us/step - loss: 0.0323\n",
      "Epoch 76/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0457\n",
      "Epoch 77/800\n",
      "24/24 [==============================] - 0s 73us/step - loss: 0.0620\n",
      "Epoch 78/800\n",
      "24/24 [==============================] - 0s 82us/step - loss: 0.0654\n",
      "Epoch 79/800\n",
      "24/24 [==============================] - 0s 81us/step - loss: 0.0498\n",
      "Epoch 80/800\n",
      "24/24 [==============================] - 0s 82us/step - loss: 0.0609\n",
      "Epoch 81/800\n",
      "24/24 [==============================] - 0s 88us/step - loss: 0.0601\n",
      "Epoch 82/800\n",
      "24/24 [==============================] - 0s 87us/step - loss: 0.0619\n",
      "Epoch 83/800\n",
      "24/24 [==============================] - 0s 70us/step - loss: 0.0389\n",
      "Epoch 84/800\n",
      "24/24 [==============================] - 0s 76us/step - loss: 0.0549\n",
      "Epoch 85/800\n",
      "24/24 [==============================] - 0s 72us/step - loss: 0.0445\n",
      "Epoch 86/800\n",
      "24/24 [==============================] - 0s 67us/step - loss: 0.0881\n",
      "Epoch 87/800\n",
      "24/24 [==============================] - 0s 87us/step - loss: 0.0261\n",
      "Epoch 88/800\n",
      "24/24 [==============================] - 0s 86us/step - loss: 0.0398\n",
      "Epoch 89/800\n",
      "24/24 [==============================] - 0s 97us/step - loss: 0.0403\n",
      "Epoch 90/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0603\n",
      "Epoch 91/800\n",
      "24/24 [==============================] - 0s 76us/step - loss: 0.0642\n",
      "Epoch 92/800\n",
      "24/24 [==============================] - 0s 76us/step - loss: 0.0819\n",
      "Epoch 93/800\n",
      "24/24 [==============================] - 0s 103us/step - loss: 0.0326\n",
      "Epoch 94/800\n",
      "24/24 [==============================] - 0s 70us/step - loss: 0.0434\n",
      "Epoch 95/800\n",
      "24/24 [==============================] - 0s 87us/step - loss: 0.0751\n",
      "Epoch 96/800\n",
      "24/24 [==============================] - 0s 79us/step - loss: 0.0379\n",
      "Epoch 97/800\n",
      "24/24 [==============================] - 0s 81us/step - loss: 0.0211\n",
      "Epoch 98/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0413\n",
      "Epoch 99/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0632\n",
      "Epoch 100/800\n",
      "24/24 [==============================] - 0s 90us/step - loss: 0.0481\n",
      "Epoch 101/800\n",
      "24/24 [==============================] - 0s 94us/step - loss: 0.0797\n",
      "Epoch 102/800\n",
      "24/24 [==============================] - 0s 82us/step - loss: 0.0283\n",
      "Epoch 103/800\n",
      "24/24 [==============================] - 0s 94us/step - loss: 0.0413\n",
      "Epoch 104/800\n",
      "24/24 [==============================] - 0s 72us/step - loss: 0.0306\n",
      "Epoch 105/800\n",
      "24/24 [==============================] - 0s 86us/step - loss: 0.0583\n",
      "Epoch 106/800\n",
      "24/24 [==============================] - 0s 83us/step - loss: 0.0513\n",
      "Epoch 107/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0433\n",
      "Epoch 108/800\n",
      "24/24 [==============================] - 0s 66us/step - loss: 0.0382\n",
      "Epoch 109/800\n",
      "24/24 [==============================] - 0s 63us/step - loss: 0.0317\n",
      "Epoch 110/800\n",
      "24/24 [==============================] - 0s 82us/step - loss: 0.0422\n",
      "Epoch 111/800\n",
      "24/24 [==============================] - 0s 72us/step - loss: 0.0503\n",
      "Epoch 112/800\n",
      "24/24 [==============================] - 0s 85us/step - loss: 0.0425\n",
      "Epoch 113/800\n",
      "24/24 [==============================] - 0s 80us/step - loss: 0.0468\n",
      "Epoch 114/800\n",
      "24/24 [==============================] - 0s 77us/step - loss: 0.0445\n",
      "Epoch 115/800\n",
      "24/24 [==============================] - 0s 100us/step - loss: 0.0316\n",
      "Epoch 116/800\n",
      "24/24 [==============================] - 0s 88us/step - loss: 0.0355\n",
      "Epoch 117/800\n",
      "24/24 [==============================] - 0s 78us/step - loss: 0.0781\n",
      "Epoch 118/800\n",
      "24/24 [==============================] - 0s 68us/step - loss: 0.0471\n",
      "Epoch 119/800\n",
      "24/24 [==============================] - 0s 72us/step - loss: 0.0557\n",
      "Epoch 120/800\n",
      "24/24 [==============================] - 0s 76us/step - loss: 0.0770\n",
      "Epoch 121/800\n",
      "24/24 [==============================] - 0s 79us/step - loss: 0.0661\n",
      "Epoch 122/800\n",
      "24/24 [==============================] - 0s 76us/step - loss: 0.0785\n",
      "Epoch 123/800\n",
      "24/24 [==============================] - 0s 79us/step - loss: 0.0494\n",
      "Epoch 124/800\n",
      "24/24 [==============================] - 0s 80us/step - loss: 0.0598\n",
      "Epoch 125/800\n",
      "24/24 [==============================] - 0s 96us/step - loss: 0.0778\n",
      "Epoch 126/800\n",
      "24/24 [==============================] - 0s 96us/step - loss: 0.0563\n",
      "Epoch 127/800\n",
      "24/24 [==============================] - 0s 65us/step - loss: 0.0404\n",
      "Epoch 128/800\n",
      "24/24 [==============================] - 0s 77us/step - loss: 0.0673\n",
      "Epoch 129/800\n",
      "24/24 [==============================] - 0s 79us/step - loss: 0.0554\n",
      "Epoch 130/800\n",
      "24/24 [==============================] - 0s 81us/step - loss: 0.0562\n",
      "Epoch 131/800\n",
      "24/24 [==============================] - 0s 72us/step - loss: 0.0375\n",
      "Epoch 132/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0598\n",
      "Epoch 133/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0634\n",
      "Epoch 134/800\n",
      "24/24 [==============================] - 0s 73us/step - loss: 0.0535\n",
      "Epoch 135/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0346\n",
      "Epoch 136/800\n",
      "24/24 [==============================] - 0s 82us/step - loss: 0.0464\n",
      "Epoch 137/800\n",
      "24/24 [==============================] - 0s 77us/step - loss: 0.0490\n",
      "Epoch 138/800\n",
      "24/24 [==============================] - 0s 69us/step - loss: 0.0586\n",
      "Epoch 139/800\n",
      "24/24 [==============================] - 0s 70us/step - loss: 0.0429\n",
      "Epoch 140/800\n",
      "24/24 [==============================] - 0s 67us/step - loss: 0.0623\n",
      "Epoch 141/800\n",
      "24/24 [==============================] - 0s 65us/step - loss: 0.0449\n",
      "Epoch 142/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0670\n",
      "Epoch 143/800\n",
      "24/24 [==============================] - 0s 83us/step - loss: 0.0306\n",
      "Epoch 144/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0414\n",
      "Epoch 145/800\n",
      "24/24 [==============================] - 0s 79us/step - loss: 0.0420\n",
      "Epoch 146/800\n",
      "24/24 [==============================] - 0s 84us/step - loss: 0.0453\n",
      "Epoch 147/800\n",
      "24/24 [==============================] - 0s 72us/step - loss: 0.0498\n",
      "Epoch 148/800\n",
      "24/24 [==============================] - 0s 117us/step - loss: 0.0605\n",
      "Epoch 149/800\n",
      "24/24 [==============================] - 0s 99us/step - loss: 0.0489\n",
      "Epoch 150/800\n",
      "24/24 [==============================] - 0s 86us/step - loss: 0.0441\n",
      "Epoch 151/800\n",
      "24/24 [==============================] - 0s 68us/step - loss: 0.0323\n",
      "Epoch 152/800\n",
      "24/24 [==============================] - 0s 77us/step - loss: 0.0451\n",
      "Epoch 153/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0809\n",
      "Epoch 154/800\n",
      "24/24 [==============================] - 0s 80us/step - loss: 0.0741\n",
      "Epoch 155/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0341\n",
      "Epoch 156/800\n",
      "24/24 [==============================] - 0s 76us/step - loss: 0.0797\n",
      "Epoch 157/800\n",
      "24/24 [==============================] - 0s 65us/step - loss: 0.0319\n",
      "Epoch 158/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0636\n",
      "Epoch 159/800\n",
      "24/24 [==============================] - 0s 96us/step - loss: 0.0337\n",
      "Epoch 160/800\n",
      "24/24 [==============================] - 0s 71us/step - loss: 0.0374\n",
      "Epoch 161/800\n",
      "24/24 [==============================] - 0s 83us/step - loss: 0.0258\n",
      "Epoch 162/800\n",
      "24/24 [==============================] - 0s 72us/step - loss: 0.0446\n",
      "Epoch 163/800\n",
      "24/24 [==============================] - 0s 109us/step - loss: 0.0683\n",
      "Epoch 164/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0702\n",
      "Epoch 165/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0389\n",
      "Epoch 166/800\n",
      "24/24 [==============================] - 0s 67us/step - loss: 0.0689\n",
      "Epoch 167/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0345\n",
      "Epoch 168/800\n",
      "24/24 [==============================] - 0s 76us/step - loss: 0.0349\n",
      "Epoch 169/800\n",
      "24/24 [==============================] - 0s 106us/step - loss: 0.0248\n",
      "Epoch 170/800\n",
      "24/24 [==============================] - 0s 82us/step - loss: 0.0344\n",
      "Epoch 171/800\n",
      "24/24 [==============================] - 0s 80us/step - loss: 0.0631\n",
      "Epoch 172/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0637\n",
      "Epoch 173/800\n",
      "24/24 [==============================] - 0s 87us/step - loss: 0.0463\n",
      "Epoch 174/800\n",
      "24/24 [==============================] - 0s 80us/step - loss: 0.0526\n",
      "Epoch 175/800\n",
      "24/24 [==============================] - 0s 82us/step - loss: 0.0684\n",
      "Epoch 176/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0653\n",
      "Epoch 177/800\n",
      "24/24 [==============================] - 0s 80us/step - loss: 0.0401\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00177: early stopping\n",
      "best epoch =  97\n",
      "smallest loss = 0.021114254370331764\n"
     ]
    }
   ],
   "source": [
    "#After the compilation of the model, well use the fit method with 500 epochs.\n",
    "#I started with epochs value of 100 and then tested the model after training. \n",
    "#The prediction was not that good. Then I modified the number of epochs to 200 and tested the model again. \n",
    "#Accuracy had improved slightly, but figured Id give it one more try. Finally, at 500 epochs \n",
    "#I found acceptable prediction accuracy.\n",
    "\n",
    "#The fit method takes three parameters; namely, x, y, and number of epochs. \n",
    "#During model training, if all the batches of data are seen by the model once, \n",
    "#we say that one epoch has been completed.\n",
    "\n",
    "# Add an early stopping callback\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    mode='min', \n",
    "    patience = 80, \n",
    "    restore_best_weights = True, \n",
    "    verbose=1)\n",
    "# Add a checkpoint where loss is minimum, and save that model\n",
    "mc = keras.callbacks.ModelCheckpoint('best_model.SB', monitor='loss', \n",
    "                     mode='min',  verbose=1, save_best_only=True)\n",
    "\n",
    "historyData = model.fit(train_xarray,train_yarray,epochs=800,callbacks=[es])\n",
    "\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(historyData.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))\n",
    "\n",
    "model.save('./best_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944f6b6c-f88f-4867-b226-1e3866ca0099",
   "metadata": {},
   "source": [
    "#### e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "546509af-7e1d-42f6-ab8f-7761961c7638",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted powet output [0.7784676, 1.2365268, 1.398347, 1.4547516, 0.8198633, 1.4198692, 1.6072476, 1.6958966, 0.884406, 1.6089764, 1.7915334, 1.8898356, 0.79398686, 1.0068575, 1.0456092, 1.0801164, 0.8315349, 1.1166992, 1.199559, 1.2819674, 0.9043511, 1.2594104, 1.3719873, 1.471992]\n",
      "mean absolute error: 0.040594803656274915\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict output using the trained model for the training data\n",
    "YP=[]\n",
    "YD=[]\n",
    "for i in range(len(train_xarray)): \n",
    "    test = [[train_xarray[i][0], train_xarray[i][1], train_xarray[i][2]]]\n",
    "    testarray = np.array(test)\n",
    "    a3 = model.predict(testarray)\n",
    "    YP.append(a3[0][1])\n",
    "    YD.append(train_yarray[i][1])\n",
    "print('predicted powet output', YP)\n",
    "#mean absolute error calculation\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "error=mae(YD,YP)\n",
    "print('mean absolute error:', error)\n",
    "#comparision of predicted vs training data set\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.scatter(YP,YD)\n",
    "plt.xlabel('Predicted power output', fontsize='16')\n",
    "plt.ylabel('training power output ', fontsize='16')\n",
    "plt.loglog()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eef206f-d03c-43c9-99ff-1b7c5efe7210",
   "metadata": {},
   "source": [
    "#### f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4a2819fc-6047-4107-846e-287a2d391f61",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted powet output [0.8476288, 0.96393216, 0.9725494, 0.9779206, 0.9346877, 1.0636415, 1.0913823, 1.1249133, 1.0386974, 1.1826637, 1.2341814, 1.2956789]\n",
      "mean absolute error: 0.22341033115690237\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict output using the trained model for the validation data\n",
    "YP=[]\n",
    "YD=[]\n",
    "for i in range(len(valid_xarray)): \n",
    "    test = [[valid_xarray[i][0], valid_xarray[i][1], valid_xarray[i][2]]]\n",
    "    testarray = np.array(test)\n",
    "    a3 = model.predict(testarray)\n",
    "    YP.append(a3[0][1])\n",
    "    YD.append(valid_yarray[i][1])\n",
    "print('predicted powet output', YP)\n",
    "#mean absolute error calculation\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "error=mae(YD,YP)\n",
    "print('mean absolute error:', error)\n",
    "#comparision of predicted vs training data set\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.scatter(YP,YD)\n",
    "plt.xlabel('Predicted power output', fontsize='16')\n",
    "plt.ylabel('training power output ', fontsize='16')\n",
    "plt.loglog()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81051da-df9c-417a-96d8-bb2f3f1006cd",
   "metadata": {},
   "source": [
    "#### g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "424842c9-da81-445b-98bc-e8623205d9cc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xdata: [[-1.          0.91176471  0.66666667]\n",
      " [-1.          1.08823529  0.66666667]\n",
      " [ 1.          0.91176471  0.66666667]\n",
      " [ 1.          1.08823529  0.66666667]\n",
      " [ 3.          0.91176471  0.66666667]\n",
      " [ 3.          1.08823529  0.66666667]\n",
      " [-1.          0.91176471  1.        ]\n",
      " [-1.          1.08823529  1.        ]\n",
      " [ 1.          0.91176471  1.        ]\n",
      " [ 1.          1.08823529  1.        ]\n",
      " [ 3.          0.91176471  1.        ]\n",
      " [ 3.          1.08823529  1.        ]\n",
      " [-1.          0.91176471  1.33333333]\n",
      " [-1.          1.08823529  1.33333333]\n",
      " [ 1.          0.91176471  1.33333333]\n",
      " [ 1.          1.08823529  1.33333333]\n",
      " [ 3.          0.91176471  1.33333333]\n",
      " [ 3.          1.08823529  1.33333333]]\n",
      "ydata: [[0.9015544  1.10684535]\n",
      " [0.91537133 1.25099602]\n",
      " [0.96373057 1.38645418]\n",
      " [0.9775475  1.43426295]\n",
      " [1.0224525  1.57768924]\n",
      " [1.03972366 1.62549801]\n",
      " [0.92918826 0.86055777]\n",
      " [0.93955095 0.88446215]\n",
      " [0.99481865 0.98804781]\n",
      " [1.00518135 1.01195219]\n",
      " [1.05699482 1.11553785]\n",
      " [1.07081174 1.14741036]\n",
      " [0.94300518 0.66932271]\n",
      " [0.95336788 0.68525896]\n",
      " [1.00863558 0.76494024]\n",
      " [1.0224525  0.78087649]\n",
      " [1.07426598 0.8685259 ]\n",
      " [1.0880829  0.89243028]]\n",
      "Stored 'xarray2' (ndarray)\n",
      "Stored 'yarray2' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import keras.backend as kb\n",
    "import tensorflow as tf\n",
    "#the follwoing 2 lines are only needed for Mac OS machines\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "#create input data array\n",
    "xdata2 = []\n",
    "\n",
    "#Part 1 input HI FLUX DATA: Air temp (degC), ID (W/sqm), load resistance (ohms)\n",
    "\n",
    "xdata2 = [[-10.0, 1550, 4.464], \n",
    "  [-10.0, 1850, 4.464], \n",
    "  [10.0, 1550, 4.464], \n",
    "  [10.0, 1850, 4.464], \n",
    "  [30.0, 1550, 4.464], \n",
    "  [30.0, 1850, 4.464], \n",
    "  [-10.0, 1550, 6.696], \n",
    "  [-10.0, 1850, 6.696], \n",
    "  [10.0, 1550, 6.696], \n",
    "  [10.0, 1850, 6.696], \n",
    "  [30.0, 1550, 6.696], \n",
    "  [30.0, 1850, 6.696], \n",
    "  [-10.0, 1550, 8.928], \n",
    "  [-10.0, 1850, 8.928],   \n",
    "  [10.0, 1550, 8.928], \n",
    "  [10.0, 1850, 8.928], \n",
    "  [30.0, 1550, 8.928], \n",
    "  [30.0, 1850, 8.928]]\n",
    "\n",
    "#normalizing the xdata using the median value.\n",
    "medianx=np.median(xdata2,axis=0)\n",
    "#print(medianx)\n",
    "Tmed2=medianx[0]\n",
    "IDmed2=medianx[1]\n",
    "Rmed2=medianx[2]\n",
    "Nx = []\n",
    "for i in range(len(xdata2)):\n",
    "    Nx.append([ xdata2[i][0]/Tmed2 , xdata2[i][1]/IDmed2 , xdata2[i][2]/Rmed2 ])\n",
    "xdata2 = Nx\n",
    "\n",
    "xarray2= np.array(xdata2)\n",
    "#print (xdata)\n",
    "print ('xdata:', xarray2)\n",
    "\n",
    "#Part 1 output HI FLUX DATA: load voltage (V) and Power out (W)\n",
    "ydata2 = [[26.1, 152.8], \n",
    " [26.5, 172.7], \n",
    " [27.9, 191.4], \n",
    " [28.3, 198.0], \n",
    " [29.6, 217.8], \n",
    " [30.1, 224.4],  \n",
    " [26.9, 118.8], \n",
    " [27.2, 122.1], \n",
    " [28.8, 136.4], \n",
    " [29.1, 139.7], \n",
    " [30.6, 154.0], \n",
    " [31.0, 158.4],  \n",
    " [27.3, 92.4], \n",
    " [27.6, 94.6], \n",
    " [29.2, 105.6], \n",
    " [29.6, 107.8], \n",
    " [31.1, 119.9], \n",
    " [31.5, 123.2]]\n",
    "\n",
    "#narmalizing the ydata using the median value.\n",
    "mediany=np.median(ydata2,axis=0)\n",
    "#print(mediany)\n",
    "VLmed2=mediany[0]\n",
    "Wdmed2=mediany[1]\n",
    "Ny=[]\n",
    "for i in range(len(ydata2)):\n",
    "    Ny.append([ ydata2[i][0]/VLmed2 , ydata2[i][1]/Wdmed2 ])\n",
    "ydata2=Ny\n",
    "yarray2= np.array(ydata2)\n",
    "#print (ydata)\n",
    "print ('ydata:', yarray2)\n",
    "%store xarray2\n",
    "%store yarray2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "679c6585-39ad-450a-8642-96353dc09cca",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted powet output [1.3143693, 1.3778472, 1.5014621, 1.5779488, 1.6853403, 1.7608742, 1.024814, 1.0395684, 1.1456562, 1.1806926, 1.294602, 1.3454968, 0.9686105, 0.97161573, 1.0729055, 1.0847666, 1.1977429, 1.2209717]\n",
      "mean absolute error: 0.20634536122459257\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict output using the trained model for the training data\n",
    "YP=[]\n",
    "YD=[]\n",
    "for i in range(len(xarray2)): \n",
    "    test = [[xarray2[i][0], xarray2[i][1], xarray2[i][2]]]\n",
    "    testarray = np.array(test)\n",
    "    a3 = model.predict(testarray)\n",
    "    YP.append(a3[0][1])\n",
    "    YD.append(yarray2[i][1])\n",
    "print('predicted powet output', YP)\n",
    "#mean absolute error calculation\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "error=mae(YD,YP)\n",
    "print('mean absolute error:', error)\n",
    "#comparision of predicted vs training data set\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.scatter(YP,YD)\n",
    "plt.xlabel('Predicted power output', fontsize='16')\n",
    "plt.ylabel('training power output ', fontsize='16')\n",
    "plt.loglog()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eb0e8a-f619-44e9-9109-ec0e48faf975",
   "metadata": {},
   "source": [
    "#### h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5ad66fda-4a21-498e-a57b-e8ed0536f127",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RL = np.linspace( 4/6.696,8/6.696,30)\n",
    "ID = np.linspace(500/800,1800/800,30)\n",
    "test = []\n",
    "outpt=[]\n",
    "    \n",
    "function = np.zeros((len(RL),len(ID)))\n",
    "for i in range(len(RL)):\n",
    "    for j in range(len(ID)):\n",
    "        test = [[ 20/10, RL[i], ID[j] ]]\n",
    "        testarray = np.array(test)\n",
    "        outpt = model.predict(testarray)\n",
    "        function[j][i] = outpt[0][1]*100.1\n",
    "\n",
    "RL = np.linspace( 4,8,30)\n",
    "ID = np.linspace(500,1800,30)  \n",
    "\n",
    "        \n",
    "X,Y = np.meshgrid(ID,RL)\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "fig.set_size_inches(10,10)\n",
    "\n",
    "        \n",
    "surf = ax.plot_surface(X, Y, function, cmap=plt.cm.coolwarm, linewidth = 0, antialiased = False)\n",
    "\n",
    "ax.set_xlabel(r'RL (Ohms)', fontsize=20)\n",
    "ax.set_ylabel(r'ID (W/m^2)', fontsize = 20)\n",
    "ax.zaxis.set_rotate_label(False)\n",
    "ax.set_zlabel(r'Power (W)', fontsize = 20, rotation = 90)\n",
    "fig.colorbar(surf,shrink=0.5,aspect=10)\n",
    "\n",
    "ax.view_init(30,225)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d10d8b-7ee0-443b-a718-675e6983541b",
   "metadata": {},
   "source": [
    "### Task 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "28e73bb6-3c75-4958-a802-95e1bc61f2f5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.    800.      6.696]\n",
      "xdata: [[-1.          0.4375      0.66666667]\n",
      " [-1.          0.8125      0.66666667]\n",
      " [-1.          1.1875      0.66666667]\n",
      " [-1.          1.5625      0.66666667]\n",
      " [ 1.          0.4375      0.66666667]\n",
      " [ 1.          0.8125      0.66666667]\n",
      " [ 1.          1.1875      0.66666667]\n",
      " [ 1.          1.5625      0.66666667]\n",
      " [ 3.          0.4375      0.66666667]\n",
      " [ 3.          0.8125      0.66666667]\n",
      " [ 3.          1.1875      0.66666667]\n",
      " [ 3.          1.5625      0.66666667]\n",
      " [-1.          0.4375      1.        ]\n",
      " [-1.          0.8125      1.        ]\n",
      " [-1.          1.1875      1.        ]\n",
      " [-1.          1.5625      1.        ]\n",
      " [ 1.          0.4375      1.        ]\n",
      " [ 1.          0.8125      1.        ]\n",
      " [ 1.          1.1875      1.        ]\n",
      " [ 1.          1.5625      1.        ]\n",
      " [ 3.          0.4375      1.        ]\n",
      " [ 3.          0.8125      1.        ]\n",
      " [ 3.          1.1875      1.        ]\n",
      " [ 3.          1.5625      1.        ]\n",
      " [-1.          0.4375      1.33333333]\n",
      " [-1.          0.8125      1.33333333]\n",
      " [-1.          1.1875      1.33333333]\n",
      " [-1.          1.5625      1.33333333]\n",
      " [ 1.          0.4375      1.33333333]\n",
      " [ 1.          0.8125      1.33333333]\n",
      " [ 1.          1.1875      1.33333333]\n",
      " [ 1.          1.5625      1.33333333]\n",
      " [ 3.          0.4375      1.33333333]\n",
      " [ 3.          0.8125      1.33333333]\n",
      " [ 3.          1.1875      1.33333333]\n",
      " [ 3.          1.5625      1.33333333]]\n",
      "[ 26.45 100.1 ]\n",
      "ydata: [[0.71455577 0.8021978 ]\n",
      " [0.88846881 1.24475524]\n",
      " [0.93761815 1.38461538]\n",
      " [0.96786389 1.46753247]\n",
      " [0.72589792 0.83016983]\n",
      " [0.94517958 1.4035964 ]\n",
      " [1.00189036 1.57442557]\n",
      " [1.03213611 1.67332667]\n",
      " [0.73345936 0.84615385]\n",
      " [0.99810964 1.56543457]\n",
      " [1.06238185 1.77522478]\n",
      " [1.09640832 1.89210789]\n",
      " [0.84688091 0.75124875]\n",
      " [0.93761815 0.92107892]\n",
      " [0.97542533 0.996004  ]\n",
      " [0.99810964 1.04495504]\n",
      " [0.89224953 0.83616384]\n",
      " [1.00189036 1.04795205]\n",
      " [1.04347826 1.13686314]\n",
      " [1.06994329 1.19480519]\n",
      " [0.93761815 0.91908092]\n",
      " [1.06238185 1.18081918]\n",
      " [1.10775047 1.28671329]\n",
      " [1.13799622 1.35364635]\n",
      " [0.88846881 0.62137862]\n",
      " [0.96030246 0.72427572]\n",
      " [0.99432892 0.77522478]\n",
      " [1.01701323 0.81018981]\n",
      " [0.94517958 0.7022977 ]\n",
      " [1.02457467 0.82617383]\n",
      " [1.06238185 0.88611389]\n",
      " [1.08506616 0.92707293]\n",
      " [1.00189036 0.78521479]\n",
      " [1.08884688 0.93406593]\n",
      " [1.13043478 1.003996  ]\n",
      " [1.15689981 1.05094905]]\n",
      "Stored 'xarray' (ndarray)\n",
      "Stored 'yarray' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "'''>>>>> start CodeP3.1.2F22\n",
    "    V.P. Carey ME249, Fall 2022\n",
    "\n",
    "Intro to Neural Network Modeling \n",
    "Keras model for PV power system'''\n",
    "\n",
    "#import useful packages\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import keras.backend as kb\n",
    "import tensorflow as tf\n",
    "#the follwoing 2 lines are only needed for Mac OS machines\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# define meadian values of input variables - add your values here\n",
    "#Tamed = 10  #make sure Tamed does not = 0\n",
    "#IDmed = 800\n",
    "#RLmed = 6\n",
    "\n",
    "#create input data array\n",
    "xdata = []\n",
    "\n",
    "#Part 1 input data: Air temp (degC), ID (W/sqm), load resistance (ohms)\n",
    "xdata = [[-10.0, 350, 4.464], \n",
    "  [-10.0, 650, 4.464], \n",
    "  [-10.0, 950, 4.464], \n",
    "  [-10.0, 1250, 4.464], \n",
    "  [10.0, 350, 4.464], \n",
    "  [10.0, 650, 4.464], \n",
    "  [10.0, 950, 4.464], \n",
    "  [10.0, 1250, 4.464], \n",
    "  [30.0, 350, 4.464], \n",
    "  [30.0, 650, 4.464], \n",
    "  [30.0, 950, 4.464], \n",
    "  [30.0, 1250, 4.464], \n",
    "  [-10.0, 350, 6.696], \n",
    "  [-10.0, 650, 6.696], \n",
    "  [-10.0, 950, 6.696], \n",
    "  [-10.0, 1250, 6.696], \n",
    "  [10.0, 350, 6.696], \n",
    "  [10.0, 650, 6.696], \n",
    "  [10.0, 950, 6.696], \n",
    "  [10.0, 1250, 6.696], \n",
    "  [30.0, 350, 6.696], \n",
    "  [30.0, 650, 6.696], \n",
    "  [30.0, 950, 6.696], \n",
    "  [30.0, 1250, 6.696], \n",
    "  [-10.0, 350, 8.928], \n",
    "  [-10.0, 650, 8.928], \n",
    "  [-10.0, 950, 8.928], \n",
    "  [-10.0, 1250, 8.928], \n",
    "  [10.0, 350, 8.928], \n",
    "  [10.0, 650, 8.928], \n",
    "  [10.0, 950, 8.928], \n",
    "  [10.0, 1250, 8.928], \n",
    "  [30.0, 350, 8.928], \n",
    "  [30.0, 650, 8.928], \n",
    "  [30.0, 950, 8.928], \n",
    "  [30.0, 1250, 8.928]] \n",
    "\n",
    "#normalizing the xdata using the median value.\n",
    "medianx=np.median(xdata,axis=0)\n",
    "print(medianx)\n",
    "Tmed=medianx[0]\n",
    "IDmed=medianx[1]\n",
    "Rmed=medianx[2]\n",
    "Nx = []\n",
    "for i in range(len(xdata)):\n",
    "    Nx.append([ xdata[i][0]/Tmed , xdata[i][1]/IDmed , xdata[i][2]/Rmed ])\n",
    "xdata = Nx\n",
    "\n",
    "xarray= np.array(xdata)\n",
    "#print (xdata)\n",
    "print ('xdata:', xarray)\n",
    "\n",
    "# define meadian values of output variables - add your values here\n",
    "#VLmed = 25\n",
    "#Wdmed = 100\n",
    "\n",
    "#Part 1 output data: VL (V) and Power out Wd (W)\n",
    "ydata = [[18.9, 80.3], \n",
    " [23.5, 124.6], \n",
    " [24.8, 138.6], \n",
    " [25.6, 146.9], \n",
    " [19.2, 83.1], \n",
    " [25.0, 140.5], \n",
    " [26.5, 157.6], \n",
    " [27.3, 167.5],  \n",
    " [19.4, 84.7], \n",
    " [26.4, 156.7], \n",
    " [28.1, 177.7], \n",
    " [29.0, 189.4],\n",
    " [22.4, 75.2], \n",
    " [24.8, 92.2], \n",
    " [25.8, 99.7], \n",
    " [26.4, 104.6], \n",
    " [23.6, 83.7], \n",
    " [26.5, 104.9], \n",
    " [27.6, 113.8], \n",
    " [28.3, 119.6], \n",
    " [24.8, 92.0], \n",
    " [28.1, 118.2], \n",
    " [29.3, 128.8], \n",
    " [30.1, 135.5],  \n",
    " [23.5, 62.2], \n",
    " [25.4, 72.5], \n",
    " [26.3, 77.6], \n",
    " [26.9, 81.1],  \n",
    " [25.0, 70.3], \n",
    " [27.1, 82.7], \n",
    " [28.1, 88.7], \n",
    " [28.7, 92.8],  \n",
    " [26.5, 78.6], \n",
    " [28.8, 93.5], \n",
    " [29.9, 100.5], \n",
    " [30.6, 105.2]] \n",
    "\n",
    "#narmalizing the ydata using the median value.\n",
    "mediany=np.median(ydata,axis=0)\n",
    "print(mediany)\n",
    "VLmed=mediany[0]\n",
    "Wdmed=mediany[1]\n",
    "Ny=[]\n",
    "for i in range(len(ydata)):\n",
    "    Ny.append([ ydata[i][0]/VLmed , ydata[i][1]/Wdmed ])\n",
    "ydata=Ny\n",
    "yarray= np.array(ydata)\n",
    "#print (ydata)\n",
    "print ('ydata:', yarray)\n",
    "%store xarray\n",
    "%store yarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8d206adb-2f00-478c-b6e9-c29b5374313e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.          0.4375      0.66666667]\n",
      " [-1.          0.8125      0.66666667]\n",
      " [-1.          1.1875      0.66666667]\n",
      " [-1.          1.5625      0.66666667]\n",
      " [ 1.          0.4375      0.66666667]\n",
      " [ 1.          0.8125      0.66666667]\n",
      " [ 1.          1.1875      0.66666667]\n",
      " [ 1.          1.5625      0.66666667]\n",
      " [ 3.          0.4375      0.66666667]\n",
      " [ 3.          0.8125      0.66666667]\n",
      " [ 3.          1.1875      0.66666667]\n",
      " [ 3.          1.5625      0.66666667]\n",
      " [-1.          0.4375      1.        ]\n",
      " [-1.          0.8125      1.        ]\n",
      " [-1.          1.1875      1.        ]\n",
      " [-1.          1.5625      1.        ]\n",
      " [ 1.          0.4375      1.        ]\n",
      " [ 1.          0.8125      1.        ]\n",
      " [ 1.          1.1875      1.        ]\n",
      " [ 1.          1.5625      1.        ]\n",
      " [ 3.          0.4375      1.        ]\n",
      " [ 3.          0.8125      1.        ]\n",
      " [ 3.          1.1875      1.        ]\n",
      " [ 3.          1.5625      1.        ]]\n",
      "[[-1.          0.4375      1.33333333]\n",
      " [-1.          0.8125      1.33333333]\n",
      " [-1.          1.1875      1.33333333]\n",
      " [-1.          1.5625      1.33333333]\n",
      " [ 1.          0.4375      1.33333333]\n",
      " [ 1.          0.8125      1.33333333]\n",
      " [ 1.          1.1875      1.33333333]\n",
      " [ 1.          1.5625      1.33333333]\n",
      " [ 3.          0.4375      1.33333333]\n",
      " [ 3.          0.8125      1.33333333]\n",
      " [ 3.          1.1875      1.33333333]\n",
      " [ 3.          1.5625      1.33333333]]\n",
      "[[0.71455577 0.8021978 ]\n",
      " [0.88846881 1.24475524]\n",
      " [0.93761815 1.38461538]\n",
      " [0.96786389 1.46753247]\n",
      " [0.72589792 0.83016983]\n",
      " [0.94517958 1.4035964 ]\n",
      " [1.00189036 1.57442557]\n",
      " [1.03213611 1.67332667]\n",
      " [0.73345936 0.84615385]\n",
      " [0.99810964 1.56543457]\n",
      " [1.06238185 1.77522478]\n",
      " [1.09640832 1.89210789]\n",
      " [0.84688091 0.75124875]\n",
      " [0.93761815 0.92107892]\n",
      " [0.97542533 0.996004  ]\n",
      " [0.99810964 1.04495504]\n",
      " [0.89224953 0.83616384]\n",
      " [1.00189036 1.04795205]\n",
      " [1.04347826 1.13686314]\n",
      " [1.06994329 1.19480519]\n",
      " [0.93761815 0.91908092]\n",
      " [1.06238185 1.18081918]\n",
      " [1.10775047 1.28671329]\n",
      " [1.13799622 1.35364635]]\n",
      "[[0.88846881 0.62137862]\n",
      " [0.96030246 0.72427572]\n",
      " [0.99432892 0.77522478]\n",
      " [1.01701323 0.81018981]\n",
      " [0.94517958 0.7022977 ]\n",
      " [1.02457467 0.82617383]\n",
      " [1.06238185 0.88611389]\n",
      " [1.08506616 0.92707293]\n",
      " [1.00189036 0.78521479]\n",
      " [1.08884688 0.93406593]\n",
      " [1.13043478 1.003996  ]\n",
      " [1.15689981 1.05094905]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "#dividing the input data array randomly into training and validation set\n",
    "#random.shuffle(xarray)\n",
    "train_xarray=xarray[:24]\n",
    "valid_xarray=xarray[24:]\n",
    "print(train_xarray)\n",
    "print(valid_xarray)\n",
    "\n",
    "#dividing the input data array randomly into training and validation set\n",
    "#random.shuffle(yarray)\n",
    "train_yarray=yarray[:24]\n",
    "valid_yarray=yarray[24:]\n",
    "print(train_yarray)\n",
    "print(valid_yarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "88473e79-23c9-478c-9d9a-fd11dd871d97",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# define neural network model\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "#As seen below, we have created four dense layers. \n",
    "#A dense layer is a layer in neural network thats fully connected. \n",
    "#In other words, all the neurons in one layer are connected to all other neurons in the next layer.\n",
    "#In the first layer, we need to provide the input shape, which is 1 in our case. \n",
    "#The activation function we have chosen is elu, which stands for exponential linear unit. .\n",
    "\n",
    "from keras import backend as K\n",
    "#initialize weights with values between -0.2 and 0.5\n",
    "initializer = keras.initializers.RandomUniform(minval= -0.2, maxval=0.5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(6, activation=K.elu, input_shape=[3],  kernel_initializer=initializer),\n",
    "    \n",
    "    keras.layers.Dense(8, activation=K.elu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(12, activation=K.elu, kernel_initializer=initializer),\n",
    "    keras.layers.Dense(16, activation=K.elu, kernel_initializer=initializer),\n",
    "    keras.layers.Dense(8, activation=K.elu, kernel_initializer=initializer),\n",
    "\n",
    "    keras.layers.Dense(2,  kernel_initializer=initializer)\n",
    "  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3cefca43-92e0-495c-8ce1-84e4f3caacfa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Were using RMSprop as our optimizer here. RMSprop stands for Root Mean Square Propagation. \n",
    "#Its one of the most popular gradient descent optimization algorithms for deep learning networks. \n",
    "#RMSprop is an optimizer thats reliable and fast.\n",
    "#Were compiling the mode using the model.compile function. The loss function used here \n",
    "#is mean squared error. After the compilation of the model, well use the fit method with ~500 epochs.\n",
    "#Number of epochs can be varied.\n",
    "\n",
    "#from tf.keras import optimizers\n",
    "rms = keras.optimizers.RMSprop(0.020)\n",
    "model.compile(loss='mean_absolute_error',optimizer=rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "09bdd7a6-3778-4985-8403-aa67060770ff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "24/24 [==============================] - 0s 253us/step - loss: 0.0716\n",
      "Epoch 2/800\n",
      "24/24 [==============================] - 0s 79us/step - loss: 0.0464\n",
      "Epoch 3/800\n",
      "24/24 [==============================] - 0s 90us/step - loss: 0.0844\n",
      "Epoch 4/800\n",
      "24/24 [==============================] - 0s 76us/step - loss: 0.0469\n",
      "Epoch 5/800\n",
      "24/24 [==============================] - 0s 78us/step - loss: 0.0462\n",
      "Epoch 6/800\n",
      "24/24 [==============================] - 0s 73us/step - loss: 0.0630\n",
      "Epoch 7/800\n",
      "24/24 [==============================] - 0s 79us/step - loss: 0.1038\n",
      "Epoch 8/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0338\n",
      "Epoch 9/800\n",
      "24/24 [==============================] - 0s 73us/step - loss: 0.0416\n",
      "Epoch 10/800\n",
      "24/24 [==============================] - 0s 76us/step - loss: 0.0495\n",
      "Epoch 11/800\n",
      "24/24 [==============================] - 0s 68us/step - loss: 0.0525\n",
      "Epoch 12/800\n",
      "24/24 [==============================] - 0s 68us/step - loss: 0.0407\n",
      "Epoch 13/800\n",
      "24/24 [==============================] - 0s 77us/step - loss: 0.0635\n",
      "Epoch 14/800\n",
      "24/24 [==============================] - 0s 76us/step - loss: 0.0676\n",
      "Epoch 15/800\n",
      "24/24 [==============================] - 0s 80us/step - loss: 0.0915\n",
      "Epoch 16/800\n",
      "24/24 [==============================] - 0s 78us/step - loss: 0.0381\n",
      "Epoch 17/800\n",
      "24/24 [==============================] - 0s 77us/step - loss: 0.0546\n",
      "Epoch 18/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0429\n",
      "Epoch 19/800\n",
      "24/24 [==============================] - 0s 73us/step - loss: 0.0315\n",
      "Epoch 20/800\n",
      "24/24 [==============================] - 0s 76us/step - loss: 0.0581\n",
      "Epoch 21/800\n",
      "24/24 [==============================] - 0s 77us/step - loss: 0.0357\n",
      "Epoch 22/800\n",
      "24/24 [==============================] - 0s 76us/step - loss: 0.0391\n",
      "Epoch 23/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0320\n",
      "Epoch 24/800\n",
      "24/24 [==============================] - 0s 80us/step - loss: 0.0282\n",
      "Epoch 25/800\n",
      "24/24 [==============================] - 0s 68us/step - loss: 0.0600\n",
      "Epoch 26/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0461\n",
      "Epoch 27/800\n",
      "24/24 [==============================] - 0s 70us/step - loss: 0.0609\n",
      "Epoch 28/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0390\n",
      "Epoch 29/800\n",
      "24/24 [==============================] - 0s 69us/step - loss: 0.0519\n",
      "Epoch 30/800\n",
      "24/24 [==============================] - 0s 70us/step - loss: 0.0941\n",
      "Epoch 31/800\n",
      "24/24 [==============================] - 0s 72us/step - loss: 0.0570\n",
      "Epoch 32/800\n",
      "24/24 [==============================] - 0s 72us/step - loss: 0.0580\n",
      "Epoch 33/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0800\n",
      "Epoch 34/800\n",
      "24/24 [==============================] - 0s 71us/step - loss: 0.0531\n",
      "Epoch 35/800\n",
      "24/24 [==============================] - 0s 72us/step - loss: 0.0436\n",
      "Epoch 36/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0570\n",
      "Epoch 37/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0674\n",
      "Epoch 38/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0546\n",
      "Epoch 39/800\n",
      "24/24 [==============================] - 0s 70us/step - loss: 0.0276\n",
      "Epoch 40/800\n",
      "24/24 [==============================] - 0s 73us/step - loss: 0.0396\n",
      "Epoch 41/800\n",
      "24/24 [==============================] - 0s 67us/step - loss: 0.0432\n",
      "Epoch 42/800\n",
      "24/24 [==============================] - 0s 79us/step - loss: 0.0426\n",
      "Epoch 43/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0607\n",
      "Epoch 44/800\n",
      "24/24 [==============================] - 0s 69us/step - loss: 0.0702\n",
      "Epoch 45/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0534\n",
      "Epoch 46/800\n",
      "24/24 [==============================] - 0s 72us/step - loss: 0.0595\n",
      "Epoch 47/800\n",
      "24/24 [==============================] - 0s 77us/step - loss: 0.0493\n",
      "Epoch 48/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0712\n",
      "Epoch 49/800\n",
      "24/24 [==============================] - 0s 77us/step - loss: 0.0535\n",
      "Epoch 50/800\n",
      "24/24 [==============================] - 0s 71us/step - loss: 0.0363\n",
      "Epoch 51/800\n",
      "24/24 [==============================] - 0s 80us/step - loss: 0.0329\n",
      "Epoch 52/800\n",
      "24/24 [==============================] - 0s 71us/step - loss: 0.0307\n",
      "Epoch 53/800\n",
      "24/24 [==============================] - 0s 70us/step - loss: 0.0527\n",
      "Epoch 54/800\n",
      "24/24 [==============================] - 0s 72us/step - loss: 0.0552\n",
      "Epoch 55/800\n",
      "24/24 [==============================] - 0s 65us/step - loss: 0.0395\n",
      "Epoch 56/800\n",
      "24/24 [==============================] - 0s 71us/step - loss: 0.0263\n",
      "Epoch 57/800\n",
      "24/24 [==============================] - 0s 66us/step - loss: 0.0591\n",
      "Epoch 58/800\n",
      "24/24 [==============================] - 0s 66us/step - loss: 0.0442\n",
      "Epoch 59/800\n",
      "24/24 [==============================] - 0s 72us/step - loss: 0.0748\n",
      "Epoch 60/800\n",
      "24/24 [==============================] - 0s 77us/step - loss: 0.0528\n",
      "Epoch 61/800\n",
      "24/24 [==============================] - 0s 79us/step - loss: 0.0778\n",
      "Epoch 62/800\n",
      "24/24 [==============================] - 0s 86us/step - loss: 0.0716\n",
      "Epoch 63/800\n",
      "24/24 [==============================] - 0s 84us/step - loss: 0.0503\n",
      "Epoch 64/800\n",
      "24/24 [==============================] - 0s 77us/step - loss: 0.0406\n",
      "Epoch 65/800\n",
      "24/24 [==============================] - 0s 73us/step - loss: 0.0310\n",
      "Epoch 66/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0358\n",
      "Epoch 67/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0202\n",
      "Epoch 68/800\n",
      "24/24 [==============================] - 0s 83us/step - loss: 0.0428\n",
      "Epoch 69/800\n",
      "24/24 [==============================] - 0s 83us/step - loss: 0.0489\n",
      "Epoch 70/800\n",
      "24/24 [==============================] - 0s 85us/step - loss: 0.0440\n",
      "Epoch 71/800\n",
      "24/24 [==============================] - 0s 77us/step - loss: 0.0395\n",
      "Epoch 72/800\n",
      "24/24 [==============================] - 0s 79us/step - loss: 0.0628\n",
      "Epoch 73/800\n",
      "24/24 [==============================] - 0s 85us/step - loss: 0.0467\n",
      "Epoch 74/800\n",
      "24/24 [==============================] - 0s 79us/step - loss: 0.0463\n",
      "Epoch 75/800\n",
      "24/24 [==============================] - 0s 72us/step - loss: 0.0903\n",
      "Epoch 76/800\n",
      "24/24 [==============================] - 0s 79us/step - loss: 0.0734\n",
      "Epoch 77/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0340\n",
      "Epoch 78/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0331\n",
      "Epoch 79/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0473\n",
      "Epoch 80/800\n",
      "24/24 [==============================] - 0s 68us/step - loss: 0.0452\n",
      "Epoch 81/800\n",
      "24/24 [==============================] - 0s 69us/step - loss: 0.0676\n",
      "Epoch 82/800\n",
      "24/24 [==============================] - 0s 76us/step - loss: 0.0635\n",
      "Epoch 83/800\n",
      "24/24 [==============================] - 0s 66us/step - loss: 0.0600\n",
      "Epoch 84/800\n",
      "24/24 [==============================] - 0s 71us/step - loss: 0.0507\n",
      "Epoch 85/800\n",
      "24/24 [==============================] - 0s 77us/step - loss: 0.0434\n",
      "Epoch 86/800\n",
      "24/24 [==============================] - 0s 78us/step - loss: 0.0889\n",
      "Epoch 87/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0466\n",
      "Epoch 88/800\n",
      "24/24 [==============================] - 0s 71us/step - loss: 0.0641\n",
      "Epoch 89/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0555\n",
      "Epoch 90/800\n",
      "24/24 [==============================] - 0s 99us/step - loss: 0.0893\n",
      "Epoch 91/800\n",
      "24/24 [==============================] - 0s 90us/step - loss: 0.0306\n",
      "Epoch 92/800\n",
      "24/24 [==============================] - 0s 78us/step - loss: 0.0461\n",
      "Epoch 93/800\n",
      "24/24 [==============================] - 0s 70us/step - loss: 0.0913\n",
      "Epoch 94/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0568\n",
      "Epoch 95/800\n",
      "24/24 [==============================] - 0s 73us/step - loss: 0.0426\n",
      "Epoch 96/800\n",
      "24/24 [==============================] - 0s 79us/step - loss: 0.0506\n",
      "Epoch 97/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0465\n",
      "Epoch 98/800\n",
      "24/24 [==============================] - 0s 83us/step - loss: 0.0508\n",
      "Epoch 99/800\n",
      "24/24 [==============================] - 0s 81us/step - loss: 0.0355\n",
      "Epoch 100/800\n",
      "24/24 [==============================] - 0s 80us/step - loss: 0.0417\n",
      "Epoch 101/800\n",
      "24/24 [==============================] - 0s 82us/step - loss: 0.0454\n",
      "Epoch 102/800\n",
      "24/24 [==============================] - 0s 99us/step - loss: 0.0740\n",
      "Epoch 103/800\n",
      "24/24 [==============================] - 0s 81us/step - loss: 0.0467\n",
      "Epoch 104/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0414\n",
      "Epoch 105/800\n",
      "24/24 [==============================] - 0s 70us/step - loss: 0.0474\n",
      "Epoch 106/800\n",
      "24/24 [==============================] - 0s 94us/step - loss: 0.0523\n",
      "Epoch 107/800\n",
      "24/24 [==============================] - 0s 82us/step - loss: 0.0435\n",
      "Epoch 108/800\n",
      "24/24 [==============================] - 0s 87us/step - loss: 0.0422\n",
      "Epoch 109/800\n",
      "24/24 [==============================] - 0s 80us/step - loss: 0.0446\n",
      "Epoch 110/800\n",
      "24/24 [==============================] - 0s 71us/step - loss: 0.0349\n",
      "Epoch 111/800\n",
      "24/24 [==============================] - 0s 75us/step - loss: 0.0347\n",
      "Epoch 112/800\n",
      "24/24 [==============================] - 0s 66us/step - loss: 0.0526\n",
      "Epoch 113/800\n",
      "24/24 [==============================] - 0s 78us/step - loss: 0.0425\n",
      "Epoch 114/800\n",
      "24/24 [==============================] - 0s 68us/step - loss: 0.0413\n",
      "Epoch 115/800\n",
      "24/24 [==============================] - 0s 78us/step - loss: 0.0426\n",
      "Epoch 116/800\n",
      "24/24 [==============================] - 0s 71us/step - loss: 0.0350\n",
      "Epoch 117/800\n",
      "24/24 [==============================] - 0s 83us/step - loss: 0.0308\n",
      "Epoch 118/800\n",
      "24/24 [==============================] - 0s 81us/step - loss: 0.0300\n",
      "Epoch 119/800\n",
      "24/24 [==============================] - 0s 87us/step - loss: 0.0416\n",
      "Epoch 120/800\n",
      "24/24 [==============================] - 0s 89us/step - loss: 0.0358\n",
      "Epoch 121/800\n",
      "24/24 [==============================] - 0s 81us/step - loss: 0.0621\n",
      "Epoch 122/800\n",
      "24/24 [==============================] - 0s 89us/step - loss: 0.0761\n",
      "Epoch 123/800\n",
      "24/24 [==============================] - 0s 73us/step - loss: 0.0597\n",
      "Epoch 124/800\n",
      "24/24 [==============================] - 0s 80us/step - loss: 0.0507\n",
      "Epoch 125/800\n",
      "24/24 [==============================] - 0s 96us/step - loss: 0.0393\n",
      "Epoch 126/800\n",
      "24/24 [==============================] - 0s 100us/step - loss: 0.0611\n",
      "Epoch 127/800\n",
      "24/24 [==============================] - 0s 95us/step - loss: 0.1019\n",
      "Epoch 128/800\n",
      "24/24 [==============================] - 0s 92us/step - loss: 0.0498\n",
      "Epoch 129/800\n",
      "24/24 [==============================] - 0s 93us/step - loss: 0.0378\n",
      "Epoch 130/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0884\n",
      "Epoch 131/800\n",
      "24/24 [==============================] - 0s 85us/step - loss: 0.0760\n",
      "Epoch 132/800\n",
      "24/24 [==============================] - 0s 88us/step - loss: 0.0418\n",
      "Epoch 133/800\n",
      "24/24 [==============================] - 0s 93us/step - loss: 0.0368\n",
      "Epoch 134/800\n",
      "24/24 [==============================] - 0s 95us/step - loss: 0.0315\n",
      "Epoch 135/800\n",
      "24/24 [==============================] - 0s 82us/step - loss: 0.0356\n",
      "Epoch 136/800\n",
      "24/24 [==============================] - 0s 94us/step - loss: 0.0346\n",
      "Epoch 137/800\n",
      "24/24 [==============================] - 0s 72us/step - loss: 0.0481\n",
      "Epoch 138/800\n",
      "24/24 [==============================] - 0s 68us/step - loss: 0.1048\n",
      "Epoch 139/800\n",
      "24/24 [==============================] - 0s 78us/step - loss: 0.0275\n",
      "Epoch 140/800\n",
      "24/24 [==============================] - 0s 70us/step - loss: 0.0631\n",
      "Epoch 141/800\n",
      "24/24 [==============================] - 0s 67us/step - loss: 0.0461\n",
      "Epoch 142/800\n",
      "24/24 [==============================] - 0s 78us/step - loss: 0.0364\n",
      "Epoch 143/800\n",
      "24/24 [==============================] - 0s 113us/step - loss: 0.0295\n",
      "Epoch 144/800\n",
      "24/24 [==============================] - 0s 93us/step - loss: 0.0454\n",
      "Epoch 145/800\n",
      "24/24 [==============================] - 0s 74us/step - loss: 0.0464\n",
      "Epoch 146/800\n",
      "24/24 [==============================] - 0s 80us/step - loss: 0.0403\n",
      "Epoch 147/800\n",
      "24/24 [==============================] - 0s 80us/step - loss: 0.0328\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00147: early stopping\n",
      "best epoch =  67\n",
      "smallest loss = 0.020231878384947777\n"
     ]
    }
   ],
   "source": [
    "#After the compilation of the model, well use the fit method with 500 epochs.\n",
    "#I started with epochs value of 100 and then tested the model after training. \n",
    "#The prediction was not that good. Then I modified the number of epochs to 200 and tested the model again. \n",
    "#Accuracy had improved slightly, but figured Id give it one more try. Finally, at 500 epochs \n",
    "#I found acceptable prediction accuracy.\n",
    "\n",
    "#The fit method takes three parameters; namely, x, y, and number of epochs. \n",
    "#During model training, if all the batches of data are seen by the model once, \n",
    "#we say that one epoch has been completed.\n",
    "\n",
    "# Add an early stopping callback\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    mode='min', \n",
    "    patience = 80, \n",
    "    restore_best_weights = True, \n",
    "    verbose=1)\n",
    "# Add a checkpoint where loss is minimum, and save that model\n",
    "mc = keras.callbacks.ModelCheckpoint('best_model.SB', monitor='loss', \n",
    "                     mode='min',  verbose=1, save_best_only=True)\n",
    "\n",
    "historyData = model.fit(train_xarray,train_yarray,epochs=800,callbacks=[es])\n",
    "\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(historyData.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))\n",
    "\n",
    "model.save('./best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b8ecff52-9fcf-48d9-9bc0-58d6d332c4bc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted powet output [0.83106786, 1.2109996, 1.3367282, 1.3643725, 0.8474352, 1.3698243, 1.4922266, 1.5444031, 0.90859485, 1.5263379, 1.632763, 1.6712427, 0.808617, 0.9483873, 1.0094131, 1.0401475, 0.85051614, 1.046883, 1.1162732, 1.1438266, 0.95298076, 1.1523662, 1.2339354, 1.2590241]\n",
      "mean absolute error: 0.05584723763651663\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict output using the trained model for the training data\n",
    "YP=[]\n",
    "YD=[]\n",
    "for i in range(len(train_xarray)): \n",
    "    test = [[train_xarray[i][0], train_xarray[i][1], train_xarray[i][2]]]\n",
    "    testarray = np.array(test)\n",
    "    a3 = model.predict(testarray)\n",
    "    YP.append(a3[0][1])\n",
    "    YD.append(train_yarray[i][1])\n",
    "print('predicted powet output', YP)\n",
    "#mean absolute error calculation\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "error=mae(YD,YP)\n",
    "print('mean absolute error:', error)\n",
    "#comparision of predicted vs training data set\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.scatter(YP,YD)\n",
    "plt.xlabel('Predicted power output', fontsize='16')\n",
    "plt.ylabel('training power output ', fontsize='16')\n",
    "plt.loglog()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ea61d30e-49a2-4403-866a-06d938909143",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted powet output [0.8110832, 0.89801085, 0.9148797, 0.9218484, 0.85981333, 0.99665594, 1.0394201, 1.0577521, 0.9513127, 1.0676774, 1.1417682, 1.1610048]\n",
      "mean absolute error: 0.14785614405776354\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict output using the trained model for the validation data\n",
    "YP=[]\n",
    "YD=[]\n",
    "for i in range(len(valid_xarray)): \n",
    "    test = [[valid_xarray[i][0], valid_xarray[i][1], valid_xarray[i][2]]]\n",
    "    testarray = np.array(test)\n",
    "    a3 = model.predict(testarray)\n",
    "    YP.append(a3[0][1])\n",
    "    YD.append(valid_yarray[i][1])\n",
    "print('predicted powet output', YP)\n",
    "#mean absolute error calculation\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "error=mae(YD,YP)\n",
    "print('mean absolute error:', error)\n",
    "#comparision of predicted vs training data set\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.scatter(YP,YD)\n",
    "plt.xlabel('Predicted power output', fontsize='16')\n",
    "plt.ylabel('training power output ', fontsize='16')\n",
    "plt.loglog()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6715bcee-f940-4ef9-a5d3-88c6adc0f80b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xdata: [[-1.          0.91176471  0.66666667]\n",
      " [-1.          1.08823529  0.66666667]\n",
      " [ 1.          0.91176471  0.66666667]\n",
      " [ 1.          1.08823529  0.66666667]\n",
      " [ 3.          0.91176471  0.66666667]\n",
      " [ 3.          1.08823529  0.66666667]\n",
      " [-1.          0.91176471  1.        ]\n",
      " [-1.          1.08823529  1.        ]\n",
      " [ 1.          0.91176471  1.        ]\n",
      " [ 1.          1.08823529  1.        ]\n",
      " [ 3.          0.91176471  1.        ]\n",
      " [ 3.          1.08823529  1.        ]\n",
      " [-1.          0.91176471  1.33333333]\n",
      " [-1.          1.08823529  1.33333333]\n",
      " [ 1.          0.91176471  1.33333333]\n",
      " [ 1.          1.08823529  1.33333333]\n",
      " [ 3.          0.91176471  1.33333333]\n",
      " [ 3.          1.08823529  1.33333333]]\n",
      "ydata: [[0.9015544  1.10684535]\n",
      " [0.91537133 1.25099602]\n",
      " [0.96373057 1.38645418]\n",
      " [0.9775475  1.43426295]\n",
      " [1.0224525  1.57768924]\n",
      " [1.03972366 1.62549801]\n",
      " [0.92918826 0.86055777]\n",
      " [0.93955095 0.88446215]\n",
      " [0.99481865 0.98804781]\n",
      " [1.00518135 1.01195219]\n",
      " [1.05699482 1.11553785]\n",
      " [1.07081174 1.14741036]\n",
      " [0.94300518 0.66932271]\n",
      " [0.95336788 0.68525896]\n",
      " [1.00863558 0.76494024]\n",
      " [1.0224525  0.78087649]\n",
      " [1.07426598 0.8685259 ]\n",
      " [1.0880829  0.89243028]]\n",
      "Stored 'xarray2' (ndarray)\n",
      "Stored 'yarray2' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import keras.backend as kb\n",
    "import tensorflow as tf\n",
    "#the follwoing 2 lines are only needed for Mac OS machines\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "#create input data array\n",
    "xdata2 = []\n",
    "\n",
    "#Part 1 input HI FLUX DATA: Air temp (degC), ID (W/sqm), load resistance (ohms)\n",
    "\n",
    "xdata2 = [[-10.0, 1550, 4.464], \n",
    "  [-10.0, 1850, 4.464], \n",
    "  [10.0, 1550, 4.464], \n",
    "  [10.0, 1850, 4.464], \n",
    "  [30.0, 1550, 4.464], \n",
    "  [30.0, 1850, 4.464], \n",
    "  [-10.0, 1550, 6.696], \n",
    "  [-10.0, 1850, 6.696], \n",
    "  [10.0, 1550, 6.696], \n",
    "  [10.0, 1850, 6.696], \n",
    "  [30.0, 1550, 6.696], \n",
    "  [30.0, 1850, 6.696], \n",
    "  [-10.0, 1550, 8.928], \n",
    "  [-10.0, 1850, 8.928],   \n",
    "  [10.0, 1550, 8.928], \n",
    "  [10.0, 1850, 8.928], \n",
    "  [30.0, 1550, 8.928], \n",
    "  [30.0, 1850, 8.928]]\n",
    "\n",
    "#normalizing the xdata using the median value.\n",
    "medianx=np.median(xdata2,axis=0)\n",
    "#print(medianx)\n",
    "Tmed2=medianx[0]\n",
    "IDmed2=medianx[1]\n",
    "Rmed2=medianx[2]\n",
    "Nx = []\n",
    "for i in range(len(xdata2)):\n",
    "    Nx.append([ xdata2[i][0]/Tmed2 , xdata2[i][1]/IDmed2 , xdata2[i][2]/Rmed2 ])\n",
    "xdata2 = Nx\n",
    "\n",
    "xarray2= np.array(xdata2)\n",
    "#print (xdata)\n",
    "print ('xdata:', xarray2)\n",
    "\n",
    "#Part 1 output HI FLUX DATA: load voltage (V) and Power out (W)\n",
    "ydata2 = [[26.1, 152.8], \n",
    " [26.5, 172.7], \n",
    " [27.9, 191.4], \n",
    " [28.3, 198.0], \n",
    " [29.6, 217.8], \n",
    " [30.1, 224.4],  \n",
    " [26.9, 118.8], \n",
    " [27.2, 122.1], \n",
    " [28.8, 136.4], \n",
    " [29.1, 139.7], \n",
    " [30.6, 154.0], \n",
    " [31.0, 158.4],  \n",
    " [27.3, 92.4], \n",
    " [27.6, 94.6], \n",
    " [29.2, 105.6], \n",
    " [29.6, 107.8], \n",
    " [31.1, 119.9], \n",
    " [31.5, 123.2]]\n",
    "\n",
    "#narmalizing the ydata using the median value.\n",
    "mediany=np.median(ydata2,axis=0)\n",
    "#print(mediany)\n",
    "VLmed2=mediany[0]\n",
    "Wdmed2=mediany[1]\n",
    "Ny=[]\n",
    "for i in range(len(ydata2)):\n",
    "    Ny.append([ ydata2[i][0]/VLmed2 , ydata2[i][1]/Wdmed2 ])\n",
    "ydata2=Ny\n",
    "yarray2= np.array(ydata2)\n",
    "#print (ydata)\n",
    "print ('ydata:', yarray2)\n",
    "%store xarray2\n",
    "%store yarray2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4c15813f-d1fa-47bd-bb51-8a1c89ba0f7b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RL = np.linspace( 4/6.696,8/6.696,30)\n",
    "ID = np.linspace(500/800,1800/800,30)\n",
    "test = []\n",
    "outpt=[]\n",
    "    \n",
    "function = np.zeros((len(RL),len(ID)))\n",
    "for i in range(len(RL)):\n",
    "    for j in range(len(ID)):\n",
    "        test = [[ 20/10, RL[i], ID[j] ]]\n",
    "        testarray = np.array(test)\n",
    "        outpt = model.predict(testarray)\n",
    "        function[j][i] = outpt[0][1]*100.1\n",
    "\n",
    "RL = np.linspace( 4,8,30)\n",
    "ID = np.linspace(500,1800,30)  \n",
    "\n",
    "        \n",
    "X,Y = np.meshgrid(ID,RL)\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "fig.set_size_inches(10,10)\n",
    "\n",
    "        \n",
    "surf = ax.plot_surface(X, Y, function, cmap=plt.cm.coolwarm, linewidth = 0, antialiased = False)\n",
    "\n",
    "ax.set_xlabel(r'RL (Ohms)', fontsize=20)\n",
    "ax.set_ylabel(r'ID (W/m^2)', fontsize = 20)\n",
    "ax.zaxis.set_rotate_label(False)\n",
    "ax.set_zlabel(r'Power (W)', fontsize = 20, rotation = 90)\n",
    "fig.colorbar(surf,shrink=0.5,aspect=10)\n",
    "\n",
    "ax.view_init(30,225)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12754afe-3b47-4088-bc80-0c72eed799e1",
   "metadata": {},
   "source": [
    "#### i)\n",
    "* With the help of the derived mean absolute errors comparing them for ther validataion sets, it can be observed that for the second model the error is lower implying it is better. Hence, the predicted data matches closely to the actual data on the second model.<br>\n",
    "* Observing the error for the training set and validataion set, there is an overfitting of both the models as the error is low for the train set but high for the validataion set, showing the model predictions are not accurate.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef311ff3-2a0b-4a0d-8206-8d7b667335d3",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "### Task 2.1\n",
    "#### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fc53c9a8-e707-431b-a5bc-cbd5b2099576",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xdata: [[0.         1.         0.33333333 0.8852459 ]\n",
      " [1.         1.         0.33333333 0.8852459 ]\n",
      " [2.         1.         0.33333333 0.8852459 ]\n",
      " [0.         1.         0.33333333 1.8870674 ]\n",
      " [1.         1.         0.33333333 1.8870674 ]\n",
      " [2.         1.         0.33333333 1.8870674 ]\n",
      " [0.         1.         0.33333333 3.50455373]\n",
      " [1.         1.         0.33333333 3.50455373]\n",
      " [2.         1.         0.33333333 3.50455373]\n",
      " [0.         1.         0.33333333 6.19672131]\n",
      " [1.         1.         0.33333333 6.19672131]\n",
      " [2.         1.         0.33333333 6.19672131]\n",
      " [0.         1.         0.83333333 0.25500911]\n",
      " [1.         1.         0.83333333 0.25500911]\n",
      " [2.         1.         0.83333333 0.25500911]\n",
      " [0.         1.         0.83333333 0.7723133 ]\n",
      " [1.         1.         0.83333333 0.7723133 ]\n",
      " [2.         1.         0.83333333 0.7723133 ]\n",
      " [0.         1.         0.83333333 1.57377049]\n",
      " [1.         1.         0.83333333 1.57377049]\n",
      " [2.         1.         0.83333333 1.57377049]\n",
      " [0.         1.         0.83333333 2.88160291]\n",
      " [1.         1.         0.83333333 2.88160291]\n",
      " [2.         1.         0.83333333 2.88160291]\n",
      " [0.         1.         1.16666667 0.17850638]\n",
      " [1.         1.         1.16666667 0.17850638]\n",
      " [2.         1.         1.16666667 0.17850638]\n",
      " [0.         1.         1.16666667 0.52094718]\n",
      " [1.         1.         1.16666667 0.52094718]\n",
      " [2.         1.         1.16666667 0.52094718]\n",
      " [0.         1.         1.16666667 1.08196721]\n",
      " [1.         1.         1.16666667 1.08196721]\n",
      " [2.         1.         1.16666667 1.08196721]\n",
      " [0.         1.         1.16666667 2.01457195]\n",
      " [1.         1.         1.16666667 2.01457195]\n",
      " [2.         1.         1.16666667 2.01457195]\n",
      " [0.         1.         1.66666667 0.1428051 ]\n",
      " [1.         1.         1.66666667 0.1428051 ]\n",
      " [2.         1.         1.66666667 0.1428051 ]\n",
      " [0.         1.         1.66666667 0.42622951]\n",
      " [1.         1.         1.66666667 0.42622951]\n",
      " [2.         1.         1.66666667 0.42622951]\n",
      " [0.         1.         1.66666667 0.91803279]\n",
      " [1.         1.         1.66666667 0.91803279]\n",
      " [2.         1.         1.66666667 0.91803279]\n",
      " [0.         1.         1.66666667 1.5154827 ]\n",
      " [1.         1.         1.66666667 1.5154827 ]\n",
      " [2.         1.         1.66666667 1.5154827 ]]\n",
      "ydata: [[0.83408885 0.51187335]\n",
      " [0.50589302 0.3764292 ]\n",
      " [0.50589302 0.1882146 ]\n",
      " [0.83408885 0.23981237]\n",
      " [1.66999093 0.9610085 ]\n",
      " [1.07887579 0.40164175]\n",
      " [0.83408885 0.12899443]\n",
      " [1.66999093 0.5171504 ]\n",
      " [2.00543971 0.74582234]\n",
      " [0.83408885 0.07270595]\n",
      " [1.66999093 0.29258282]\n",
      " [3.33998187 1.17033128]\n",
      " [0.87760653 1.96599238]\n",
      " [0.37715322 0.72881853]\n",
      " [0.37715322 0.36411609]\n",
      " [0.87760653 0.64907652]\n",
      " [1.75521306 2.59689241]\n",
      " [1.14415231 1.10348871]\n",
      " [0.87760653 0.31838171]\n",
      " [1.75702629 1.27411316]\n",
      " [2.33363554 2.24919378]\n",
      " [0.87760653 0.17355614]\n",
      " [1.75521306 0.69598358]\n",
      " [3.51223935 2.78393433]\n",
      " [0.89392566 2.90882439]\n",
      " [0.36990027 1.0038112 ]\n",
      " [0.36990027 0.5019056 ]\n",
      " [0.89392566 0.9961888 ]\n",
      " [1.78785131 3.98651422]\n",
      " [1.08250227 1.46467312]\n",
      " [0.89392566 0.47962474]\n",
      " [1.78785131 1.91967165]\n",
      " [2.25022665 3.04250953]\n",
      " [0.89401632 0.25740252]\n",
      " [1.78785131 1.03078276]\n",
      " [3.57570263 4.12371738]\n",
      " [0.92112421 3.86338317]\n",
      " [0.41885766 1.60011727]\n",
      " [0.41885766 0.79976546]\n",
      " [0.92112421 1.29404867]\n",
      " [1.84224841 5.17795368]\n",
      " [1.25113327 2.38756963]\n",
      " [0.92112421 0.60099678]\n",
      " [1.84224841 2.4039871 ]\n",
      " [2.69446963 5.14335972]\n",
      " [0.92112421 0.36352976]\n",
      " [1.84224841 1.45587804]\n",
      " [3.68449683 5.82527118]]\n",
      "Stored 'xarray' (ndarray)\n",
      "Stored 'yarray' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "#import useful packages\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import keras.backend as kb\n",
    "import tensorflow as tf\n",
    "#the follwoing 2 lines are only needed for Mac OS machines\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "#create input data array\n",
    "xdata = []\n",
    "\n",
    "#Part 2 input data: Mode number, Air temp (degC), ID (W/sqm), load resistance (ohms)\n",
    "xdata = [[0., 10.0, 200.0, 24.3], \n",
    " [1., 10.0, 200.0, 24.3], \n",
    " [2., 10.0, 200.0, 24.3], \n",
    " [0., 10.0, 200.0, 51.8], \n",
    " [1., 10.0, 200.0, 51.8],\n",
    "         \n",
    " [2., 10.0, 200.0, 51.8], \n",
    " [0., 10.0, 200.0, 96.2], \n",
    " [1., 10.0, 200.0, 96.2], \n",
    " [2., 10.0, 200.0, 96.2], \n",
    " [0., 10.0, 200.0, 170.1],\n",
    "         \n",
    " [1., 10.0, 200.0, 170.1], \n",
    " [2., 10.0, 200.0, 170.1], \n",
    " [0., 10.0, 500.0, 7.0], \n",
    " [1., 10.0, 500.0, 7.0], \n",
    " [2., 10.0, 500.0, 7.0], \n",
    "         \n",
    " [0., 10.0, 500.0, 21.2], \n",
    " [1., 10.0, 500.0, 21.2], \n",
    " [2., 10.0, 500.0, 21.2], \n",
    " [0., 10.0, 500.0, 43.2], \n",
    " [1., 10.0, 500.0, 43.2], \n",
    "         \n",
    " [2., 10.0, 500.0, 43.2], \n",
    " [0., 10.0, 500.0, 79.1], \n",
    " [1., 10.0, 500.0, 79.1], \n",
    " [2., 10.0, 500.0, 79.1], \n",
    " [0., 10.0, 700.0, 4.9], \n",
    "         \n",
    " [1., 10.0, 700.0, 4.9], \n",
    " [2., 10.0, 700.0, 4.9], \n",
    " [0., 10.0, 700.0, 14.3], \n",
    " [1., 10.0, 700.0, 14.3], \n",
    " [2., 10.0, 700.0, 14.3], \n",
    "         \n",
    " [0., 10.0, 700.0, 29.7], \n",
    " [1., 10.0, 700.0, 29.7], \n",
    " [2., 10.0, 700.0, 29.7], \n",
    " [0., 10.0, 700.0, 55.3], \n",
    " [1., 10.0, 700.0, 55.3], \n",
    " [2., 10.0, 700.0, 55.3], \n",
    "         \n",
    " [0., 10.0, 1000.0, 3.92], \n",
    " [1., 10.0, 1000.0, 3.92], \n",
    " [2., 10.0, 1000.0, 3.92], \n",
    " [0., 10.0, 1000.0, 11.7], \n",
    " [1., 10.0, 1000.0, 11.7], \n",
    "         \n",
    " [2., 10.0, 1000.0, 11.7], \n",
    " [0., 10.0, 1000.0, 25.2], \n",
    " [1., 10.0, 1000.0, 25.2], \n",
    " [2., 10.0, 1000.0, 25.2], \n",
    " [0., 10.0, 1000.0, 41.6], \n",
    " [1., 10.0, 1000.0, 41.6], \n",
    " [2., 10.0, 1000.0, 41.6]]\n",
    "medianx=[]\n",
    "mediany=[]\n",
    "#normalizing the xdata using the median value.\n",
    "medianx=np.median(xdata,axis=0)\n",
    "#print(medianx)\n",
    "Tmed=medianx[1]\n",
    "IDmed=medianx[2]\n",
    "Rmed=medianx[3]\n",
    "Nx = []\n",
    "for i in range(len(xdata)):\n",
    "    Nx.append([ xdata[i][0], xdata[i][1]/Tmed , xdata[i][2]/IDmed , xdata[i][3]/Rmed ])\n",
    "xdata = Nx\n",
    "\n",
    "xarray= np.array(xdata)\n",
    "#print (xdata)\n",
    "print ('xdata:', xarray)\n",
    "\n",
    "#Part 2 output data for above specified Mode and conditons: VL (V) and Power out (W)\n",
    "ydata = [[46.0, 87.3], \n",
    "         [27.9, 64.2], \n",
    "         [27.9, 32.1], \n",
    "         [46.0, 40.9], \n",
    "         [92.1, 163.9], \n",
    "         [59.5, 68.5], \n",
    "         [46.0, 22.0], \n",
    "         [92.1, 88.2], \n",
    "         [110.6, 127.2], \n",
    "         [46.0, 12.4], \n",
    "         [92.1, 49.9], \n",
    "         [184.2, 199.6], \n",
    "         [48.4, 335.3], \n",
    "         [20.8, 124.3], \n",
    "         [20.8, 62.1], \n",
    "         [48.4, 110.7], \n",
    "         [96.8, 442.9], \n",
    "         [63.1, 188.2], \n",
    "         [48.4, 54.3], \n",
    "         [96.9, 217.3], \n",
    "         [128.7, 383.6], \n",
    "         [48.4, 29.6], \n",
    "         [96.8, 118.7], \n",
    "         [193.7, 474.8], \n",
    "         [49.3, 496.1], \n",
    "         [20.4, 171.2], \n",
    "         [20.4, 85.6], \n",
    "         [49.3, 169.9], \n",
    "         [98.6, 679.9], \n",
    "         [59.7, 249.8], \n",
    "         [49.3, 81.8], \n",
    "         [98.6, 327.4], \n",
    "         [124.1, 518.9], \n",
    "         [49.305, 43.9], \n",
    "         [98.6, 175.8], \n",
    "         [197.2, 703.3], \n",
    "         [50.8, 658.9], \n",
    "         [23.1, 272.9], \n",
    "         [23.1, 136.4], \n",
    "         [50.8, 220.7], \n",
    "         [101.6, 883.1], \n",
    "         [69.0, 407.2], \n",
    "         [50.8, 102.5], \n",
    "         [101.6, 410.0], \n",
    "         [148.6, 877.2], \n",
    "         [50.8, 62.0], \n",
    "         [101.6, 248.3], \n",
    "         [203.2, 993.5]]\n",
    "\n",
    "#narmalizing the ydata using the median value.\n",
    "mediany=np.median(ydata,axis=0)\n",
    "#print(mediany)\n",
    "VLmed=mediany[0]\n",
    "Wdmed=mediany[1]\n",
    "Ny=[]\n",
    "for i in range(len(ydata)):\n",
    "    Ny.append([ ydata[i][0]/VLmed , ydata[i][1]/Wdmed ])\n",
    "ydata=Ny\n",
    "yarray= np.array(ydata)\n",
    "#print (ydata)\n",
    "print ('ydata:', yarray)\n",
    "%store xarray\n",
    "%store yarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc04c69d-15c8-4229-a9d9-943439cd2a70",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5f7086ea-4648-4b7a-b62d-a82f0ce113ed",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 4) (12, 4) (36, 2) (12, 2)\n",
      "training input array:\n",
      "[[0.         1.         0.83333333 0.7723133 ]\n",
      " [0.         1.         1.66666667 0.1428051 ]\n",
      " [2.         1.         0.83333333 0.7723133 ]\n",
      " [1.         1.         1.66666667 0.42622951]\n",
      " [2.         1.         0.33333333 1.8870674 ]\n",
      " [0.         1.         0.33333333 1.8870674 ]\n",
      " [1.         1.         0.33333333 3.50455373]\n",
      " [0.         1.         1.16666667 2.01457195]\n",
      " [0.         1.         0.83333333 0.25500911]\n",
      " [2.         1.         0.33333333 3.50455373]\n",
      " [0.         1.         1.66666667 0.91803279]\n",
      " [2.         1.         1.66666667 1.5154827 ]\n",
      " [1.         1.         0.33333333 0.8852459 ]\n",
      " [1.         1.         1.16666667 0.52094718]\n",
      " [0.         1.         1.16666667 1.08196721]\n",
      " [1.         1.         0.83333333 2.88160291]\n",
      " [1.         1.         1.66666667 0.91803279]\n",
      " [1.         1.         1.16666667 1.08196721]\n",
      " [0.         1.         0.83333333 2.88160291]\n",
      " [1.         1.         0.83333333 1.57377049]\n",
      " [2.         1.         1.16666667 1.08196721]\n",
      " [0.         1.         1.66666667 0.42622951]\n",
      " [2.         1.         0.33333333 6.19672131]\n",
      " [0.         1.         0.33333333 6.19672131]\n",
      " [1.         1.         1.66666667 1.5154827 ]\n",
      " [1.         1.         0.83333333 0.25500911]\n",
      " [1.         1.         1.66666667 0.1428051 ]\n",
      " [2.         1.         0.33333333 0.8852459 ]\n",
      " [2.         1.         1.16666667 0.17850638]\n",
      " [2.         1.         1.16666667 2.01457195]\n",
      " [1.         1.         1.16666667 0.17850638]\n",
      " [1.         1.         1.16666667 2.01457195]\n",
      " [2.         1.         1.66666667 0.1428051 ]\n",
      " [1.         1.         0.83333333 0.7723133 ]\n",
      " [1.         1.         0.33333333 6.19672131]\n",
      " [0.         1.         0.83333333 1.57377049]]\n",
      "validation input array:\n",
      "[[0.         1.         0.33333333 0.8852459 ]\n",
      " [2.         1.         1.66666667 0.42622951]\n",
      " [1.         1.         0.33333333 1.8870674 ]\n",
      " [0.         1.         0.33333333 3.50455373]\n",
      " [2.         1.         0.83333333 0.25500911]\n",
      " [2.         1.         1.16666667 0.52094718]\n",
      " [2.         1.         0.83333333 2.88160291]\n",
      " [0.         1.         1.16666667 0.52094718]\n",
      " [2.         1.         1.66666667 0.91803279]\n",
      " [2.         1.         0.83333333 1.57377049]\n",
      " [0.         1.         1.16666667 0.17850638]\n",
      " [0.         1.         1.66666667 1.5154827 ]]\n",
      "training Output array:\n",
      "[[0.87760653 0.64907652]\n",
      " [0.92112421 3.86338317]\n",
      " [1.14415231 1.10348871]\n",
      " [1.84224841 5.17795368]\n",
      " [1.07887579 0.40164175]\n",
      " [0.83408885 0.23981237]\n",
      " [1.66999093 0.5171504 ]\n",
      " [0.89401632 0.25740252]\n",
      " [0.87760653 1.96599238]\n",
      " [2.00543971 0.74582234]\n",
      " [0.92112421 0.60099678]\n",
      " [3.68449683 5.82527118]\n",
      " [0.50589302 0.3764292 ]\n",
      " [1.78785131 3.98651422]\n",
      " [0.89392566 0.47962474]\n",
      " [1.75521306 0.69598358]\n",
      " [1.84224841 2.4039871 ]\n",
      " [1.78785131 1.91967165]\n",
      " [0.87760653 0.17355614]\n",
      " [1.75702629 1.27411316]\n",
      " [2.25022665 3.04250953]\n",
      " [0.92112421 1.29404867]\n",
      " [3.33998187 1.17033128]\n",
      " [0.83408885 0.07270595]\n",
      " [1.84224841 1.45587804]\n",
      " [0.37715322 0.72881853]\n",
      " [0.41885766 1.60011727]\n",
      " [0.50589302 0.1882146 ]\n",
      " [0.36990027 0.5019056 ]\n",
      " [3.57570263 4.12371738]\n",
      " [0.36990027 1.0038112 ]\n",
      " [1.78785131 1.03078276]\n",
      " [0.41885766 0.79976546]\n",
      " [1.75521306 2.59689241]\n",
      " [1.66999093 0.29258282]\n",
      " [0.87760653 0.31838171]]\n",
      "validation otput array:\n",
      "[[0.83408885 0.51187335]\n",
      " [1.25113327 2.38756963]\n",
      " [1.66999093 0.9610085 ]\n",
      " [0.83408885 0.12899443]\n",
      " [0.37715322 0.36411609]\n",
      " [1.08250227 1.46467312]\n",
      " [3.51223935 2.78393433]\n",
      " [0.89392566 0.9961888 ]\n",
      " [2.69446963 5.14335972]\n",
      " [2.33363554 2.24919378]\n",
      " [0.89392566 2.90882439]\n",
      " [0.92112421 0.36352976]]\n"
     ]
    }
   ],
   "source": [
    "'''import random\n",
    "\n",
    "#dividing the input data array randomly into training and validation set\n",
    "#random.shuffle(xarray)\n",
    "train_xarray=xarray[:36]\n",
    "valid_xarray=xarray[36:]\n",
    "print(train_xarray)\n",
    "print(valid_xarray)\n",
    "\n",
    "#dividing the input data array randomly into training and validation set\n",
    "#random.shuffle(yarray)\n",
    "train_yarray=yarray[:36]\n",
    "valid_yarray=yarray[36:]\n",
    "print(train_yarray)\n",
    "print(valid_yarray)\n",
    "%store train_xarray\n",
    "%store train_yarray\n",
    "%store valid_xarray\n",
    "%store valid_yarray'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_xarray,valid_xarray,train_yarray,valid_yarray = train_test_split(xarray, yarray, test_size=0.25, random_state=13)\n",
    "\n",
    "print(train_xarray.shape,valid_xarray.shape,train_yarray.shape,valid_yarray.shape)\n",
    "print('training input array:')\n",
    "print(train_xarray)\n",
    "print('validation input array:') \n",
    "print(valid_xarray)\n",
    "print('training Output array:')\n",
    "print(train_yarray)\n",
    "print('validation otput array:') \n",
    "print(valid_yarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea09029c-c977-43c9-979e-9343d7ff7543",
   "metadata": {},
   "source": [
    "#### c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "da4f6f7a-71fe-4e0a-8e04-6efc51eac6ec",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# define neural network model\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "#As seen below, we have created four dense layers. \n",
    "#A dense layer is a layer in neural network thats fully connected. \n",
    "#In other words, all the neurons in one layer are connected to all other neurons in the next layer.\n",
    "#In the first layer, we need to provide the input shape, which is 1 in our case. \n",
    "#The activation function we have chosen is elu, which stands for exponential linear unit. .\n",
    "\n",
    "from keras import backend as K\n",
    "#initialize weights with values between -0.2 and 0.5\n",
    "initializer = keras.initializers.RandomUniform(minval= -0.2, maxval=0.5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(12, activation=K.relu, input_shape=[4],  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(32, activation=K.relu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(16, activation=K.relu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(8, activation=K.relu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(2,  kernel_initializer=initializer)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1f154562-aae0-45f4-8cbb-8d8c08373b4e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Were using RMSprop as our optimizer here. RMSprop stands for Root Mean Square Propagation. \n",
    "#Its one of the most popular gradient descent optimization algorithms for deep learning networks. \n",
    "#RMSprop is an optimizer thats reliable and fast.\n",
    "#Were compiling the mode using the model.compile function. The loss function used here \n",
    "#is mean squared error. After the compilation of the model, well use the fit method with ~500 epochs.\n",
    "#Number of epochs can be varied.\n",
    "\n",
    "#from tf.keras import optimizers\n",
    "rms = keras.optimizers.RMSprop(0.0068)\n",
    "model.compile(loss='mean_absolute_error',optimizer=rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb65216-ec81-466f-b6c1-1c11ea2a27c5",
   "metadata": {},
   "source": [
    "#### d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f247e4c0-fb6a-4031-bf3b-a211d00382b6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2500\n",
      "36/36 [==============================] - 0s 282us/step - loss: 0.0604\n",
      "Epoch 2/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0323\n",
      "Epoch 3/2500\n",
      "36/36 [==============================] - 0s 128us/step - loss: 0.0299\n",
      "Epoch 4/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0330\n",
      "Epoch 5/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0473\n",
      "Epoch 6/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0650\n",
      "Epoch 7/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0364\n",
      "Epoch 8/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0822\n",
      "Epoch 9/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0503\n",
      "Epoch 10/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.1383\n",
      "Epoch 11/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0371\n",
      "Epoch 12/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0410\n",
      "Epoch 13/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0623\n",
      "Epoch 14/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0428\n",
      "Epoch 15/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0475\n",
      "Epoch 16/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0405\n",
      "Epoch 17/2500\n",
      "36/36 [==============================] - 0s 100us/step - loss: 0.0487\n",
      "Epoch 18/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0534\n",
      "Epoch 19/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0662\n",
      "Epoch 20/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0737\n",
      "Epoch 21/2500\n",
      "36/36 [==============================] - 0s 99us/step - loss: 0.0542\n",
      "Epoch 22/2500\n",
      "36/36 [==============================] - 0s 99us/step - loss: 0.0372\n",
      "Epoch 23/2500\n",
      "36/36 [==============================] - 0s 100us/step - loss: 0.0525\n",
      "Epoch 24/2500\n",
      "36/36 [==============================] - 0s 98us/step - loss: 0.0618\n",
      "Epoch 25/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0379\n",
      "Epoch 26/2500\n",
      "36/36 [==============================] - 0s 100us/step - loss: 0.0507\n",
      "Epoch 27/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0441\n",
      "Epoch 28/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0841\n",
      "Epoch 29/2500\n",
      "36/36 [==============================] - 0s 126us/step - loss: 0.0887\n",
      "Epoch 30/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0521\n",
      "Epoch 31/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0956\n",
      "Epoch 32/2500\n",
      "36/36 [==============================] - 0s 126us/step - loss: 0.0448\n",
      "Epoch 33/2500\n",
      "36/36 [==============================] - 0s 124us/step - loss: 0.0341\n",
      "Epoch 34/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0284\n",
      "Epoch 35/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0809\n",
      "Epoch 36/2500\n",
      "36/36 [==============================] - 0s 96us/step - loss: 0.0556\n",
      "Epoch 37/2500\n",
      "36/36 [==============================] - 0s 98us/step - loss: 0.0785\n",
      "Epoch 38/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0369\n",
      "Epoch 39/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0576\n",
      "Epoch 40/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0749\n",
      "Epoch 41/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0311\n",
      "Epoch 42/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0538\n",
      "Epoch 43/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0292\n",
      "Epoch 44/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0546\n",
      "Epoch 45/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0710\n",
      "Epoch 46/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0242\n",
      "Epoch 47/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0410\n",
      "Epoch 48/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0426\n",
      "Epoch 49/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0358\n",
      "Epoch 50/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0711\n",
      "Epoch 51/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0560\n",
      "Epoch 52/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0365\n",
      "Epoch 53/2500\n",
      "36/36 [==============================] - 0s 123us/step - loss: 0.0377\n",
      "Epoch 54/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0428\n",
      "Epoch 55/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0460\n",
      "Epoch 56/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0391\n",
      "Epoch 57/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0871\n",
      "Epoch 58/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0491\n",
      "Epoch 59/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0305\n",
      "Epoch 60/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0467\n",
      "Epoch 61/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0261\n",
      "Epoch 62/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0780\n",
      "Epoch 63/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0366\n",
      "Epoch 64/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0676\n",
      "Epoch 65/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0512\n",
      "Epoch 66/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0447\n",
      "Epoch 67/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0505\n",
      "Epoch 68/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0625\n",
      "Epoch 69/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0537\n",
      "Epoch 70/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0676\n",
      "Epoch 71/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0419\n",
      "Epoch 72/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0439\n",
      "Epoch 73/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0338\n",
      "Epoch 74/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0297\n",
      "Epoch 75/2500\n",
      "36/36 [==============================] - 0s 99us/step - loss: 0.0465\n",
      "Epoch 76/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0459\n",
      "Epoch 77/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0709\n",
      "Epoch 78/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0456\n",
      "Epoch 79/2500\n",
      "36/36 [==============================] - 0s 121us/step - loss: 0.0520\n",
      "Epoch 80/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0663\n",
      "Epoch 81/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0413\n",
      "Epoch 82/2500\n",
      "36/36 [==============================] - 0s 124us/step - loss: 0.0615\n",
      "Epoch 83/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0379\n",
      "Epoch 84/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0541\n",
      "Epoch 85/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0528\n",
      "Epoch 86/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0354\n",
      "Epoch 87/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0647\n",
      "Epoch 88/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0371\n",
      "Epoch 89/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0438\n",
      "Epoch 90/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0431\n",
      "Epoch 91/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0422\n",
      "Epoch 92/2500\n",
      "36/36 [==============================] - 0s 122us/step - loss: 0.0906\n",
      "Epoch 93/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0422\n",
      "Epoch 94/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0471\n",
      "Epoch 95/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0286\n",
      "Epoch 96/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0349\n",
      "Epoch 97/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0403\n",
      "Epoch 98/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0344\n",
      "Epoch 99/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0615\n",
      "Epoch 100/2500\n",
      "36/36 [==============================] - 0s 128us/step - loss: 0.0524\n",
      "Epoch 101/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0569\n",
      "Epoch 102/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0392\n",
      "Epoch 103/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0398\n",
      "Epoch 104/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0424\n",
      "Epoch 105/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.1321\n",
      "Epoch 106/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0420\n",
      "Epoch 107/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0523\n",
      "Epoch 108/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0414\n",
      "Epoch 109/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0381\n",
      "Epoch 110/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0343\n",
      "Epoch 111/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0445\n",
      "Epoch 112/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0282\n",
      "Epoch 113/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0628\n",
      "Epoch 114/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0800\n",
      "Epoch 115/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0427\n",
      "Epoch 116/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0723\n",
      "Epoch 117/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0640\n",
      "Epoch 118/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0469\n",
      "Epoch 119/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0445\n",
      "Epoch 120/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0347\n",
      "Epoch 121/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0778\n",
      "Epoch 122/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0588\n",
      "Epoch 123/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0510\n",
      "Epoch 124/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0472\n",
      "Epoch 125/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0763\n",
      "Epoch 126/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0635\n",
      "Epoch 127/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0561\n",
      "Epoch 128/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0319\n",
      "Epoch 129/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0375\n",
      "Epoch 130/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0685\n",
      "Epoch 131/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0750\n",
      "Epoch 132/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0693\n",
      "Epoch 133/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0541\n",
      "Epoch 134/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0329\n",
      "Epoch 135/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0703\n",
      "Epoch 136/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0644\n",
      "Epoch 137/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0299\n",
      "Epoch 138/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0588\n",
      "Epoch 139/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0295\n",
      "Epoch 140/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0428\n",
      "Epoch 141/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0544\n",
      "Epoch 142/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0787\n",
      "Epoch 143/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0456\n",
      "Epoch 144/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0409\n",
      "Epoch 145/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0274\n",
      "Epoch 146/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0398\n",
      "Epoch 147/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0342\n",
      "Epoch 148/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0366\n",
      "Epoch 149/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0526\n",
      "Epoch 150/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0725\n",
      "Epoch 151/2500\n",
      "36/36 [==============================] - 0s 156us/step - loss: 0.0362\n",
      "Epoch 152/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0484\n",
      "Epoch 153/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0529\n",
      "Epoch 154/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0478\n",
      "Epoch 155/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0536\n",
      "Epoch 156/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0614\n",
      "Epoch 157/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0598\n",
      "Epoch 158/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0309\n",
      "Epoch 159/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0384\n",
      "Epoch 160/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0867\n",
      "Epoch 161/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0351\n",
      "Epoch 162/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0972\n",
      "Epoch 163/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0606\n",
      "Epoch 164/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0332\n",
      "Epoch 165/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0390\n",
      "Epoch 166/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0378\n",
      "Epoch 167/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0497\n",
      "Epoch 168/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0748\n",
      "Epoch 169/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0416\n",
      "Epoch 170/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0441\n",
      "Epoch 171/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0496\n",
      "Epoch 172/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0362\n",
      "Epoch 173/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0942\n",
      "Epoch 174/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0383\n",
      "Epoch 175/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0506\n",
      "Epoch 176/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0452\n",
      "Epoch 177/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0302\n",
      "Epoch 178/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0808\n",
      "Epoch 179/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0897\n",
      "Epoch 180/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0343\n",
      "Epoch 181/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0488\n",
      "Epoch 182/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0530\n",
      "Epoch 183/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0431\n",
      "Epoch 184/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0376\n",
      "Epoch 185/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0405\n",
      "Epoch 186/2500\n",
      "36/36 [==============================] - 0s 121us/step - loss: 0.0638\n",
      "Epoch 187/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0542\n",
      "Epoch 188/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0505\n",
      "Epoch 189/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0402\n",
      "Epoch 190/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0571\n",
      "Epoch 191/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0943\n",
      "Epoch 192/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0301\n",
      "Epoch 193/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0472\n",
      "Epoch 194/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0500\n",
      "Epoch 195/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0398\n",
      "Epoch 196/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0654\n",
      "Epoch 197/2500\n",
      "36/36 [==============================] - 0s 100us/step - loss: 0.0372\n",
      "Epoch 198/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0445\n",
      "Epoch 199/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0483\n",
      "Epoch 200/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0874\n",
      "Epoch 201/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0527\n",
      "Epoch 202/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0355\n",
      "Epoch 203/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0410\n",
      "Epoch 204/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0563\n",
      "Epoch 205/2500\n",
      "36/36 [==============================] - 0s 129us/step - loss: 0.0342\n",
      "Epoch 206/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0695\n",
      "Epoch 207/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0662\n",
      "Epoch 208/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0433\n",
      "Epoch 209/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0260\n",
      "Epoch 210/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0572\n",
      "Epoch 211/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0476\n",
      "Epoch 212/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0596\n",
      "Epoch 213/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0599\n",
      "Epoch 214/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0486\n",
      "Epoch 215/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0522\n",
      "Epoch 216/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0494\n",
      "Epoch 217/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0361\n",
      "Epoch 218/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0302\n",
      "Epoch 219/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0936\n",
      "Epoch 220/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0411\n",
      "Epoch 221/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0561\n",
      "Epoch 222/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0662\n",
      "Epoch 223/2500\n",
      "36/36 [==============================] - 0s 137us/step - loss: 0.0495\n",
      "Epoch 224/2500\n",
      "36/36 [==============================] - 0s 126us/step - loss: 0.0392\n",
      "Epoch 225/2500\n",
      "36/36 [==============================] - 0s 128us/step - loss: 0.0484\n",
      "Epoch 226/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0454\n",
      "Epoch 227/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0299\n",
      "Epoch 228/2500\n",
      "36/36 [==============================] - 0s 128us/step - loss: 0.0686\n",
      "Epoch 229/2500\n",
      "36/36 [==============================] - 0s 122us/step - loss: 0.0523\n",
      "Epoch 230/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0538\n",
      "Epoch 231/2500\n",
      "36/36 [==============================] - 0s 128us/step - loss: 0.0475\n",
      "Epoch 232/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0521\n",
      "Epoch 233/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0315\n",
      "Epoch 234/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0509\n",
      "Epoch 235/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0313\n",
      "Epoch 236/2500\n",
      "36/36 [==============================] - 0s 122us/step - loss: 0.0396\n",
      "Epoch 237/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0511\n",
      "Epoch 238/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0502\n",
      "Epoch 239/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0665\n",
      "Epoch 240/2500\n",
      "36/36 [==============================] - 0s 122us/step - loss: 0.0505\n",
      "Epoch 241/2500\n",
      "36/36 [==============================] - 0s 122us/step - loss: 0.0386\n",
      "Epoch 242/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0393\n",
      "Epoch 243/2500\n",
      "36/36 [==============================] - 0s 135us/step - loss: 0.0362\n",
      "Epoch 244/2500\n",
      "36/36 [==============================] - 0s 127us/step - loss: 0.0356\n",
      "Epoch 245/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0670\n",
      "Epoch 246/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0513\n",
      "Epoch 247/2500\n",
      "36/36 [==============================] - 0s 121us/step - loss: 0.0356\n",
      "Epoch 248/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0273\n",
      "Epoch 249/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0709\n",
      "Epoch 250/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0386\n",
      "Epoch 251/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0313\n",
      "Epoch 252/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0297\n",
      "Epoch 253/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0545\n",
      "Epoch 254/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0637\n",
      "Epoch 255/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0650\n",
      "Epoch 256/2500\n",
      "36/36 [==============================] - 0s 122us/step - loss: 0.0476\n",
      "Epoch 257/2500\n",
      "36/36 [==============================] - 0s 128us/step - loss: 0.0447\n",
      "Epoch 258/2500\n",
      "36/36 [==============================] - 0s 127us/step - loss: 0.0640\n",
      "Epoch 259/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0479\n",
      "Epoch 260/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0567\n",
      "Epoch 261/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0699\n",
      "Epoch 262/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0508\n",
      "Epoch 263/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0345\n",
      "Epoch 264/2500\n",
      "36/36 [==============================] - 0s 121us/step - loss: 0.0740\n",
      "Epoch 265/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0337\n",
      "Epoch 266/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0398\n",
      "Epoch 267/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0388\n",
      "Epoch 268/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0675\n",
      "Epoch 269/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0533\n",
      "Epoch 270/2500\n",
      "36/36 [==============================] - 0s 122us/step - loss: 0.0308\n",
      "Epoch 271/2500\n",
      "36/36 [==============================] - 0s 123us/step - loss: 0.0443\n",
      "Epoch 272/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0318\n",
      "Epoch 273/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0925\n",
      "Epoch 274/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0402\n",
      "Epoch 275/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0250\n",
      "Epoch 276/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0344\n",
      "Epoch 277/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0461\n",
      "Epoch 278/2500\n",
      "36/36 [==============================] - 0s 121us/step - loss: 0.0622\n",
      "Epoch 279/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0433\n",
      "Epoch 280/2500\n",
      "36/36 [==============================] - 0s 121us/step - loss: 0.0922\n",
      "Epoch 281/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0682\n",
      "Epoch 282/2500\n",
      "36/36 [==============================] - 0s 126us/step - loss: 0.0759\n",
      "Epoch 283/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0627\n",
      "Epoch 284/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0946\n",
      "Epoch 285/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0326\n",
      "Epoch 286/2500\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.048 - 0s 114us/step - loss: 0.0461\n",
      "Epoch 287/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0495\n",
      "Epoch 288/2500\n",
      "36/36 [==============================] - 0s 121us/step - loss: 0.0360\n",
      "Epoch 289/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0363\n",
      "Epoch 290/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0547\n",
      "Epoch 291/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0591\n",
      "Epoch 292/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0570\n",
      "Epoch 293/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0741\n",
      "Epoch 294/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0336\n",
      "Epoch 295/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0383\n",
      "Epoch 296/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0501\n",
      "Epoch 297/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0522\n",
      "Epoch 298/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0317\n",
      "Epoch 299/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0564\n",
      "Epoch 300/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0433\n",
      "Epoch 301/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0829\n",
      "Epoch 302/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.1283\n",
      "Epoch 303/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0425\n",
      "Epoch 304/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0508\n",
      "Epoch 305/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0732\n",
      "Epoch 306/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0541\n",
      "Epoch 307/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0325\n",
      "Epoch 308/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0442\n",
      "Epoch 309/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0352\n",
      "Epoch 310/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0439\n",
      "Epoch 311/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0404\n",
      "Epoch 312/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0580\n",
      "Epoch 313/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0674\n",
      "Epoch 314/2500\n",
      "36/36 [==============================] - 0s 125us/step - loss: 0.0581\n",
      "Epoch 315/2500\n",
      "36/36 [==============================] - 0s 122us/step - loss: 0.0390\n",
      "Epoch 316/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0307\n",
      "Epoch 317/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0427\n",
      "Epoch 318/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0432\n",
      "Epoch 319/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0251\n",
      "Epoch 320/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0449\n",
      "Epoch 321/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0414\n",
      "Epoch 322/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0460\n",
      "Epoch 323/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0318\n",
      "Epoch 324/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0293\n",
      "Epoch 325/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0964\n",
      "Epoch 326/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0721\n",
      "Epoch 327/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0411\n",
      "Epoch 328/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0646\n",
      "Epoch 329/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0457\n",
      "Epoch 330/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0447\n",
      "Epoch 331/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0540\n",
      "Epoch 332/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0414\n",
      "Epoch 333/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.1008\n",
      "Epoch 334/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0525\n",
      "Epoch 335/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0305\n",
      "Epoch 336/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0765\n",
      "Epoch 337/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0830\n",
      "Epoch 338/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0652\n",
      "Epoch 339/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0615\n",
      "Epoch 340/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0550\n",
      "Epoch 341/2500\n",
      "36/36 [==============================] - 0s 121us/step - loss: 0.0409\n",
      "Epoch 342/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0496\n",
      "Epoch 343/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0407\n",
      "Epoch 344/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0413\n",
      "Epoch 345/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0387\n",
      "Epoch 346/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0331\n",
      "Epoch 347/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0459\n",
      "Epoch 348/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0748\n",
      "Epoch 349/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0448\n",
      "Epoch 350/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0806\n",
      "Epoch 351/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0329\n",
      "Epoch 352/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0467\n",
      "Epoch 353/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0441\n",
      "Epoch 354/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0528\n",
      "Epoch 355/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0358\n",
      "Epoch 356/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0583\n",
      "Epoch 357/2500\n",
      "36/36 [==============================] - 0s 126us/step - loss: 0.0290\n",
      "Epoch 358/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0515\n",
      "Epoch 359/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0555\n",
      "Epoch 360/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0606\n",
      "Epoch 361/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0746\n",
      "Epoch 362/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0579\n",
      "Epoch 363/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0293\n",
      "Epoch 364/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0326\n",
      "Epoch 365/2500\n",
      "36/36 [==============================] - 0s 124us/step - loss: 0.0866\n",
      "Epoch 366/2500\n",
      "36/36 [==============================] - 0s 122us/step - loss: 0.0411\n",
      "Epoch 367/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0465\n",
      "Epoch 368/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0606\n",
      "Epoch 369/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0341\n",
      "Epoch 370/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0507\n",
      "Epoch 371/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0624\n",
      "Epoch 372/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0359\n",
      "Epoch 373/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0403\n",
      "Epoch 374/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0368\n",
      "Epoch 375/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0400\n",
      "Epoch 376/2500\n",
      "36/36 [==============================] - 0s 121us/step - loss: 0.0741\n",
      "Epoch 377/2500\n",
      "36/36 [==============================] - 0s 126us/step - loss: 0.0344\n",
      "Epoch 378/2500\n",
      "36/36 [==============================] - 0s 121us/step - loss: 0.0454\n",
      "Epoch 379/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0508\n",
      "Epoch 380/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0561\n",
      "Epoch 381/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0457\n",
      "Epoch 382/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0566\n",
      "Epoch 383/2500\n",
      "36/36 [==============================] - 0s 122us/step - loss: 0.0454\n",
      "Epoch 384/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0979\n",
      "Epoch 385/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0585\n",
      "Epoch 386/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0603\n",
      "Epoch 387/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0968\n",
      "Epoch 388/2500\n",
      "36/36 [==============================] - 0s 126us/step - loss: 0.0358\n",
      "Epoch 389/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0460\n",
      "Epoch 390/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0461\n",
      "Epoch 391/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0354\n",
      "Epoch 392/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0388\n",
      "Epoch 393/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0347\n",
      "Epoch 394/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0780\n",
      "Epoch 395/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0270\n",
      "Epoch 396/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0513\n",
      "Epoch 397/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0659\n",
      "Epoch 398/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0502\n",
      "Epoch 399/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0524\n",
      "Epoch 400/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0632\n",
      "Epoch 401/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0331\n",
      "Epoch 402/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0562\n",
      "Epoch 403/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0776\n",
      "Epoch 404/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0362\n",
      "Epoch 405/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0399\n",
      "Epoch 406/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0406\n",
      "Epoch 407/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0549\n",
      "Epoch 408/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0415\n",
      "Epoch 409/2500\n",
      "36/36 [==============================] - 0s 98us/step - loss: 0.0334\n",
      "Epoch 410/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0672\n",
      "Epoch 411/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0578\n",
      "Epoch 412/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0536\n",
      "Epoch 413/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0411\n",
      "Epoch 414/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0463\n",
      "Epoch 415/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0472\n",
      "Epoch 416/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0340\n",
      "Epoch 417/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0644\n",
      "Epoch 418/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0484\n",
      "Epoch 419/2500\n",
      "36/36 [==============================] - 0s 122us/step - loss: 0.0426\n",
      "Epoch 420/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0334\n",
      "Epoch 421/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0455\n",
      "Epoch 422/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0364\n",
      "Epoch 423/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0740\n",
      "Epoch 424/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0523\n",
      "Epoch 425/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0500\n",
      "Epoch 426/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0382\n",
      "Epoch 427/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0569\n",
      "Epoch 428/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0574\n",
      "Epoch 429/2500\n",
      "36/36 [==============================] - 0s 124us/step - loss: 0.0326\n",
      "Epoch 430/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0444\n",
      "Epoch 431/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0300\n",
      "Epoch 432/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0326\n",
      "Epoch 433/2500\n",
      "36/36 [==============================] - 0s 126us/step - loss: 0.0624\n",
      "Epoch 434/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0533\n",
      "Epoch 435/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0557\n",
      "Epoch 436/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0464\n",
      "Epoch 437/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0428\n",
      "Epoch 438/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.1257\n",
      "Epoch 439/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0394\n",
      "Epoch 440/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0656\n",
      "Epoch 441/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0377\n",
      "Epoch 442/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0420\n",
      "Epoch 443/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0340\n",
      "Epoch 444/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0624\n",
      "Epoch 445/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0428\n",
      "Epoch 446/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0703\n",
      "Epoch 447/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0327\n",
      "Epoch 448/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0419\n",
      "Epoch 449/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0533\n",
      "Epoch 450/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0534\n",
      "Epoch 451/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0369\n",
      "Epoch 452/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0622\n",
      "Epoch 453/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0618\n",
      "Epoch 454/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0543\n",
      "Epoch 455/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0429\n",
      "Epoch 456/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0503\n",
      "Epoch 457/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0789\n",
      "Epoch 458/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0360\n",
      "Epoch 459/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0371\n",
      "Epoch 460/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0981\n",
      "Epoch 461/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0439\n",
      "Epoch 462/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0474\n",
      "Epoch 463/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0480\n",
      "Epoch 464/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0375\n",
      "Epoch 465/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0875\n",
      "Epoch 466/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0335\n",
      "Epoch 467/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0448\n",
      "Epoch 468/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0239\n",
      "Epoch 469/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0730\n",
      "Epoch 470/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0320\n",
      "Epoch 471/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0568\n",
      "Epoch 472/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0904\n",
      "Epoch 473/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0449\n",
      "Epoch 474/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0312\n",
      "Epoch 475/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0749\n",
      "Epoch 476/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0553\n",
      "Epoch 477/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.1139\n",
      "Epoch 478/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0475\n",
      "Epoch 479/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0700\n",
      "Epoch 480/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0519\n",
      "Epoch 481/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0609\n",
      "Epoch 482/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0566\n",
      "Epoch 483/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0401\n",
      "Epoch 484/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0315\n",
      "Epoch 485/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0316\n",
      "Epoch 486/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0501\n",
      "Epoch 487/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0525\n",
      "Epoch 488/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0370\n",
      "Epoch 489/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0452\n",
      "Epoch 490/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0402\n",
      "Epoch 491/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0906\n",
      "Epoch 492/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0390\n",
      "Epoch 493/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0470\n",
      "Epoch 494/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0547\n",
      "Epoch 495/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0258\n",
      "Epoch 496/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0524\n",
      "Epoch 497/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0334\n",
      "Epoch 498/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0330\n",
      "Epoch 499/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0698\n",
      "Epoch 500/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0380\n",
      "Epoch 501/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0383\n",
      "Epoch 502/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0784\n",
      "Epoch 503/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0336\n",
      "Epoch 504/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0404\n",
      "Epoch 505/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0332\n",
      "Epoch 506/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0471\n",
      "Epoch 507/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0349\n",
      "Epoch 508/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0841\n",
      "Epoch 509/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0931\n",
      "Epoch 510/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0428\n",
      "Epoch 511/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0644\n",
      "Epoch 512/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0382\n",
      "Epoch 513/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0482\n",
      "Epoch 514/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0443\n",
      "Epoch 515/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0474\n",
      "Epoch 516/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0824\n",
      "Epoch 517/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0359\n",
      "Epoch 518/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0852\n",
      "Epoch 519/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0322\n",
      "Epoch 520/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0384\n",
      "Epoch 521/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0341\n",
      "Epoch 522/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0343\n",
      "Epoch 523/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0666\n",
      "Epoch 524/2500\n",
      "36/36 [==============================] - 0s 128us/step - loss: 0.0508\n",
      "Epoch 525/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0473\n",
      "Epoch 526/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0637\n",
      "Epoch 527/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0511\n",
      "Epoch 528/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0732\n",
      "Epoch 529/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0337\n",
      "Epoch 530/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0260\n",
      "Epoch 531/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0423\n",
      "Epoch 532/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0440\n",
      "Epoch 533/2500\n",
      "36/36 [==============================] - 0s 96us/step - loss: 0.0567\n",
      "Epoch 534/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.1165\n",
      "Epoch 535/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0534\n",
      "Epoch 536/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0344\n",
      "Epoch 537/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0386\n",
      "Epoch 538/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0444\n",
      "Epoch 539/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0569\n",
      "Epoch 540/2500\n",
      "36/36 [==============================] - 0s 124us/step - loss: 0.0451\n",
      "Epoch 541/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0693\n",
      "Epoch 542/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0512\n",
      "Epoch 543/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0415\n",
      "Epoch 544/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0491\n",
      "Epoch 545/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0433\n",
      "Epoch 546/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0343\n",
      "Epoch 547/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0347\n",
      "Epoch 548/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0329\n",
      "Epoch 549/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0284\n",
      "Epoch 550/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0773\n",
      "Epoch 551/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0489\n",
      "Epoch 552/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0500\n",
      "Epoch 553/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0446\n",
      "Epoch 554/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0364\n",
      "Epoch 555/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0429\n",
      "Epoch 556/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0559\n",
      "Epoch 557/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0452\n",
      "Epoch 558/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0416\n",
      "Epoch 559/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0402\n",
      "Epoch 560/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0698\n",
      "Epoch 561/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0646\n",
      "Epoch 562/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0471\n",
      "Epoch 563/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0420\n",
      "Epoch 564/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0512\n",
      "Epoch 565/2500\n",
      "36/36 [==============================] - 0s 127us/step - loss: 0.0301\n",
      "Epoch 566/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0279\n",
      "Epoch 567/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0518\n",
      "Epoch 568/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0704\n",
      "Epoch 569/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.1202\n",
      "Epoch 570/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0343\n",
      "Epoch 571/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0355\n",
      "Epoch 572/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0454\n",
      "Epoch 573/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0502\n",
      "Epoch 574/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0504\n",
      "Epoch 575/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0520\n",
      "Epoch 576/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0540\n",
      "Epoch 577/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0428\n",
      "Epoch 578/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0446\n",
      "Epoch 579/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0602\n",
      "Epoch 580/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0339\n",
      "Epoch 581/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0277\n",
      "Epoch 582/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0444\n",
      "Epoch 583/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0506\n",
      "Epoch 584/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0251\n",
      "Epoch 585/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0587\n",
      "Epoch 586/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0294\n",
      "Epoch 587/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0918\n",
      "Epoch 588/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0700\n",
      "Epoch 589/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0455\n",
      "Epoch 590/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0653\n",
      "Epoch 591/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0536\n",
      "Epoch 592/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0440\n",
      "Epoch 593/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0359\n",
      "Epoch 594/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0363\n",
      "Epoch 595/2500\n",
      "36/36 [==============================] - 0s 98us/step - loss: 0.0344\n",
      "Epoch 596/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0506\n",
      "Epoch 597/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0976\n",
      "Epoch 598/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0522\n",
      "Epoch 599/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0404\n",
      "Epoch 600/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0595\n",
      "Epoch 601/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0357\n",
      "Epoch 602/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0322\n",
      "Epoch 603/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0699\n",
      "Epoch 604/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0483\n",
      "Epoch 605/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0253\n",
      "Epoch 606/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0341\n",
      "Epoch 607/2500\n",
      "36/36 [==============================] - 0s 100us/step - loss: 0.0784\n",
      "Epoch 608/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0354\n",
      "Epoch 609/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0347\n",
      "Epoch 610/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0459\n",
      "Epoch 611/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0801\n",
      "Epoch 612/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0568\n",
      "Epoch 613/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0298\n",
      "Epoch 614/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0464\n",
      "Epoch 615/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0612\n",
      "Epoch 616/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0575\n",
      "Epoch 617/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0646\n",
      "Epoch 618/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0581\n",
      "Epoch 619/2500\n",
      "36/36 [==============================] - 0s 121us/step - loss: 0.0570\n",
      "Epoch 620/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0476\n",
      "Epoch 621/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0471\n",
      "Epoch 622/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0887\n",
      "Epoch 623/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0392\n",
      "Epoch 624/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0345\n",
      "Epoch 625/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0447\n",
      "Epoch 626/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0566\n",
      "Epoch 627/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0426\n",
      "Epoch 628/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0756\n",
      "Epoch 629/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0539\n",
      "Epoch 630/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0548\n",
      "Epoch 631/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0621\n",
      "Epoch 632/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0373\n",
      "Epoch 633/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0723\n",
      "Epoch 634/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0540\n",
      "Epoch 635/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0429\n",
      "Epoch 636/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0333\n",
      "Epoch 637/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0438\n",
      "Epoch 638/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0376\n",
      "Epoch 639/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.1107\n",
      "Epoch 640/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0485\n",
      "Epoch 641/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0539\n",
      "Epoch 642/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0385\n",
      "Epoch 643/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0571\n",
      "Epoch 644/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0511\n",
      "Epoch 645/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0496\n",
      "Epoch 646/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0372\n",
      "Epoch 647/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0887\n",
      "Epoch 648/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0417\n",
      "Epoch 649/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0315\n",
      "Epoch 650/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0329\n",
      "Epoch 651/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0581\n",
      "Epoch 652/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0528\n",
      "Epoch 653/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0940\n",
      "Epoch 654/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0369\n",
      "Epoch 655/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0364\n",
      "Epoch 656/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0606\n",
      "Epoch 657/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0789\n",
      "Epoch 658/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0682\n",
      "Epoch 659/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0803\n",
      "Epoch 660/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0416\n",
      "Epoch 661/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0490\n",
      "Epoch 662/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0581\n",
      "Epoch 663/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0442\n",
      "Epoch 664/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0542\n",
      "Epoch 665/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0347\n",
      "Epoch 666/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0566\n",
      "Epoch 667/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0424\n",
      "Epoch 668/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0639\n",
      "Epoch 669/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0642\n",
      "Epoch 670/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0442\n",
      "Epoch 671/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0556\n",
      "Epoch 672/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0713\n",
      "Epoch 673/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0551\n",
      "Epoch 674/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0527\n",
      "Epoch 675/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0606\n",
      "Epoch 676/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0446\n",
      "Epoch 677/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0432\n",
      "Epoch 678/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0412\n",
      "Epoch 679/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0444\n",
      "Epoch 680/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0383\n",
      "Epoch 681/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0460\n",
      "Epoch 682/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0344\n",
      "Epoch 683/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0318\n",
      "Epoch 684/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0543\n",
      "Epoch 685/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0401\n",
      "Epoch 686/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0436\n",
      "Epoch 687/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0436\n",
      "Epoch 688/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0574\n",
      "Epoch 689/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0609\n",
      "Epoch 690/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0496\n",
      "Epoch 691/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0544\n",
      "Epoch 692/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0594\n",
      "Epoch 693/2500\n",
      "36/36 [==============================] - 0s 125us/step - loss: 0.0386\n",
      "Epoch 694/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0348\n",
      "Epoch 695/2500\n",
      "36/36 [==============================] - 0s 124us/step - loss: 0.0457\n",
      "Epoch 696/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0365\n",
      "Epoch 697/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0578\n",
      "Epoch 698/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.1092\n",
      "Epoch 699/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0384\n",
      "Epoch 700/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0696\n",
      "Epoch 701/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0496\n",
      "Epoch 702/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0327\n",
      "Epoch 703/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0474\n",
      "Epoch 704/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0341\n",
      "Epoch 705/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0554\n",
      "Epoch 706/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0489\n",
      "Epoch 707/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0571\n",
      "Epoch 708/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0582\n",
      "Epoch 709/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0304\n",
      "Epoch 710/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0527\n",
      "Epoch 711/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0583\n",
      "Epoch 712/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.1146\n",
      "Epoch 713/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0650\n",
      "Epoch 714/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0483\n",
      "Epoch 715/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0355\n",
      "Epoch 716/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0453\n",
      "Epoch 717/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0542\n",
      "Epoch 718/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0557\n",
      "Epoch 719/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0410\n",
      "Epoch 720/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0584\n",
      "Epoch 721/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0456\n",
      "Epoch 722/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0580\n",
      "Epoch 723/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0570\n",
      "Epoch 724/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0475\n",
      "Epoch 725/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0443\n",
      "Epoch 726/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0510\n",
      "Epoch 727/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0292\n",
      "Epoch 728/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.1221\n",
      "Epoch 729/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0342\n",
      "Epoch 730/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0650\n",
      "Epoch 731/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0785\n",
      "Epoch 732/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0687\n",
      "Epoch 733/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0435\n",
      "Epoch 734/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0714\n",
      "Epoch 735/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0500\n",
      "Epoch 736/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0650\n",
      "Epoch 737/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0366\n",
      "Epoch 738/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0319\n",
      "Epoch 739/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0637\n",
      "Epoch 740/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0706\n",
      "Epoch 741/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0330\n",
      "Epoch 742/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0542\n",
      "Epoch 743/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0536\n",
      "Epoch 744/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0371\n",
      "Epoch 745/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0567\n",
      "Epoch 746/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0543\n",
      "Epoch 747/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0598\n",
      "Epoch 748/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0542\n",
      "Epoch 749/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0423\n",
      "Epoch 750/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0556\n",
      "Epoch 751/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0475\n",
      "Epoch 752/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0688\n",
      "Epoch 753/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0419\n",
      "Epoch 754/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0656\n",
      "Epoch 755/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0641\n",
      "Epoch 756/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0745\n",
      "Epoch 757/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0342\n",
      "Epoch 758/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0659\n",
      "Epoch 759/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0760\n",
      "Epoch 760/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0544\n",
      "Epoch 761/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0296\n",
      "Epoch 762/2500\n",
      "36/36 [==============================] - 0s 121us/step - loss: 0.0962\n",
      "Epoch 763/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0365\n",
      "Epoch 764/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0333\n",
      "Epoch 765/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0497\n",
      "Epoch 766/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0521\n",
      "Epoch 767/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0404\n",
      "Epoch 768/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0454\n",
      "Epoch 769/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0547\n",
      "Epoch 770/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0998\n",
      "Epoch 771/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0599\n",
      "Epoch 772/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0483\n",
      "Epoch 773/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0561\n",
      "Epoch 774/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0409\n",
      "Epoch 775/2500\n",
      "36/36 [==============================] - 0s 122us/step - loss: 0.0547\n",
      "Epoch 776/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0447\n",
      "Epoch 777/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0669\n",
      "Epoch 778/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0440\n",
      "Epoch 779/2500\n",
      "36/36 [==============================] - 0s 124us/step - loss: 0.0365\n",
      "Epoch 780/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0600\n",
      "Epoch 781/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0433\n",
      "Epoch 782/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0360\n",
      "Epoch 783/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0676\n",
      "Epoch 784/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0639\n",
      "Epoch 785/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0764\n",
      "Epoch 786/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0473\n",
      "Epoch 787/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0362\n",
      "Epoch 788/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0358\n",
      "Epoch 789/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0383\n",
      "Epoch 790/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0285\n",
      "Epoch 791/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0516\n",
      "Epoch 792/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0936\n",
      "Epoch 793/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0526\n",
      "Epoch 794/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0795\n",
      "Epoch 795/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0341\n",
      "Epoch 796/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0644\n",
      "Epoch 797/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0466\n",
      "Epoch 798/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0391\n",
      "Epoch 799/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0836\n",
      "Epoch 800/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0512\n",
      "Epoch 801/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0473\n",
      "Epoch 802/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0464\n",
      "Epoch 803/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0487\n",
      "Epoch 804/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0510\n",
      "Epoch 805/2500\n",
      "36/36 [==============================] - 0s 122us/step - loss: 0.0489\n",
      "Epoch 806/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0318\n",
      "Epoch 807/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0502\n",
      "Epoch 808/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0817\n",
      "Epoch 809/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0890\n",
      "Epoch 810/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0340\n",
      "Epoch 811/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0329\n",
      "Epoch 812/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0573\n",
      "Epoch 813/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0509\n",
      "Epoch 814/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0465\n",
      "Epoch 815/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0587\n",
      "Epoch 816/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0438\n",
      "Epoch 817/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0433\n",
      "Epoch 818/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0427\n",
      "Epoch 819/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0373\n",
      "Epoch 820/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0346\n",
      "Epoch 821/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0402\n",
      "Epoch 822/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0409\n",
      "Epoch 823/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0527\n",
      "Epoch 824/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0557\n",
      "Epoch 825/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0748\n",
      "Epoch 826/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0583\n",
      "Epoch 827/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0606\n",
      "Epoch 828/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0388\n",
      "Epoch 829/2500\n",
      "36/36 [==============================] - 0s 124us/step - loss: 0.0400\n",
      "Epoch 830/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0552\n",
      "Epoch 831/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0504\n",
      "Epoch 832/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0570\n",
      "Epoch 833/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0329\n",
      "Epoch 834/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0470\n",
      "Epoch 835/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0364\n",
      "Epoch 836/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0599\n",
      "Epoch 837/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0399\n",
      "Epoch 838/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0396\n",
      "Epoch 839/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0799\n",
      "Epoch 840/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0514\n",
      "Epoch 841/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0287\n",
      "Epoch 842/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0274\n",
      "Epoch 843/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0468\n",
      "Epoch 844/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0455\n",
      "Epoch 845/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0555\n",
      "Epoch 846/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0401\n",
      "Epoch 847/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0467\n",
      "Epoch 848/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0818\n",
      "Epoch 849/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0634\n",
      "Epoch 850/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0420\n",
      "Epoch 851/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0877\n",
      "Epoch 852/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0851\n",
      "Epoch 853/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0341\n",
      "Epoch 854/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0274\n",
      "Epoch 855/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0357\n",
      "Epoch 856/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0791\n",
      "Epoch 857/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0312\n",
      "Epoch 858/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0340\n",
      "Epoch 859/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0262\n",
      "Epoch 860/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0469\n",
      "Epoch 861/2500\n",
      "36/36 [==============================] - 0s 100us/step - loss: 0.0326\n",
      "Epoch 862/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0390\n",
      "Epoch 863/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0515\n",
      "Epoch 864/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0455\n",
      "Epoch 865/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0304\n",
      "Epoch 866/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0472\n",
      "Epoch 867/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0579\n",
      "Epoch 868/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0573\n",
      "Epoch 869/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0593\n",
      "Epoch 870/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0451\n",
      "Epoch 871/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0355\n",
      "Epoch 872/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0712\n",
      "Epoch 873/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0504\n",
      "Epoch 874/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0309\n",
      "Epoch 875/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0285\n",
      "Epoch 876/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0624\n",
      "Epoch 877/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0557\n",
      "Epoch 878/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0778\n",
      "Epoch 879/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0508\n",
      "Epoch 880/2500\n",
      "36/36 [==============================] - 0s 122us/step - loss: 0.0575\n",
      "Epoch 881/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0357\n",
      "Epoch 882/2500\n",
      "36/36 [==============================] - 0s 100us/step - loss: 0.0493\n",
      "Epoch 883/2500\n",
      "36/36 [==============================] - 0s 128us/step - loss: 0.0470\n",
      "Epoch 884/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0419\n",
      "Epoch 885/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0347\n",
      "Epoch 886/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0388\n",
      "Epoch 887/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0715\n",
      "Epoch 888/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0533\n",
      "Epoch 889/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0278\n",
      "Epoch 890/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0719\n",
      "Epoch 891/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0954\n",
      "Epoch 892/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0712\n",
      "Epoch 893/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0367\n",
      "Epoch 894/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0247\n",
      "Epoch 895/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0631\n",
      "Epoch 896/2500\n",
      "36/36 [==============================] - 0s 121us/step - loss: 0.0393\n",
      "Epoch 897/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0363\n",
      "Epoch 898/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0353\n",
      "Epoch 899/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0574\n",
      "Epoch 900/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0503\n",
      "Epoch 901/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0390\n",
      "Epoch 902/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0430\n",
      "Epoch 903/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0567\n",
      "Epoch 904/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0480\n",
      "Epoch 905/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0612\n",
      "Epoch 906/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0411\n",
      "Epoch 907/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0359\n",
      "Epoch 908/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0480\n",
      "Epoch 909/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0494\n",
      "Epoch 910/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0402\n",
      "Epoch 911/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0260\n",
      "Epoch 912/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0381\n",
      "Epoch 913/2500\n",
      "36/36 [==============================] - 0s 121us/step - loss: 0.0542\n",
      "Epoch 914/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0377\n",
      "Epoch 915/2500\n",
      "36/36 [==============================] - 0s 121us/step - loss: 0.1070\n",
      "Epoch 916/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0858\n",
      "Epoch 917/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0556\n",
      "Epoch 918/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0402\n",
      "Epoch 919/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0345\n",
      "Epoch 920/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0398\n",
      "Epoch 921/2500\n",
      "36/36 [==============================] - 0s 123us/step - loss: 0.0618\n",
      "Epoch 922/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0868\n",
      "Epoch 923/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0385\n",
      "Epoch 924/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0589\n",
      "Epoch 925/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0872\n",
      "Epoch 926/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0439\n",
      "Epoch 927/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0435\n",
      "Epoch 928/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0384\n",
      "Epoch 929/2500\n",
      "36/36 [==============================] - 0s 123us/step - loss: 0.0555\n",
      "Epoch 930/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0365\n",
      "Epoch 931/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0502\n",
      "Epoch 932/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0537\n",
      "Epoch 933/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0617\n",
      "Epoch 934/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0730\n",
      "Epoch 935/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0718\n",
      "Epoch 936/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0410\n",
      "Epoch 937/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0715\n",
      "Epoch 938/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0426\n",
      "Epoch 939/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0514\n",
      "Epoch 940/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0560\n",
      "Epoch 941/2500\n",
      "36/36 [==============================] - 0s 121us/step - loss: 0.0331\n",
      "Epoch 942/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0432\n",
      "Epoch 943/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0507\n",
      "Epoch 944/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0614\n",
      "Epoch 945/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0348\n",
      "Epoch 946/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0516\n",
      "Epoch 947/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0313\n",
      "Epoch 948/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0641\n",
      "Epoch 949/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0437\n",
      "Epoch 950/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0579\n",
      "Epoch 951/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0598\n",
      "Epoch 952/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0280\n",
      "Epoch 953/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0767\n",
      "Epoch 954/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0702\n",
      "Epoch 955/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0512\n",
      "Epoch 956/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0506\n",
      "Epoch 957/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0470\n",
      "Epoch 958/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.1034\n",
      "Epoch 959/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0647\n",
      "Epoch 960/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0590\n",
      "Epoch 961/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0361\n",
      "Epoch 962/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0436\n",
      "Epoch 963/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0776\n",
      "Epoch 964/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0461\n",
      "Epoch 965/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0567\n",
      "Epoch 966/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0621\n",
      "Epoch 967/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0545\n",
      "Epoch 968/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0479\n",
      "Epoch 969/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0347\n",
      "Epoch 970/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0370\n",
      "Epoch 971/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0692\n",
      "Epoch 972/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0961\n",
      "Epoch 973/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0463\n",
      "Epoch 974/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0613\n",
      "Epoch 975/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0696\n",
      "Epoch 976/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0261\n",
      "Epoch 977/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0338\n",
      "Epoch 978/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0254\n",
      "Epoch 979/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0490\n",
      "Epoch 980/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0688\n",
      "Epoch 981/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0445\n",
      "Epoch 982/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0531\n",
      "Epoch 983/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0434\n",
      "Epoch 984/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0493\n",
      "Epoch 985/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0344\n",
      "Epoch 986/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0600\n",
      "Epoch 987/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0435\n",
      "Epoch 988/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0460\n",
      "Epoch 989/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0377\n",
      "Epoch 990/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0923\n",
      "Epoch 991/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0378\n",
      "Epoch 992/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0505\n",
      "Epoch 993/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0464\n",
      "Epoch 994/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0414\n",
      "Epoch 995/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0414\n",
      "Epoch 996/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0383\n",
      "Epoch 997/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0407\n",
      "Epoch 998/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0357\n",
      "Epoch 999/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0447\n",
      "Epoch 1000/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0463\n",
      "Epoch 1001/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0493\n",
      "Epoch 1002/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0326\n",
      "Epoch 1003/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0374\n",
      "Epoch 1004/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0261\n",
      "Epoch 1005/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0490\n",
      "Epoch 1006/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0964\n",
      "Epoch 1007/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0324\n",
      "Epoch 1008/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0363\n",
      "Epoch 1009/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0305\n",
      "Epoch 1010/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0487\n",
      "Epoch 1011/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0337\n",
      "Epoch 1012/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0650\n",
      "Epoch 1013/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0496\n",
      "Epoch 1014/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0510\n",
      "Epoch 1015/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0544\n",
      "Epoch 1016/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0567\n",
      "Epoch 1017/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0353\n",
      "Epoch 1018/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0491\n",
      "Epoch 1019/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0562\n",
      "Epoch 1020/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0807\n",
      "Epoch 1021/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0335\n",
      "Epoch 1022/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.1047\n",
      "Epoch 1023/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0706\n",
      "Epoch 1024/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0393\n",
      "Epoch 1025/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0805\n",
      "Epoch 1026/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0395\n",
      "Epoch 1027/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0448\n",
      "Epoch 1028/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0369\n",
      "Epoch 1029/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0864\n",
      "Epoch 1030/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0442\n",
      "Epoch 1031/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0626\n",
      "Epoch 1032/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0402\n",
      "Epoch 1033/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0428\n",
      "Epoch 1034/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0550\n",
      "Epoch 1035/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0351\n",
      "Epoch 1036/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0329\n",
      "Epoch 1037/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0509\n",
      "Epoch 1038/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0368\n",
      "Epoch 1039/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0802\n",
      "Epoch 1040/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0411\n",
      "Epoch 1041/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0374\n",
      "Epoch 1042/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0680\n",
      "Epoch 1043/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0379\n",
      "Epoch 1044/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0384\n",
      "Epoch 1045/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0306\n",
      "Epoch 1046/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0296\n",
      "Epoch 1047/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0428\n",
      "Epoch 1048/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0427\n",
      "Epoch 1049/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0692\n",
      "Epoch 1050/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0611\n",
      "Epoch 1051/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0566\n",
      "Epoch 1052/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0687\n",
      "Epoch 1053/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0465\n",
      "Epoch 1054/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0752\n",
      "Epoch 1055/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0810\n",
      "Epoch 1056/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0389\n",
      "Epoch 1057/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0372\n",
      "Epoch 1058/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0365\n",
      "Epoch 1059/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0577\n",
      "Epoch 1060/2500\n",
      "36/36 [==============================] - 0s 122us/step - loss: 0.0325\n",
      "Epoch 1061/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0406\n",
      "Epoch 1062/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0408\n",
      "Epoch 1063/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0255\n",
      "Epoch 1064/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0301\n",
      "Epoch 1065/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0518\n",
      "Epoch 1066/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0407\n",
      "Epoch 1067/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0755\n",
      "Epoch 1068/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0506\n",
      "Epoch 1069/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0376\n",
      "Epoch 1070/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0252\n",
      "Epoch 1071/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0502\n",
      "Epoch 1072/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0516\n",
      "Epoch 1073/2500\n",
      "36/36 [==============================] - 0s 122us/step - loss: 0.0390\n",
      "Epoch 1074/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0595\n",
      "Epoch 1075/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0513\n",
      "Epoch 1076/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0460\n",
      "Epoch 1077/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0867\n",
      "Epoch 1078/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0597\n",
      "Epoch 1079/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0475\n",
      "Epoch 1080/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0405\n",
      "Epoch 1081/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0540\n",
      "Epoch 1082/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0376\n",
      "Epoch 1083/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0290\n",
      "Epoch 1084/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0298\n",
      "Epoch 1085/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0435\n",
      "Epoch 1086/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0601\n",
      "Epoch 1087/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0922\n",
      "Epoch 1088/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0686\n",
      "Epoch 1089/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0531\n",
      "Epoch 1090/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0447\n",
      "Epoch 1091/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0562\n",
      "Epoch 1092/2500\n",
      "36/36 [==============================] - 0s 100us/step - loss: 0.0571\n",
      "Epoch 1093/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0288\n",
      "Epoch 1094/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0559\n",
      "Epoch 1095/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0569\n",
      "Epoch 1096/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.1233\n",
      "Epoch 1097/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0455\n",
      "Epoch 1098/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0542\n",
      "Epoch 1099/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.1119\n",
      "Epoch 1100/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0519\n",
      "Epoch 1101/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0557\n",
      "Epoch 1102/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0364\n",
      "Epoch 1103/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0535\n",
      "Epoch 1104/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0363\n",
      "Epoch 1105/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0576\n",
      "Epoch 1106/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0513\n",
      "Epoch 1107/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0376\n",
      "Epoch 1108/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0345\n",
      "Epoch 1109/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0716\n",
      "Epoch 1110/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0338\n",
      "Epoch 1111/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0409\n",
      "Epoch 1112/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0467\n",
      "Epoch 1113/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0460\n",
      "Epoch 1114/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0412\n",
      "Epoch 1115/2500\n",
      "36/36 [==============================] - 0s 122us/step - loss: 0.0511\n",
      "Epoch 1116/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0625\n",
      "Epoch 1117/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0427\n",
      "Epoch 1118/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0627\n",
      "Epoch 1119/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0336\n",
      "Epoch 1120/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0780\n",
      "Epoch 1121/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0475\n",
      "Epoch 1122/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0710\n",
      "Epoch 1123/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0675\n",
      "Epoch 1124/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0474\n",
      "Epoch 1125/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0570\n",
      "Epoch 1126/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0990\n",
      "Epoch 1127/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0468\n",
      "Epoch 1128/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0447\n",
      "Epoch 1129/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0495\n",
      "Epoch 1130/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0302\n",
      "Epoch 1131/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0260\n",
      "Epoch 1132/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0401\n",
      "Epoch 1133/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0579\n",
      "Epoch 1134/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0634\n",
      "Epoch 1135/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0460\n",
      "Epoch 1136/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0470\n",
      "Epoch 1137/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0536\n",
      "Epoch 1138/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0832\n",
      "Epoch 1139/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0494\n",
      "Epoch 1140/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0401\n",
      "Epoch 1141/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0469\n",
      "Epoch 1142/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0289\n",
      "Epoch 1143/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0738\n",
      "Epoch 1144/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0387\n",
      "Epoch 1145/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0497\n",
      "Epoch 1146/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0572\n",
      "Epoch 1147/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0358\n",
      "Epoch 1148/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0412\n",
      "Epoch 1149/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0432\n",
      "Epoch 1150/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0736\n",
      "Epoch 1151/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0569\n",
      "Epoch 1152/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0348\n",
      "Epoch 1153/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0500\n",
      "Epoch 1154/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0332\n",
      "Epoch 1155/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0500\n",
      "Epoch 1156/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0283\n",
      "Epoch 1157/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0695\n",
      "Epoch 1158/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0902\n",
      "Epoch 1159/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0700\n",
      "Epoch 1160/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0574\n",
      "Epoch 1161/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0363\n",
      "Epoch 1162/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0392\n",
      "Epoch 1163/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0560\n",
      "Epoch 1164/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0450\n",
      "Epoch 1165/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0245\n",
      "Epoch 1166/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0570\n",
      "Epoch 1167/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0422\n",
      "Epoch 1168/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0581\n",
      "Epoch 1169/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.1081\n",
      "Epoch 1170/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0458\n",
      "Epoch 1171/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0569\n",
      "Epoch 1172/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0360\n",
      "Epoch 1173/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0746\n",
      "Epoch 1174/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0442\n",
      "Epoch 1175/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0438\n",
      "Epoch 1176/2500\n",
      "36/36 [==============================] - 0s 132us/step - loss: 0.0396\n",
      "Epoch 1177/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0402\n",
      "Epoch 1178/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0474\n",
      "Epoch 1179/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0608\n",
      "Epoch 1180/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0479\n",
      "Epoch 1181/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0277\n",
      "Epoch 1182/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0350\n",
      "Epoch 1183/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0612\n",
      "Epoch 1184/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0635\n",
      "Epoch 1185/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0715\n",
      "Epoch 1186/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0667\n",
      "Epoch 1187/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0491\n",
      "Epoch 1188/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0513\n",
      "Epoch 1189/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0352\n",
      "Epoch 1190/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0412\n",
      "Epoch 1191/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0501\n",
      "Epoch 1192/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0695\n",
      "Epoch 1193/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0450\n",
      "Epoch 1194/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0420\n",
      "Epoch 1195/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0400\n",
      "Epoch 1196/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0450\n",
      "Epoch 1197/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0683\n",
      "Epoch 1198/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0680\n",
      "Epoch 1199/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0672\n",
      "Epoch 1200/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0502\n",
      "Epoch 1201/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0352\n",
      "Epoch 1202/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0655\n",
      "Epoch 1203/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0404\n",
      "Epoch 1204/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0590\n",
      "Epoch 1205/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0913\n",
      "Epoch 1206/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0697\n",
      "Epoch 1207/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0328\n",
      "Epoch 1208/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0867\n",
      "Epoch 1209/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0380\n",
      "Epoch 1210/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0339\n",
      "Epoch 1211/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0794\n",
      "Epoch 1212/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0286\n",
      "Epoch 1213/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0615\n",
      "Epoch 1214/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0584\n",
      "Epoch 1215/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0686\n",
      "Epoch 1216/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0662\n",
      "Epoch 1217/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0385\n",
      "Epoch 1218/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0421\n",
      "Epoch 1219/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0718\n",
      "Epoch 1220/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0437\n",
      "Epoch 1221/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0667\n",
      "Epoch 1222/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0507\n",
      "Epoch 1223/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0357\n",
      "Epoch 1224/2500\n",
      "36/36 [==============================] - 0s 124us/step - loss: 0.0478\n",
      "Epoch 1225/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0592\n",
      "Epoch 1226/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0501\n",
      "Epoch 1227/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0577\n",
      "Epoch 1228/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0376\n",
      "Epoch 1229/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0461\n",
      "Epoch 1230/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0634\n",
      "Epoch 1231/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0859\n",
      "Epoch 1232/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0375\n",
      "Epoch 1233/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0546\n",
      "Epoch 1234/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0931\n",
      "Epoch 1235/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0833\n",
      "Epoch 1236/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0471\n",
      "Epoch 1237/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0390\n",
      "Epoch 1238/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0571\n",
      "Epoch 1239/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0608\n",
      "Epoch 1240/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0432\n",
      "Epoch 1241/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.1022\n",
      "Epoch 1242/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0553\n",
      "Epoch 1243/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0315\n",
      "Epoch 1244/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0542\n",
      "Epoch 1245/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0514\n",
      "Epoch 1246/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0420\n",
      "Epoch 1247/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0421\n",
      "Epoch 1248/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0842\n",
      "Epoch 1249/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0430\n",
      "Epoch 1250/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0364\n",
      "Epoch 1251/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0486\n",
      "Epoch 1252/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0647\n",
      "Epoch 1253/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0462\n",
      "Epoch 1254/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0413\n",
      "Epoch 1255/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0448\n",
      "Epoch 1256/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0511\n",
      "Epoch 1257/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0453\n",
      "Epoch 1258/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0369\n",
      "Epoch 1259/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0283\n",
      "Epoch 1260/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0389\n",
      "Epoch 1261/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0452\n",
      "Epoch 1262/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0344\n",
      "Epoch 1263/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0512\n",
      "Epoch 1264/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0559\n",
      "Epoch 1265/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0417\n",
      "Epoch 1266/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.1177\n",
      "Epoch 1267/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0489\n",
      "Epoch 1268/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0295\n",
      "Epoch 1269/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0407\n",
      "Epoch 1270/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0365\n",
      "Epoch 1271/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0412\n",
      "Epoch 1272/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.1033\n",
      "Epoch 1273/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0813\n",
      "Epoch 1274/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0405\n",
      "Epoch 1275/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0376\n",
      "Epoch 1276/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0588\n",
      "Epoch 1277/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0638\n",
      "Epoch 1278/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0544\n",
      "Epoch 1279/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0355\n",
      "Epoch 1280/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0285\n",
      "Epoch 1281/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0614\n",
      "Epoch 1282/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0513\n",
      "Epoch 1283/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0415\n",
      "Epoch 1284/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0377\n",
      "Epoch 1285/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0911\n",
      "Epoch 1286/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0511\n",
      "Epoch 1287/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0832\n",
      "Epoch 1288/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0305\n",
      "Epoch 1289/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0875\n",
      "Epoch 1290/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0385\n",
      "Epoch 1291/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0416\n",
      "Epoch 1292/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0372\n",
      "Epoch 1293/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0307\n",
      "Epoch 1294/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0547\n",
      "Epoch 1295/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0437\n",
      "Epoch 1296/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0430\n",
      "Epoch 1297/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0446\n",
      "Epoch 1298/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0440\n",
      "Epoch 1299/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0586\n",
      "Epoch 1300/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0491\n",
      "Epoch 1301/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0462\n",
      "Epoch 1302/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0366\n",
      "Epoch 1303/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0821\n",
      "Epoch 1304/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0701\n",
      "Epoch 1305/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0917\n",
      "Epoch 1306/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0418\n",
      "Epoch 1307/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0412\n",
      "Epoch 1308/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0411\n",
      "Epoch 1309/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0372\n",
      "Epoch 1310/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0630\n",
      "Epoch 1311/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0511\n",
      "Epoch 1312/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0429\n",
      "Epoch 1313/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0405\n",
      "Epoch 1314/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0324\n",
      "Epoch 1315/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0386\n",
      "Epoch 1316/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0464\n",
      "Epoch 1317/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0526\n",
      "Epoch 1318/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0532\n",
      "Epoch 1319/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0404\n",
      "Epoch 1320/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0534\n",
      "Epoch 1321/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0356\n",
      "Epoch 1322/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0287\n",
      "Epoch 1323/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0514\n",
      "Epoch 1324/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0611\n",
      "Epoch 1325/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0771\n",
      "Epoch 1326/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0563\n",
      "Epoch 1327/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0400\n",
      "Epoch 1328/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0406\n",
      "Epoch 1329/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0378\n",
      "Epoch 1330/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0518\n",
      "Epoch 1331/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0390\n",
      "Epoch 1332/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0529\n",
      "Epoch 1333/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0842\n",
      "Epoch 1334/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0477\n",
      "Epoch 1335/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0529\n",
      "Epoch 1336/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0528\n",
      "Epoch 1337/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0476\n",
      "Epoch 1338/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0585\n",
      "Epoch 1339/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0509\n",
      "Epoch 1340/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0349\n",
      "Epoch 1341/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0470\n",
      "Epoch 1342/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0703\n",
      "Epoch 1343/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0552\n",
      "Epoch 1344/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0247\n",
      "Epoch 1345/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0556\n",
      "Epoch 1346/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0434\n",
      "Epoch 1347/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0318\n",
      "Epoch 1348/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0403\n",
      "Epoch 1349/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0440\n",
      "Epoch 1350/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0375\n",
      "Epoch 1351/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0952\n",
      "Epoch 1352/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0557\n",
      "Epoch 1353/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0603\n",
      "Epoch 1354/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0298\n",
      "Epoch 1355/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0389\n",
      "Epoch 1356/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0415\n",
      "Epoch 1357/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0369\n",
      "Epoch 1358/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0535\n",
      "Epoch 1359/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0579\n",
      "Epoch 1360/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0670\n",
      "Epoch 1361/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0513\n",
      "Epoch 1362/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0286\n",
      "Epoch 1363/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0420\n",
      "Epoch 1364/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0526\n",
      "Epoch 1365/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0511\n",
      "Epoch 1366/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0818\n",
      "Epoch 1367/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0419\n",
      "Epoch 1368/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0607\n",
      "Epoch 1369/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0518\n",
      "Epoch 1370/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0515\n",
      "Epoch 1371/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0378\n",
      "Epoch 1372/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0423\n",
      "Epoch 1373/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0962\n",
      "Epoch 1374/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0420\n",
      "Epoch 1375/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0648\n",
      "Epoch 1376/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0638\n",
      "Epoch 1377/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0414\n",
      "Epoch 1378/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0432\n",
      "Epoch 1379/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0415\n",
      "Epoch 1380/2500\n",
      "36/36 [==============================] - 0s 127us/step - loss: 0.0590\n",
      "Epoch 1381/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0381\n",
      "Epoch 1382/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0218\n",
      "Epoch 1383/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0373\n",
      "Epoch 1384/2500\n",
      "36/36 [==============================] - 0s 122us/step - loss: 0.0303\n",
      "Epoch 1385/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0657\n",
      "Epoch 1386/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0416\n",
      "Epoch 1387/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0257\n",
      "Epoch 1388/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0255\n",
      "Epoch 1389/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0730\n",
      "Epoch 1390/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0498\n",
      "Epoch 1391/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0474\n",
      "Epoch 1392/2500\n",
      "36/36 [==============================] - 0s 121us/step - loss: 0.0367\n",
      "Epoch 1393/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0467\n",
      "Epoch 1394/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0360\n",
      "Epoch 1395/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0745\n",
      "Epoch 1396/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.1014\n",
      "Epoch 1397/2500\n",
      "36/36 [==============================] - 0s 125us/step - loss: 0.0586\n",
      "Epoch 1398/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0548\n",
      "Epoch 1399/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0388\n",
      "Epoch 1400/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0345\n",
      "Epoch 1401/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0908\n",
      "Epoch 1402/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0392\n",
      "Epoch 1403/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0381\n",
      "Epoch 1404/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0265\n",
      "Epoch 1405/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0755\n",
      "Epoch 1406/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0384\n",
      "Epoch 1407/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0434\n",
      "Epoch 1408/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0404\n",
      "Epoch 1409/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0486\n",
      "Epoch 1410/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0459\n",
      "Epoch 1411/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0285\n",
      "Epoch 1412/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0419\n",
      "Epoch 1413/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0279\n",
      "Epoch 1414/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.1042\n",
      "Epoch 1415/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0849\n",
      "Epoch 1416/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0579\n",
      "Epoch 1417/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0650\n",
      "Epoch 1418/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0647\n",
      "Epoch 1419/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0559\n",
      "Epoch 1420/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0437\n",
      "Epoch 1421/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0545\n",
      "Epoch 1422/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0651\n",
      "Epoch 1423/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0312\n",
      "Epoch 1424/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0544\n",
      "Epoch 1425/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0326\n",
      "Epoch 1426/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0463\n",
      "Epoch 1427/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0487\n",
      "Epoch 1428/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0446\n",
      "Epoch 1429/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0449\n",
      "Epoch 1430/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0494\n",
      "Epoch 1431/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0477\n",
      "Epoch 1432/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0458\n",
      "Epoch 1433/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0500\n",
      "Epoch 1434/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0494\n",
      "Epoch 1435/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0425\n",
      "Epoch 1436/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0652\n",
      "Epoch 1437/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0592\n",
      "Epoch 1438/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0695\n",
      "Epoch 1439/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0503\n",
      "Epoch 1440/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0413\n",
      "Epoch 1441/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0499\n",
      "Epoch 1442/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0616\n",
      "Epoch 1443/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0408\n",
      "Epoch 1444/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0326\n",
      "Epoch 1445/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0332\n",
      "Epoch 1446/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0666\n",
      "Epoch 1447/2500\n",
      "36/36 [==============================] - 0s 124us/step - loss: 0.0495\n",
      "Epoch 1448/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0540\n",
      "Epoch 1449/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0653\n",
      "Epoch 1450/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0637\n",
      "Epoch 1451/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0463\n",
      "Epoch 1452/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0439\n",
      "Epoch 1453/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0492\n",
      "Epoch 1454/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0865\n",
      "Epoch 1455/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0510\n",
      "Epoch 1456/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0283\n",
      "Epoch 1457/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0501\n",
      "Epoch 1458/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0645\n",
      "Epoch 1459/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0402\n",
      "Epoch 1460/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0425\n",
      "Epoch 1461/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0509\n",
      "Epoch 1462/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0435\n",
      "Epoch 1463/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0727\n",
      "Epoch 1464/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0493\n",
      "Epoch 1465/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0606\n",
      "Epoch 1466/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0358\n",
      "Epoch 1467/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0405\n",
      "Epoch 1468/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0425\n",
      "Epoch 1469/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0801\n",
      "Epoch 1470/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0648\n",
      "Epoch 1471/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0281\n",
      "Epoch 1472/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0629\n",
      "Epoch 1473/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0461\n",
      "Epoch 1474/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0327\n",
      "Epoch 1475/2500\n",
      "36/36 [==============================] - 0s 100us/step - loss: 0.0528\n",
      "Epoch 1476/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0402\n",
      "Epoch 1477/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0440\n",
      "Epoch 1478/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0467\n",
      "Epoch 1479/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0487\n",
      "Epoch 1480/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0477\n",
      "Epoch 1481/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0327\n",
      "Epoch 1482/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0392\n",
      "Epoch 1483/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0411\n",
      "Epoch 1484/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0999\n",
      "Epoch 1485/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0479\n",
      "Epoch 1486/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0259\n",
      "Epoch 1487/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0358\n",
      "Epoch 1488/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0236\n",
      "Epoch 1489/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0299\n",
      "Epoch 1490/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0319\n",
      "Epoch 1491/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0397\n",
      "Epoch 1492/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0528\n",
      "Epoch 1493/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0421\n",
      "Epoch 1494/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0374\n",
      "Epoch 1495/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0514\n",
      "Epoch 1496/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0700\n",
      "Epoch 1497/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0331\n",
      "Epoch 1498/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0350\n",
      "Epoch 1499/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0554\n",
      "Epoch 1500/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0608\n",
      "Epoch 1501/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0985\n",
      "Epoch 1502/2500\n",
      "36/36 [==============================] - 0s 98us/step - loss: 0.0699\n",
      "Epoch 1503/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0370\n",
      "Epoch 1504/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0398\n",
      "Epoch 1505/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0385\n",
      "Epoch 1506/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0725\n",
      "Epoch 1507/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0437\n",
      "Epoch 1508/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0492\n",
      "Epoch 1509/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0757\n",
      "Epoch 1510/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0380\n",
      "Epoch 1511/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0303\n",
      "Epoch 1512/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0377\n",
      "Epoch 1513/2500\n",
      "36/36 [==============================] - 0s 123us/step - loss: 0.0870\n",
      "Epoch 1514/2500\n",
      "36/36 [==============================] - 0s 124us/step - loss: 0.0382\n",
      "Epoch 1515/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0292\n",
      "Epoch 1516/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0435\n",
      "Epoch 1517/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0267\n",
      "Epoch 1518/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0566\n",
      "Epoch 1519/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0643\n",
      "Epoch 1520/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.1000\n",
      "Epoch 1521/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0426\n",
      "Epoch 1522/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0739\n",
      "Epoch 1523/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0518\n",
      "Epoch 1524/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0422\n",
      "Epoch 1525/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0536\n",
      "Epoch 1526/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0415\n",
      "Epoch 1527/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0505\n",
      "Epoch 1528/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0386\n",
      "Epoch 1529/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0367\n",
      "Epoch 1530/2500\n",
      "36/36 [==============================] - 0s 123us/step - loss: 0.0381\n",
      "Epoch 1531/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0308\n",
      "Epoch 1532/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0593\n",
      "Epoch 1533/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0381\n",
      "Epoch 1534/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0747\n",
      "Epoch 1535/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0357\n",
      "Epoch 1536/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0419\n",
      "Epoch 1537/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0642\n",
      "Epoch 1538/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.1200\n",
      "Epoch 1539/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0669\n",
      "Epoch 1540/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0699\n",
      "Epoch 1541/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0304\n",
      "Epoch 1542/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0424\n",
      "Epoch 1543/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0523\n",
      "Epoch 1544/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0386\n",
      "Epoch 1545/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0304\n",
      "Epoch 1546/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0488\n",
      "Epoch 1547/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0746\n",
      "Epoch 1548/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0420\n",
      "Epoch 1549/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.1198\n",
      "Epoch 1550/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0777\n",
      "Epoch 1551/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0496\n",
      "Epoch 1552/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0806\n",
      "Epoch 1553/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0630\n",
      "Epoch 1554/2500\n",
      "36/36 [==============================] - 0s 100us/step - loss: 0.0509\n",
      "Epoch 1555/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0513\n",
      "Epoch 1556/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0514\n",
      "Epoch 1557/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0482\n",
      "Epoch 1558/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0346\n",
      "Epoch 1559/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0894\n",
      "Epoch 1560/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0330\n",
      "Epoch 1561/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0406\n",
      "Epoch 1562/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0368\n",
      "Epoch 1563/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0427\n",
      "Epoch 1564/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0625\n",
      "Epoch 1565/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0361\n",
      "Epoch 1566/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0290\n",
      "Epoch 1567/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0305\n",
      "Epoch 1568/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0393\n",
      "Epoch 1569/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0585\n",
      "Epoch 1570/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0423\n",
      "Epoch 1571/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0441\n",
      "Epoch 1572/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0425\n",
      "Epoch 1573/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0344\n",
      "Epoch 1574/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0610\n",
      "Epoch 1575/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0351\n",
      "Epoch 1576/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0373\n",
      "Epoch 1577/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0582\n",
      "Epoch 1578/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0441\n",
      "Epoch 1579/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0414\n",
      "Epoch 1580/2500\n",
      "36/36 [==============================] - 0s 100us/step - loss: 0.0451\n",
      "Epoch 1581/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0540\n",
      "Epoch 1582/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0554\n",
      "Epoch 1583/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0601\n",
      "Epoch 1584/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0461\n",
      "Epoch 1585/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0987\n",
      "Epoch 1586/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0399\n",
      "Epoch 1587/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0454\n",
      "Epoch 1588/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0454\n",
      "Epoch 1589/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0399\n",
      "Epoch 1590/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0508\n",
      "Epoch 1591/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0384\n",
      "Epoch 1592/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0408\n",
      "Epoch 1593/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0705\n",
      "Epoch 1594/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0487\n",
      "Epoch 1595/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0369\n",
      "Epoch 1596/2500\n",
      "36/36 [==============================] - 0s 99us/step - loss: 0.0433\n",
      "Epoch 1597/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0417\n",
      "Epoch 1598/2500\n",
      "36/36 [==============================] - 0s 92us/step - loss: 0.0403\n",
      "Epoch 1599/2500\n",
      "36/36 [==============================] - 0s 98us/step - loss: 0.0319\n",
      "Epoch 1600/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0548\n",
      "Epoch 1601/2500\n",
      "36/36 [==============================] - 0s 97us/step - loss: 0.0558\n",
      "Epoch 1602/2500\n",
      "36/36 [==============================] - 0s 100us/step - loss: 0.0808\n",
      "Epoch 1603/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0539\n",
      "Epoch 1604/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0662\n",
      "Epoch 1605/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0921\n",
      "Epoch 1606/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0520\n",
      "Epoch 1607/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0742\n",
      "Epoch 1608/2500\n",
      "36/36 [==============================] - 0s 121us/step - loss: 0.0536\n",
      "Epoch 1609/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0755\n",
      "Epoch 1610/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0806\n",
      "Epoch 1611/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0523\n",
      "Epoch 1612/2500\n",
      "36/36 [==============================] - 0s 96us/step - loss: 0.0589\n",
      "Epoch 1613/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0361\n",
      "Epoch 1614/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0461\n",
      "Epoch 1615/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0558\n",
      "Epoch 1616/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.1235\n",
      "Epoch 1617/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0458\n",
      "Epoch 1618/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0550\n",
      "Epoch 1619/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0214\n",
      "Epoch 1620/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0384\n",
      "Epoch 1621/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0248\n",
      "Epoch 1622/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0380\n",
      "Epoch 1623/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0473\n",
      "Epoch 1624/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0648\n",
      "Epoch 1625/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0360\n",
      "Epoch 1626/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0741\n",
      "Epoch 1627/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0610\n",
      "Epoch 1628/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0751\n",
      "Epoch 1629/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0915\n",
      "Epoch 1630/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0559\n",
      "Epoch 1631/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0591\n",
      "Epoch 1632/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0425\n",
      "Epoch 1633/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0464\n",
      "Epoch 1634/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0397\n",
      "Epoch 1635/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0324\n",
      "Epoch 1636/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0334\n",
      "Epoch 1637/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0638\n",
      "Epoch 1638/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0401\n",
      "Epoch 1639/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0291\n",
      "Epoch 1640/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0355\n",
      "Epoch 1641/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0657\n",
      "Epoch 1642/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0641\n",
      "Epoch 1643/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0703\n",
      "Epoch 1644/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0388\n",
      "Epoch 1645/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0602\n",
      "Epoch 1646/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0358\n",
      "Epoch 1647/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0632\n",
      "Epoch 1648/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0509\n",
      "Epoch 1649/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0685\n",
      "Epoch 1650/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0556\n",
      "Epoch 1651/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0485\n",
      "Epoch 1652/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0285\n",
      "Epoch 1653/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0385\n",
      "Epoch 1654/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0312\n",
      "Epoch 1655/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0286\n",
      "Epoch 1656/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0550\n",
      "Epoch 1657/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0772\n",
      "Epoch 1658/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0532\n",
      "Epoch 1659/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0420\n",
      "Epoch 1660/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0329\n",
      "Epoch 1661/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0733\n",
      "Epoch 1662/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0448\n",
      "Epoch 1663/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.1020\n",
      "Epoch 1664/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0584\n",
      "Epoch 1665/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0526\n",
      "Epoch 1666/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0403\n",
      "Epoch 1667/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0296\n",
      "Epoch 1668/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0536\n",
      "Epoch 1669/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0386\n",
      "Epoch 1670/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0591\n",
      "Epoch 1671/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0732\n",
      "Epoch 1672/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0441\n",
      "Epoch 1673/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0782\n",
      "Epoch 1674/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0612\n",
      "Epoch 1675/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0292\n",
      "Epoch 1676/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0670\n",
      "Epoch 1677/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0356\n",
      "Epoch 1678/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0585\n",
      "Epoch 1679/2500\n",
      "36/36 [==============================] - 0s 100us/step - loss: 0.0526\n",
      "Epoch 1680/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0580\n",
      "Epoch 1681/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0394\n",
      "Epoch 1682/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0554\n",
      "Epoch 1683/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0303\n",
      "Epoch 1684/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0557\n",
      "Epoch 1685/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0539\n",
      "Epoch 1686/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0501\n",
      "Epoch 1687/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0361\n",
      "Epoch 1688/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0670\n",
      "Epoch 1689/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0791\n",
      "Epoch 1690/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0502\n",
      "Epoch 1691/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0438\n",
      "Epoch 1692/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0483\n",
      "Epoch 1693/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0327\n",
      "Epoch 1694/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0490\n",
      "Epoch 1695/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0344\n",
      "Epoch 1696/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0325\n",
      "Epoch 1697/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0982\n",
      "Epoch 1698/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0471\n",
      "Epoch 1699/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0581\n",
      "Epoch 1700/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0393\n",
      "Epoch 1701/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0322\n",
      "Epoch 1702/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0305\n",
      "Epoch 1703/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0519\n",
      "Epoch 1704/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0423\n",
      "Epoch 1705/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0381\n",
      "Epoch 1706/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0305\n",
      "Epoch 1707/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0704\n",
      "Epoch 1708/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0774\n",
      "Epoch 1709/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.1441\n",
      "Epoch 1710/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0479\n",
      "Epoch 1711/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0465\n",
      "Epoch 1712/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0542\n",
      "Epoch 1713/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0489\n",
      "Epoch 1714/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0738\n",
      "Epoch 1715/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0301\n",
      "Epoch 1716/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0518\n",
      "Epoch 1717/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0517\n",
      "Epoch 1718/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0445\n",
      "Epoch 1719/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0314\n",
      "Epoch 1720/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0761\n",
      "Epoch 1721/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0744\n",
      "Epoch 1722/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0447\n",
      "Epoch 1723/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0513\n",
      "Epoch 1724/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0353\n",
      "Epoch 1725/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0716\n",
      "Epoch 1726/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0506\n",
      "Epoch 1727/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0414\n",
      "Epoch 1728/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0320\n",
      "Epoch 1729/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0400\n",
      "Epoch 1730/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0464\n",
      "Epoch 1731/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0497\n",
      "Epoch 1732/2500\n",
      "36/36 [==============================] - 0s 97us/step - loss: 0.0491\n",
      "Epoch 1733/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0504\n",
      "Epoch 1734/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0763\n",
      "Epoch 1735/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0527\n",
      "Epoch 1736/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0275\n",
      "Epoch 1737/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0438\n",
      "Epoch 1738/2500\n",
      "36/36 [==============================] - 0s 123us/step - loss: 0.0899\n",
      "Epoch 1739/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0423\n",
      "Epoch 1740/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0408\n",
      "Epoch 1741/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0341\n",
      "Epoch 1742/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0441\n",
      "Epoch 1743/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0429\n",
      "Epoch 1744/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0483\n",
      "Epoch 1745/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0836\n",
      "Epoch 1746/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0227\n",
      "Epoch 1747/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0268\n",
      "Epoch 1748/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0419\n",
      "Epoch 1749/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0388\n",
      "Epoch 1750/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0605\n",
      "Epoch 1751/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0669\n",
      "Epoch 1752/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0600\n",
      "Epoch 1753/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0495\n",
      "Epoch 1754/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0459\n",
      "Epoch 1755/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0424\n",
      "Epoch 1756/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0540\n",
      "Epoch 1757/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0510\n",
      "Epoch 1758/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0441\n",
      "Epoch 1759/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0478\n",
      "Epoch 1760/2500\n",
      "36/36 [==============================] - 0s 121us/step - loss: 0.0445\n",
      "Epoch 1761/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0339\n",
      "Epoch 1762/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0400\n",
      "Epoch 1763/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0318\n",
      "Epoch 1764/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0338\n",
      "Epoch 1765/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0301\n",
      "Epoch 1766/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0347\n",
      "Epoch 1767/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0239\n",
      "Epoch 1768/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.1048\n",
      "Epoch 1769/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0433\n",
      "Epoch 1770/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0540\n",
      "Epoch 1771/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0336\n",
      "Epoch 1772/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0533\n",
      "Epoch 1773/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0397\n",
      "Epoch 1774/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0609\n",
      "Epoch 1775/2500\n",
      "36/36 [==============================] - 0s 122us/step - loss: 0.0373\n",
      "Epoch 1776/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0508\n",
      "Epoch 1777/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0831\n",
      "Epoch 1778/2500\n",
      "36/36 [==============================] - 0s 99us/step - loss: 0.0420\n",
      "Epoch 1779/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0806\n",
      "Epoch 1780/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0488\n",
      "Epoch 1781/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0626\n",
      "Epoch 1782/2500\n",
      "36/36 [==============================] - 0s 99us/step - loss: 0.0502\n",
      "Epoch 1783/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0426\n",
      "Epoch 1784/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0329\n",
      "Epoch 1785/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0668\n",
      "Epoch 1786/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.1216\n",
      "Epoch 1787/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0711\n",
      "Epoch 1788/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0454\n",
      "Epoch 1789/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0515\n",
      "Epoch 1790/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0355\n",
      "Epoch 1791/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0437\n",
      "Epoch 1792/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0385\n",
      "Epoch 1793/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0476\n",
      "Epoch 1794/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0314\n",
      "Epoch 1795/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0507\n",
      "Epoch 1796/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0549\n",
      "Epoch 1797/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0400\n",
      "Epoch 1798/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0318\n",
      "Epoch 1799/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0406\n",
      "Epoch 1800/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0566\n",
      "Epoch 1801/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0371\n",
      "Epoch 1802/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0296\n",
      "Epoch 1803/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0241\n",
      "Epoch 1804/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0633\n",
      "Epoch 1805/2500\n",
      "36/36 [==============================] - 0s 126us/step - loss: 0.0690\n",
      "Epoch 1806/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0458\n",
      "Epoch 1807/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0598\n",
      "Epoch 1808/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0508\n",
      "Epoch 1809/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0468\n",
      "Epoch 1810/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0383\n",
      "Epoch 1811/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0693\n",
      "Epoch 1812/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0650\n",
      "Epoch 1813/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0393\n",
      "Epoch 1814/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0561\n",
      "Epoch 1815/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0379\n",
      "Epoch 1816/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0733\n",
      "Epoch 1817/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0412\n",
      "Epoch 1818/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0608\n",
      "Epoch 1819/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0460\n",
      "Epoch 1820/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0591\n",
      "Epoch 1821/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0414\n",
      "Epoch 1822/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0369\n",
      "Epoch 1823/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0379\n",
      "Epoch 1824/2500\n",
      "36/36 [==============================] - 0s 99us/step - loss: 0.0323\n",
      "Epoch 1825/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0637\n",
      "Epoch 1826/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0483\n",
      "Epoch 1827/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0324\n",
      "Epoch 1828/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0557\n",
      "Epoch 1829/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0578\n",
      "Epoch 1830/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0353\n",
      "Epoch 1831/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0937\n",
      "Epoch 1832/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0428\n",
      "Epoch 1833/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0312\n",
      "Epoch 1834/2500\n",
      "36/36 [==============================] - 0s 126us/step - loss: 0.0521\n",
      "Epoch 1835/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0351\n",
      "Epoch 1836/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0466\n",
      "Epoch 1837/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0286\n",
      "Epoch 1838/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0483\n",
      "Epoch 1839/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0695\n",
      "Epoch 1840/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0595\n",
      "Epoch 1841/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0418\n",
      "Epoch 1842/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0364\n",
      "Epoch 1843/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0239\n",
      "Epoch 1844/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0530\n",
      "Epoch 1845/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0435\n",
      "Epoch 1846/2500\n",
      "36/36 [==============================] - 0s 126us/step - loss: 0.0421\n",
      "Epoch 1847/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0512\n",
      "Epoch 1848/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0355\n",
      "Epoch 1849/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0298\n",
      "Epoch 1850/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0550\n",
      "Epoch 1851/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0455\n",
      "Epoch 1852/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0664\n",
      "Epoch 1853/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0659\n",
      "Epoch 1854/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0609\n",
      "Epoch 1855/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0544\n",
      "Epoch 1856/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0492\n",
      "Epoch 1857/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0355\n",
      "Epoch 1858/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0520\n",
      "Epoch 1859/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0412\n",
      "Epoch 1860/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0523\n",
      "Epoch 1861/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0275\n",
      "Epoch 1862/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0325\n",
      "Epoch 1863/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0683\n",
      "Epoch 1864/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0680\n",
      "Epoch 1865/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0567\n",
      "Epoch 1866/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0342\n",
      "Epoch 1867/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0451\n",
      "Epoch 1868/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0290\n",
      "Epoch 1869/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0352\n",
      "Epoch 1870/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0409\n",
      "Epoch 1871/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0459\n",
      "Epoch 1872/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0764\n",
      "Epoch 1873/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0676\n",
      "Epoch 1874/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0448\n",
      "Epoch 1875/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0744\n",
      "Epoch 1876/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0478\n",
      "Epoch 1877/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0270\n",
      "Epoch 1878/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0491\n",
      "Epoch 1879/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0391\n",
      "Epoch 1880/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0466\n",
      "Epoch 1881/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0437\n",
      "Epoch 1882/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0570\n",
      "Epoch 1883/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0374\n",
      "Epoch 1884/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0398\n",
      "Epoch 1885/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0384\n",
      "Epoch 1886/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0521\n",
      "Epoch 1887/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0408\n",
      "Epoch 1888/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0505\n",
      "Epoch 1889/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0554\n",
      "Epoch 1890/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0588\n",
      "Epoch 1891/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0672\n",
      "Epoch 1892/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0407\n",
      "Epoch 1893/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0689\n",
      "Epoch 1894/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0413\n",
      "Epoch 1895/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0488\n",
      "Epoch 1896/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0980\n",
      "Epoch 1897/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0393\n",
      "Epoch 1898/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0609\n",
      "Epoch 1899/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0340\n",
      "Epoch 1900/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0256\n",
      "Epoch 1901/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0490\n",
      "Epoch 1902/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0602\n",
      "Epoch 1903/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0362\n",
      "Epoch 1904/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0305\n",
      "Epoch 1905/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0377\n",
      "Epoch 1906/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0316\n",
      "Epoch 1907/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0638\n",
      "Epoch 1908/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0394\n",
      "Epoch 1909/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0262\n",
      "Epoch 1910/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0324\n",
      "Epoch 1911/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0434\n",
      "Epoch 1912/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0376\n",
      "Epoch 1913/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0588\n",
      "Epoch 1914/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0534\n",
      "Epoch 1915/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0515\n",
      "Epoch 1916/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0417\n",
      "Epoch 1917/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0391\n",
      "Epoch 1918/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0563\n",
      "Epoch 1919/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0581\n",
      "Epoch 1920/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0365\n",
      "Epoch 1921/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0427\n",
      "Epoch 1922/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0406\n",
      "Epoch 1923/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0321\n",
      "Epoch 1924/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0640\n",
      "Epoch 1925/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0672\n",
      "Epoch 1926/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0741\n",
      "Epoch 1927/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0427\n",
      "Epoch 1928/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.1150\n",
      "Epoch 1929/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0415\n",
      "Epoch 1930/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0337\n",
      "Epoch 1931/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0344\n",
      "Epoch 1932/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0459\n",
      "Epoch 1933/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0386\n",
      "Epoch 1934/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0706\n",
      "Epoch 1935/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0538\n",
      "Epoch 1936/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0456\n",
      "Epoch 1937/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0374\n",
      "Epoch 1938/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0363\n",
      "Epoch 1939/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0370\n",
      "Epoch 1940/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0421\n",
      "Epoch 1941/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0421\n",
      "Epoch 1942/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0535\n",
      "Epoch 1943/2500\n",
      "36/36 [==============================] - 0s 100us/step - loss: 0.0319\n",
      "Epoch 1944/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0609\n",
      "Epoch 1945/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0480\n",
      "Epoch 1946/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0677\n",
      "Epoch 1947/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0390\n",
      "Epoch 1948/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0984\n",
      "Epoch 1949/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0494\n",
      "Epoch 1950/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0524\n",
      "Epoch 1951/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0721\n",
      "Epoch 1952/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0421\n",
      "Epoch 1953/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0550\n",
      "Epoch 1954/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0382\n",
      "Epoch 1955/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0388\n",
      "Epoch 1956/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0430\n",
      "Epoch 1957/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0563\n",
      "Epoch 1958/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0536\n",
      "Epoch 1959/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0508\n",
      "Epoch 1960/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0681\n",
      "Epoch 1961/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0656\n",
      "Epoch 1962/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0289\n",
      "Epoch 1963/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0449\n",
      "Epoch 1964/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0456\n",
      "Epoch 1965/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0314\n",
      "Epoch 1966/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0558\n",
      "Epoch 1967/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0744\n",
      "Epoch 1968/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0523\n",
      "Epoch 1969/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0481\n",
      "Epoch 1970/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0351\n",
      "Epoch 1971/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0416\n",
      "Epoch 1972/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0499\n",
      "Epoch 1973/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0484\n",
      "Epoch 1974/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0597\n",
      "Epoch 1975/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0372\n",
      "Epoch 1976/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0516\n",
      "Epoch 1977/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0590\n",
      "Epoch 1978/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0867\n",
      "Epoch 1979/2500\n",
      "36/36 [==============================] - 0s 100us/step - loss: 0.0600\n",
      "Epoch 1980/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0404\n",
      "Epoch 1981/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0479\n",
      "Epoch 1982/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0511\n",
      "Epoch 1983/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0762\n",
      "Epoch 1984/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0726\n",
      "Epoch 1985/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0683\n",
      "Epoch 1986/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0727\n",
      "Epoch 1987/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0342\n",
      "Epoch 1988/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0325\n",
      "Epoch 1989/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0499\n",
      "Epoch 1990/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0461\n",
      "Epoch 1991/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0582\n",
      "Epoch 1992/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0400\n",
      "Epoch 1993/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0385\n",
      "Epoch 1994/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0431\n",
      "Epoch 1995/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0418\n",
      "Epoch 1996/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0329\n",
      "Epoch 1997/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0345\n",
      "Epoch 1998/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0411\n",
      "Epoch 1999/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0424\n",
      "Epoch 2000/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0297\n",
      "Epoch 2001/2500\n",
      "36/36 [==============================] - 0s 125us/step - loss: 0.0748\n",
      "Epoch 2002/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0797\n",
      "Epoch 2003/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0470\n",
      "Epoch 2004/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0409\n",
      "Epoch 2005/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0614\n",
      "Epoch 2006/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0439\n",
      "Epoch 2007/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0462\n",
      "Epoch 2008/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0358\n",
      "Epoch 2009/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0602\n",
      "Epoch 2010/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0596\n",
      "Epoch 2011/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0354\n",
      "Epoch 2012/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0586\n",
      "Epoch 2013/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0905\n",
      "Epoch 2014/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0265\n",
      "Epoch 2015/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0504\n",
      "Epoch 2016/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0250\n",
      "Epoch 2017/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0308\n",
      "Epoch 2018/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0544\n",
      "Epoch 2019/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0462\n",
      "Epoch 2020/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0389\n",
      "Epoch 2021/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0413\n",
      "Epoch 2022/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0952\n",
      "Epoch 2023/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0475\n",
      "Epoch 2024/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0724\n",
      "Epoch 2025/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0463\n",
      "Epoch 2026/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0608\n",
      "Epoch 2027/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0397\n",
      "Epoch 2028/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0361\n",
      "Epoch 2029/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0457\n",
      "Epoch 2030/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0691\n",
      "Epoch 2031/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0566\n",
      "Epoch 2032/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0545\n",
      "Epoch 2033/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0382\n",
      "Epoch 2034/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0671\n",
      "Epoch 2035/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0381\n",
      "Epoch 2036/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0528\n",
      "Epoch 2037/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0766\n",
      "Epoch 2038/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0829\n",
      "Epoch 2039/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0505\n",
      "Epoch 2040/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0938\n",
      "Epoch 2041/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0513\n",
      "Epoch 2042/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0424\n",
      "Epoch 2043/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0563\n",
      "Epoch 2044/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0324\n",
      "Epoch 2045/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0257\n",
      "Epoch 2046/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0308\n",
      "Epoch 2047/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0407\n",
      "Epoch 2048/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0591\n",
      "Epoch 2049/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0738\n",
      "Epoch 2050/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0599\n",
      "Epoch 2051/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0469\n",
      "Epoch 2052/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0374\n",
      "Epoch 2053/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0730\n",
      "Epoch 2054/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0428\n",
      "Epoch 2055/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0797\n",
      "Epoch 2056/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0411\n",
      "Epoch 2057/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0374\n",
      "Epoch 2058/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0292\n",
      "Epoch 2059/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0639\n",
      "Epoch 2060/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0491\n",
      "Epoch 2061/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0382\n",
      "Epoch 2062/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0560\n",
      "Epoch 2063/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0258\n",
      "Epoch 2064/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0363\n",
      "Epoch 2065/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0369\n",
      "Epoch 2066/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0637\n",
      "Epoch 2067/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0673\n",
      "Epoch 2068/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0504\n",
      "Epoch 2069/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0606\n",
      "Epoch 2070/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0284\n",
      "Epoch 2071/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0270\n",
      "Epoch 2072/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0464\n",
      "Epoch 2073/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0423\n",
      "Epoch 2074/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.1148\n",
      "Epoch 2075/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0840\n",
      "Epoch 2076/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0344\n",
      "Epoch 2077/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0443\n",
      "Epoch 2078/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0320\n",
      "Epoch 2079/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0606\n",
      "Epoch 2080/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0262\n",
      "Epoch 2081/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0416\n",
      "Epoch 2082/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0462\n",
      "Epoch 2083/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0400\n",
      "Epoch 2084/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0318\n",
      "Epoch 2085/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0498\n",
      "Epoch 2086/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0679\n",
      "Epoch 2087/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0276\n",
      "Epoch 2088/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0504\n",
      "Epoch 2089/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0491\n",
      "Epoch 2090/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0602\n",
      "Epoch 2091/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0445\n",
      "Epoch 2092/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0525\n",
      "Epoch 2093/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0683\n",
      "Epoch 2094/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0754\n",
      "Epoch 2095/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0444\n",
      "Epoch 2096/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0660\n",
      "Epoch 2097/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0446\n",
      "Epoch 2098/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0423\n",
      "Epoch 2099/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0420\n",
      "Epoch 2100/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0366\n",
      "Epoch 2101/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0521\n",
      "Epoch 2102/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0313\n",
      "Epoch 2103/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0491\n",
      "Epoch 2104/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0544\n",
      "Epoch 2105/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0405\n",
      "Epoch 2106/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0339\n",
      "Epoch 2107/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0760\n",
      "Epoch 2108/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0340\n",
      "Epoch 2109/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0273\n",
      "Epoch 2110/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0927\n",
      "Epoch 2111/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0517\n",
      "Epoch 2112/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0328\n",
      "Epoch 2113/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0477\n",
      "Epoch 2114/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0412\n",
      "Epoch 2115/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0313\n",
      "Epoch 2116/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0470\n",
      "Epoch 2117/2500\n",
      "36/36 [==============================] - 0s 100us/step - loss: 0.0399\n",
      "Epoch 2118/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0528\n",
      "Epoch 2119/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0321\n",
      "Epoch 2120/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0623\n",
      "Epoch 2121/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0417\n",
      "Epoch 2122/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0547\n",
      "Epoch 2123/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0506\n",
      "Epoch 2124/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0346\n",
      "Epoch 2125/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0375\n",
      "Epoch 2126/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0657\n",
      "Epoch 2127/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0283\n",
      "Epoch 2128/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0289\n",
      "Epoch 2129/2500\n",
      "36/36 [==============================] - 0s 98us/step - loss: 0.0496\n",
      "Epoch 2130/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0484\n",
      "Epoch 2131/2500\n",
      "36/36 [==============================] - 0s 128us/step - loss: 0.0493\n",
      "Epoch 2132/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0306\n",
      "Epoch 2133/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0631\n",
      "Epoch 2134/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0368\n",
      "Epoch 2135/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0363\n",
      "Epoch 2136/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0406\n",
      "Epoch 2137/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0707\n",
      "Epoch 2138/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0586\n",
      "Epoch 2139/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0495\n",
      "Epoch 2140/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0407\n",
      "Epoch 2141/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0232\n",
      "Epoch 2142/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0610\n",
      "Epoch 2143/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0455\n",
      "Epoch 2144/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0607\n",
      "Epoch 2145/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0374\n",
      "Epoch 2146/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0575\n",
      "Epoch 2147/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0280\n",
      "Epoch 2148/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0530\n",
      "Epoch 2149/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0447\n",
      "Epoch 2150/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0316\n",
      "Epoch 2151/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0702\n",
      "Epoch 2152/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0412\n",
      "Epoch 2153/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0353\n",
      "Epoch 2154/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0341\n",
      "Epoch 2155/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0193\n",
      "Epoch 2156/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0242\n",
      "Epoch 2157/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0601\n",
      "Epoch 2158/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0617\n",
      "Epoch 2159/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0906\n",
      "Epoch 2160/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0584\n",
      "Epoch 2161/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0533\n",
      "Epoch 2162/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0435\n",
      "Epoch 2163/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0528\n",
      "Epoch 2164/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0477\n",
      "Epoch 2165/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0378\n",
      "Epoch 2166/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0302\n",
      "Epoch 2167/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0441\n",
      "Epoch 2168/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0563\n",
      "Epoch 2169/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0636\n",
      "Epoch 2170/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.1152\n",
      "Epoch 2171/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.1197\n",
      "Epoch 2172/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.1451\n",
      "Epoch 2173/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0950\n",
      "Epoch 2174/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0688\n",
      "Epoch 2175/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0655\n",
      "Epoch 2176/2500\n",
      "36/36 [==============================] - 0s 122us/step - loss: 0.0582\n",
      "Epoch 2177/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0262\n",
      "Epoch 2178/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0412\n",
      "Epoch 2179/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0403\n",
      "Epoch 2180/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0302\n",
      "Epoch 2181/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0564\n",
      "Epoch 2182/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0634\n",
      "Epoch 2183/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0363\n",
      "Epoch 2184/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0661\n",
      "Epoch 2185/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0492\n",
      "Epoch 2186/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0614\n",
      "Epoch 2187/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0437\n",
      "Epoch 2188/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0413\n",
      "Epoch 2189/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0443\n",
      "Epoch 2190/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0450\n",
      "Epoch 2191/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0373\n",
      "Epoch 2192/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0531\n",
      "Epoch 2193/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0616\n",
      "Epoch 2194/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0467\n",
      "Epoch 2195/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0519\n",
      "Epoch 2196/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0625\n",
      "Epoch 2197/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0366\n",
      "Epoch 2198/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0637\n",
      "Epoch 2199/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0363\n",
      "Epoch 2200/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0309\n",
      "Epoch 2201/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0433\n",
      "Epoch 2202/2500\n",
      "36/36 [==============================] - 0s 128us/step - loss: 0.0434\n",
      "Epoch 2203/2500\n",
      "36/36 [==============================] - 0s 126us/step - loss: 0.0303\n",
      "Epoch 2204/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0558\n",
      "Epoch 2205/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0402\n",
      "Epoch 2206/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0471\n",
      "Epoch 2207/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0671\n",
      "Epoch 2208/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0521\n",
      "Epoch 2209/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0343\n",
      "Epoch 2210/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0382\n",
      "Epoch 2211/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0238\n",
      "Epoch 2212/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0373\n",
      "Epoch 2213/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0410\n",
      "Epoch 2214/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0334\n",
      "Epoch 2215/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0412\n",
      "Epoch 2216/2500\n",
      "36/36 [==============================] - 0s 100us/step - loss: 0.0673\n",
      "Epoch 2217/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0698\n",
      "Epoch 2218/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0657\n",
      "Epoch 2219/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0538\n",
      "Epoch 2220/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0533\n",
      "Epoch 2221/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0324\n",
      "Epoch 2222/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0455\n",
      "Epoch 2223/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0618\n",
      "Epoch 2224/2500\n",
      "36/36 [==============================] - 0s 128us/step - loss: 0.0464\n",
      "Epoch 2225/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0424\n",
      "Epoch 2226/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0306\n",
      "Epoch 2227/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0382\n",
      "Epoch 2228/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0352\n",
      "Epoch 2229/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0863\n",
      "Epoch 2230/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0630\n",
      "Epoch 2231/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0434\n",
      "Epoch 2232/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0723\n",
      "Epoch 2233/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0362\n",
      "Epoch 2234/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0412\n",
      "Epoch 2235/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0503\n",
      "Epoch 2236/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0374\n",
      "Epoch 2237/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0324\n",
      "Epoch 2238/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0475\n",
      "Epoch 2239/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0496\n",
      "Epoch 2240/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0369\n",
      "Epoch 2241/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0287\n",
      "Epoch 2242/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0769\n",
      "Epoch 2243/2500\n",
      "36/36 [==============================] - 0s 99us/step - loss: 0.0722\n",
      "Epoch 2244/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0547\n",
      "Epoch 2245/2500\n",
      "36/36 [==============================] - 0s 100us/step - loss: 0.0556\n",
      "Epoch 2246/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0549\n",
      "Epoch 2247/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0255\n",
      "Epoch 2248/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0435\n",
      "Epoch 2249/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0349\n",
      "Epoch 2250/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0355\n",
      "Epoch 2251/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0257\n",
      "Epoch 2252/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0384\n",
      "Epoch 2253/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0568\n",
      "Epoch 2254/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0754\n",
      "Epoch 2255/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0348\n",
      "Epoch 2256/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0355\n",
      "Epoch 2257/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0388\n",
      "Epoch 2258/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0407\n",
      "Epoch 2259/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0456\n",
      "Epoch 2260/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0476\n",
      "Epoch 2261/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0619\n",
      "Epoch 2262/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0448\n",
      "Epoch 2263/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0477\n",
      "Epoch 2264/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0454\n",
      "Epoch 2265/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0629\n",
      "Epoch 2266/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.1107\n",
      "Epoch 2267/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0326\n",
      "Epoch 2268/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0526\n",
      "Epoch 2269/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0410\n",
      "Epoch 2270/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0334\n",
      "Epoch 2271/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0438\n",
      "Epoch 2272/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0575\n",
      "Epoch 2273/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0474\n",
      "Epoch 2274/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0462\n",
      "Epoch 2275/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0338\n",
      "Epoch 2276/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0459\n",
      "Epoch 2277/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0867\n",
      "Epoch 2278/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0626\n",
      "Epoch 2279/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0357\n",
      "Epoch 2280/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0276\n",
      "Epoch 2281/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0500\n",
      "Epoch 2282/2500\n",
      "36/36 [==============================] - 0s 124us/step - loss: 0.0566\n",
      "Epoch 2283/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0719\n",
      "Epoch 2284/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0324\n",
      "Epoch 2285/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0560\n",
      "Epoch 2286/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0518\n",
      "Epoch 2287/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0992\n",
      "Epoch 2288/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0313\n",
      "Epoch 2289/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0405\n",
      "Epoch 2290/2500\n",
      "36/36 [==============================] - 0s 125us/step - loss: 0.0292\n",
      "Epoch 2291/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0468\n",
      "Epoch 2292/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.1095\n",
      "Epoch 2293/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0499\n",
      "Epoch 2294/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0401\n",
      "Epoch 2295/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0642\n",
      "Epoch 2296/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0252\n",
      "Epoch 2297/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0232\n",
      "Epoch 2298/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0343\n",
      "Epoch 2299/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0329\n",
      "Epoch 2300/2500\n",
      "36/36 [==============================] - 0s 128us/step - loss: 0.0516\n",
      "Epoch 2301/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0432\n",
      "Epoch 2302/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0279\n",
      "Epoch 2303/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0467\n",
      "Epoch 2304/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0315\n",
      "Epoch 2305/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0399\n",
      "Epoch 2306/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0624\n",
      "Epoch 2307/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.1585\n",
      "Epoch 2308/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0495\n",
      "Epoch 2309/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0548\n",
      "Epoch 2310/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0410\n",
      "Epoch 2311/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0306\n",
      "Epoch 2312/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0813\n",
      "Epoch 2313/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0529\n",
      "Epoch 2314/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0537\n",
      "Epoch 2315/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0594\n",
      "Epoch 2316/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0356\n",
      "Epoch 2317/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0509\n",
      "Epoch 2318/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0365\n",
      "Epoch 2319/2500\n",
      "36/36 [==============================] - 0s 121us/step - loss: 0.0306\n",
      "Epoch 2320/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0405\n",
      "Epoch 2321/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0329\n",
      "Epoch 2322/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0505\n",
      "Epoch 2323/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0840\n",
      "Epoch 2324/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0545\n",
      "Epoch 2325/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0324\n",
      "Epoch 2326/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0535\n",
      "Epoch 2327/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0419\n",
      "Epoch 2328/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0635\n",
      "Epoch 2329/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0541\n",
      "Epoch 2330/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0676\n",
      "Epoch 2331/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0423\n",
      "Epoch 2332/2500\n",
      "36/36 [==============================] - 0s 99us/step - loss: 0.0418\n",
      "Epoch 2333/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0589\n",
      "Epoch 2334/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0393\n",
      "Epoch 2335/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0466\n",
      "Epoch 2336/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0354\n",
      "Epoch 2337/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0269\n",
      "Epoch 2338/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0422\n",
      "Epoch 2339/2500\n",
      "36/36 [==============================] - 0s 100us/step - loss: 0.0465\n",
      "Epoch 2340/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0498\n",
      "Epoch 2341/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0314\n",
      "Epoch 2342/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0333\n",
      "Epoch 2343/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0261\n",
      "Epoch 2344/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0313\n",
      "Epoch 2345/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0281\n",
      "Epoch 2346/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0541\n",
      "Epoch 2347/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0803\n",
      "Epoch 2348/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0479\n",
      "Epoch 2349/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0644\n",
      "Epoch 2350/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0556\n",
      "Epoch 2351/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0262\n",
      "Epoch 2352/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0399\n",
      "Epoch 2353/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0416\n",
      "Epoch 2354/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0439\n",
      "Epoch 2355/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0649\n",
      "Epoch 2356/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0513\n",
      "Epoch 2357/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0396\n",
      "Epoch 2358/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0520\n",
      "Epoch 2359/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0454\n",
      "Epoch 2360/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0696\n",
      "Epoch 2361/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0461\n",
      "Epoch 2362/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0515\n",
      "Epoch 2363/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0449\n",
      "Epoch 2364/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0396\n",
      "Epoch 2365/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0382\n",
      "Epoch 2366/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0303\n",
      "Epoch 2367/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0480\n",
      "Epoch 2368/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0482\n",
      "Epoch 2369/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0475\n",
      "Epoch 2370/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0429\n",
      "Epoch 2371/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0656\n",
      "Epoch 2372/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0690\n",
      "Epoch 2373/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0410\n",
      "Epoch 2374/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0937\n",
      "Epoch 2375/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0562\n",
      "Epoch 2376/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0317\n",
      "Epoch 2377/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0373\n",
      "Epoch 2378/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0546\n",
      "Epoch 2379/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0671\n",
      "Epoch 2380/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0390\n",
      "Epoch 2381/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0595\n",
      "Epoch 2382/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0386\n",
      "Epoch 2383/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0355\n",
      "Epoch 2384/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0537\n",
      "Epoch 2385/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0926\n",
      "Epoch 2386/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0385\n",
      "Epoch 2387/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0549\n",
      "Epoch 2388/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0399\n",
      "Epoch 2389/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0309\n",
      "Epoch 2390/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0452\n",
      "Epoch 2391/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.1424\n",
      "Epoch 2392/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.1080\n",
      "Epoch 2393/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0540\n",
      "Epoch 2394/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0589\n",
      "Epoch 2395/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0512\n",
      "Epoch 2396/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0551\n",
      "Epoch 2397/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0504\n",
      "Epoch 2398/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0513\n",
      "Epoch 2399/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0628\n",
      "Epoch 2400/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0514\n",
      "Epoch 2401/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0520\n",
      "Epoch 2402/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0565\n",
      "Epoch 2403/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0696\n",
      "Epoch 2404/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0447\n",
      "Epoch 2405/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0788\n",
      "Epoch 2406/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0374\n",
      "Epoch 2407/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0290\n",
      "Epoch 2408/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0428\n",
      "Epoch 2409/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0516\n",
      "Epoch 2410/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0358\n",
      "Epoch 2411/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0458\n",
      "Epoch 2412/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0446\n",
      "Epoch 2413/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0805\n",
      "Epoch 2414/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0523\n",
      "Epoch 2415/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0378\n",
      "Epoch 2416/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0305\n",
      "Epoch 2417/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0576\n",
      "Epoch 2418/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0541\n",
      "Epoch 2419/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0436\n",
      "Epoch 2420/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0389\n",
      "Epoch 2421/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0652\n",
      "Epoch 2422/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0539\n",
      "Epoch 2423/2500\n",
      "36/36 [==============================] - 0s 97us/step - loss: 0.0423\n",
      "Epoch 2424/2500\n",
      "36/36 [==============================] - 0s 120us/step - loss: 0.0303\n",
      "Epoch 2425/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0535\n",
      "Epoch 2426/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0400\n",
      "Epoch 2427/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0453\n",
      "Epoch 2428/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0595\n",
      "Epoch 2429/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0795\n",
      "Epoch 2430/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0398\n",
      "Epoch 2431/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0310\n",
      "Epoch 2432/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0477\n",
      "Epoch 2433/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0537\n",
      "Epoch 2434/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0423\n",
      "Epoch 2435/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0398\n",
      "Epoch 2436/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0332\n",
      "Epoch 2437/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0621\n",
      "Epoch 2438/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0319\n",
      "Epoch 2439/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0290\n",
      "Epoch 2440/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0898\n",
      "Epoch 2441/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.1057\n",
      "Epoch 2442/2500\n",
      "36/36 [==============================] - 0s 105us/step - loss: 0.0709\n",
      "Epoch 2443/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0477\n",
      "Epoch 2444/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0490\n",
      "Epoch 2445/2500\n",
      "36/36 [==============================] - 0s 102us/step - loss: 0.0265\n",
      "Epoch 2446/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0503\n",
      "Epoch 2447/2500\n",
      "36/36 [==============================] - 0s 109us/step - loss: 0.0501\n",
      "Epoch 2448/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0313\n",
      "Epoch 2449/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0532\n",
      "Epoch 2450/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0373\n",
      "Epoch 2451/2500\n",
      "36/36 [==============================] - 0s 103us/step - loss: 0.0379\n",
      "Epoch 2452/2500\n",
      "36/36 [==============================] - 0s 118us/step - loss: 0.0419\n",
      "Epoch 2453/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0442\n",
      "Epoch 2454/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0304\n",
      "Epoch 2455/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0521\n",
      "Epoch 2456/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0770\n",
      "Epoch 2457/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0513\n",
      "Epoch 2458/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0553\n",
      "Epoch 2459/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0829\n",
      "Epoch 2460/2500\n",
      "36/36 [==============================] - 0s 115us/step - loss: 0.0489\n",
      "Epoch 2461/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0750\n",
      "Epoch 2462/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0499\n",
      "Epoch 2463/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0613\n",
      "Epoch 2464/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0425\n",
      "Epoch 2465/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0643\n",
      "Epoch 2466/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0520\n",
      "Epoch 2467/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0788\n",
      "Epoch 2468/2500\n",
      "36/36 [==============================] - 0s 119us/step - loss: 0.0830\n",
      "Epoch 2469/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0537\n",
      "Epoch 2470/2500\n",
      "36/36 [==============================] - 0s 106us/step - loss: 0.0415\n",
      "Epoch 2471/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0385\n",
      "Epoch 2472/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0435\n",
      "Epoch 2473/2500\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0405\n",
      "Epoch 2474/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0458\n",
      "Epoch 2475/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0363\n",
      "Epoch 2476/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0448\n",
      "Epoch 2477/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0882\n",
      "Epoch 2478/2500\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.0511\n",
      "Epoch 2479/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0429\n",
      "Epoch 2480/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0693\n",
      "Epoch 2481/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0451\n",
      "Epoch 2482/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0408\n",
      "Epoch 2483/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0478\n",
      "Epoch 2484/2500\n",
      "36/36 [==============================] - 0s 113us/step - loss: 0.0317\n",
      "Epoch 2485/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0547\n",
      "Epoch 2486/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0323\n",
      "Epoch 2487/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0255\n",
      "Epoch 2488/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0434\n",
      "Epoch 2489/2500\n",
      "36/36 [==============================] - 0s 117us/step - loss: 0.0377\n",
      "Epoch 2490/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0657\n",
      "Epoch 2491/2500\n",
      "36/36 [==============================] - 0s 101us/step - loss: 0.0452\n",
      "Epoch 2492/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0563\n",
      "Epoch 2493/2500\n",
      "36/36 [==============================] - 0s 104us/step - loss: 0.0371\n",
      "Epoch 2494/2500\n",
      "36/36 [==============================] - 0s 112us/step - loss: 0.0601\n",
      "Epoch 2495/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0526\n",
      "Epoch 2496/2500\n",
      "36/36 [==============================] - 0s 110us/step - loss: 0.0479\n",
      "Epoch 2497/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0384\n",
      "Epoch 2498/2500\n",
      "36/36 [==============================] - 0s 107us/step - loss: 0.0493\n",
      "Epoch 2499/2500\n",
      "36/36 [==============================] - 0s 116us/step - loss: 0.0387\n",
      "Epoch 2500/2500\n",
      "36/36 [==============================] - 0s 108us/step - loss: 0.0422\n",
      "best epoch =  2155\n",
      "smallest loss = 0.019276334179772273\n"
     ]
    }
   ],
   "source": [
    "#After the compilation of the model, well use the fit method with 500 epochs.\n",
    "#I started with epochs value of 100 and then tested the model after training. \n",
    "#The prediction was not that good. Then I modified the number of epochs to 200 and tested the model again. \n",
    "#Accuracy had improved slightly, but figured Id give it one more try. Finally, at 500 epochs \n",
    "#I found acceptable prediction accuracy.\n",
    "#The fit method takes three parameters; namely, x, y, and number of epochs. \n",
    "#During model training, if all the batches of data are seen by the model once, \n",
    "#we say that one epoch has been completed.\n",
    "\n",
    "# Add an early stopping callback\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    mode='min', \n",
    "    patience = 2000, \n",
    "    restore_best_weights = True, \n",
    "    verbose=1)\n",
    "# Add a checkpoint where loss is minimum, and save that model\n",
    "mc = keras.callbacks.ModelCheckpoint('best_model.SB', monitor='loss', \n",
    "                     mode='min',  verbose=1, save_best_only=True)\n",
    "\n",
    "historyData = model.fit(train_xarray,train_yarray,epochs=2500,callbacks=[es])\n",
    "\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(historyData.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))\n",
    "\n",
    "model.save('./best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec39752e-136a-4e8d-b33a-cb79ee21c17d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6r/qjkmb3mx55l9vc9x538f6ypr0000gn/T/ipykernel_3679/3703174503.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtaskmode_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "taskmode_model = keras.models.load_model(\"best_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea804d4-980f-484a-a3ec-5fb55b163d63",
   "metadata": {},
   "source": [
    "#### e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5779025c-bc69-4000-9cd0-522d81f33a1d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted powet output [0.5912887, 3.8692174, 1.068664, 4.9590983, 0.4029278, 0.21419539, 0.48802203, 0.21467322, 1.9376602, 0.717002, 0.54135346, 5.732037, 0.35190973, 3.9082437, 0.41951084, 0.64349437, 2.359037, 1.8345422, 0.1712408, 1.1960601, 3.0481026, 1.2388363, 1.1272856, 0.084851086, 1.3806577, 0.7406517, 1.5717554, 0.18879473, 0.5063218, 4.0466943, 1.0330123, 0.8961961, 0.7913245, 2.5710046, 0.28233802, 0.26568317]\n",
      "mean absolute error: 0.04517847154745872\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict output using the trained model for the training data\n",
    "YP=[]\n",
    "YD=[]\n",
    "for i in range(len(train_xarray)): \n",
    "    test = [[train_xarray[i][0], train_xarray[i][1], train_xarray[i][2], train_xarray[i][3]]]\n",
    "    testarray = np.array(test)\n",
    "    a3 = model.predict(testarray)\n",
    "    YP.append(a3[0][1])\n",
    "    YD.append(train_yarray[i][1])\n",
    "print('predicted powet output', YP)\n",
    "#mean absolute error calculation\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "error=mae(YD,YP)\n",
    "print('mean absolute error:', error)\n",
    "#comparision of predicted vs training data set\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.scatter(YP,YD)\n",
    "plt.xlabel('Predicted power output', fontsize='16')\n",
    "plt.ylabel('training power output ', fontsize='16')\n",
    "plt.loglog()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a0aaba-51e2-4c79-80e7-5ba4ab44ddb7",
   "metadata": {},
   "source": [
    "#### f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0978281a-b042-4893-a570-a9b59dd8c0ff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted powet output [0.5910975, 1.05437, 0.65896297, 0.1618075, 0.50785697, 1.096823, 0.8102579, 0.69804627, 3.912833, 2.293673, 3.5146825, 0.32435456]\n",
      "mean absolute error: 0.537560967942737\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict output using the trained model for the validation data\n",
    "YP=[]\n",
    "YD=[]\n",
    "for i in range(len(valid_xarray)): \n",
    "    test = [[valid_xarray[i][0], valid_xarray[i][1], valid_xarray[i][2], valid_xarray[i][3]]]\n",
    "    testarray = np.array(test)\n",
    "    a3 = model.predict(testarray)\n",
    "    YP.append(a3[0][1])\n",
    "    YD.append(valid_yarray[i][1])\n",
    "print('predicted powet output', YP)\n",
    "#mean absolute error calculation\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "error=mae(YD,YP)\n",
    "print('mean absolute error:', error)\n",
    "#comparision of predicted vs training data set\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.scatter(YP,YD)\n",
    "plt.xlabel('Predicted power output', fontsize='16')\n",
    "plt.ylabel('training power output ', fontsize='16')\n",
    "plt.loglog()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da84d070-5bf5-453d-b211-8078810a6da4",
   "metadata": {},
   "source": [
    "### Task 2.2\n",
    "#### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec3e3cdc-c246-4b7e-a8f9-c2de56916de5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xarray= \n",
      " [[1.         0.28571429 0.81818182]\n",
      " [1.         0.28571429 1.74410774]\n",
      " [1.         0.28571429 3.23905724]\n",
      " [1.         0.28571429 4.48484848]\n",
      " [1.         0.28571429 5.72727273]\n",
      " [1.         0.71428571 0.23569024]\n",
      " [1.         0.71428571 0.71380471]\n",
      " [1.         0.71428571 1.45454545]\n",
      " [1.         0.71428571 2.06060606]\n",
      " [1.         0.71428571 2.66329966]\n",
      " [1.         1.         0.16498316]\n",
      " [1.         1.         0.48148148]\n",
      " [1.         1.         1.        ]\n",
      " [1.         1.         1.44444444]\n",
      " [1.         1.         1.86195286]\n",
      " [1.         1.42857143 0.13198653]\n",
      " [1.         1.42857143 0.39393939]\n",
      " [1.         1.42857143 0.84848485]\n",
      " [1.         1.42857143 1.12457912]\n",
      " [1.         1.42857143 1.4006734 ]\n",
      " [1.81       0.71428571 0.23569024]\n",
      " [1.85       0.71428571 0.71380471]\n",
      " [1.9        0.71428571 1.45454545]\n",
      " [1.86       0.71428571 2.06060606]\n",
      " [1.88       0.71428571 2.66329966]\n",
      " [0.21       1.42857143 0.13198653]\n",
      " [0.2        1.42857143 0.39393939]\n",
      " [0.19       1.42857143 0.84848485]\n",
      " [0.23       1.42857143 1.12457912]\n",
      " [0.24       1.42857143 1.4006734 ]\n",
      " [0.05       1.         0.16498316]\n",
      " [0.07       1.         0.48148148]\n",
      " [0.1        1.         1.        ]\n",
      " [0.08       1.         1.44444444]\n",
      " [0.02       1.         1.86195286]\n",
      " [1.52       0.28571429 0.81818182]\n",
      " [1.54       0.28571429 1.74410774]\n",
      " [2.12       1.42857143 0.13198653]\n",
      " [1.94       1.42857143 0.39393939]\n",
      " [1.92       1.42857143 0.84848485]]\n",
      "yarray \n",
      " [[0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "'''>>>>> proto P3.2.2F22\n",
    "    V.P. Carey ME249, Fall 2022\n",
    "\n",
    "Intro to Neural Network Modeling \n",
    "Keras model for PV panel electrical power system'''\n",
    "\n",
    "#import useful packages\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import keras.backend as kb\n",
    "import tensorflow as tf\n",
    "#the following 2 lines are only needed for Mac OS machines\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "#create input data array\n",
    "#Part 2 input data: Air temp (degC), ID (W/sqm), load resistance (ohms)\n",
    "xdata = []\n",
    "Tamed=1\n",
    "IDmed=1\n",
    "RLmed=1\n",
    "xdata = [[10.0/Tamed, 200.0/IDmed, 24.3/RLmed], \n",
    " [10.0/Tamed, 200.0/IDmed, 51.8/RLmed], \n",
    " [10.0/Tamed, 200.0/IDmed, 96.2/RLmed],\n",
    " [10.0/Tamed, 200.0/IDmed, 133.2/RLmed],\n",
    " [10.0/Tamed, 200.0/IDmed, 170.1/RLmed], \n",
    " [10.0/Tamed, 500.0/IDmed, 7.0/RLmed], \n",
    " [10.0/Tamed, 500.0/IDmed, 21.2/RLmed], \n",
    " [10.0/Tamed, 500.0/IDmed, 43.2/RLmed], \n",
    " [10.0/Tamed, 500.0/IDmed, 61.2/RLmed],\n",
    " [10.0/Tamed, 500.0/IDmed, 79.1/RLmed], \n",
    " [10.0/Tamed, 700.0/IDmed, 4.9/RLmed], \n",
    " [10.0/Tamed, 700.0/IDmed, 14.3/RLmed], \n",
    " [10.0/Tamed, 700.0/IDmed, 29.7/RLmed],\n",
    " [10.0/Tamed, 700.0/IDmed, 42.9/RLmed],\n",
    " [10.0/Tamed, 700.0/IDmed, 55.3/RLmed], \n",
    " [10.0/Tamed, 1000.0/IDmed, 3.92/RLmed], \n",
    " [10.0/Tamed, 1000.0/IDmed, 11.7/RLmed], \n",
    " [10.0/Tamed, 1000.0/IDmed, 25.2/RLmed],\n",
    " [10.0/Tamed, 1000.0/IDmed, 33.4/RLmed],\n",
    " [10.0/Tamed, 1000.0/IDmed, 41.6/RLmed],\n",
    " [18.1/Tamed, 500.0/IDmed, 7.0/RLmed], \n",
    " [18.5/Tamed, 500.0/IDmed, 21.2/RLmed], \n",
    " [19.0/Tamed, 500.0/IDmed, 43.2/RLmed], \n",
    " [18.6/Tamed, 500.0/IDmed, 61.2/RLmed],\n",
    " [18.8/Tamed, 500.0/IDmed, 79.1/RLmed], \n",
    " [2.1/Tamed, 1000.0/IDmed, 3.92/RLmed], \n",
    " [2.0/Tamed, 1000.0/IDmed, 11.7/RLmed], \n",
    " [1.9/Tamed, 1000.0/IDmed, 25.2/RLmed],\n",
    " [2.3/Tamed, 1000.0/IDmed, 33.4/RLmed],\n",
    " [2.4/Tamed, 1000.0/IDmed, 41.6/RLmed],\n",
    " [0.5/Tamed, 700.0/IDmed, 4.9/RLmed], \n",
    " [0.7/Tamed, 700.0/IDmed, 14.3/RLmed], \n",
    " [1.0/Tamed, 700.0/IDmed, 29.7/RLmed],\n",
    " [0.8/Tamed, 700.0/IDmed, 42.9/RLmed],\n",
    " [0.2/Tamed, 700.0/IDmed, 55.3/RLmed], \n",
    " [15.2/Tamed, 200.0/IDmed, 24.3/RLmed], \n",
    " [15.4/Tamed, 200.0/IDmed, 51.8/RLmed], \n",
    " [21.2/Tamed, 1000.0/IDmed, 3.92/RLmed], \n",
    " [19.4/Tamed, 1000.0/IDmed, 11.7/RLmed], \n",
    " [19.2/Tamed, 1000.0/IDmed, 25.2/RLmed]]\n",
    "\n",
    "#determining the median value and normalizing the xdata\n",
    "medianx=np.median(xdata,axis=0)\n",
    "#print(medianx)\n",
    "Tmed=medianx[0]\n",
    "IDmed=medianx[1]\n",
    "Rmed=medianx[2]\n",
    "Nx = []\n",
    "for i in range(len(xdata)):\n",
    "    Nx.append([ xdata[i][0]/Tmed , xdata[i][1]/IDmed , xdata[i][2]/Rmed ])\n",
    "xdata = Nx\n",
    "xarray= np.array(xdata)\n",
    "#print (xdata)\n",
    "print ('xarray= \\n', xarray)\n",
    "\n",
    "# values of output variable\n",
    "\n",
    "#Part 2 output data: mode resulting in maximum power output Mmax\n",
    "ydata = []\n",
    "ydata = [[0.], \n",
    " [1.], \n",
    " [2.], \n",
    " [2.], \n",
    " [2.],     \n",
    " [0.], \n",
    " [1.], \n",
    " [2.],\n",
    " [2.],\n",
    " [2.],      \n",
    " [0.], \n",
    " [1.], \n",
    " [2.], \n",
    " [2.],\n",
    " [2.],      \n",
    " [0.], \n",
    " [1.], \n",
    " [2.], \n",
    " [2.],\n",
    " [2.],        \n",
    " [0.], \n",
    " [1.], \n",
    " [2.],\n",
    " [2.],\n",
    " [2.],       \n",
    " [0.], \n",
    " [1.], \n",
    " [2.], \n",
    " [2.],\n",
    " [2.],       \n",
    " [0.], \n",
    " [1.], \n",
    " [2.], \n",
    " [2.],\n",
    " [2.],      \n",
    " [0.], \n",
    " [1.], \n",
    " [0.], \n",
    " [1.], \n",
    " [2.] ]\n",
    "yarray= np.array(ydata)\n",
    "#print (ydata)\n",
    "print ('yarray \\n', yarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85626d20-7d32-4b7f-9085-5b271ff97da9",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8257f7b-80db-48db-aaa9-50964a8ae56d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ydataCatOHEarray = \n",
      " [[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Change the labels above from categorical to one-hot encoding\n",
    "ydataCatOHE = []\n",
    "#classes = [0 1 2]\n",
    "for i in range(len(ydata)):\n",
    "    if ydata[i][0]==0.:\n",
    "        ydataCatOHE.append([1, 0, 0])\n",
    "    elif ydata[i][0]==1.:\n",
    "        ydataCatOHE.append([0, 1, 0])\n",
    "    elif ydata[i][0]==2.:\n",
    "        ydataCatOHE.append([0, 0, 1])\n",
    "ydataCatOHEarray= np.array(ydataCatOHE)\n",
    "\n",
    "#print('ydataCatOHE = \\n', ydataCatOHE)\n",
    "print('ydataCatOHEarray = \\n', ydataCatOHEarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b58441e-e057-47f4-9ee4-fea091d7cef6",
   "metadata": {},
   "source": [
    "#### c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0777dcad-47e4-46ab-ae82-54b436b9519a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 3) (10, 3) (30, 3) (10, 3)\n",
      "training input array:\n",
      "[[1.         0.71428571 0.23569024]\n",
      " [1.         0.28571429 5.72727273]\n",
      " [0.19       1.42857143 0.84848485]\n",
      " [1.         0.71428571 0.71380471]\n",
      " [0.07       1.         0.48148148]\n",
      " [1.         1.         1.        ]\n",
      " [1.         0.71428571 2.06060606]\n",
      " [0.23       1.42857143 1.12457912]\n",
      " [1.92       1.42857143 0.84848485]\n",
      " [1.         0.28571429 1.74410774]\n",
      " [1.9        0.71428571 1.45454545]\n",
      " [1.88       0.71428571 2.66329966]\n",
      " [0.24       1.42857143 1.4006734 ]\n",
      " [1.52       0.28571429 0.81818182]\n",
      " [1.85       0.71428571 0.71380471]\n",
      " [1.         1.42857143 1.4006734 ]\n",
      " [1.         0.28571429 0.81818182]\n",
      " [0.08       1.         1.44444444]\n",
      " [1.81       0.71428571 0.23569024]\n",
      " [1.         1.         0.48148148]\n",
      " [1.         0.71428571 2.66329966]\n",
      " [1.94       1.42857143 0.39393939]\n",
      " [1.         1.         1.44444444]\n",
      " [1.         0.28571429 3.23905724]\n",
      " [0.2        1.42857143 0.39393939]\n",
      " [0.21       1.42857143 0.13198653]\n",
      " [0.02       1.         1.86195286]\n",
      " [1.         1.42857143 0.39393939]\n",
      " [1.         1.         0.16498316]\n",
      " [1.         1.42857143 1.12457912]]\n",
      "validation input array:\n",
      "[[0.05       1.         0.16498316]\n",
      " [1.         1.42857143 0.84848485]\n",
      " [1.86       0.71428571 2.06060606]\n",
      " [0.1        1.         1.        ]\n",
      " [1.         1.42857143 0.13198653]\n",
      " [2.12       1.42857143 0.13198653]\n",
      " [1.54       0.28571429 1.74410774]\n",
      " [1.         1.         1.86195286]\n",
      " [1.         0.28571429 4.48484848]\n",
      " [1.         0.71428571 1.45454545]]\n",
      "training OHE labels:\n",
      "[[1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]]\n",
      "validation OHE labels:\n",
      "[[1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X,valid_X,train_label,valid_label = train_test_split(xarray, ydataCatOHEarray, test_size=0.25, random_state=13)\n",
    "\n",
    "print(train_X.shape,valid_X.shape,train_label.shape,valid_label.shape)\n",
    "print('training input array:')\n",
    "print(train_X)\n",
    "print('validation input array:') \n",
    "print(valid_X)\n",
    "print('training OHE labels:')\n",
    "print(train_label)\n",
    "print('validation OHE labels:') \n",
    "print(valid_label)\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc96ad7-7b71-49f3-871b-d23f56fab02c",
   "metadata": {},
   "source": [
    "#### d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0ecec40-2833-4d96-9e2b-e7d50a43140a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 21:54:21.462583: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-15 21:54:21.463098: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 10. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# define neural network model\n",
    "#In the first layer, the input shape is provided, which is 3 in our case. \n",
    "#As seen below, we have included three dense layers. \n",
    "#The activation function we have chosen is elu, which stands for exponential linear unit. .\n",
    "\n",
    "from keras import backend as K\n",
    "#initialize weights with values between -0.2 and 0.5\n",
    "initializer = keras.initializers.RandomUniform(minval= -0.2, maxval=0.5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(16, activation=K.elu, input_shape=[3],  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(32, activation=K.elu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(16, activation=K.elu, kernel_initializer=initializer), \n",
    "    keras.layers.Dense(num_classes, activation='softmax')\n",
    "  ])\n",
    "#ADD OUTPUT LAYER, REMOVE DROPOUTS FOR FIRST PART, ADD LATER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e98eb03-6f94-445f-a9d2-f0e19efa8f2f",
   "metadata": {},
   "source": [
    "#### e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "193683bc-704e-457f-bff7-209dd464bb60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 1,187\n",
      "Trainable params: 1,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#COMPLIE THE MODEL\n",
    "'''After the model is created, you compile it using the Adam optimizer, one of the\n",
    "most popular optimization algorithms. \n",
    "\n",
    "Additionally, you specify the loss type which is categorical cross entropy which\n",
    "is used for multi-class classification.  Lastly, you specify the metrics as accuracy which you want to\n",
    "analyze while the model is training.'''\n",
    "#COMPLETE THE model.compile STATEMENT BELOW\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#SUMMARIZE MODEL\n",
    "'''To visualize the layers that created in the above step, use the summary function.\n",
    "This will show some parameters (weights and biases) in each layer and also the total parameters in your model.''' \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a183978-40f9-4cb8-92bb-fd20f9e5f17d",
   "metadata": {},
   "source": [
    "#### f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a088e21c-6a26-445d-b986-1bce142df7f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30 samples, validate on 10 samples\n",
      "Epoch 1/3000\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 4.2699 - accuracy: 0.5333 - val_loss: 3.8432 - val_accuracy: 0.6000\n",
      "Epoch 2/3000\n",
      "30/30 [==============================] - 0s 160us/step - loss: 4.0369 - accuracy: 0.5333 - val_loss: 3.6320 - val_accuracy: 0.6000\n",
      "Epoch 3/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 3.8092 - accuracy: 0.5333 - val_loss: 3.4260 - val_accuracy: 0.6000\n",
      "Epoch 4/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 3.5867 - accuracy: 0.5333 - val_loss: 3.2251 - val_accuracy: 0.6000\n",
      "Epoch 5/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 3.3695 - accuracy: 0.5333 - val_loss: 3.0293 - val_accuracy: 0.6000\n",
      "Epoch 6/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 3.1576 - accuracy: 0.5333 - val_loss: 2.8387 - val_accuracy: 0.6000\n",
      "Epoch 7/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 2.9511 - accuracy: 0.5333 - val_loss: 2.6533 - val_accuracy: 0.6000\n",
      "Epoch 8/3000\n",
      "30/30 [==============================] - 0s 149us/step - loss: 2.7502 - accuracy: 0.5333 - val_loss: 2.4734 - val_accuracy: 0.6000\n",
      "Epoch 9/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 2.5550 - accuracy: 0.5333 - val_loss: 2.2991 - val_accuracy: 0.6000\n",
      "Epoch 10/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 2.3660 - accuracy: 0.5333 - val_loss: 2.1308 - val_accuracy: 0.6000\n",
      "Epoch 11/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 2.1834 - accuracy: 0.5333 - val_loss: 1.9688 - val_accuracy: 0.6000\n",
      "Epoch 12/3000\n",
      "30/30 [==============================] - 0s 163us/step - loss: 2.0079 - accuracy: 0.5333 - val_loss: 1.8134 - val_accuracy: 0.6000\n",
      "Epoch 13/3000\n",
      "30/30 [==============================] - 0s 168us/step - loss: 1.8400 - accuracy: 0.5333 - val_loss: 1.6657 - val_accuracy: 0.6000\n",
      "Epoch 14/3000\n",
      "30/30 [==============================] - 0s 212us/step - loss: 1.6809 - accuracy: 0.5333 - val_loss: 1.5264 - val_accuracy: 0.6000\n",
      "Epoch 15/3000\n",
      "30/30 [==============================] - 0s 154us/step - loss: 1.5317 - accuracy: 0.5333 - val_loss: 1.3967 - val_accuracy: 0.6000\n",
      "Epoch 16/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 1.3938 - accuracy: 0.5333 - val_loss: 1.2783 - val_accuracy: 0.6000\n",
      "Epoch 17/3000\n",
      "30/30 [==============================] - 0s 150us/step - loss: 1.2692 - accuracy: 0.5333 - val_loss: 1.1734 - val_accuracy: 0.6000\n",
      "Epoch 18/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 1.1599 - accuracy: 0.5333 - val_loss: 1.0843 - val_accuracy: 0.6000\n",
      "Epoch 19/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 1.0682 - accuracy: 0.5333 - val_loss: 1.0138 - val_accuracy: 0.6000\n",
      "Epoch 20/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.9963 - accuracy: 0.5333 - val_loss: 0.9645 - val_accuracy: 0.6000\n",
      "Epoch 21/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.9461 - accuracy: 0.5333 - val_loss: 0.9380 - val_accuracy: 0.6000\n",
      "Epoch 22/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.9181 - accuracy: 0.5333 - val_loss: 0.9341 - val_accuracy: 0.6000\n",
      "Epoch 23/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.9113 - accuracy: 0.5667 - val_loss: 0.9496 - val_accuracy: 0.5000\n",
      "Epoch 24/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.9223 - accuracy: 0.5667 - val_loss: 0.9788 - val_accuracy: 0.5000\n",
      "Epoch 25/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.9456 - accuracy: 0.4333 - val_loss: 1.0141 - val_accuracy: 0.5000\n",
      "Epoch 26/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.9744 - accuracy: 0.4667 - val_loss: 1.0480 - val_accuracy: 0.4000\n",
      "Epoch 27/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 1.0022 - accuracy: 0.4333 - val_loss: 1.0744 - val_accuracy: 0.2000\n",
      "Epoch 28/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 1.0238 - accuracy: 0.4000 - val_loss: 1.0899 - val_accuracy: 0.2000\n",
      "Epoch 29/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 1.0362 - accuracy: 0.3667 - val_loss: 1.0934 - val_accuracy: 0.2000\n",
      "Epoch 30/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 1.0383 - accuracy: 0.3333 - val_loss: 1.0856 - val_accuracy: 0.2000\n",
      "Epoch 31/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 1.0309 - accuracy: 0.4000 - val_loss: 1.0685 - val_accuracy: 0.2000\n",
      "Epoch 32/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 1.0156 - accuracy: 0.4000 - val_loss: 1.0450 - val_accuracy: 0.4000\n",
      "Epoch 33/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.9948 - accuracy: 0.4000 - val_loss: 1.0181 - val_accuracy: 0.4000\n",
      "Epoch 34/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.9711 - accuracy: 0.4333 - val_loss: 0.9906 - val_accuracy: 0.4000\n",
      "Epoch 35/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.9469 - accuracy: 0.5000 - val_loss: 0.9648 - val_accuracy: 0.5000\n",
      "Epoch 36/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.9242 - accuracy: 0.4667 - val_loss: 0.9426 - val_accuracy: 0.5000\n",
      "Epoch 37/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.9044 - accuracy: 0.5333 - val_loss: 0.9248 - val_accuracy: 0.5000\n",
      "Epoch 38/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.8885 - accuracy: 0.5667 - val_loss: 0.9117 - val_accuracy: 0.6000\n",
      "Epoch 39/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.8766 - accuracy: 0.6000 - val_loss: 0.9030 - val_accuracy: 0.6000\n",
      "Epoch 40/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.8685 - accuracy: 0.6000 - val_loss: 0.8981 - val_accuracy: 0.6000\n",
      "Epoch 41/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.8638 - accuracy: 0.6000 - val_loss: 0.8963 - val_accuracy: 0.6000\n",
      "Epoch 42/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.8616 - accuracy: 0.5667 - val_loss: 0.8965 - val_accuracy: 0.6000\n",
      "Epoch 43/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.8613 - accuracy: 0.5333 - val_loss: 0.8979 - val_accuracy: 0.6000\n",
      "Epoch 44/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.8620 - accuracy: 0.5333 - val_loss: 0.9000 - val_accuracy: 0.6000\n",
      "Epoch 45/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.8631 - accuracy: 0.5333 - val_loss: 0.9019 - val_accuracy: 0.6000\n",
      "Epoch 46/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.8641 - accuracy: 0.5333 - val_loss: 0.9034 - val_accuracy: 0.6000\n",
      "Epoch 47/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.8645 - accuracy: 0.5333 - val_loss: 0.9041 - val_accuracy: 0.6000\n",
      "Epoch 48/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.8641 - accuracy: 0.5333 - val_loss: 0.9039 - val_accuracy: 0.6000\n",
      "Epoch 49/3000\n",
      "30/30 [==============================] - 0s 167us/step - loss: 0.8627 - accuracy: 0.5333 - val_loss: 0.9028 - val_accuracy: 0.6000\n",
      "Epoch 50/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.8604 - accuracy: 0.5333 - val_loss: 0.9008 - val_accuracy: 0.6000\n",
      "Epoch 51/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.8573 - accuracy: 0.5333 - val_loss: 0.8981 - val_accuracy: 0.6000\n",
      "Epoch 52/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.8534 - accuracy: 0.5333 - val_loss: 0.8949 - val_accuracy: 0.6000\n",
      "Epoch 53/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.8490 - accuracy: 0.5333 - val_loss: 0.8914 - val_accuracy: 0.6000\n",
      "Epoch 54/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.8443 - accuracy: 0.5333 - val_loss: 0.8878 - val_accuracy: 0.6000\n",
      "Epoch 55/3000\n",
      "30/30 [==============================] - 0s 141us/step - loss: 0.8395 - accuracy: 0.5333 - val_loss: 0.8843 - val_accuracy: 0.6000\n",
      "Epoch 56/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.8349 - accuracy: 0.5333 - val_loss: 0.8811 - val_accuracy: 0.6000\n",
      "Epoch 57/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.8305 - accuracy: 0.5333 - val_loss: 0.8783 - val_accuracy: 0.6000\n",
      "Epoch 58/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.8265 - accuracy: 0.5667 - val_loss: 0.8758 - val_accuracy: 0.6000\n",
      "Epoch 59/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.8230 - accuracy: 0.6000 - val_loss: 0.8739 - val_accuracy: 0.6000\n",
      "Epoch 60/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.8200 - accuracy: 0.6000 - val_loss: 0.8723 - val_accuracy: 0.6000\n",
      "Epoch 61/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.8175 - accuracy: 0.6000 - val_loss: 0.8710 - val_accuracy: 0.6000\n",
      "Epoch 62/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.8153 - accuracy: 0.6000 - val_loss: 0.8699 - val_accuracy: 0.6000\n",
      "Epoch 63/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.8135 - accuracy: 0.6000 - val_loss: 0.8690 - val_accuracy: 0.6000\n",
      "Epoch 64/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.8118 - accuracy: 0.6000 - val_loss: 0.8679 - val_accuracy: 0.6000\n",
      "Epoch 65/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.8102 - accuracy: 0.6000 - val_loss: 0.8668 - val_accuracy: 0.6000\n",
      "Epoch 66/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.8086 - accuracy: 0.6000 - val_loss: 0.8654 - val_accuracy: 0.6000\n",
      "Epoch 67/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.8069 - accuracy: 0.6000 - val_loss: 0.8637 - val_accuracy: 0.6000\n",
      "Epoch 68/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.8050 - accuracy: 0.6000 - val_loss: 0.8618 - val_accuracy: 0.6000\n",
      "Epoch 69/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.8030 - accuracy: 0.6000 - val_loss: 0.8596 - val_accuracy: 0.6000\n",
      "Epoch 70/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.8008 - accuracy: 0.6000 - val_loss: 0.8572 - val_accuracy: 0.6000\n",
      "Epoch 71/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.7985 - accuracy: 0.6000 - val_loss: 0.8546 - val_accuracy: 0.6000\n",
      "Epoch 72/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.7961 - accuracy: 0.6000 - val_loss: 0.8519 - val_accuracy: 0.6000\n",
      "Epoch 73/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.7937 - accuracy: 0.6000 - val_loss: 0.8492 - val_accuracy: 0.6000\n",
      "Epoch 74/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.7912 - accuracy: 0.6000 - val_loss: 0.8465 - val_accuracy: 0.6000\n",
      "Epoch 75/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.7888 - accuracy: 0.6000 - val_loss: 0.8439 - val_accuracy: 0.6000\n",
      "Epoch 76/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.7864 - accuracy: 0.6000 - val_loss: 0.8414 - val_accuracy: 0.6000\n",
      "Epoch 77/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.7841 - accuracy: 0.6000 - val_loss: 0.8391 - val_accuracy: 0.6000\n",
      "Epoch 78/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.7819 - accuracy: 0.6000 - val_loss: 0.8368 - val_accuracy: 0.6000\n",
      "Epoch 79/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.7798 - accuracy: 0.6000 - val_loss: 0.8347 - val_accuracy: 0.6000\n",
      "Epoch 80/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.7778 - accuracy: 0.6000 - val_loss: 0.8327 - val_accuracy: 0.6000\n",
      "Epoch 81/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.7758 - accuracy: 0.6000 - val_loss: 0.8308 - val_accuracy: 0.6000\n",
      "Epoch 82/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.7739 - accuracy: 0.6000 - val_loss: 0.8290 - val_accuracy: 0.6000\n",
      "Epoch 83/3000\n",
      "30/30 [==============================] - 0s 144us/step - loss: 0.7720 - accuracy: 0.6000 - val_loss: 0.8272 - val_accuracy: 0.6000\n",
      "Epoch 84/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.7700 - accuracy: 0.6000 - val_loss: 0.8255 - val_accuracy: 0.6000\n",
      "Epoch 85/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.7681 - accuracy: 0.6000 - val_loss: 0.8239 - val_accuracy: 0.6000\n",
      "Epoch 86/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.7662 - accuracy: 0.6000 - val_loss: 0.8222 - val_accuracy: 0.6000\n",
      "Epoch 87/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.7642 - accuracy: 0.6000 - val_loss: 0.8206 - val_accuracy: 0.6000\n",
      "Epoch 88/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.7622 - accuracy: 0.6000 - val_loss: 0.8190 - val_accuracy: 0.6000\n",
      "Epoch 89/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.7602 - accuracy: 0.6000 - val_loss: 0.8175 - val_accuracy: 0.6000\n",
      "Epoch 90/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.7582 - accuracy: 0.6000 - val_loss: 0.8159 - val_accuracy: 0.6000\n",
      "Epoch 91/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.7562 - accuracy: 0.6000 - val_loss: 0.8144 - val_accuracy: 0.6000\n",
      "Epoch 92/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.7541 - accuracy: 0.6000 - val_loss: 0.8128 - val_accuracy: 0.6000\n",
      "Epoch 93/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.7521 - accuracy: 0.6000 - val_loss: 0.8113 - val_accuracy: 0.6000\n",
      "Epoch 94/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.7502 - accuracy: 0.6000 - val_loss: 0.8098 - val_accuracy: 0.6000\n",
      "Epoch 95/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.7482 - accuracy: 0.6000 - val_loss: 0.8083 - val_accuracy: 0.6000\n",
      "Epoch 96/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.7462 - accuracy: 0.6000 - val_loss: 0.8068 - val_accuracy: 0.6000\n",
      "Epoch 97/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.7443 - accuracy: 0.6000 - val_loss: 0.8053 - val_accuracy: 0.6000\n",
      "Epoch 98/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.7424 - accuracy: 0.6000 - val_loss: 0.8038 - val_accuracy: 0.6000\n",
      "Epoch 99/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.7405 - accuracy: 0.6000 - val_loss: 0.8022 - val_accuracy: 0.6000\n",
      "Epoch 100/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.7386 - accuracy: 0.6000 - val_loss: 0.8006 - val_accuracy: 0.6000\n",
      "Epoch 101/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.7368 - accuracy: 0.6333 - val_loss: 0.7989 - val_accuracy: 0.6000\n",
      "Epoch 102/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.7349 - accuracy: 0.6333 - val_loss: 0.7972 - val_accuracy: 0.6000\n",
      "Epoch 103/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.7330 - accuracy: 0.6333 - val_loss: 0.7955 - val_accuracy: 0.6000\n",
      "Epoch 104/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.7311 - accuracy: 0.6333 - val_loss: 0.7938 - val_accuracy: 0.6000\n",
      "Epoch 105/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.7293 - accuracy: 0.6333 - val_loss: 0.7920 - val_accuracy: 0.6000\n",
      "Epoch 106/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.7274 - accuracy: 0.6333 - val_loss: 0.7901 - val_accuracy: 0.6000\n",
      "Epoch 107/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.7256 - accuracy: 0.6333 - val_loss: 0.7883 - val_accuracy: 0.6000\n",
      "Epoch 108/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.7237 - accuracy: 0.6333 - val_loss: 0.7865 - val_accuracy: 0.6000\n",
      "Epoch 109/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.7218 - accuracy: 0.6333 - val_loss: 0.7846 - val_accuracy: 0.6000\n",
      "Epoch 110/3000\n",
      "30/30 [==============================] - 0s 142us/step - loss: 0.7200 - accuracy: 0.6333 - val_loss: 0.7828 - val_accuracy: 0.6000\n",
      "Epoch 111/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.7182 - accuracy: 0.6667 - val_loss: 0.7809 - val_accuracy: 0.6000\n",
      "Epoch 112/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.7164 - accuracy: 0.6667 - val_loss: 0.7791 - val_accuracy: 0.6000\n",
      "Epoch 113/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.7146 - accuracy: 0.6667 - val_loss: 0.7773 - val_accuracy: 0.6000\n",
      "Epoch 114/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.7128 - accuracy: 0.6333 - val_loss: 0.7755 - val_accuracy: 0.6000\n",
      "Epoch 115/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.7110 - accuracy: 0.6333 - val_loss: 0.7737 - val_accuracy: 0.6000\n",
      "Epoch 116/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.7092 - accuracy: 0.6333 - val_loss: 0.7720 - val_accuracy: 0.6000\n",
      "Epoch 117/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.7074 - accuracy: 0.6333 - val_loss: 0.7703 - val_accuracy: 0.6000\n",
      "Epoch 118/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.7057 - accuracy: 0.6667 - val_loss: 0.7686 - val_accuracy: 0.6000\n",
      "Epoch 119/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.7039 - accuracy: 0.6667 - val_loss: 0.7669 - val_accuracy: 0.6000\n",
      "Epoch 120/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.7022 - accuracy: 0.7000 - val_loss: 0.7652 - val_accuracy: 0.6000\n",
      "Epoch 121/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.7004 - accuracy: 0.7000 - val_loss: 0.7636 - val_accuracy: 0.6000\n",
      "Epoch 122/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.6987 - accuracy: 0.7000 - val_loss: 0.7619 - val_accuracy: 0.6000\n",
      "Epoch 123/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.6970 - accuracy: 0.7000 - val_loss: 0.7603 - val_accuracy: 0.6000\n",
      "Epoch 124/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.6953 - accuracy: 0.7000 - val_loss: 0.7587 - val_accuracy: 0.6000\n",
      "Epoch 125/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.6936 - accuracy: 0.7000 - val_loss: 0.7571 - val_accuracy: 0.6000\n",
      "Epoch 126/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.6919 - accuracy: 0.7000 - val_loss: 0.7555 - val_accuracy: 0.6000\n",
      "Epoch 127/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.6902 - accuracy: 0.7000 - val_loss: 0.7540 - val_accuracy: 0.6000\n",
      "Epoch 128/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.6886 - accuracy: 0.7000 - val_loss: 0.7524 - val_accuracy: 0.6000\n",
      "Epoch 129/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.6869 - accuracy: 0.7000 - val_loss: 0.7509 - val_accuracy: 0.6000\n",
      "Epoch 130/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.6853 - accuracy: 0.7000 - val_loss: 0.7493 - val_accuracy: 0.6000\n",
      "Epoch 131/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.6836 - accuracy: 0.7000 - val_loss: 0.7477 - val_accuracy: 0.6000\n",
      "Epoch 132/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.6820 - accuracy: 0.7000 - val_loss: 0.7462 - val_accuracy: 0.6000\n",
      "Epoch 133/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.6804 - accuracy: 0.7000 - val_loss: 0.7446 - val_accuracy: 0.6000\n",
      "Epoch 134/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.6788 - accuracy: 0.7000 - val_loss: 0.7431 - val_accuracy: 0.6000\n",
      "Epoch 135/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.6772 - accuracy: 0.7000 - val_loss: 0.7415 - val_accuracy: 0.6000\n",
      "Epoch 136/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.6756 - accuracy: 0.7000 - val_loss: 0.7400 - val_accuracy: 0.6000\n",
      "Epoch 137/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.6740 - accuracy: 0.7000 - val_loss: 0.7384 - val_accuracy: 0.6000\n",
      "Epoch 138/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.6725 - accuracy: 0.7000 - val_loss: 0.7369 - val_accuracy: 0.6000\n",
      "Epoch 139/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.6709 - accuracy: 0.7000 - val_loss: 0.7353 - val_accuracy: 0.6000\n",
      "Epoch 140/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.6694 - accuracy: 0.7000 - val_loss: 0.7338 - val_accuracy: 0.6000\n",
      "Epoch 141/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.6679 - accuracy: 0.7000 - val_loss: 0.7322 - val_accuracy: 0.6000\n",
      "Epoch 142/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.6663 - accuracy: 0.7000 - val_loss: 0.7307 - val_accuracy: 0.6000\n",
      "Epoch 143/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.6648 - accuracy: 0.7333 - val_loss: 0.7291 - val_accuracy: 0.6000\n",
      "Epoch 144/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.6633 - accuracy: 0.7333 - val_loss: 0.7276 - val_accuracy: 0.6000\n",
      "Epoch 145/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.6618 - accuracy: 0.7333 - val_loss: 0.7261 - val_accuracy: 0.6000\n",
      "Epoch 146/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.6604 - accuracy: 0.7333 - val_loss: 0.7245 - val_accuracy: 0.6000\n",
      "Epoch 147/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.6589 - accuracy: 0.7333 - val_loss: 0.7230 - val_accuracy: 0.6000\n",
      "Epoch 148/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.6575 - accuracy: 0.7333 - val_loss: 0.7215 - val_accuracy: 0.6000\n",
      "Epoch 149/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.6560 - accuracy: 0.7333 - val_loss: 0.7201 - val_accuracy: 0.6000\n",
      "Epoch 150/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.6546 - accuracy: 0.7333 - val_loss: 0.7186 - val_accuracy: 0.6000\n",
      "Epoch 151/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.6531 - accuracy: 0.7333 - val_loss: 0.7171 - val_accuracy: 0.6000\n",
      "Epoch 152/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.6517 - accuracy: 0.7333 - val_loss: 0.7157 - val_accuracy: 0.6000\n",
      "Epoch 153/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.6503 - accuracy: 0.7333 - val_loss: 0.7142 - val_accuracy: 0.6000\n",
      "Epoch 154/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.6489 - accuracy: 0.7333 - val_loss: 0.7128 - val_accuracy: 0.6000\n",
      "Epoch 155/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.6476 - accuracy: 0.7333 - val_loss: 0.7113 - val_accuracy: 0.6000\n",
      "Epoch 156/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.6462 - accuracy: 0.7333 - val_loss: 0.7099 - val_accuracy: 0.6000\n",
      "Epoch 157/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.6448 - accuracy: 0.7333 - val_loss: 0.7085 - val_accuracy: 0.6000\n",
      "Epoch 158/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.6435 - accuracy: 0.7333 - val_loss: 0.7071 - val_accuracy: 0.6000\n",
      "Epoch 159/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.6421 - accuracy: 0.7667 - val_loss: 0.7057 - val_accuracy: 0.6000\n",
      "Epoch 160/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.6408 - accuracy: 0.7667 - val_loss: 0.7043 - val_accuracy: 0.6000\n",
      "Epoch 161/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.6395 - accuracy: 0.7667 - val_loss: 0.7030 - val_accuracy: 0.6000\n",
      "Epoch 162/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.6382 - accuracy: 0.7667 - val_loss: 0.7016 - val_accuracy: 0.6000\n",
      "Epoch 163/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.6369 - accuracy: 0.7667 - val_loss: 0.7002 - val_accuracy: 0.6000\n",
      "Epoch 164/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.6356 - accuracy: 0.7667 - val_loss: 0.6989 - val_accuracy: 0.6000\n",
      "Epoch 165/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.6343 - accuracy: 0.7667 - val_loss: 0.6975 - val_accuracy: 0.6000\n",
      "Epoch 166/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.6330 - accuracy: 0.7667 - val_loss: 0.6962 - val_accuracy: 0.6000\n",
      "Epoch 167/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.6318 - accuracy: 0.7667 - val_loss: 0.6948 - val_accuracy: 0.6000\n",
      "Epoch 168/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.6305 - accuracy: 0.7667 - val_loss: 0.6935 - val_accuracy: 0.6000\n",
      "Epoch 169/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.6293 - accuracy: 0.7667 - val_loss: 0.6922 - val_accuracy: 0.6000\n",
      "Epoch 170/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 0.6280 - accuracy: 0.7667 - val_loss: 0.6908 - val_accuracy: 0.6000\n",
      "Epoch 171/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.6268 - accuracy: 0.7667 - val_loss: 0.6895 - val_accuracy: 0.6000\n",
      "Epoch 172/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.6256 - accuracy: 0.7667 - val_loss: 0.6882 - val_accuracy: 0.6000\n",
      "Epoch 173/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.6244 - accuracy: 0.7667 - val_loss: 0.6869 - val_accuracy: 0.6000\n",
      "Epoch 174/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.6232 - accuracy: 0.7667 - val_loss: 0.6856 - val_accuracy: 0.6000\n",
      "Epoch 175/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.6220 - accuracy: 0.7667 - val_loss: 0.6844 - val_accuracy: 0.6000\n",
      "Epoch 176/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.6208 - accuracy: 0.7667 - val_loss: 0.6831 - val_accuracy: 0.6000\n",
      "Epoch 177/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.6196 - accuracy: 0.7667 - val_loss: 0.6818 - val_accuracy: 0.6000\n",
      "Epoch 178/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.6185 - accuracy: 0.7667 - val_loss: 0.6805 - val_accuracy: 0.6000\n",
      "Epoch 179/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.6173 - accuracy: 0.7667 - val_loss: 0.6793 - val_accuracy: 0.6000\n",
      "Epoch 180/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.6162 - accuracy: 0.7667 - val_loss: 0.6780 - val_accuracy: 0.6000\n",
      "Epoch 181/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.6150 - accuracy: 0.7667 - val_loss: 0.6768 - val_accuracy: 0.6000\n",
      "Epoch 182/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.6139 - accuracy: 0.7667 - val_loss: 0.6755 - val_accuracy: 0.6000\n",
      "Epoch 183/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.6128 - accuracy: 0.7333 - val_loss: 0.6743 - val_accuracy: 0.6000\n",
      "Epoch 184/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.6116 - accuracy: 0.7667 - val_loss: 0.6731 - val_accuracy: 0.6000\n",
      "Epoch 185/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.6105 - accuracy: 0.7667 - val_loss: 0.6719 - val_accuracy: 0.6000\n",
      "Epoch 186/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.6094 - accuracy: 0.8000 - val_loss: 0.6707 - val_accuracy: 0.6000\n",
      "Epoch 187/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.6083 - accuracy: 0.8000 - val_loss: 0.6695 - val_accuracy: 0.6000\n",
      "Epoch 188/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.6072 - accuracy: 0.8000 - val_loss: 0.6683 - val_accuracy: 0.6000\n",
      "Epoch 189/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.6062 - accuracy: 0.8000 - val_loss: 0.6671 - val_accuracy: 0.6000\n",
      "Epoch 190/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.6051 - accuracy: 0.8000 - val_loss: 0.6659 - val_accuracy: 0.6000\n",
      "Epoch 191/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.6040 - accuracy: 0.8000 - val_loss: 0.6647 - val_accuracy: 0.6000\n",
      "Epoch 192/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.6029 - accuracy: 0.8000 - val_loss: 0.6635 - val_accuracy: 0.6000\n",
      "Epoch 193/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.6019 - accuracy: 0.8000 - val_loss: 0.6624 - val_accuracy: 0.6000\n",
      "Epoch 194/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.6008 - accuracy: 0.8000 - val_loss: 0.6612 - val_accuracy: 0.6000\n",
      "Epoch 195/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.5998 - accuracy: 0.8000 - val_loss: 0.6600 - val_accuracy: 0.6000\n",
      "Epoch 196/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.5987 - accuracy: 0.8000 - val_loss: 0.6589 - val_accuracy: 0.6000\n",
      "Epoch 197/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.5977 - accuracy: 0.8000 - val_loss: 0.6577 - val_accuracy: 0.6000\n",
      "Epoch 198/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.5967 - accuracy: 0.8000 - val_loss: 0.6566 - val_accuracy: 0.6000\n",
      "Epoch 199/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.5956 - accuracy: 0.8000 - val_loss: 0.6555 - val_accuracy: 0.6000\n",
      "Epoch 200/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.5946 - accuracy: 0.8000 - val_loss: 0.6544 - val_accuracy: 0.6000\n",
      "Epoch 201/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.5936 - accuracy: 0.8000 - val_loss: 0.6532 - val_accuracy: 0.6000\n",
      "Epoch 202/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.5926 - accuracy: 0.8000 - val_loss: 0.6521 - val_accuracy: 0.6000\n",
      "Epoch 203/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.5916 - accuracy: 0.8000 - val_loss: 0.6510 - val_accuracy: 0.6000\n",
      "Epoch 204/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.5906 - accuracy: 0.8000 - val_loss: 0.6499 - val_accuracy: 0.6000\n",
      "Epoch 205/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.5896 - accuracy: 0.8000 - val_loss: 0.6488 - val_accuracy: 0.6000\n",
      "Epoch 206/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.5886 - accuracy: 0.8000 - val_loss: 0.6477 - val_accuracy: 0.6000\n",
      "Epoch 207/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.5876 - accuracy: 0.8000 - val_loss: 0.6466 - val_accuracy: 0.6000\n",
      "Epoch 208/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.5866 - accuracy: 0.8000 - val_loss: 0.6455 - val_accuracy: 0.6000\n",
      "Epoch 209/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.5857 - accuracy: 0.8000 - val_loss: 0.6445 - val_accuracy: 0.6000\n",
      "Epoch 210/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.5847 - accuracy: 0.8000 - val_loss: 0.6434 - val_accuracy: 0.6000\n",
      "Epoch 211/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.5837 - accuracy: 0.8000 - val_loss: 0.6423 - val_accuracy: 0.6000\n",
      "Epoch 212/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.5827 - accuracy: 0.8000 - val_loss: 0.6413 - val_accuracy: 0.6000\n",
      "Epoch 213/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.5818 - accuracy: 0.8000 - val_loss: 0.6402 - val_accuracy: 0.6000\n",
      "Epoch 214/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.5808 - accuracy: 0.8000 - val_loss: 0.6391 - val_accuracy: 0.6000\n",
      "Epoch 215/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.5799 - accuracy: 0.8000 - val_loss: 0.6381 - val_accuracy: 0.6000\n",
      "Epoch 216/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.5789 - accuracy: 0.8000 - val_loss: 0.6370 - val_accuracy: 0.6000\n",
      "Epoch 217/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.5780 - accuracy: 0.8000 - val_loss: 0.6360 - val_accuracy: 0.6000\n",
      "Epoch 218/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 0.5770 - accuracy: 0.8000 - val_loss: 0.6350 - val_accuracy: 0.6000\n",
      "Epoch 219/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.5761 - accuracy: 0.8000 - val_loss: 0.6339 - val_accuracy: 0.6000\n",
      "Epoch 220/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.5751 - accuracy: 0.8000 - val_loss: 0.6329 - val_accuracy: 0.6000\n",
      "Epoch 221/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.5742 - accuracy: 0.8000 - val_loss: 0.6319 - val_accuracy: 0.6000\n",
      "Epoch 222/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.5733 - accuracy: 0.8000 - val_loss: 0.6309 - val_accuracy: 0.6000\n",
      "Epoch 223/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.5723 - accuracy: 0.8000 - val_loss: 0.6299 - val_accuracy: 0.6000\n",
      "Epoch 224/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.5714 - accuracy: 0.8000 - val_loss: 0.6289 - val_accuracy: 0.7000\n",
      "Epoch 225/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.5705 - accuracy: 0.8000 - val_loss: 0.6279 - val_accuracy: 0.7000\n",
      "Epoch 226/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.5695 - accuracy: 0.8000 - val_loss: 0.6269 - val_accuracy: 0.7000\n",
      "Epoch 227/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.5686 - accuracy: 0.8000 - val_loss: 0.6259 - val_accuracy: 0.7000\n",
      "Epoch 228/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.5677 - accuracy: 0.8000 - val_loss: 0.6249 - val_accuracy: 0.7000\n",
      "Epoch 229/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.5668 - accuracy: 0.8000 - val_loss: 0.6239 - val_accuracy: 0.7000\n",
      "Epoch 230/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.5659 - accuracy: 0.8000 - val_loss: 0.6229 - val_accuracy: 0.7000\n",
      "Epoch 231/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.5649 - accuracy: 0.8000 - val_loss: 0.6219 - val_accuracy: 0.7000\n",
      "Epoch 232/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.5640 - accuracy: 0.8000 - val_loss: 0.6209 - val_accuracy: 0.7000\n",
      "Epoch 233/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.5631 - accuracy: 0.8000 - val_loss: 0.6200 - val_accuracy: 0.7000\n",
      "Epoch 234/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.5622 - accuracy: 0.8000 - val_loss: 0.6190 - val_accuracy: 0.7000\n",
      "Epoch 235/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.5613 - accuracy: 0.8000 - val_loss: 0.6180 - val_accuracy: 0.7000\n",
      "Epoch 236/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.5604 - accuracy: 0.8000 - val_loss: 0.6171 - val_accuracy: 0.7000\n",
      "Epoch 237/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.5595 - accuracy: 0.8000 - val_loss: 0.6161 - val_accuracy: 0.7000\n",
      "Epoch 238/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.5586 - accuracy: 0.8000 - val_loss: 0.6151 - val_accuracy: 0.7000\n",
      "Epoch 239/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.5577 - accuracy: 0.8000 - val_loss: 0.6142 - val_accuracy: 0.7000\n",
      "Epoch 240/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.5568 - accuracy: 0.8333 - val_loss: 0.6132 - val_accuracy: 0.7000\n",
      "Epoch 241/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.5559 - accuracy: 0.8333 - val_loss: 0.6123 - val_accuracy: 0.7000\n",
      "Epoch 242/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.5550 - accuracy: 0.8333 - val_loss: 0.6114 - val_accuracy: 0.7000\n",
      "Epoch 243/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.5541 - accuracy: 0.8333 - val_loss: 0.6104 - val_accuracy: 0.7000\n",
      "Epoch 244/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.5532 - accuracy: 0.8333 - val_loss: 0.6095 - val_accuracy: 0.7000\n",
      "Epoch 245/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.5523 - accuracy: 0.8333 - val_loss: 0.6086 - val_accuracy: 0.7000\n",
      "Epoch 246/3000\n",
      "30/30 [==============================] - 0s 94us/step - loss: 0.5514 - accuracy: 0.8333 - val_loss: 0.6076 - val_accuracy: 0.7000\n",
      "Epoch 247/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.5505 - accuracy: 0.8000 - val_loss: 0.6067 - val_accuracy: 0.7000\n",
      "Epoch 248/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.5496 - accuracy: 0.8333 - val_loss: 0.6058 - val_accuracy: 0.7000\n",
      "Epoch 249/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.5487 - accuracy: 0.8333 - val_loss: 0.6049 - val_accuracy: 0.7000\n",
      "Epoch 250/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.5478 - accuracy: 0.8333 - val_loss: 0.6039 - val_accuracy: 0.7000\n",
      "Epoch 251/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.5469 - accuracy: 0.8333 - val_loss: 0.6030 - val_accuracy: 0.7000\n",
      "Epoch 252/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.5460 - accuracy: 0.8333 - val_loss: 0.6021 - val_accuracy: 0.7000\n",
      "Epoch 253/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.5451 - accuracy: 0.8333 - val_loss: 0.6012 - val_accuracy: 0.7000\n",
      "Epoch 254/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.5443 - accuracy: 0.8333 - val_loss: 0.6003 - val_accuracy: 0.7000\n",
      "Epoch 255/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.5434 - accuracy: 0.8333 - val_loss: 0.5994 - val_accuracy: 0.7000\n",
      "Epoch 256/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.5425 - accuracy: 0.8333 - val_loss: 0.5985 - val_accuracy: 0.7000\n",
      "Epoch 257/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.5416 - accuracy: 0.8333 - val_loss: 0.5976 - val_accuracy: 0.7000\n",
      "Epoch 258/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.5407 - accuracy: 0.8333 - val_loss: 0.5967 - val_accuracy: 0.7000\n",
      "Epoch 259/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.5398 - accuracy: 0.8333 - val_loss: 0.5958 - val_accuracy: 0.7000\n",
      "Epoch 260/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.5389 - accuracy: 0.8333 - val_loss: 0.5949 - val_accuracy: 0.7000\n",
      "Epoch 261/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.5380 - accuracy: 0.8333 - val_loss: 0.5941 - val_accuracy: 0.7000\n",
      "Epoch 262/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.5371 - accuracy: 0.8333 - val_loss: 0.5932 - val_accuracy: 0.7000\n",
      "Epoch 263/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.5363 - accuracy: 0.8333 - val_loss: 0.5923 - val_accuracy: 0.7000\n",
      "Epoch 264/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.5354 - accuracy: 0.8333 - val_loss: 0.5914 - val_accuracy: 0.7000\n",
      "Epoch 265/3000\n",
      "30/30 [==============================] - 0s 146us/step - loss: 0.5345 - accuracy: 0.8333 - val_loss: 0.5905 - val_accuracy: 0.7000\n",
      "Epoch 266/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.5336 - accuracy: 0.8333 - val_loss: 0.5897 - val_accuracy: 0.7000\n",
      "Epoch 267/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.5327 - accuracy: 0.8333 - val_loss: 0.5888 - val_accuracy: 0.7000\n",
      "Epoch 268/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.5318 - accuracy: 0.8333 - val_loss: 0.5879 - val_accuracy: 0.7000\n",
      "Epoch 269/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.5309 - accuracy: 0.8333 - val_loss: 0.5871 - val_accuracy: 0.7000\n",
      "Epoch 270/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.5300 - accuracy: 0.8333 - val_loss: 0.5862 - val_accuracy: 0.7000\n",
      "Epoch 271/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.5292 - accuracy: 0.8333 - val_loss: 0.5854 - val_accuracy: 0.7000\n",
      "Epoch 272/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.5283 - accuracy: 0.8333 - val_loss: 0.5845 - val_accuracy: 0.7000\n",
      "Epoch 273/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.5274 - accuracy: 0.8333 - val_loss: 0.5836 - val_accuracy: 0.7000\n",
      "Epoch 274/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.5265 - accuracy: 0.8333 - val_loss: 0.5828 - val_accuracy: 0.7000\n",
      "Epoch 275/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.5256 - accuracy: 0.8333 - val_loss: 0.5819 - val_accuracy: 0.7000\n",
      "Epoch 276/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.5247 - accuracy: 0.8333 - val_loss: 0.5811 - val_accuracy: 0.7000\n",
      "Epoch 277/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.5238 - accuracy: 0.8333 - val_loss: 0.5802 - val_accuracy: 0.7000\n",
      "Epoch 278/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.5229 - accuracy: 0.8333 - val_loss: 0.5794 - val_accuracy: 0.7000\n",
      "Epoch 279/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.5221 - accuracy: 0.8333 - val_loss: 0.5786 - val_accuracy: 0.7000\n",
      "Epoch 280/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.5212 - accuracy: 0.8333 - val_loss: 0.5777 - val_accuracy: 0.7000\n",
      "Epoch 281/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.5203 - accuracy: 0.8333 - val_loss: 0.5769 - val_accuracy: 0.7000\n",
      "Epoch 282/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.5194 - accuracy: 0.8333 - val_loss: 0.5760 - val_accuracy: 0.7000\n",
      "Epoch 283/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.5185 - accuracy: 0.8333 - val_loss: 0.5752 - val_accuracy: 0.7000\n",
      "Epoch 284/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.5176 - accuracy: 0.8333 - val_loss: 0.5744 - val_accuracy: 0.7000\n",
      "Epoch 285/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.5167 - accuracy: 0.8333 - val_loss: 0.5736 - val_accuracy: 0.7000\n",
      "Epoch 286/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.5158 - accuracy: 0.8333 - val_loss: 0.5727 - val_accuracy: 0.7000\n",
      "Epoch 287/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.5149 - accuracy: 0.8333 - val_loss: 0.5719 - val_accuracy: 0.7000\n",
      "Epoch 288/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.5140 - accuracy: 0.8333 - val_loss: 0.5711 - val_accuracy: 0.7000\n",
      "Epoch 289/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.5131 - accuracy: 0.8333 - val_loss: 0.5703 - val_accuracy: 0.7000\n",
      "Epoch 290/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.5123 - accuracy: 0.8333 - val_loss: 0.5694 - val_accuracy: 0.7000\n",
      "Epoch 291/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.5114 - accuracy: 0.8333 - val_loss: 0.5686 - val_accuracy: 0.7000\n",
      "Epoch 292/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.5105 - accuracy: 0.8333 - val_loss: 0.5678 - val_accuracy: 0.7000\n",
      "Epoch 293/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.5096 - accuracy: 0.8333 - val_loss: 0.5670 - val_accuracy: 0.7000\n",
      "Epoch 294/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.5087 - accuracy: 0.8333 - val_loss: 0.5662 - val_accuracy: 0.7000\n",
      "Epoch 295/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.5078 - accuracy: 0.8333 - val_loss: 0.5654 - val_accuracy: 0.7000\n",
      "Epoch 296/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.5069 - accuracy: 0.8333 - val_loss: 0.5646 - val_accuracy: 0.7000\n",
      "Epoch 297/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.5060 - accuracy: 0.8333 - val_loss: 0.5638 - val_accuracy: 0.7000\n",
      "Epoch 298/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.5051 - accuracy: 0.8333 - val_loss: 0.5630 - val_accuracy: 0.7000\n",
      "Epoch 299/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.5042 - accuracy: 0.8333 - val_loss: 0.5622 - val_accuracy: 0.7000\n",
      "Epoch 300/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.5033 - accuracy: 0.8333 - val_loss: 0.5614 - val_accuracy: 0.7000\n",
      "Epoch 301/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.5024 - accuracy: 0.8333 - val_loss: 0.5606 - val_accuracy: 0.7000\n",
      "Epoch 302/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.5015 - accuracy: 0.8333 - val_loss: 0.5598 - val_accuracy: 0.7000\n",
      "Epoch 303/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.5006 - accuracy: 0.8333 - val_loss: 0.5590 - val_accuracy: 0.7000\n",
      "Epoch 304/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.4997 - accuracy: 0.8333 - val_loss: 0.5582 - val_accuracy: 0.7000\n",
      "Epoch 305/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.4988 - accuracy: 0.8333 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 306/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.4979 - accuracy: 0.8333 - val_loss: 0.5566 - val_accuracy: 0.7000\n",
      "Epoch 307/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.4970 - accuracy: 0.8333 - val_loss: 0.5559 - val_accuracy: 0.7000\n",
      "Epoch 308/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.4961 - accuracy: 0.8333 - val_loss: 0.5551 - val_accuracy: 0.7000\n",
      "Epoch 309/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.4952 - accuracy: 0.8333 - val_loss: 0.5543 - val_accuracy: 0.7000\n",
      "Epoch 310/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.4943 - accuracy: 0.8333 - val_loss: 0.5535 - val_accuracy: 0.7000\n",
      "Epoch 311/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.4934 - accuracy: 0.8333 - val_loss: 0.5527 - val_accuracy: 0.7000\n",
      "Epoch 312/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.4925 - accuracy: 0.8333 - val_loss: 0.5520 - val_accuracy: 0.7000\n",
      "Epoch 313/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.4916 - accuracy: 0.8333 - val_loss: 0.5512 - val_accuracy: 0.7000\n",
      "Epoch 314/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.4906 - accuracy: 0.8333 - val_loss: 0.5504 - val_accuracy: 0.7000\n",
      "Epoch 315/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.4897 - accuracy: 0.8333 - val_loss: 0.5497 - val_accuracy: 0.7000\n",
      "Epoch 316/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.4888 - accuracy: 0.8333 - val_loss: 0.5489 - val_accuracy: 0.7000\n",
      "Epoch 317/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.4879 - accuracy: 0.8333 - val_loss: 0.5481 - val_accuracy: 0.7000\n",
      "Epoch 318/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.4870 - accuracy: 0.8333 - val_loss: 0.5474 - val_accuracy: 0.7000\n",
      "Epoch 319/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.4861 - accuracy: 0.8333 - val_loss: 0.5466 - val_accuracy: 0.7000\n",
      "Epoch 320/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.4852 - accuracy: 0.8333 - val_loss: 0.5458 - val_accuracy: 0.7000\n",
      "Epoch 321/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.4843 - accuracy: 0.8333 - val_loss: 0.5451 - val_accuracy: 0.7000\n",
      "Epoch 322/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.4834 - accuracy: 0.8333 - val_loss: 0.5443 - val_accuracy: 0.7000\n",
      "Epoch 323/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.4824 - accuracy: 0.8333 - val_loss: 0.5436 - val_accuracy: 0.7000\n",
      "Epoch 324/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.4815 - accuracy: 0.8333 - val_loss: 0.5428 - val_accuracy: 0.7000\n",
      "Epoch 325/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.4806 - accuracy: 0.8333 - val_loss: 0.5421 - val_accuracy: 0.7000\n",
      "Epoch 326/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.4797 - accuracy: 0.8333 - val_loss: 0.5413 - val_accuracy: 0.7000\n",
      "Epoch 327/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.4788 - accuracy: 0.8333 - val_loss: 0.5406 - val_accuracy: 0.7000\n",
      "Epoch 328/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.4779 - accuracy: 0.8333 - val_loss: 0.5398 - val_accuracy: 0.7000\n",
      "Epoch 329/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.4769 - accuracy: 0.8333 - val_loss: 0.5391 - val_accuracy: 0.7000\n",
      "Epoch 330/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.4760 - accuracy: 0.8333 - val_loss: 0.5384 - val_accuracy: 0.7000\n",
      "Epoch 331/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.4751 - accuracy: 0.8667 - val_loss: 0.5376 - val_accuracy: 0.7000\n",
      "Epoch 332/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.4742 - accuracy: 0.8667 - val_loss: 0.5369 - val_accuracy: 0.7000\n",
      "Epoch 333/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.4733 - accuracy: 0.8667 - val_loss: 0.5362 - val_accuracy: 0.7000\n",
      "Epoch 334/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.4723 - accuracy: 0.8667 - val_loss: 0.5355 - val_accuracy: 0.7000\n",
      "Epoch 335/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.4714 - accuracy: 0.8667 - val_loss: 0.5347 - val_accuracy: 0.7000\n",
      "Epoch 336/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.4705 - accuracy: 0.9000 - val_loss: 0.5340 - val_accuracy: 0.7000\n",
      "Epoch 337/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.4696 - accuracy: 0.9000 - val_loss: 0.5333 - val_accuracy: 0.7000\n",
      "Epoch 338/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.4686 - accuracy: 0.9000 - val_loss: 0.5326 - val_accuracy: 0.7000\n",
      "Epoch 339/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.4677 - accuracy: 0.9000 - val_loss: 0.5318 - val_accuracy: 0.7000\n",
      "Epoch 340/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.4668 - accuracy: 0.9000 - val_loss: 0.5311 - val_accuracy: 0.7000\n",
      "Epoch 341/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.4659 - accuracy: 0.9000 - val_loss: 0.5304 - val_accuracy: 0.7000\n",
      "Epoch 342/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.4649 - accuracy: 0.9000 - val_loss: 0.5297 - val_accuracy: 0.7000\n",
      "Epoch 343/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.4640 - accuracy: 0.9000 - val_loss: 0.5290 - val_accuracy: 0.7000\n",
      "Epoch 344/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.4631 - accuracy: 0.9000 - val_loss: 0.5283 - val_accuracy: 0.7000\n",
      "Epoch 345/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.4622 - accuracy: 0.9000 - val_loss: 0.5276 - val_accuracy: 0.7000\n",
      "Epoch 346/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.4612 - accuracy: 0.9000 - val_loss: 0.5269 - val_accuracy: 0.7000\n",
      "Epoch 347/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.4603 - accuracy: 0.9000 - val_loss: 0.5262 - val_accuracy: 0.7000\n",
      "Epoch 348/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.4594 - accuracy: 0.9000 - val_loss: 0.5255 - val_accuracy: 0.7000\n",
      "Epoch 349/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.4584 - accuracy: 0.9000 - val_loss: 0.5248 - val_accuracy: 0.7000\n",
      "Epoch 350/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.4575 - accuracy: 0.9000 - val_loss: 0.5241 - val_accuracy: 0.7000\n",
      "Epoch 351/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.4566 - accuracy: 0.9000 - val_loss: 0.5234 - val_accuracy: 0.7000\n",
      "Epoch 352/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.4556 - accuracy: 0.9000 - val_loss: 0.5227 - val_accuracy: 0.7000\n",
      "Epoch 353/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.4547 - accuracy: 0.9000 - val_loss: 0.5220 - val_accuracy: 0.7000\n",
      "Epoch 354/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.4537 - accuracy: 0.9000 - val_loss: 0.5214 - val_accuracy: 0.7000\n",
      "Epoch 355/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.4528 - accuracy: 0.9000 - val_loss: 0.5207 - val_accuracy: 0.7000\n",
      "Epoch 356/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.4519 - accuracy: 0.9000 - val_loss: 0.5200 - val_accuracy: 0.7000\n",
      "Epoch 357/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.4509 - accuracy: 0.9000 - val_loss: 0.5193 - val_accuracy: 0.7000\n",
      "Epoch 358/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.4500 - accuracy: 0.9000 - val_loss: 0.5186 - val_accuracy: 0.7000\n",
      "Epoch 359/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.4490 - accuracy: 0.9000 - val_loss: 0.5180 - val_accuracy: 0.7000\n",
      "Epoch 360/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.4481 - accuracy: 0.9000 - val_loss: 0.5173 - val_accuracy: 0.7000\n",
      "Epoch 361/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.4472 - accuracy: 0.9000 - val_loss: 0.5166 - val_accuracy: 0.7000\n",
      "Epoch 362/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.4462 - accuracy: 0.9000 - val_loss: 0.5160 - val_accuracy: 0.7000\n",
      "Epoch 363/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.4453 - accuracy: 0.9000 - val_loss: 0.5153 - val_accuracy: 0.7000\n",
      "Epoch 364/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.4443 - accuracy: 0.9000 - val_loss: 0.5146 - val_accuracy: 0.8000\n",
      "Epoch 365/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.4434 - accuracy: 0.9000 - val_loss: 0.5140 - val_accuracy: 0.8000\n",
      "Epoch 366/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.4424 - accuracy: 0.9000 - val_loss: 0.5133 - val_accuracy: 0.8000\n",
      "Epoch 367/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.4415 - accuracy: 0.9333 - val_loss: 0.5127 - val_accuracy: 0.8000\n",
      "Epoch 368/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.4405 - accuracy: 0.9333 - val_loss: 0.5120 - val_accuracy: 0.8000\n",
      "Epoch 369/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.4396 - accuracy: 0.9333 - val_loss: 0.5114 - val_accuracy: 0.8000\n",
      "Epoch 370/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.4387 - accuracy: 0.9333 - val_loss: 0.5107 - val_accuracy: 0.8000\n",
      "Epoch 371/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.4377 - accuracy: 0.9333 - val_loss: 0.5101 - val_accuracy: 0.8000\n",
      "Epoch 372/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.4368 - accuracy: 0.9333 - val_loss: 0.5094 - val_accuracy: 0.8000\n",
      "Epoch 373/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.4358 - accuracy: 0.9333 - val_loss: 0.5088 - val_accuracy: 0.8000\n",
      "Epoch 374/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.4349 - accuracy: 0.9333 - val_loss: 0.5082 - val_accuracy: 0.8000\n",
      "Epoch 375/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.4339 - accuracy: 0.9333 - val_loss: 0.5075 - val_accuracy: 0.8000\n",
      "Epoch 376/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.4330 - accuracy: 0.9333 - val_loss: 0.5069 - val_accuracy: 0.8000\n",
      "Epoch 377/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.4320 - accuracy: 0.9333 - val_loss: 0.5063 - val_accuracy: 0.8000\n",
      "Epoch 378/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.4311 - accuracy: 0.9333 - val_loss: 0.5057 - val_accuracy: 0.8000\n",
      "Epoch 379/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.4301 - accuracy: 0.9333 - val_loss: 0.5051 - val_accuracy: 0.8000\n",
      "Epoch 380/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.4292 - accuracy: 0.9333 - val_loss: 0.5044 - val_accuracy: 0.8000\n",
      "Epoch 381/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.4282 - accuracy: 0.9333 - val_loss: 0.5038 - val_accuracy: 0.8000\n",
      "Epoch 382/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.4273 - accuracy: 0.9333 - val_loss: 0.5032 - val_accuracy: 0.8000\n",
      "Epoch 383/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.4263 - accuracy: 0.9333 - val_loss: 0.5026 - val_accuracy: 0.8000\n",
      "Epoch 384/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.4254 - accuracy: 0.9333 - val_loss: 0.5020 - val_accuracy: 0.8000\n",
      "Epoch 385/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.4244 - accuracy: 0.9333 - val_loss: 0.5014 - val_accuracy: 0.8000\n",
      "Epoch 386/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.4234 - accuracy: 0.9333 - val_loss: 0.5009 - val_accuracy: 0.8000\n",
      "Epoch 387/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.4225 - accuracy: 0.9333 - val_loss: 0.5003 - val_accuracy: 0.8000\n",
      "Epoch 388/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.4215 - accuracy: 0.9333 - val_loss: 0.4997 - val_accuracy: 0.8000\n",
      "Epoch 389/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.4206 - accuracy: 0.9333 - val_loss: 0.4991 - val_accuracy: 0.8000\n",
      "Epoch 390/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.4196 - accuracy: 0.9333 - val_loss: 0.4985 - val_accuracy: 0.8000\n",
      "Epoch 391/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.4187 - accuracy: 0.9333 - val_loss: 0.4980 - val_accuracy: 0.8000\n",
      "Epoch 392/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.4177 - accuracy: 0.9333 - val_loss: 0.4974 - val_accuracy: 0.8000\n",
      "Epoch 393/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.4168 - accuracy: 0.9333 - val_loss: 0.4968 - val_accuracy: 0.8000\n",
      "Epoch 394/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.4158 - accuracy: 0.9333 - val_loss: 0.4963 - val_accuracy: 0.8000\n",
      "Epoch 395/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.4149 - accuracy: 0.9333 - val_loss: 0.4957 - val_accuracy: 0.8000\n",
      "Epoch 396/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.4139 - accuracy: 0.9333 - val_loss: 0.4951 - val_accuracy: 0.8000\n",
      "Epoch 397/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.4130 - accuracy: 0.9333 - val_loss: 0.4946 - val_accuracy: 0.8000\n",
      "Epoch 398/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.4120 - accuracy: 0.9333 - val_loss: 0.4941 - val_accuracy: 0.8000\n",
      "Epoch 399/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.4111 - accuracy: 0.9333 - val_loss: 0.4935 - val_accuracy: 0.8000\n",
      "Epoch 400/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.4101 - accuracy: 0.9333 - val_loss: 0.4930 - val_accuracy: 0.8000\n",
      "Epoch 401/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.4091 - accuracy: 0.9333 - val_loss: 0.4924 - val_accuracy: 0.8000\n",
      "Epoch 402/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.4082 - accuracy: 0.9333 - val_loss: 0.4919 - val_accuracy: 0.8000\n",
      "Epoch 403/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.4072 - accuracy: 0.9333 - val_loss: 0.4914 - val_accuracy: 0.8000\n",
      "Epoch 404/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.4063 - accuracy: 0.9333 - val_loss: 0.4909 - val_accuracy: 0.8000\n",
      "Epoch 405/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.4053 - accuracy: 0.9333 - val_loss: 0.4904 - val_accuracy: 0.8000\n",
      "Epoch 406/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.4044 - accuracy: 0.9333 - val_loss: 0.4899 - val_accuracy: 0.8000\n",
      "Epoch 407/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.4034 - accuracy: 0.9333 - val_loss: 0.4894 - val_accuracy: 0.8000\n",
      "Epoch 408/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.4025 - accuracy: 0.9333 - val_loss: 0.4889 - val_accuracy: 0.8000\n",
      "Epoch 409/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.4015 - accuracy: 0.9333 - val_loss: 0.4884 - val_accuracy: 0.8000\n",
      "Epoch 410/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.4006 - accuracy: 0.9333 - val_loss: 0.4879 - val_accuracy: 0.8000\n",
      "Epoch 411/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.3996 - accuracy: 0.9333 - val_loss: 0.4874 - val_accuracy: 0.8000\n",
      "Epoch 412/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.3987 - accuracy: 0.9333 - val_loss: 0.4869 - val_accuracy: 0.8000\n",
      "Epoch 413/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.3977 - accuracy: 0.9333 - val_loss: 0.4864 - val_accuracy: 0.8000\n",
      "Epoch 414/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.3968 - accuracy: 0.9333 - val_loss: 0.4860 - val_accuracy: 0.8000\n",
      "Epoch 415/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.3958 - accuracy: 0.9333 - val_loss: 0.4855 - val_accuracy: 0.8000\n",
      "Epoch 416/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.3949 - accuracy: 0.9333 - val_loss: 0.4850 - val_accuracy: 0.8000\n",
      "Epoch 417/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.3939 - accuracy: 0.9333 - val_loss: 0.4846 - val_accuracy: 0.8000\n",
      "Epoch 418/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.3930 - accuracy: 0.9333 - val_loss: 0.4841 - val_accuracy: 0.8000\n",
      "Epoch 419/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.3920 - accuracy: 0.9333 - val_loss: 0.4837 - val_accuracy: 0.8000\n",
      "Epoch 420/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.3911 - accuracy: 0.9333 - val_loss: 0.4832 - val_accuracy: 0.8000\n",
      "Epoch 421/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.3901 - accuracy: 0.9333 - val_loss: 0.4828 - val_accuracy: 0.8000\n",
      "Epoch 422/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 0.3892 - accuracy: 0.9333 - val_loss: 0.4824 - val_accuracy: 0.8000\n",
      "Epoch 423/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.3882 - accuracy: 0.9333 - val_loss: 0.4819 - val_accuracy: 0.8000\n",
      "Epoch 424/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.3873 - accuracy: 0.9333 - val_loss: 0.4815 - val_accuracy: 0.8000\n",
      "Epoch 425/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.3863 - accuracy: 0.9333 - val_loss: 0.4811 - val_accuracy: 0.8000\n",
      "Epoch 426/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.3854 - accuracy: 0.9333 - val_loss: 0.4807 - val_accuracy: 0.8000\n",
      "Epoch 427/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.3844 - accuracy: 0.9333 - val_loss: 0.4803 - val_accuracy: 0.8000\n",
      "Epoch 428/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.3835 - accuracy: 0.9333 - val_loss: 0.4799 - val_accuracy: 0.8000\n",
      "Epoch 429/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.3826 - accuracy: 0.9333 - val_loss: 0.4795 - val_accuracy: 0.8000\n",
      "Epoch 430/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.3816 - accuracy: 0.9333 - val_loss: 0.4791 - val_accuracy: 0.8000\n",
      "Epoch 431/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.3807 - accuracy: 0.9333 - val_loss: 0.4787 - val_accuracy: 0.8000\n",
      "Epoch 432/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.3797 - accuracy: 0.9333 - val_loss: 0.4783 - val_accuracy: 0.8000\n",
      "Epoch 433/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.3788 - accuracy: 0.9333 - val_loss: 0.4780 - val_accuracy: 0.8000\n",
      "Epoch 434/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.3779 - accuracy: 0.9333 - val_loss: 0.4776 - val_accuracy: 0.8000\n",
      "Epoch 435/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.3769 - accuracy: 0.9333 - val_loss: 0.4773 - val_accuracy: 0.7000\n",
      "Epoch 436/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.3760 - accuracy: 0.9333 - val_loss: 0.4769 - val_accuracy: 0.7000\n",
      "Epoch 437/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.3751 - accuracy: 0.9333 - val_loss: 0.4766 - val_accuracy: 0.7000\n",
      "Epoch 438/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.3741 - accuracy: 0.9333 - val_loss: 0.4762 - val_accuracy: 0.7000\n",
      "Epoch 439/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.3732 - accuracy: 0.9333 - val_loss: 0.4759 - val_accuracy: 0.7000\n",
      "Epoch 440/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.3723 - accuracy: 0.9333 - val_loss: 0.4756 - val_accuracy: 0.7000\n",
      "Epoch 441/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.3713 - accuracy: 0.9333 - val_loss: 0.4753 - val_accuracy: 0.7000\n",
      "Epoch 442/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.3704 - accuracy: 0.9333 - val_loss: 0.4750 - val_accuracy: 0.7000\n",
      "Epoch 443/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.3695 - accuracy: 0.9333 - val_loss: 0.4747 - val_accuracy: 0.7000\n",
      "Epoch 444/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.3685 - accuracy: 0.9333 - val_loss: 0.4744 - val_accuracy: 0.7000\n",
      "Epoch 445/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.3676 - accuracy: 0.9333 - val_loss: 0.4741 - val_accuracy: 0.7000\n",
      "Epoch 446/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.3667 - accuracy: 0.9333 - val_loss: 0.4738 - val_accuracy: 0.7000\n",
      "Epoch 447/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.3658 - accuracy: 0.9333 - val_loss: 0.4735 - val_accuracy: 0.7000\n",
      "Epoch 448/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.3648 - accuracy: 0.9333 - val_loss: 0.4732 - val_accuracy: 0.7000\n",
      "Epoch 449/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.3639 - accuracy: 0.9333 - val_loss: 0.4730 - val_accuracy: 0.7000\n",
      "Epoch 450/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.3630 - accuracy: 0.9333 - val_loss: 0.4727 - val_accuracy: 0.7000\n",
      "Epoch 451/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.3621 - accuracy: 0.9333 - val_loss: 0.4724 - val_accuracy: 0.7000\n",
      "Epoch 452/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.3612 - accuracy: 0.9333 - val_loss: 0.4722 - val_accuracy: 0.7000\n",
      "Epoch 453/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.3602 - accuracy: 0.9333 - val_loss: 0.4720 - val_accuracy: 0.7000\n",
      "Epoch 454/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.3593 - accuracy: 0.9333 - val_loss: 0.4717 - val_accuracy: 0.7000\n",
      "Epoch 455/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.3584 - accuracy: 0.9333 - val_loss: 0.4715 - val_accuracy: 0.7000\n",
      "Epoch 456/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.3575 - accuracy: 0.9333 - val_loss: 0.4713 - val_accuracy: 0.7000\n",
      "Epoch 457/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.3566 - accuracy: 0.9333 - val_loss: 0.4710 - val_accuracy: 0.7000\n",
      "Epoch 458/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.3557 - accuracy: 0.9333 - val_loss: 0.4708 - val_accuracy: 0.7000\n",
      "Epoch 459/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.3548 - accuracy: 0.9333 - val_loss: 0.4706 - val_accuracy: 0.7000\n",
      "Epoch 460/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.3539 - accuracy: 0.9333 - val_loss: 0.4704 - val_accuracy: 0.7000\n",
      "Epoch 461/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.3529 - accuracy: 0.9333 - val_loss: 0.4702 - val_accuracy: 0.7000\n",
      "Epoch 462/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.3520 - accuracy: 0.9333 - val_loss: 0.4700 - val_accuracy: 0.7000\n",
      "Epoch 463/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.3511 - accuracy: 0.9333 - val_loss: 0.4699 - val_accuracy: 0.7000\n",
      "Epoch 464/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.3502 - accuracy: 0.9333 - val_loss: 0.4697 - val_accuracy: 0.7000\n",
      "Epoch 465/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.3493 - accuracy: 0.9333 - val_loss: 0.4695 - val_accuracy: 0.7000\n",
      "Epoch 466/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.3484 - accuracy: 0.9333 - val_loss: 0.4694 - val_accuracy: 0.7000\n",
      "Epoch 467/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.3475 - accuracy: 0.9333 - val_loss: 0.4692 - val_accuracy: 0.7000\n",
      "Epoch 468/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.3467 - accuracy: 0.9333 - val_loss: 0.4691 - val_accuracy: 0.7000\n",
      "Epoch 469/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3458 - accuracy: 0.9333 - val_loss: 0.4689 - val_accuracy: 0.7000\n",
      "Epoch 470/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.3449 - accuracy: 0.9333 - val_loss: 0.4688 - val_accuracy: 0.7000\n",
      "Epoch 471/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.3440 - accuracy: 0.9333 - val_loss: 0.4686 - val_accuracy: 0.7000\n",
      "Epoch 472/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.3431 - accuracy: 0.9333 - val_loss: 0.4685 - val_accuracy: 0.7000\n",
      "Epoch 473/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.3422 - accuracy: 0.9333 - val_loss: 0.4684 - val_accuracy: 0.7000\n",
      "Epoch 474/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.3413 - accuracy: 0.9333 - val_loss: 0.4683 - val_accuracy: 0.7000\n",
      "Epoch 475/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.3404 - accuracy: 0.9333 - val_loss: 0.4682 - val_accuracy: 0.7000\n",
      "Epoch 476/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.3396 - accuracy: 0.9333 - val_loss: 0.4681 - val_accuracy: 0.7000\n",
      "Epoch 477/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.3387 - accuracy: 0.9333 - val_loss: 0.4680 - val_accuracy: 0.7000\n",
      "Epoch 478/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.3378 - accuracy: 0.9333 - val_loss: 0.4679 - val_accuracy: 0.7000\n",
      "Epoch 479/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.3369 - accuracy: 0.9333 - val_loss: 0.4678 - val_accuracy: 0.7000\n",
      "Epoch 480/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.3361 - accuracy: 0.9333 - val_loss: 0.4678 - val_accuracy: 0.7000\n",
      "Epoch 481/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.3352 - accuracy: 0.9333 - val_loss: 0.4677 - val_accuracy: 0.7000\n",
      "Epoch 482/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.3343 - accuracy: 0.9333 - val_loss: 0.4676 - val_accuracy: 0.7000\n",
      "Epoch 483/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.3334 - accuracy: 0.9333 - val_loss: 0.4676 - val_accuracy: 0.7000\n",
      "Epoch 484/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.3326 - accuracy: 0.9333 - val_loss: 0.4675 - val_accuracy: 0.7000\n",
      "Epoch 485/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.3317 - accuracy: 0.9333 - val_loss: 0.4675 - val_accuracy: 0.7000\n",
      "Epoch 486/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.3309 - accuracy: 0.9333 - val_loss: 0.4675 - val_accuracy: 0.7000\n",
      "Epoch 487/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.3300 - accuracy: 0.9333 - val_loss: 0.4675 - val_accuracy: 0.7000\n",
      "Epoch 488/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.3291 - accuracy: 0.9333 - val_loss: 0.4674 - val_accuracy: 0.7000\n",
      "Epoch 489/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.3283 - accuracy: 0.9333 - val_loss: 0.4674 - val_accuracy: 0.7000\n",
      "Epoch 490/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.3274 - accuracy: 0.9333 - val_loss: 0.4674 - val_accuracy: 0.7000\n",
      "Epoch 491/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.3266 - accuracy: 0.9333 - val_loss: 0.4674 - val_accuracy: 0.7000\n",
      "Epoch 492/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.3257 - accuracy: 0.9333 - val_loss: 0.4674 - val_accuracy: 0.7000\n",
      "Epoch 493/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.3249 - accuracy: 0.9333 - val_loss: 0.4674 - val_accuracy: 0.7000\n",
      "Epoch 494/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.3240 - accuracy: 0.9333 - val_loss: 0.4675 - val_accuracy: 0.7000\n",
      "Epoch 495/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.3232 - accuracy: 0.9333 - val_loss: 0.4675 - val_accuracy: 0.7000\n",
      "Epoch 496/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.3223 - accuracy: 0.9333 - val_loss: 0.4675 - val_accuracy: 0.7000\n",
      "Epoch 497/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.3215 - accuracy: 0.9333 - val_loss: 0.4676 - val_accuracy: 0.7000\n",
      "Epoch 498/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.3207 - accuracy: 0.9333 - val_loss: 0.4676 - val_accuracy: 0.7000\n",
      "Epoch 499/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.3198 - accuracy: 0.9333 - val_loss: 0.4677 - val_accuracy: 0.7000\n",
      "Epoch 500/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.3190 - accuracy: 0.9333 - val_loss: 0.4677 - val_accuracy: 0.7000\n",
      "Epoch 501/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.3182 - accuracy: 0.9333 - val_loss: 0.4678 - val_accuracy: 0.7000\n",
      "Epoch 502/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.3173 - accuracy: 0.9333 - val_loss: 0.4678 - val_accuracy: 0.7000\n",
      "Epoch 503/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.3165 - accuracy: 0.9333 - val_loss: 0.4679 - val_accuracy: 0.7000\n",
      "Epoch 504/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.3157 - accuracy: 0.9333 - val_loss: 0.4680 - val_accuracy: 0.7000\n",
      "Epoch 505/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.3149 - accuracy: 0.9333 - val_loss: 0.4681 - val_accuracy: 0.7000\n",
      "Epoch 506/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.3140 - accuracy: 0.9333 - val_loss: 0.4682 - val_accuracy: 0.7000\n",
      "Epoch 507/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.3132 - accuracy: 0.9333 - val_loss: 0.4683 - val_accuracy: 0.7000\n",
      "Epoch 508/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.3124 - accuracy: 0.9333 - val_loss: 0.4684 - val_accuracy: 0.7000\n",
      "Epoch 509/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.3116 - accuracy: 0.9333 - val_loss: 0.4685 - val_accuracy: 0.7000\n",
      "Epoch 510/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.3108 - accuracy: 0.9333 - val_loss: 0.4687 - val_accuracy: 0.7000\n",
      "Epoch 511/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.3100 - accuracy: 0.9333 - val_loss: 0.4688 - val_accuracy: 0.7000\n",
      "Epoch 512/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.3092 - accuracy: 0.9333 - val_loss: 0.4689 - val_accuracy: 0.7000\n",
      "Epoch 513/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.3084 - accuracy: 0.9333 - val_loss: 0.4691 - val_accuracy: 0.7000\n",
      "Epoch 514/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.3076 - accuracy: 0.9333 - val_loss: 0.4692 - val_accuracy: 0.7000\n",
      "Epoch 515/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.3068 - accuracy: 0.9333 - val_loss: 0.4694 - val_accuracy: 0.7000\n",
      "Epoch 516/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.3060 - accuracy: 0.9333 - val_loss: 0.4696 - val_accuracy: 0.7000\n",
      "Epoch 517/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.3052 - accuracy: 0.9333 - val_loss: 0.4697 - val_accuracy: 0.7000\n",
      "Epoch 518/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.3044 - accuracy: 0.9333 - val_loss: 0.4699 - val_accuracy: 0.7000\n",
      "Epoch 519/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.3036 - accuracy: 0.9333 - val_loss: 0.4701 - val_accuracy: 0.7000\n",
      "Epoch 520/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.3028 - accuracy: 0.9333 - val_loss: 0.4703 - val_accuracy: 0.7000\n",
      "Epoch 521/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.3020 - accuracy: 0.9333 - val_loss: 0.4705 - val_accuracy: 0.7000\n",
      "Epoch 522/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.3012 - accuracy: 0.9333 - val_loss: 0.4707 - val_accuracy: 0.7000\n",
      "Epoch 523/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.3005 - accuracy: 0.9333 - val_loss: 0.4709 - val_accuracy: 0.7000\n",
      "Epoch 524/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.2997 - accuracy: 0.9333 - val_loss: 0.4711 - val_accuracy: 0.7000\n",
      "Epoch 525/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.2989 - accuracy: 0.9333 - val_loss: 0.4713 - val_accuracy: 0.7000\n",
      "Epoch 526/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.2981 - accuracy: 0.9333 - val_loss: 0.4715 - val_accuracy: 0.7000\n",
      "Epoch 527/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.2974 - accuracy: 0.9333 - val_loss: 0.4717 - val_accuracy: 0.7000\n",
      "Epoch 528/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.2966 - accuracy: 0.9333 - val_loss: 0.4720 - val_accuracy: 0.7000\n",
      "Epoch 529/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.2958 - accuracy: 0.9333 - val_loss: 0.4722 - val_accuracy: 0.7000\n",
      "Epoch 530/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.2951 - accuracy: 0.9333 - val_loss: 0.4725 - val_accuracy: 0.7000\n",
      "Epoch 531/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.2943 - accuracy: 0.9333 - val_loss: 0.4727 - val_accuracy: 0.7000\n",
      "Epoch 532/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.2935 - accuracy: 0.9333 - val_loss: 0.4730 - val_accuracy: 0.7000\n",
      "Epoch 533/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.2928 - accuracy: 0.9333 - val_loss: 0.4732 - val_accuracy: 0.7000\n",
      "Epoch 534/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.2920 - accuracy: 0.9333 - val_loss: 0.4735 - val_accuracy: 0.7000\n",
      "Epoch 535/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.2913 - accuracy: 0.9333 - val_loss: 0.4738 - val_accuracy: 0.7000\n",
      "Epoch 536/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.2905 - accuracy: 0.9333 - val_loss: 0.4741 - val_accuracy: 0.7000\n",
      "Epoch 537/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.2898 - accuracy: 0.9333 - val_loss: 0.4744 - val_accuracy: 0.7000\n",
      "Epoch 538/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.2890 - accuracy: 0.9333 - val_loss: 0.4746 - val_accuracy: 0.7000\n",
      "Epoch 539/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.2883 - accuracy: 0.9333 - val_loss: 0.4749 - val_accuracy: 0.7000\n",
      "Epoch 540/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.2875 - accuracy: 0.9333 - val_loss: 0.4753 - val_accuracy: 0.7000\n",
      "Epoch 541/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.2868 - accuracy: 0.9333 - val_loss: 0.4756 - val_accuracy: 0.7000\n",
      "Epoch 542/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.2861 - accuracy: 0.9333 - val_loss: 0.4759 - val_accuracy: 0.7000\n",
      "Epoch 543/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2853 - accuracy: 0.9333 - val_loss: 0.4762 - val_accuracy: 0.7000\n",
      "Epoch 544/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.2846 - accuracy: 0.9333 - val_loss: 0.4765 - val_accuracy: 0.7000\n",
      "Epoch 545/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.2839 - accuracy: 0.9333 - val_loss: 0.4769 - val_accuracy: 0.7000\n",
      "Epoch 546/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.2832 - accuracy: 0.9333 - val_loss: 0.4772 - val_accuracy: 0.7000\n",
      "Epoch 547/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.2824 - accuracy: 0.9333 - val_loss: 0.4775 - val_accuracy: 0.7000\n",
      "Epoch 548/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.2817 - accuracy: 0.9333 - val_loss: 0.4779 - val_accuracy: 0.7000\n",
      "Epoch 549/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.2810 - accuracy: 0.9333 - val_loss: 0.4782 - val_accuracy: 0.7000\n",
      "Epoch 550/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.2803 - accuracy: 0.9333 - val_loss: 0.4786 - val_accuracy: 0.7000\n",
      "Epoch 551/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.2796 - accuracy: 0.9333 - val_loss: 0.4790 - val_accuracy: 0.7000\n",
      "Epoch 552/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.2789 - accuracy: 0.9333 - val_loss: 0.4793 - val_accuracy: 0.7000\n",
      "Epoch 553/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.2782 - accuracy: 0.9333 - val_loss: 0.4797 - val_accuracy: 0.7000\n",
      "Epoch 554/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.2775 - accuracy: 0.9333 - val_loss: 0.4801 - val_accuracy: 0.7000\n",
      "Epoch 555/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.2768 - accuracy: 0.9333 - val_loss: 0.4805 - val_accuracy: 0.7000\n",
      "Epoch 556/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.2761 - accuracy: 0.9333 - val_loss: 0.4809 - val_accuracy: 0.7000\n",
      "Epoch 557/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.2754 - accuracy: 0.9333 - val_loss: 0.4813 - val_accuracy: 0.7000\n",
      "Epoch 558/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.2747 - accuracy: 0.9333 - val_loss: 0.4817 - val_accuracy: 0.7000\n",
      "Epoch 559/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.2740 - accuracy: 0.9333 - val_loss: 0.4821 - val_accuracy: 0.7000\n",
      "Epoch 560/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.2733 - accuracy: 0.9333 - val_loss: 0.4825 - val_accuracy: 0.7000\n",
      "Epoch 561/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.2726 - accuracy: 0.9333 - val_loss: 0.4829 - val_accuracy: 0.7000\n",
      "Epoch 562/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.2719 - accuracy: 0.9333 - val_loss: 0.4833 - val_accuracy: 0.7000\n",
      "Epoch 563/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.2712 - accuracy: 0.9333 - val_loss: 0.4837 - val_accuracy: 0.7000\n",
      "Epoch 564/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.2705 - accuracy: 0.9333 - val_loss: 0.4841 - val_accuracy: 0.7000\n",
      "Epoch 565/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.2699 - accuracy: 0.9333 - val_loss: 0.4846 - val_accuracy: 0.7000\n",
      "Epoch 566/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.2692 - accuracy: 0.9333 - val_loss: 0.4850 - val_accuracy: 0.7000\n",
      "Epoch 567/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.2685 - accuracy: 0.9333 - val_loss: 0.4855 - val_accuracy: 0.7000\n",
      "Epoch 568/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.2678 - accuracy: 0.9333 - val_loss: 0.4859 - val_accuracy: 0.7000\n",
      "Epoch 569/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2672 - accuracy: 0.9333 - val_loss: 0.4863 - val_accuracy: 0.7000\n",
      "Epoch 570/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2665 - accuracy: 0.9333 - val_loss: 0.4868 - val_accuracy: 0.7000\n",
      "Epoch 571/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.2659 - accuracy: 0.9333 - val_loss: 0.4873 - val_accuracy: 0.7000\n",
      "Epoch 572/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.2652 - accuracy: 0.9333 - val_loss: 0.4877 - val_accuracy: 0.7000\n",
      "Epoch 573/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.2645 - accuracy: 0.9333 - val_loss: 0.4882 - val_accuracy: 0.7000\n",
      "Epoch 574/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.2639 - accuracy: 0.9333 - val_loss: 0.4887 - val_accuracy: 0.7000\n",
      "Epoch 575/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.2632 - accuracy: 0.9333 - val_loss: 0.4891 - val_accuracy: 0.7000\n",
      "Epoch 576/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.2626 - accuracy: 0.9333 - val_loss: 0.4896 - val_accuracy: 0.7000\n",
      "Epoch 577/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.2619 - accuracy: 0.9333 - val_loss: 0.4901 - val_accuracy: 0.7000\n",
      "Epoch 578/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.2613 - accuracy: 0.9333 - val_loss: 0.4906 - val_accuracy: 0.7000\n",
      "Epoch 579/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.2606 - accuracy: 0.9333 - val_loss: 0.4911 - val_accuracy: 0.7000\n",
      "Epoch 580/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.2600 - accuracy: 0.9333 - val_loss: 0.4916 - val_accuracy: 0.7000\n",
      "Epoch 581/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.2594 - accuracy: 0.9333 - val_loss: 0.4921 - val_accuracy: 0.7000\n",
      "Epoch 582/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.2587 - accuracy: 0.9333 - val_loss: 0.4926 - val_accuracy: 0.7000\n",
      "Epoch 583/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.2581 - accuracy: 0.9333 - val_loss: 0.4931 - val_accuracy: 0.7000\n",
      "Epoch 584/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.2575 - accuracy: 0.9333 - val_loss: 0.4936 - val_accuracy: 0.7000\n",
      "Epoch 585/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.2568 - accuracy: 0.9333 - val_loss: 0.4941 - val_accuracy: 0.7000\n",
      "Epoch 586/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.2562 - accuracy: 0.9333 - val_loss: 0.4946 - val_accuracy: 0.7000\n",
      "Epoch 587/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.2556 - accuracy: 0.9333 - val_loss: 0.4951 - val_accuracy: 0.7000\n",
      "Epoch 588/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.2550 - accuracy: 0.9333 - val_loss: 0.4956 - val_accuracy: 0.7000\n",
      "Epoch 589/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.2544 - accuracy: 0.9333 - val_loss: 0.4962 - val_accuracy: 0.7000\n",
      "Epoch 590/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.2537 - accuracy: 0.9333 - val_loss: 0.4967 - val_accuracy: 0.7000\n",
      "Epoch 591/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.2531 - accuracy: 0.9333 - val_loss: 0.4972 - val_accuracy: 0.7000\n",
      "Epoch 592/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.2525 - accuracy: 0.9333 - val_loss: 0.4977 - val_accuracy: 0.7000\n",
      "Epoch 593/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.2519 - accuracy: 0.9333 - val_loss: 0.4983 - val_accuracy: 0.7000\n",
      "Epoch 594/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.2513 - accuracy: 0.9333 - val_loss: 0.4988 - val_accuracy: 0.7000\n",
      "Epoch 595/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.2507 - accuracy: 0.9333 - val_loss: 0.4994 - val_accuracy: 0.7000\n",
      "Epoch 596/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.2501 - accuracy: 0.9333 - val_loss: 0.4999 - val_accuracy: 0.7000\n",
      "Epoch 597/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.2495 - accuracy: 0.9333 - val_loss: 0.5004 - val_accuracy: 0.7000\n",
      "Epoch 598/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2489 - accuracy: 0.9333 - val_loss: 0.5010 - val_accuracy: 0.7000\n",
      "Epoch 599/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2483 - accuracy: 0.9333 - val_loss: 0.5015 - val_accuracy: 0.7000\n",
      "Epoch 600/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.2477 - accuracy: 0.9333 - val_loss: 0.5021 - val_accuracy: 0.7000\n",
      "Epoch 601/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.2471 - accuracy: 0.9333 - val_loss: 0.5026 - val_accuracy: 0.7000\n",
      "Epoch 602/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.2465 - accuracy: 0.9333 - val_loss: 0.5032 - val_accuracy: 0.7000\n",
      "Epoch 603/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.2460 - accuracy: 0.9333 - val_loss: 0.5038 - val_accuracy: 0.7000\n",
      "Epoch 604/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.2454 - accuracy: 0.9333 - val_loss: 0.5043 - val_accuracy: 0.7000\n",
      "Epoch 605/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.2448 - accuracy: 0.9333 - val_loss: 0.5049 - val_accuracy: 0.7000\n",
      "Epoch 606/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.2442 - accuracy: 0.9333 - val_loss: 0.5054 - val_accuracy: 0.7000\n",
      "Epoch 607/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.2436 - accuracy: 0.9333 - val_loss: 0.5060 - val_accuracy: 0.7000\n",
      "Epoch 608/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.2431 - accuracy: 0.9333 - val_loss: 0.5066 - val_accuracy: 0.7000\n",
      "Epoch 609/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.2425 - accuracy: 0.9333 - val_loss: 0.5071 - val_accuracy: 0.7000\n",
      "Epoch 610/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.2419 - accuracy: 0.9333 - val_loss: 0.5077 - val_accuracy: 0.7000\n",
      "Epoch 611/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.2414 - accuracy: 0.9333 - val_loss: 0.5083 - val_accuracy: 0.7000\n",
      "Epoch 612/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.2408 - accuracy: 0.9333 - val_loss: 0.5088 - val_accuracy: 0.7000\n",
      "Epoch 613/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.2402 - accuracy: 0.9333 - val_loss: 0.5094 - val_accuracy: 0.7000\n",
      "Epoch 614/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.2397 - accuracy: 0.9333 - val_loss: 0.5100 - val_accuracy: 0.7000\n",
      "Epoch 615/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.2391 - accuracy: 0.9333 - val_loss: 0.5106 - val_accuracy: 0.7000\n",
      "Epoch 616/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.2385 - accuracy: 0.9333 - val_loss: 0.5111 - val_accuracy: 0.7000\n",
      "Epoch 617/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.2380 - accuracy: 0.9333 - val_loss: 0.5117 - val_accuracy: 0.7000\n",
      "Epoch 618/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.2374 - accuracy: 0.9333 - val_loss: 0.5123 - val_accuracy: 0.7000\n",
      "Epoch 619/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.2369 - accuracy: 0.9333 - val_loss: 0.5129 - val_accuracy: 0.7000\n",
      "Epoch 620/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2363 - accuracy: 0.9333 - val_loss: 0.5134 - val_accuracy: 0.7000\n",
      "Epoch 621/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.2358 - accuracy: 0.9333 - val_loss: 0.5140 - val_accuracy: 0.7000\n",
      "Epoch 622/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.2353 - accuracy: 0.9333 - val_loss: 0.5146 - val_accuracy: 0.7000\n",
      "Epoch 623/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.2347 - accuracy: 0.9333 - val_loss: 0.5152 - val_accuracy: 0.7000\n",
      "Epoch 624/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.2342 - accuracy: 0.9333 - val_loss: 0.5157 - val_accuracy: 0.7000\n",
      "Epoch 625/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.2336 - accuracy: 0.9333 - val_loss: 0.5163 - val_accuracy: 0.7000\n",
      "Epoch 626/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.2331 - accuracy: 0.9333 - val_loss: 0.5169 - val_accuracy: 0.7000\n",
      "Epoch 627/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.2326 - accuracy: 0.9333 - val_loss: 0.5175 - val_accuracy: 0.7000\n",
      "Epoch 628/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.2320 - accuracy: 0.9333 - val_loss: 0.5180 - val_accuracy: 0.7000\n",
      "Epoch 629/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.2315 - accuracy: 0.9333 - val_loss: 0.5186 - val_accuracy: 0.7000\n",
      "Epoch 630/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.2310 - accuracy: 0.9333 - val_loss: 0.5192 - val_accuracy: 0.7000\n",
      "Epoch 631/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2305 - accuracy: 0.9333 - val_loss: 0.5198 - val_accuracy: 0.7000\n",
      "Epoch 632/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.2299 - accuracy: 0.9333 - val_loss: 0.5204 - val_accuracy: 0.7000\n",
      "Epoch 633/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.2294 - accuracy: 0.9333 - val_loss: 0.5209 - val_accuracy: 0.7000\n",
      "Epoch 634/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.2289 - accuracy: 0.9333 - val_loss: 0.5215 - val_accuracy: 0.7000\n",
      "Epoch 635/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.2284 - accuracy: 0.9333 - val_loss: 0.5221 - val_accuracy: 0.7000\n",
      "Epoch 636/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.2279 - accuracy: 0.9333 - val_loss: 0.5226 - val_accuracy: 0.7000\n",
      "Epoch 637/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.2274 - accuracy: 0.9333 - val_loss: 0.5232 - val_accuracy: 0.7000\n",
      "Epoch 638/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.2269 - accuracy: 0.9333 - val_loss: 0.5238 - val_accuracy: 0.7000\n",
      "Epoch 639/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.2264 - accuracy: 0.9333 - val_loss: 0.5244 - val_accuracy: 0.7000\n",
      "Epoch 640/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.2258 - accuracy: 0.9333 - val_loss: 0.5249 - val_accuracy: 0.7000\n",
      "Epoch 641/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.2253 - accuracy: 0.9333 - val_loss: 0.5255 - val_accuracy: 0.7000\n",
      "Epoch 642/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.2248 - accuracy: 0.9333 - val_loss: 0.5261 - val_accuracy: 0.7000\n",
      "Epoch 643/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.2243 - accuracy: 0.9333 - val_loss: 0.5266 - val_accuracy: 0.7000\n",
      "Epoch 644/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.2238 - accuracy: 0.9333 - val_loss: 0.5272 - val_accuracy: 0.7000\n",
      "Epoch 645/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.2234 - accuracy: 0.9333 - val_loss: 0.5278 - val_accuracy: 0.7000\n",
      "Epoch 646/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.2229 - accuracy: 0.9333 - val_loss: 0.5283 - val_accuracy: 0.7000\n",
      "Epoch 647/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.2224 - accuracy: 0.9333 - val_loss: 0.5289 - val_accuracy: 0.7000\n",
      "Epoch 648/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2219 - accuracy: 0.9333 - val_loss: 0.5294 - val_accuracy: 0.7000\n",
      "Epoch 649/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.2214 - accuracy: 0.9333 - val_loss: 0.5300 - val_accuracy: 0.7000\n",
      "Epoch 650/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.2209 - accuracy: 0.9333 - val_loss: 0.5305 - val_accuracy: 0.7000\n",
      "Epoch 651/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.2204 - accuracy: 0.9333 - val_loss: 0.5311 - val_accuracy: 0.7000\n",
      "Epoch 652/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.2199 - accuracy: 0.9333 - val_loss: 0.5316 - val_accuracy: 0.7000\n",
      "Epoch 653/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.2195 - accuracy: 0.9333 - val_loss: 0.5322 - val_accuracy: 0.7000\n",
      "Epoch 654/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.2190 - accuracy: 0.9333 - val_loss: 0.5327 - val_accuracy: 0.7000\n",
      "Epoch 655/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.2185 - accuracy: 0.9333 - val_loss: 0.5333 - val_accuracy: 0.7000\n",
      "Epoch 656/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.2180 - accuracy: 0.9333 - val_loss: 0.5338 - val_accuracy: 0.7000\n",
      "Epoch 657/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.2176 - accuracy: 0.9333 - val_loss: 0.5344 - val_accuracy: 0.7000\n",
      "Epoch 658/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.2171 - accuracy: 0.9333 - val_loss: 0.5349 - val_accuracy: 0.7000\n",
      "Epoch 659/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.2166 - accuracy: 0.9333 - val_loss: 0.5354 - val_accuracy: 0.7000\n",
      "Epoch 660/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.2161 - accuracy: 0.9333 - val_loss: 0.5360 - val_accuracy: 0.7000\n",
      "Epoch 661/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.2157 - accuracy: 0.9333 - val_loss: 0.5365 - val_accuracy: 0.7000\n",
      "Epoch 662/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.2152 - accuracy: 0.9333 - val_loss: 0.5370 - val_accuracy: 0.7000\n",
      "Epoch 663/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.2148 - accuracy: 0.9333 - val_loss: 0.5375 - val_accuracy: 0.7000\n",
      "Epoch 664/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.2143 - accuracy: 0.9333 - val_loss: 0.5380 - val_accuracy: 0.7000\n",
      "Epoch 665/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.2138 - accuracy: 0.9333 - val_loss: 0.5386 - val_accuracy: 0.7000\n",
      "Epoch 666/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.2134 - accuracy: 0.9333 - val_loss: 0.5391 - val_accuracy: 0.7000\n",
      "Epoch 667/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.2129 - accuracy: 0.9333 - val_loss: 0.5396 - val_accuracy: 0.7000\n",
      "Epoch 668/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.2125 - accuracy: 0.9333 - val_loss: 0.5401 - val_accuracy: 0.7000\n",
      "Epoch 669/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.2120 - accuracy: 0.9333 - val_loss: 0.5406 - val_accuracy: 0.7000\n",
      "Epoch 670/3000\n",
      "30/30 [==============================] - 0s 89us/step - loss: 0.2116 - accuracy: 0.9333 - val_loss: 0.5411 - val_accuracy: 0.7000\n",
      "Epoch 671/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.2111 - accuracy: 0.9333 - val_loss: 0.5416 - val_accuracy: 0.7000\n",
      "Epoch 672/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.2107 - accuracy: 0.9333 - val_loss: 0.5421 - val_accuracy: 0.7000\n",
      "Epoch 673/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.2102 - accuracy: 0.9333 - val_loss: 0.5426 - val_accuracy: 0.7000\n",
      "Epoch 674/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.2098 - accuracy: 0.9333 - val_loss: 0.5430 - val_accuracy: 0.7000\n",
      "Epoch 675/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.2094 - accuracy: 0.9333 - val_loss: 0.5435 - val_accuracy: 0.7000\n",
      "Epoch 676/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.2089 - accuracy: 0.9333 - val_loss: 0.5440 - val_accuracy: 0.7000\n",
      "Epoch 677/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.2085 - accuracy: 0.9333 - val_loss: 0.5445 - val_accuracy: 0.7000\n",
      "Epoch 678/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.2080 - accuracy: 0.9333 - val_loss: 0.5449 - val_accuracy: 0.7000\n",
      "Epoch 679/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.2076 - accuracy: 0.9333 - val_loss: 0.5454 - val_accuracy: 0.7000\n",
      "Epoch 680/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.2072 - accuracy: 0.9333 - val_loss: 0.5458 - val_accuracy: 0.7000\n",
      "Epoch 681/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.2067 - accuracy: 0.9333 - val_loss: 0.5463 - val_accuracy: 0.7000\n",
      "Epoch 682/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.2063 - accuracy: 0.9333 - val_loss: 0.5467 - val_accuracy: 0.7000\n",
      "Epoch 683/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.2059 - accuracy: 0.9333 - val_loss: 0.5472 - val_accuracy: 0.7000\n",
      "Epoch 684/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.2055 - accuracy: 0.9333 - val_loss: 0.5476 - val_accuracy: 0.7000\n",
      "Epoch 685/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.2050 - accuracy: 0.9333 - val_loss: 0.5481 - val_accuracy: 0.7000\n",
      "Epoch 686/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.2046 - accuracy: 0.9333 - val_loss: 0.5485 - val_accuracy: 0.7000\n",
      "Epoch 687/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.2042 - accuracy: 0.9333 - val_loss: 0.5489 - val_accuracy: 0.7000\n",
      "Epoch 688/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.2038 - accuracy: 0.9333 - val_loss: 0.5493 - val_accuracy: 0.7000\n",
      "Epoch 689/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.2033 - accuracy: 0.9333 - val_loss: 0.5498 - val_accuracy: 0.7000\n",
      "Epoch 690/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.2029 - accuracy: 0.9333 - val_loss: 0.5502 - val_accuracy: 0.7000\n",
      "Epoch 691/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.2025 - accuracy: 0.9333 - val_loss: 0.5506 - val_accuracy: 0.7000\n",
      "Epoch 692/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.2021 - accuracy: 0.9333 - val_loss: 0.5510 - val_accuracy: 0.7000\n",
      "Epoch 693/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.2017 - accuracy: 0.9333 - val_loss: 0.5514 - val_accuracy: 0.7000\n",
      "Epoch 694/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.2013 - accuracy: 0.9333 - val_loss: 0.5518 - val_accuracy: 0.7000\n",
      "Epoch 695/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.2009 - accuracy: 0.9333 - val_loss: 0.5521 - val_accuracy: 0.7000\n",
      "Epoch 696/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2005 - accuracy: 0.9333 - val_loss: 0.5525 - val_accuracy: 0.7000\n",
      "Epoch 697/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.2000 - accuracy: 0.9333 - val_loss: 0.5529 - val_accuracy: 0.7000\n",
      "Epoch 698/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.1996 - accuracy: 0.9333 - val_loss: 0.5533 - val_accuracy: 0.7000\n",
      "Epoch 699/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.1992 - accuracy: 0.9333 - val_loss: 0.5536 - val_accuracy: 0.7000\n",
      "Epoch 700/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.1988 - accuracy: 0.9333 - val_loss: 0.5540 - val_accuracy: 0.7000\n",
      "Epoch 701/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.1984 - accuracy: 0.9333 - val_loss: 0.5543 - val_accuracy: 0.7000\n",
      "Epoch 702/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.1980 - accuracy: 0.9333 - val_loss: 0.5547 - val_accuracy: 0.7000\n",
      "Epoch 703/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.1976 - accuracy: 0.9333 - val_loss: 0.5550 - val_accuracy: 0.7000\n",
      "Epoch 704/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1972 - accuracy: 0.9333 - val_loss: 0.5554 - val_accuracy: 0.7000\n",
      "Epoch 705/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1968 - accuracy: 0.9333 - val_loss: 0.5557 - val_accuracy: 0.7000\n",
      "Epoch 706/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.1964 - accuracy: 0.9333 - val_loss: 0.5560 - val_accuracy: 0.7000\n",
      "Epoch 707/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.1960 - accuracy: 0.9333 - val_loss: 0.5563 - val_accuracy: 0.7000\n",
      "Epoch 708/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.1957 - accuracy: 0.9333 - val_loss: 0.5566 - val_accuracy: 0.7000\n",
      "Epoch 709/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.1953 - accuracy: 0.9333 - val_loss: 0.5569 - val_accuracy: 0.7000\n",
      "Epoch 710/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.1949 - accuracy: 0.9333 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 711/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.1945 - accuracy: 0.9333 - val_loss: 0.5575 - val_accuracy: 0.7000\n",
      "Epoch 712/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.1941 - accuracy: 0.9333 - val_loss: 0.5578 - val_accuracy: 0.7000\n",
      "Epoch 713/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.1937 - accuracy: 0.9333 - val_loss: 0.5581 - val_accuracy: 0.7000\n",
      "Epoch 714/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.1933 - accuracy: 0.9333 - val_loss: 0.5583 - val_accuracy: 0.7000\n",
      "Epoch 715/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.1929 - accuracy: 0.9333 - val_loss: 0.5586 - val_accuracy: 0.7000\n",
      "Epoch 716/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.1926 - accuracy: 0.9333 - val_loss: 0.5588 - val_accuracy: 0.7000\n",
      "Epoch 717/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.1922 - accuracy: 0.9333 - val_loss: 0.5591 - val_accuracy: 0.7000\n",
      "Epoch 718/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.1918 - accuracy: 0.9333 - val_loss: 0.5593 - val_accuracy: 0.7000\n",
      "Epoch 719/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1914 - accuracy: 0.9333 - val_loss: 0.5596 - val_accuracy: 0.7000\n",
      "Epoch 720/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.1910 - accuracy: 0.9333 - val_loss: 0.5598 - val_accuracy: 0.7000\n",
      "Epoch 721/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.1907 - accuracy: 0.9333 - val_loss: 0.5600 - val_accuracy: 0.7000\n",
      "Epoch 722/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.1903 - accuracy: 0.9333 - val_loss: 0.5602 - val_accuracy: 0.7000\n",
      "Epoch 723/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.1899 - accuracy: 0.9333 - val_loss: 0.5604 - val_accuracy: 0.7000\n",
      "Epoch 724/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.1896 - accuracy: 0.9333 - val_loss: 0.5606 - val_accuracy: 0.7000\n",
      "Epoch 725/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.1892 - accuracy: 0.9333 - val_loss: 0.5608 - val_accuracy: 0.7000\n",
      "Epoch 726/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.1888 - accuracy: 0.9333 - val_loss: 0.5610 - val_accuracy: 0.7000\n",
      "Epoch 727/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.1884 - accuracy: 0.9333 - val_loss: 0.5612 - val_accuracy: 0.7000\n",
      "Epoch 728/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.1881 - accuracy: 0.9333 - val_loss: 0.5614 - val_accuracy: 0.7000\n",
      "Epoch 729/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.1877 - accuracy: 0.9333 - val_loss: 0.5615 - val_accuracy: 0.7000\n",
      "Epoch 730/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.1873 - accuracy: 0.9333 - val_loss: 0.5617 - val_accuracy: 0.7000\n",
      "Epoch 731/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.1870 - accuracy: 0.9333 - val_loss: 0.5618 - val_accuracy: 0.7000\n",
      "Epoch 732/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.1866 - accuracy: 0.9333 - val_loss: 0.5620 - val_accuracy: 0.7000\n",
      "Epoch 733/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.1862 - accuracy: 0.9333 - val_loss: 0.5621 - val_accuracy: 0.7000\n",
      "Epoch 734/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.1859 - accuracy: 0.9333 - val_loss: 0.5622 - val_accuracy: 0.7000\n",
      "Epoch 735/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1855 - accuracy: 0.9333 - val_loss: 0.5624 - val_accuracy: 0.7000\n",
      "Epoch 736/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.1852 - accuracy: 0.9333 - val_loss: 0.5625 - val_accuracy: 0.7000\n",
      "Epoch 737/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.1848 - accuracy: 0.9333 - val_loss: 0.5626 - val_accuracy: 0.7000\n",
      "Epoch 738/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.1844 - accuracy: 0.9333 - val_loss: 0.5627 - val_accuracy: 0.7000\n",
      "Epoch 739/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.1841 - accuracy: 0.9333 - val_loss: 0.5628 - val_accuracy: 0.7000\n",
      "Epoch 740/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.1837 - accuracy: 0.9333 - val_loss: 0.5628 - val_accuracy: 0.7000\n",
      "Epoch 741/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.1834 - accuracy: 0.9333 - val_loss: 0.5629 - val_accuracy: 0.7000\n",
      "Epoch 742/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.1830 - accuracy: 0.9333 - val_loss: 0.5630 - val_accuracy: 0.7000\n",
      "Epoch 743/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.1827 - accuracy: 0.9333 - val_loss: 0.5630 - val_accuracy: 0.7000\n",
      "Epoch 744/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.1823 - accuracy: 0.9333 - val_loss: 0.5631 - val_accuracy: 0.7000\n",
      "Epoch 745/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1820 - accuracy: 0.9333 - val_loss: 0.5631 - val_accuracy: 0.7000\n",
      "Epoch 746/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1816 - accuracy: 0.9333 - val_loss: 0.5632 - val_accuracy: 0.7000\n",
      "Epoch 747/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.1813 - accuracy: 0.9333 - val_loss: 0.5632 - val_accuracy: 0.7000\n",
      "Epoch 748/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1809 - accuracy: 0.9333 - val_loss: 0.5632 - val_accuracy: 0.7000\n",
      "Epoch 749/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.1806 - accuracy: 0.9333 - val_loss: 0.5632 - val_accuracy: 0.7000\n",
      "Epoch 750/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1802 - accuracy: 0.9333 - val_loss: 0.5632 - val_accuracy: 0.7000\n",
      "Epoch 751/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1799 - accuracy: 0.9333 - val_loss: 0.5632 - val_accuracy: 0.7000\n",
      "Epoch 752/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.1795 - accuracy: 0.9333 - val_loss: 0.5632 - val_accuracy: 0.7000\n",
      "Epoch 753/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.1792 - accuracy: 0.9333 - val_loss: 0.5631 - val_accuracy: 0.7000\n",
      "Epoch 754/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.1788 - accuracy: 0.9333 - val_loss: 0.5631 - val_accuracy: 0.7000\n",
      "Epoch 755/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.1785 - accuracy: 0.9333 - val_loss: 0.5630 - val_accuracy: 0.7000\n",
      "Epoch 756/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.1782 - accuracy: 0.9333 - val_loss: 0.5630 - val_accuracy: 0.7000\n",
      "Epoch 757/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.1778 - accuracy: 0.9333 - val_loss: 0.5629 - val_accuracy: 0.7000\n",
      "Epoch 758/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.1775 - accuracy: 0.9333 - val_loss: 0.5628 - val_accuracy: 0.7000\n",
      "Epoch 759/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.1771 - accuracy: 0.9333 - val_loss: 0.5628 - val_accuracy: 0.7000\n",
      "Epoch 760/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.1768 - accuracy: 0.9333 - val_loss: 0.5627 - val_accuracy: 0.7000\n",
      "Epoch 761/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.1765 - accuracy: 0.9333 - val_loss: 0.5626 - val_accuracy: 0.7000\n",
      "Epoch 762/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.1761 - accuracy: 0.9333 - val_loss: 0.5624 - val_accuracy: 0.7000\n",
      "Epoch 763/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.1758 - accuracy: 0.9000 - val_loss: 0.5623 - val_accuracy: 0.7000\n",
      "Epoch 764/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.1754 - accuracy: 0.9000 - val_loss: 0.5622 - val_accuracy: 0.7000\n",
      "Epoch 765/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.1751 - accuracy: 0.9000 - val_loss: 0.5621 - val_accuracy: 0.7000\n",
      "Epoch 766/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.1748 - accuracy: 0.9000 - val_loss: 0.5619 - val_accuracy: 0.7000\n",
      "Epoch 767/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.1744 - accuracy: 0.9000 - val_loss: 0.5617 - val_accuracy: 0.7000\n",
      "Epoch 768/3000\n",
      "30/30 [==============================] - 0s 93us/step - loss: 0.1741 - accuracy: 0.9000 - val_loss: 0.5616 - val_accuracy: 0.7000\n",
      "Epoch 769/3000\n",
      "30/30 [==============================] - 0s 93us/step - loss: 0.1738 - accuracy: 0.9000 - val_loss: 0.5614 - val_accuracy: 0.7000\n",
      "Epoch 770/3000\n",
      "30/30 [==============================] - 0s 92us/step - loss: 0.1734 - accuracy: 0.9000 - val_loss: 0.5612 - val_accuracy: 0.7000\n",
      "Epoch 771/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.1731 - accuracy: 0.9000 - val_loss: 0.5610 - val_accuracy: 0.7000\n",
      "Epoch 772/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.1728 - accuracy: 0.9000 - val_loss: 0.5608 - val_accuracy: 0.7000\n",
      "Epoch 773/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.1724 - accuracy: 0.9000 - val_loss: 0.5606 - val_accuracy: 0.7000\n",
      "Epoch 774/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.1721 - accuracy: 0.9000 - val_loss: 0.5604 - val_accuracy: 0.7000\n",
      "Epoch 775/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.1718 - accuracy: 0.9000 - val_loss: 0.5602 - val_accuracy: 0.7000\n",
      "Epoch 776/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.1715 - accuracy: 0.9000 - val_loss: 0.5599 - val_accuracy: 0.7000\n",
      "Epoch 777/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.1711 - accuracy: 0.9000 - val_loss: 0.5597 - val_accuracy: 0.7000\n",
      "Epoch 778/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.1708 - accuracy: 0.9000 - val_loss: 0.5594 - val_accuracy: 0.7000\n",
      "Epoch 779/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.1705 - accuracy: 0.9000 - val_loss: 0.5591 - val_accuracy: 0.7000\n",
      "Epoch 780/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.1702 - accuracy: 0.9000 - val_loss: 0.5588 - val_accuracy: 0.7000\n",
      "Epoch 781/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.1698 - accuracy: 0.9000 - val_loss: 0.5585 - val_accuracy: 0.7000\n",
      "Epoch 782/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.1695 - accuracy: 0.9000 - val_loss: 0.5582 - val_accuracy: 0.7000\n",
      "Epoch 783/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.1692 - accuracy: 0.9000 - val_loss: 0.5579 - val_accuracy: 0.7000\n",
      "Epoch 784/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.1689 - accuracy: 0.9000 - val_loss: 0.5576 - val_accuracy: 0.7000\n",
      "Epoch 785/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.1685 - accuracy: 0.9000 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 786/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.1682 - accuracy: 0.9000 - val_loss: 0.5569 - val_accuracy: 0.7000\n",
      "Epoch 787/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.1679 - accuracy: 0.9000 - val_loss: 0.5566 - val_accuracy: 0.7000\n",
      "Epoch 788/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.1676 - accuracy: 0.9000 - val_loss: 0.5562 - val_accuracy: 0.7000\n",
      "Epoch 789/3000\n",
      "30/30 [==============================] - 0s 94us/step - loss: 0.1672 - accuracy: 0.9000 - val_loss: 0.5559 - val_accuracy: 0.7000\n",
      "Epoch 790/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.1669 - accuracy: 0.9000 - val_loss: 0.5555 - val_accuracy: 0.7000\n",
      "Epoch 791/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.1666 - accuracy: 0.9000 - val_loss: 0.5551 - val_accuracy: 0.7000\n",
      "Epoch 792/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.1663 - accuracy: 0.9000 - val_loss: 0.5547 - val_accuracy: 0.7000\n",
      "Epoch 793/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.1660 - accuracy: 0.9000 - val_loss: 0.5543 - val_accuracy: 0.7000\n",
      "Epoch 794/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.1657 - accuracy: 0.9000 - val_loss: 0.5539 - val_accuracy: 0.7000\n",
      "Epoch 795/3000\n",
      "30/30 [==============================] - 0s 92us/step - loss: 0.1653 - accuracy: 0.9000 - val_loss: 0.5534 - val_accuracy: 0.7000\n",
      "Epoch 796/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.1650 - accuracy: 0.9000 - val_loss: 0.5530 - val_accuracy: 0.7000\n",
      "Epoch 797/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.1647 - accuracy: 0.9000 - val_loss: 0.5525 - val_accuracy: 0.7000\n",
      "Epoch 798/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.1644 - accuracy: 0.9000 - val_loss: 0.5521 - val_accuracy: 0.7000\n",
      "Epoch 799/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.1641 - accuracy: 0.9000 - val_loss: 0.5516 - val_accuracy: 0.7000\n",
      "Epoch 800/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.1638 - accuracy: 0.9000 - val_loss: 0.5511 - val_accuracy: 0.7000\n",
      "Epoch 801/3000\n",
      "30/30 [==============================] - 0s 92us/step - loss: 0.1634 - accuracy: 0.9000 - val_loss: 0.5506 - val_accuracy: 0.7000\n",
      "Epoch 802/3000\n",
      "30/30 [==============================] - 0s 94us/step - loss: 0.1631 - accuracy: 0.9000 - val_loss: 0.5501 - val_accuracy: 0.7000\n",
      "Epoch 803/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.1628 - accuracy: 0.9000 - val_loss: 0.5495 - val_accuracy: 0.7000\n",
      "Epoch 804/3000\n",
      "30/30 [==============================] - 0s 94us/step - loss: 0.1625 - accuracy: 0.9000 - val_loss: 0.5490 - val_accuracy: 0.7000\n",
      "Epoch 805/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.1622 - accuracy: 0.9000 - val_loss: 0.5484 - val_accuracy: 0.7000\n",
      "Epoch 806/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.1619 - accuracy: 0.9000 - val_loss: 0.5478 - val_accuracy: 0.7000\n",
      "Epoch 807/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.1616 - accuracy: 0.9000 - val_loss: 0.5472 - val_accuracy: 0.7000\n",
      "Epoch 808/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.1613 - accuracy: 0.9333 - val_loss: 0.5466 - val_accuracy: 0.7000\n",
      "Epoch 809/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.1610 - accuracy: 0.9333 - val_loss: 0.5460 - val_accuracy: 0.7000\n",
      "Epoch 810/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.1606 - accuracy: 0.9333 - val_loss: 0.5454 - val_accuracy: 0.7000\n",
      "Epoch 811/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.1603 - accuracy: 0.9333 - val_loss: 0.5448 - val_accuracy: 0.7000\n",
      "Epoch 812/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.1600 - accuracy: 0.9333 - val_loss: 0.5442 - val_accuracy: 0.7000\n",
      "Epoch 813/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.1597 - accuracy: 0.9333 - val_loss: 0.5436 - val_accuracy: 0.7000\n",
      "Epoch 814/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.1594 - accuracy: 0.9333 - val_loss: 0.5430 - val_accuracy: 0.7000\n",
      "Epoch 815/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.1591 - accuracy: 0.9333 - val_loss: 0.5423 - val_accuracy: 0.7000\n",
      "Epoch 816/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.1588 - accuracy: 0.9333 - val_loss: 0.5417 - val_accuracy: 0.7000\n",
      "Epoch 817/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.1585 - accuracy: 0.9333 - val_loss: 0.5410 - val_accuracy: 0.7000\n",
      "Epoch 818/3000\n",
      "30/30 [==============================] - 0s 93us/step - loss: 0.1582 - accuracy: 0.9333 - val_loss: 0.5404 - val_accuracy: 0.7000\n",
      "Epoch 819/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.1579 - accuracy: 0.9333 - val_loss: 0.5397 - val_accuracy: 0.7000\n",
      "Epoch 820/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.1576 - accuracy: 0.9333 - val_loss: 0.5391 - val_accuracy: 0.7000\n",
      "Epoch 821/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.1573 - accuracy: 0.9333 - val_loss: 0.5384 - val_accuracy: 0.7000\n",
      "Epoch 822/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.1570 - accuracy: 0.9333 - val_loss: 0.5377 - val_accuracy: 0.7000\n",
      "Epoch 823/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.1567 - accuracy: 0.9333 - val_loss: 0.5370 - val_accuracy: 0.7000\n",
      "Epoch 824/3000\n",
      "30/30 [==============================] - 0s 94us/step - loss: 0.1564 - accuracy: 0.9333 - val_loss: 0.5363 - val_accuracy: 0.7000\n",
      "Epoch 825/3000\n",
      "30/30 [==============================] - 0s 91us/step - loss: 0.1561 - accuracy: 0.9333 - val_loss: 0.5356 - val_accuracy: 0.7000\n",
      "Epoch 826/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.1558 - accuracy: 0.9333 - val_loss: 0.5349 - val_accuracy: 0.7000\n",
      "Epoch 827/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.1555 - accuracy: 0.9333 - val_loss: 0.5342 - val_accuracy: 0.7000\n",
      "Epoch 828/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.1552 - accuracy: 0.9333 - val_loss: 0.5334 - val_accuracy: 0.7000\n",
      "Epoch 829/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.1549 - accuracy: 0.9333 - val_loss: 0.5327 - val_accuracy: 0.7000\n",
      "Epoch 830/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.1546 - accuracy: 0.9333 - val_loss: 0.5319 - val_accuracy: 0.7000\n",
      "Epoch 831/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1543 - accuracy: 0.9333 - val_loss: 0.5311 - val_accuracy: 0.7000\n",
      "Epoch 832/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.1540 - accuracy: 0.9333 - val_loss: 0.5304 - val_accuracy: 0.7000\n",
      "Epoch 833/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.1537 - accuracy: 0.9333 - val_loss: 0.5296 - val_accuracy: 0.7000\n",
      "Epoch 834/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.1534 - accuracy: 0.9333 - val_loss: 0.5288 - val_accuracy: 0.7000\n",
      "Epoch 835/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.1531 - accuracy: 0.9333 - val_loss: 0.5280 - val_accuracy: 0.7000\n",
      "Epoch 836/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.1529 - accuracy: 0.9333 - val_loss: 0.5272 - val_accuracy: 0.7000\n",
      "Epoch 837/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.1526 - accuracy: 0.9333 - val_loss: 0.5263 - val_accuracy: 0.7000\n",
      "Epoch 838/3000\n",
      "30/30 [==============================] - 0s 93us/step - loss: 0.1523 - accuracy: 0.9333 - val_loss: 0.5255 - val_accuracy: 0.7000\n",
      "Epoch 839/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.1520 - accuracy: 0.9333 - val_loss: 0.5247 - val_accuracy: 0.7000\n",
      "Epoch 840/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 0.1517 - accuracy: 0.9333 - val_loss: 0.5238 - val_accuracy: 0.7000\n",
      "Epoch 841/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.1514 - accuracy: 0.9333 - val_loss: 0.5229 - val_accuracy: 0.7000\n",
      "Epoch 842/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.1511 - accuracy: 0.9333 - val_loss: 0.5221 - val_accuracy: 0.7000\n",
      "Epoch 843/3000\n",
      "30/30 [==============================] - 0s 94us/step - loss: 0.1508 - accuracy: 0.9333 - val_loss: 0.5212 - val_accuracy: 0.7000\n",
      "Epoch 844/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.1505 - accuracy: 0.9333 - val_loss: 0.5203 - val_accuracy: 0.7000\n",
      "Epoch 845/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.1502 - accuracy: 0.9333 - val_loss: 0.5194 - val_accuracy: 0.7000\n",
      "Epoch 846/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.1500 - accuracy: 0.9333 - val_loss: 0.5185 - val_accuracy: 0.7000\n",
      "Epoch 847/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.1497 - accuracy: 0.9333 - val_loss: 0.5176 - val_accuracy: 0.7000\n",
      "Epoch 848/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.1494 - accuracy: 0.9333 - val_loss: 0.5167 - val_accuracy: 0.7000\n",
      "Epoch 849/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.1491 - accuracy: 0.9333 - val_loss: 0.5157 - val_accuracy: 0.7000\n",
      "Epoch 850/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.1488 - accuracy: 0.9333 - val_loss: 0.5148 - val_accuracy: 0.8000\n",
      "Epoch 851/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.1485 - accuracy: 0.9333 - val_loss: 0.5139 - val_accuracy: 0.8000\n",
      "Epoch 852/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.1482 - accuracy: 0.9333 - val_loss: 0.5129 - val_accuracy: 0.8000\n",
      "Epoch 853/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1479 - accuracy: 0.9333 - val_loss: 0.5119 - val_accuracy: 0.8000\n",
      "Epoch 854/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.1477 - accuracy: 0.9333 - val_loss: 0.5109 - val_accuracy: 0.8000\n",
      "Epoch 855/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.1474 - accuracy: 0.9333 - val_loss: 0.5099 - val_accuracy: 0.8000\n",
      "Epoch 856/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1471 - accuracy: 0.9333 - val_loss: 0.5089 - val_accuracy: 0.8000\n",
      "Epoch 857/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.1468 - accuracy: 0.9333 - val_loss: 0.5079 - val_accuracy: 0.8000\n",
      "Epoch 858/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.1465 - accuracy: 0.9333 - val_loss: 0.5069 - val_accuracy: 0.8000\n",
      "Epoch 859/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.1462 - accuracy: 0.9333 - val_loss: 0.5059 - val_accuracy: 0.8000\n",
      "Epoch 860/3000\n",
      "30/30 [==============================] - 0s 421us/step - loss: 0.1459 - accuracy: 0.9333 - val_loss: 0.5048 - val_accuracy: 0.8000\n",
      "Epoch 861/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.1457 - accuracy: 0.9333 - val_loss: 0.5038 - val_accuracy: 0.8000\n",
      "Epoch 862/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.1454 - accuracy: 0.9333 - val_loss: 0.5027 - val_accuracy: 0.8000\n",
      "Epoch 863/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.1451 - accuracy: 0.9333 - val_loss: 0.5016 - val_accuracy: 0.8000\n",
      "Epoch 864/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.1448 - accuracy: 0.9333 - val_loss: 0.5006 - val_accuracy: 0.8000\n",
      "Epoch 865/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1445 - accuracy: 0.9333 - val_loss: 0.4995 - val_accuracy: 0.8000\n",
      "Epoch 866/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1442 - accuracy: 0.9333 - val_loss: 0.4984 - val_accuracy: 0.8000\n",
      "Epoch 867/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1440 - accuracy: 0.9333 - val_loss: 0.4973 - val_accuracy: 0.8000\n",
      "Epoch 868/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1437 - accuracy: 0.9333 - val_loss: 0.4962 - val_accuracy: 0.8000\n",
      "Epoch 869/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1434 - accuracy: 0.9333 - val_loss: 0.4951 - val_accuracy: 0.8000\n",
      "Epoch 870/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1431 - accuracy: 0.9333 - val_loss: 0.4940 - val_accuracy: 0.8000\n",
      "Epoch 871/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.1428 - accuracy: 0.9333 - val_loss: 0.4928 - val_accuracy: 0.8000\n",
      "Epoch 872/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1426 - accuracy: 0.9333 - val_loss: 0.4917 - val_accuracy: 0.8000\n",
      "Epoch 873/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1423 - accuracy: 0.9333 - val_loss: 0.4906 - val_accuracy: 0.8000\n",
      "Epoch 874/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.1420 - accuracy: 0.9333 - val_loss: 0.4894 - val_accuracy: 0.8000\n",
      "Epoch 875/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.1417 - accuracy: 0.9333 - val_loss: 0.4882 - val_accuracy: 0.8000\n",
      "Epoch 876/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.1414 - accuracy: 0.9333 - val_loss: 0.4871 - val_accuracy: 0.8000\n",
      "Epoch 877/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.1411 - accuracy: 0.9333 - val_loss: 0.4859 - val_accuracy: 0.8000\n",
      "Epoch 878/3000\n",
      "30/30 [==============================] - 0s 461us/step - loss: 0.1409 - accuracy: 0.9333 - val_loss: 0.4847 - val_accuracy: 0.8000\n",
      "Epoch 879/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.1406 - accuracy: 0.9333 - val_loss: 0.4835 - val_accuracy: 0.8000\n",
      "Epoch 880/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.1403 - accuracy: 0.9333 - val_loss: 0.4823 - val_accuracy: 0.8000\n",
      "Epoch 881/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.1400 - accuracy: 0.9333 - val_loss: 0.4811 - val_accuracy: 0.8000\n",
      "Epoch 882/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.1397 - accuracy: 0.9333 - val_loss: 0.4799 - val_accuracy: 0.8000\n",
      "Epoch 883/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.1395 - accuracy: 0.9333 - val_loss: 0.4787 - val_accuracy: 0.8000\n",
      "Epoch 884/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.1392 - accuracy: 0.9333 - val_loss: 0.4775 - val_accuracy: 0.8000\n",
      "Epoch 885/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.1389 - accuracy: 0.9333 - val_loss: 0.4762 - val_accuracy: 0.8000\n",
      "Epoch 886/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.1386 - accuracy: 0.9333 - val_loss: 0.4750 - val_accuracy: 0.8000\n",
      "Epoch 887/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.1383 - accuracy: 0.9333 - val_loss: 0.4738 - val_accuracy: 0.8000\n",
      "Epoch 888/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.1381 - accuracy: 0.9333 - val_loss: 0.4725 - val_accuracy: 0.8000\n",
      "Epoch 889/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.1378 - accuracy: 0.9667 - val_loss: 0.4712 - val_accuracy: 0.8000\n",
      "Epoch 890/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.1375 - accuracy: 0.9667 - val_loss: 0.4700 - val_accuracy: 0.8000\n",
      "Epoch 891/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.1372 - accuracy: 0.9667 - val_loss: 0.4687 - val_accuracy: 0.8000\n",
      "Epoch 892/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.1369 - accuracy: 0.9667 - val_loss: 0.4674 - val_accuracy: 0.8000\n",
      "Epoch 893/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.1367 - accuracy: 0.9667 - val_loss: 0.4661 - val_accuracy: 0.8000\n",
      "Epoch 894/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.1364 - accuracy: 0.9667 - val_loss: 0.4648 - val_accuracy: 0.8000\n",
      "Epoch 895/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.1361 - accuracy: 0.9667 - val_loss: 0.4635 - val_accuracy: 0.8000\n",
      "Epoch 896/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.1358 - accuracy: 0.9667 - val_loss: 0.4622 - val_accuracy: 0.8000\n",
      "Epoch 897/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.1355 - accuracy: 0.9667 - val_loss: 0.4609 - val_accuracy: 0.8000\n",
      "Epoch 898/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1353 - accuracy: 0.9667 - val_loss: 0.4596 - val_accuracy: 0.8000\n",
      "Epoch 899/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.1350 - accuracy: 0.9667 - val_loss: 0.4583 - val_accuracy: 0.8000\n",
      "Epoch 900/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1347 - accuracy: 0.9667 - val_loss: 0.4570 - val_accuracy: 0.8000\n",
      "Epoch 901/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.1344 - accuracy: 0.9667 - val_loss: 0.4556 - val_accuracy: 0.8000\n",
      "Epoch 902/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.1341 - accuracy: 0.9667 - val_loss: 0.4543 - val_accuracy: 0.8000\n",
      "Epoch 903/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.1338 - accuracy: 0.9667 - val_loss: 0.4529 - val_accuracy: 0.8000\n",
      "Epoch 904/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.1336 - accuracy: 0.9667 - val_loss: 0.4516 - val_accuracy: 0.8000\n",
      "Epoch 905/3000\n",
      "30/30 [==============================] - 0s 175us/step - loss: 0.1333 - accuracy: 0.9667 - val_loss: 0.4502 - val_accuracy: 0.8000\n",
      "Epoch 906/3000\n",
      "30/30 [==============================] - 0s 228us/step - loss: 0.1330 - accuracy: 0.9667 - val_loss: 0.4488 - val_accuracy: 0.8000\n",
      "Epoch 907/3000\n",
      "30/30 [==============================] - 0s 191us/step - loss: 0.1327 - accuracy: 0.9667 - val_loss: 0.4475 - val_accuracy: 0.8000\n",
      "Epoch 908/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.1324 - accuracy: 0.9667 - val_loss: 0.4461 - val_accuracy: 0.8000\n",
      "Epoch 909/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1322 - accuracy: 0.9667 - val_loss: 0.4447 - val_accuracy: 0.8000\n",
      "Epoch 910/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.1319 - accuracy: 0.9667 - val_loss: 0.4433 - val_accuracy: 0.8000\n",
      "Epoch 911/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1316 - accuracy: 0.9667 - val_loss: 0.4419 - val_accuracy: 0.8000\n",
      "Epoch 912/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1313 - accuracy: 0.9667 - val_loss: 0.4405 - val_accuracy: 0.8000\n",
      "Epoch 913/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1310 - accuracy: 0.9667 - val_loss: 0.4391 - val_accuracy: 0.8000\n",
      "Epoch 914/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1307 - accuracy: 0.9667 - val_loss: 0.4377 - val_accuracy: 0.8000\n",
      "Epoch 915/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.1305 - accuracy: 0.9667 - val_loss: 0.4363 - val_accuracy: 0.8000\n",
      "Epoch 916/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 0.1302 - accuracy: 0.9667 - val_loss: 0.4348 - val_accuracy: 0.8000\n",
      "Epoch 917/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.1299 - accuracy: 0.9667 - val_loss: 0.4334 - val_accuracy: 0.8000\n",
      "Epoch 918/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.1296 - accuracy: 0.9667 - val_loss: 0.4319 - val_accuracy: 0.8000\n",
      "Epoch 919/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.1293 - accuracy: 0.9667 - val_loss: 0.4305 - val_accuracy: 0.8000\n",
      "Epoch 920/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.1290 - accuracy: 0.9667 - val_loss: 0.4290 - val_accuracy: 0.8000\n",
      "Epoch 921/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.1288 - accuracy: 0.9667 - val_loss: 0.4276 - val_accuracy: 0.8000\n",
      "Epoch 922/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.1285 - accuracy: 0.9667 - val_loss: 0.4261 - val_accuracy: 0.8000\n",
      "Epoch 923/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.1282 - accuracy: 0.9667 - val_loss: 0.4247 - val_accuracy: 0.8000\n",
      "Epoch 924/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.1279 - accuracy: 0.9667 - val_loss: 0.4232 - val_accuracy: 0.8000\n",
      "Epoch 925/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.1276 - accuracy: 0.9667 - val_loss: 0.4217 - val_accuracy: 0.8000\n",
      "Epoch 926/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.1273 - accuracy: 0.9667 - val_loss: 0.4202 - val_accuracy: 0.8000\n",
      "Epoch 927/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.1270 - accuracy: 0.9667 - val_loss: 0.4187 - val_accuracy: 0.8000\n",
      "Epoch 928/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.1268 - accuracy: 0.9667 - val_loss: 0.4172 - val_accuracy: 0.8000\n",
      "Epoch 929/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.1265 - accuracy: 0.9667 - val_loss: 0.4157 - val_accuracy: 0.8000\n",
      "Epoch 930/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1262 - accuracy: 0.9667 - val_loss: 0.4142 - val_accuracy: 0.8000\n",
      "Epoch 931/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.1259 - accuracy: 0.9667 - val_loss: 0.4127 - val_accuracy: 0.8000\n",
      "Epoch 932/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.1256 - accuracy: 0.9667 - val_loss: 0.4112 - val_accuracy: 0.8000\n",
      "Epoch 933/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.1253 - accuracy: 0.9667 - val_loss: 0.4096 - val_accuracy: 0.8000\n",
      "Epoch 934/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.1250 - accuracy: 0.9667 - val_loss: 0.4081 - val_accuracy: 0.8000\n",
      "Epoch 935/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.1247 - accuracy: 0.9667 - val_loss: 0.4066 - val_accuracy: 0.8000\n",
      "Epoch 936/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.1244 - accuracy: 0.9667 - val_loss: 0.4050 - val_accuracy: 0.8000\n",
      "Epoch 937/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.1241 - accuracy: 0.9667 - val_loss: 0.4035 - val_accuracy: 0.8000\n",
      "Epoch 938/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.1239 - accuracy: 0.9667 - val_loss: 0.4019 - val_accuracy: 0.8000\n",
      "Epoch 939/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.1236 - accuracy: 0.9667 - val_loss: 0.4004 - val_accuracy: 0.8000\n",
      "Epoch 940/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1233 - accuracy: 0.9667 - val_loss: 0.3988 - val_accuracy: 0.8000\n",
      "Epoch 941/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.1230 - accuracy: 0.9667 - val_loss: 0.3972 - val_accuracy: 0.8000\n",
      "Epoch 942/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.1227 - accuracy: 0.9667 - val_loss: 0.3957 - val_accuracy: 0.8000\n",
      "Epoch 943/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.1224 - accuracy: 0.9667 - val_loss: 0.3941 - val_accuracy: 0.8000\n",
      "Epoch 944/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.1221 - accuracy: 0.9667 - val_loss: 0.3925 - val_accuracy: 0.8000\n",
      "Epoch 945/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1218 - accuracy: 0.9667 - val_loss: 0.3909 - val_accuracy: 0.8000\n",
      "Epoch 946/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.1215 - accuracy: 0.9667 - val_loss: 0.3893 - val_accuracy: 0.8000\n",
      "Epoch 947/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1212 - accuracy: 0.9667 - val_loss: 0.3877 - val_accuracy: 0.8000\n",
      "Epoch 948/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1209 - accuracy: 0.9667 - val_loss: 0.3861 - val_accuracy: 0.8000\n",
      "Epoch 949/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.1206 - accuracy: 0.9667 - val_loss: 0.3845 - val_accuracy: 0.8000\n",
      "Epoch 950/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.1203 - accuracy: 0.9667 - val_loss: 0.3828 - val_accuracy: 0.8000\n",
      "Epoch 951/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.1200 - accuracy: 0.9667 - val_loss: 0.3812 - val_accuracy: 0.8000\n",
      "Epoch 952/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.1197 - accuracy: 0.9667 - val_loss: 0.3796 - val_accuracy: 0.8000\n",
      "Epoch 953/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.1194 - accuracy: 0.9667 - val_loss: 0.3779 - val_accuracy: 0.8000\n",
      "Epoch 954/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.1191 - accuracy: 0.9667 - val_loss: 0.3763 - val_accuracy: 0.8000\n",
      "Epoch 955/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.1188 - accuracy: 0.9667 - val_loss: 0.3747 - val_accuracy: 0.8000\n",
      "Epoch 956/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.1185 - accuracy: 0.9667 - val_loss: 0.3730 - val_accuracy: 0.8000\n",
      "Epoch 957/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.1182 - accuracy: 0.9667 - val_loss: 0.3713 - val_accuracy: 0.8000\n",
      "Epoch 958/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.1179 - accuracy: 1.0000 - val_loss: 0.3697 - val_accuracy: 0.8000\n",
      "Epoch 959/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.1176 - accuracy: 1.0000 - val_loss: 0.3680 - val_accuracy: 0.8000\n",
      "Epoch 960/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.1173 - accuracy: 1.0000 - val_loss: 0.3663 - val_accuracy: 0.8000\n",
      "Epoch 961/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.1170 - accuracy: 1.0000 - val_loss: 0.3647 - val_accuracy: 0.8000\n",
      "Epoch 962/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.1167 - accuracy: 1.0000 - val_loss: 0.3630 - val_accuracy: 0.8000\n",
      "Epoch 963/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.1164 - accuracy: 1.0000 - val_loss: 0.3613 - val_accuracy: 0.8000\n",
      "Epoch 964/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.1161 - accuracy: 1.0000 - val_loss: 0.3596 - val_accuracy: 0.8000\n",
      "Epoch 965/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.1158 - accuracy: 1.0000 - val_loss: 0.3579 - val_accuracy: 0.8000\n",
      "Epoch 966/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.1155 - accuracy: 1.0000 - val_loss: 0.3562 - val_accuracy: 0.8000\n",
      "Epoch 967/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.1152 - accuracy: 1.0000 - val_loss: 0.3545 - val_accuracy: 0.8000\n",
      "Epoch 968/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.1149 - accuracy: 1.0000 - val_loss: 0.3528 - val_accuracy: 0.8000\n",
      "Epoch 969/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.1146 - accuracy: 1.0000 - val_loss: 0.3511 - val_accuracy: 0.8000\n",
      "Epoch 970/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.1143 - accuracy: 1.0000 - val_loss: 0.3494 - val_accuracy: 0.8000\n",
      "Epoch 971/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.1140 - accuracy: 1.0000 - val_loss: 0.3477 - val_accuracy: 0.8000\n",
      "Epoch 972/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.1137 - accuracy: 1.0000 - val_loss: 0.3460 - val_accuracy: 0.8000\n",
      "Epoch 973/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.1134 - accuracy: 1.0000 - val_loss: 0.3443 - val_accuracy: 0.9000\n",
      "Epoch 974/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.1131 - accuracy: 1.0000 - val_loss: 0.3426 - val_accuracy: 0.9000\n",
      "Epoch 975/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.1128 - accuracy: 1.0000 - val_loss: 0.3409 - val_accuracy: 0.9000\n",
      "Epoch 976/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.1125 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.9000\n",
      "Epoch 977/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.1122 - accuracy: 1.0000 - val_loss: 0.3375 - val_accuracy: 0.9000\n",
      "Epoch 978/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.1119 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.9000\n",
      "Epoch 979/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.1116 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9000\n",
      "Epoch 980/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.1113 - accuracy: 1.0000 - val_loss: 0.3325 - val_accuracy: 0.9000\n",
      "Epoch 981/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.1110 - accuracy: 1.0000 - val_loss: 0.3308 - val_accuracy: 0.9000\n",
      "Epoch 982/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.1107 - accuracy: 1.0000 - val_loss: 0.3291 - val_accuracy: 0.9000\n",
      "Epoch 983/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.1104 - accuracy: 1.0000 - val_loss: 0.3275 - val_accuracy: 0.9000\n",
      "Epoch 984/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.1101 - accuracy: 1.0000 - val_loss: 0.3258 - val_accuracy: 0.9000\n",
      "Epoch 985/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.1098 - accuracy: 1.0000 - val_loss: 0.3242 - val_accuracy: 0.9000\n",
      "Epoch 986/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.1095 - accuracy: 1.0000 - val_loss: 0.3225 - val_accuracy: 0.9000\n",
      "Epoch 987/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.1092 - accuracy: 1.0000 - val_loss: 0.3209 - val_accuracy: 0.9000\n",
      "Epoch 988/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.1089 - accuracy: 1.0000 - val_loss: 0.3192 - val_accuracy: 0.9000\n",
      "Epoch 989/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1086 - accuracy: 1.0000 - val_loss: 0.3176 - val_accuracy: 0.9000\n",
      "Epoch 990/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1083 - accuracy: 1.0000 - val_loss: 0.3160 - val_accuracy: 0.9000\n",
      "Epoch 991/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.1080 - accuracy: 1.0000 - val_loss: 0.3143 - val_accuracy: 0.9000\n",
      "Epoch 992/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.1077 - accuracy: 1.0000 - val_loss: 0.3127 - val_accuracy: 0.9000\n",
      "Epoch 993/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.1074 - accuracy: 1.0000 - val_loss: 0.3111 - val_accuracy: 0.9000\n",
      "Epoch 994/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.1071 - accuracy: 1.0000 - val_loss: 0.3095 - val_accuracy: 0.9000\n",
      "Epoch 995/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.1068 - accuracy: 1.0000 - val_loss: 0.3079 - val_accuracy: 0.9000\n",
      "Epoch 996/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.1065 - accuracy: 1.0000 - val_loss: 0.3063 - val_accuracy: 0.9000\n",
      "Epoch 997/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.1062 - accuracy: 1.0000 - val_loss: 0.3047 - val_accuracy: 0.9000\n",
      "Epoch 998/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.1059 - accuracy: 1.0000 - val_loss: 0.3031 - val_accuracy: 0.9000\n",
      "Epoch 999/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.1056 - accuracy: 1.0000 - val_loss: 0.3015 - val_accuracy: 0.9000\n",
      "Epoch 1000/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.1053 - accuracy: 1.0000 - val_loss: 0.2999 - val_accuracy: 0.9000\n",
      "Epoch 1001/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.1050 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.9000\n",
      "Epoch 1002/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.1047 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.9000\n",
      "Epoch 1003/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.1044 - accuracy: 1.0000 - val_loss: 0.2952 - val_accuracy: 0.9000\n",
      "Epoch 1004/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.1041 - accuracy: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.9000\n",
      "Epoch 1005/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1038 - accuracy: 1.0000 - val_loss: 0.2921 - val_accuracy: 0.9000\n",
      "Epoch 1006/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1035 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9000\n",
      "Epoch 1007/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.1032 - accuracy: 1.0000 - val_loss: 0.2890 - val_accuracy: 0.9000\n",
      "Epoch 1008/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.1029 - accuracy: 1.0000 - val_loss: 0.2875 - val_accuracy: 0.9000\n",
      "Epoch 1009/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.1026 - accuracy: 1.0000 - val_loss: 0.2860 - val_accuracy: 0.9000\n",
      "Epoch 1010/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.1023 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.9000\n",
      "Epoch 1011/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.1020 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9000\n",
      "Epoch 1012/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.1017 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9000\n",
      "Epoch 1013/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.1014 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.9000\n",
      "Epoch 1014/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.1011 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.9000\n",
      "Epoch 1015/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1008 - accuracy: 1.0000 - val_loss: 0.2769 - val_accuracy: 0.9000\n",
      "Epoch 1016/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.1005 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9000\n",
      "Epoch 1017/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.1002 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9000\n",
      "Epoch 1018/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0999 - accuracy: 1.0000 - val_loss: 0.2725 - val_accuracy: 0.9000\n",
      "Epoch 1019/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0996 - accuracy: 1.0000 - val_loss: 0.2710 - val_accuracy: 0.9000\n",
      "Epoch 1020/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0993 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9000\n",
      "Epoch 1021/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0990 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9000\n",
      "Epoch 1022/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0987 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9000\n",
      "Epoch 1023/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0984 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 0.9000\n",
      "Epoch 1024/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0981 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.9000\n",
      "Epoch 1025/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0978 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9000\n",
      "Epoch 1026/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0975 - accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.9000\n",
      "Epoch 1027/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0972 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9000\n",
      "Epoch 1028/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0969 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9000\n",
      "Epoch 1029/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0966 - accuracy: 1.0000 - val_loss: 0.2567 - val_accuracy: 0.9000\n",
      "Epoch 1030/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0963 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9000\n",
      "Epoch 1031/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0960 - accuracy: 1.0000 - val_loss: 0.2539 - val_accuracy: 0.9000\n",
      "Epoch 1032/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0957 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9000\n",
      "Epoch 1033/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0954 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9000\n",
      "Epoch 1034/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0951 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9000\n",
      "Epoch 1035/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0948 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9000\n",
      "Epoch 1036/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0945 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.9000\n",
      "Epoch 1037/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0942 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9000\n",
      "Epoch 1038/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0939 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9000\n",
      "Epoch 1039/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0937 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9000\n",
      "Epoch 1040/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0934 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9000\n",
      "Epoch 1041/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0931 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9000\n",
      "Epoch 1042/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0928 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9000\n",
      "Epoch 1043/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0925 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9000\n",
      "Epoch 1044/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0922 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9000\n",
      "Epoch 1045/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0919 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9000\n",
      "Epoch 1046/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0916 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.9000\n",
      "Epoch 1047/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0913 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9000\n",
      "Epoch 1048/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0910 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.9000\n",
      "Epoch 1049/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0907 - accuracy: 1.0000 - val_loss: 0.2301 - val_accuracy: 0.9000\n",
      "Epoch 1050/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0904 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9000\n",
      "Epoch 1051/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0901 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9000\n",
      "Epoch 1052/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0898 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9000\n",
      "Epoch 1053/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0895 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9000\n",
      "Epoch 1054/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0892 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9000\n",
      "Epoch 1055/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0889 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 0.9000\n",
      "Epoch 1056/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0886 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9000\n",
      "Epoch 1057/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0883 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9000\n",
      "Epoch 1058/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0880 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9000\n",
      "Epoch 1059/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0877 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9000\n",
      "Epoch 1060/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0875 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.9000\n",
      "Epoch 1061/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0872 - accuracy: 1.0000 - val_loss: 0.2151 - val_accuracy: 0.9000\n",
      "Epoch 1062/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0869 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 1.0000\n",
      "Epoch 1063/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0866 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 1.0000\n",
      "Epoch 1064/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0863 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 1.0000\n",
      "Epoch 1065/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0860 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 1.0000\n",
      "Epoch 1066/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0857 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 1.0000\n",
      "Epoch 1067/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0854 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 1.0000\n",
      "Epoch 1068/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0851 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 1.0000\n",
      "Epoch 1069/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0848 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 1.0000\n",
      "Epoch 1070/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0845 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 1.0000\n",
      "Epoch 1071/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0843 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 1.0000\n",
      "Epoch 1072/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0840 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 1.0000\n",
      "Epoch 1073/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0837 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 1.0000\n",
      "Epoch 1074/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0834 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 1.0000\n",
      "Epoch 1075/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0831 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 1.0000\n",
      "Epoch 1076/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0828 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 1.0000\n",
      "Epoch 1077/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0825 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 1.0000\n",
      "Epoch 1078/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0822 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 1.0000\n",
      "Epoch 1079/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0820 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 1.0000\n",
      "Epoch 1080/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0817 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 1.0000\n",
      "Epoch 1081/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0814 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 1.0000\n",
      "Epoch 1082/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0811 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 1.0000\n",
      "Epoch 1083/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0808 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 1.0000\n",
      "Epoch 1084/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0805 - accuracy: 1.0000 - val_loss: 0.1895 - val_accuracy: 1.0000\n",
      "Epoch 1085/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 0.1885 - val_accuracy: 1.0000\n",
      "Epoch 1086/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0800 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 1.0000\n",
      "Epoch 1087/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0797 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 1.0000\n",
      "Epoch 1088/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0794 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 1.0000\n",
      "Epoch 1089/3000\n",
      "30/30 [==============================] - 0s 94us/step - loss: 0.0791 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 1.0000\n",
      "Epoch 1090/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0788 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 1.0000\n",
      "Epoch 1091/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0785 - accuracy: 1.0000 - val_loss: 0.1825 - val_accuracy: 1.0000\n",
      "Epoch 1092/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0782 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 1.0000\n",
      "Epoch 1093/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0780 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 1.0000\n",
      "Epoch 1094/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 0.1797 - val_accuracy: 1.0000\n",
      "Epoch 1095/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0774 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 1.0000\n",
      "Epoch 1096/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 1.0000\n",
      "Epoch 1097/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 0.0768 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 1.0000\n",
      "Epoch 1098/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0765 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 1.0000\n",
      "Epoch 1099/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0763 - accuracy: 1.0000 - val_loss: 0.1750 - val_accuracy: 1.0000\n",
      "Epoch 1100/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0760 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 1.0000\n",
      "Epoch 1101/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0757 - accuracy: 1.0000 - val_loss: 0.1731 - val_accuracy: 1.0000\n",
      "Epoch 1102/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0754 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 1.0000\n",
      "Epoch 1103/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0751 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 1.0000\n",
      "Epoch 1104/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0748 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 1.0000\n",
      "Epoch 1105/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0746 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 1.0000\n",
      "Epoch 1106/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0743 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 1.0000\n",
      "Epoch 1107/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0740 - accuracy: 1.0000 - val_loss: 0.1677 - val_accuracy: 1.0000\n",
      "Epoch 1108/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.0737 - accuracy: 1.0000 - val_loss: 0.1669 - val_accuracy: 1.0000\n",
      "Epoch 1109/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0734 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 1.0000\n",
      "Epoch 1110/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0732 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 1.0000\n",
      "Epoch 1111/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0729 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 1.0000\n",
      "Epoch 1112/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.1634 - val_accuracy: 1.0000\n",
      "Epoch 1113/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0723 - accuracy: 1.0000 - val_loss: 0.1625 - val_accuracy: 1.0000\n",
      "Epoch 1114/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0720 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 1.0000\n",
      "Epoch 1115/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0718 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 1.0000\n",
      "Epoch 1116/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0715 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 1.0000\n",
      "Epoch 1117/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0712 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 1.0000\n",
      "Epoch 1118/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.0709 - accuracy: 1.0000 - val_loss: 0.1583 - val_accuracy: 1.0000\n",
      "Epoch 1119/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0707 - accuracy: 1.0000 - val_loss: 0.1575 - val_accuracy: 1.0000\n",
      "Epoch 1120/3000\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0704 - accuracy: 1.0000 - val_loss: 0.1567 - val_accuracy: 1.0000\n",
      "Epoch 1121/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0701 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 1.0000\n",
      "Epoch 1122/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0698 - accuracy: 1.0000 - val_loss: 0.1551 - val_accuracy: 1.0000\n",
      "Epoch 1123/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0696 - accuracy: 1.0000 - val_loss: 0.1542 - val_accuracy: 1.0000\n",
      "Epoch 1124/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0693 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 1.0000\n",
      "Epoch 1125/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 1.0000\n",
      "Epoch 1126/3000\n",
      "30/30 [==============================] - 0s 94us/step - loss: 0.0687 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 1.0000\n",
      "Epoch 1127/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.1511 - val_accuracy: 1.0000\n",
      "Epoch 1128/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0682 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 1.0000\n",
      "Epoch 1129/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.1495 - val_accuracy: 1.0000\n",
      "Epoch 1130/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 0.1487 - val_accuracy: 1.0000\n",
      "Epoch 1131/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.1479 - val_accuracy: 1.0000\n",
      "Epoch 1132/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0671 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 1.0000\n",
      "Epoch 1133/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0668 - accuracy: 1.0000 - val_loss: 0.1464 - val_accuracy: 1.0000\n",
      "Epoch 1134/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.1456 - val_accuracy: 1.0000\n",
      "Epoch 1135/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.1449 - val_accuracy: 1.0000\n",
      "Epoch 1136/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0660 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 1.0000\n",
      "Epoch 1137/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0657 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 1.0000\n",
      "Epoch 1138/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 1.0000\n",
      "Epoch 1139/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.1419 - val_accuracy: 1.0000\n",
      "Epoch 1140/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0649 - accuracy: 1.0000 - val_loss: 0.1412 - val_accuracy: 1.0000\n",
      "Epoch 1141/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 1.0000\n",
      "Epoch 1142/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0644 - accuracy: 1.0000 - val_loss: 0.1397 - val_accuracy: 1.0000\n",
      "Epoch 1143/3000\n",
      "30/30 [==============================] - 0s 93us/step - loss: 0.0641 - accuracy: 1.0000 - val_loss: 0.1390 - val_accuracy: 1.0000\n",
      "Epoch 1144/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0639 - accuracy: 1.0000 - val_loss: 0.1383 - val_accuracy: 1.0000\n",
      "Epoch 1145/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 1.0000\n",
      "Epoch 1146/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0633 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 1.0000\n",
      "Epoch 1147/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0631 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 1.0000\n",
      "Epoch 1148/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0628 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 1.0000\n",
      "Epoch 1149/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0626 - accuracy: 1.0000 - val_loss: 0.1347 - val_accuracy: 1.0000\n",
      "Epoch 1150/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0623 - accuracy: 1.0000 - val_loss: 0.1340 - val_accuracy: 1.0000\n",
      "Epoch 1151/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.1333 - val_accuracy: 1.0000\n",
      "Epoch 1152/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 1.0000\n",
      "Epoch 1153/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.1319 - val_accuracy: 1.0000\n",
      "Epoch 1154/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.1313 - val_accuracy: 1.0000\n",
      "Epoch 1155/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 1.0000\n",
      "Epoch 1156/3000\n",
      "30/30 [==============================] - 0s 94us/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 1.0000\n",
      "Epoch 1157/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 1.0000\n",
      "Epoch 1158/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 1.0000\n",
      "Epoch 1159/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 1.0000\n",
      "Epoch 1160/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 1.0000\n",
      "Epoch 1161/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 1.0000\n",
      "Epoch 1162/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 0.0592 - accuracy: 1.0000 - val_loss: 0.1259 - val_accuracy: 1.0000\n",
      "Epoch 1163/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0589 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 1.0000\n",
      "Epoch 1164/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.1247 - val_accuracy: 1.0000\n",
      "Epoch 1165/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.1240 - val_accuracy: 1.0000\n",
      "Epoch 1166/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0582 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 1.0000\n",
      "Epoch 1167/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0579 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 1.0000\n",
      "Epoch 1168/3000\n",
      "30/30 [==============================] - 0s 92us/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 1.0000\n",
      "Epoch 1169/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 1.0000\n",
      "Epoch 1170/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0572 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 1.0000\n",
      "Epoch 1171/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.1202 - val_accuracy: 1.0000\n",
      "Epoch 1172/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0567 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 1.0000\n",
      "Epoch 1173/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 1.0000\n",
      "Epoch 1174/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0562 - accuracy: 1.0000 - val_loss: 0.1184 - val_accuracy: 1.0000\n",
      "Epoch 1175/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0559 - accuracy: 1.0000 - val_loss: 0.1178 - val_accuracy: 1.0000\n",
      "Epoch 1176/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.1172 - val_accuracy: 1.0000\n",
      "Epoch 1177/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 1.0000\n",
      "Epoch 1178/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.1160 - val_accuracy: 1.0000\n",
      "Epoch 1179/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.1154 - val_accuracy: 1.0000\n",
      "Epoch 1180/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.1148 - val_accuracy: 1.0000\n",
      "Epoch 1181/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.1142 - val_accuracy: 1.0000\n",
      "Epoch 1182/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.1136 - val_accuracy: 1.0000\n",
      "Epoch 1183/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0540 - accuracy: 1.0000 - val_loss: 0.1131 - val_accuracy: 1.0000\n",
      "Epoch 1184/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.1125 - val_accuracy: 1.0000\n",
      "Epoch 1185/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 1.0000\n",
      "Epoch 1186/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 0.1113 - val_accuracy: 1.0000\n",
      "Epoch 1187/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 1.0000\n",
      "Epoch 1188/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.1102 - val_accuracy: 1.0000\n",
      "Epoch 1189/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 1.0000\n",
      "Epoch 1190/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 1.0000\n",
      "Epoch 1191/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 1.0000\n",
      "Epoch 1192/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 1.0000\n",
      "Epoch 1193/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 1.0000\n",
      "Epoch 1194/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 1.0000\n",
      "Epoch 1195/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.1064 - val_accuracy: 1.0000\n",
      "Epoch 1196/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0509 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 1.0000\n",
      "Epoch 1197/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0507 - accuracy: 1.0000 - val_loss: 0.1053 - val_accuracy: 1.0000\n",
      "Epoch 1198/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 1.0000\n",
      "Epoch 1199/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 1.0000\n",
      "Epoch 1200/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.1037 - val_accuracy: 1.0000\n",
      "Epoch 1201/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 0.1032 - val_accuracy: 1.0000\n",
      "Epoch 1202/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 1.0000\n",
      "Epoch 1203/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 1.0000\n",
      "Epoch 1204/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 1.0000\n",
      "Epoch 1205/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 1.0000\n",
      "Epoch 1206/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 0.1006 - val_accuracy: 1.0000\n",
      "Epoch 1207/3000\n",
      "30/30 [==============================] - 0s 94us/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 1.0000\n",
      "Epoch 1208/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 0.0996 - val_accuracy: 1.0000\n",
      "Epoch 1209/3000\n",
      "30/30 [==============================] - 0s 94us/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 0.0991 - val_accuracy: 1.0000\n",
      "Epoch 1210/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 1.0000\n",
      "Epoch 1211/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 1.0000\n",
      "Epoch 1212/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 1.0000\n",
      "Epoch 1213/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 1.0000\n",
      "Epoch 1214/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 1.0000\n",
      "Epoch 1215/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 1.0000\n",
      "Epoch 1216/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 1.0000\n",
      "Epoch 1217/3000\n",
      "30/30 [==============================] - 0s 93us/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 1.0000\n",
      "Epoch 1218/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 1.0000\n",
      "Epoch 1219/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 1.0000\n",
      "Epoch 1220/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 1.0000\n",
      "Epoch 1221/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.0932 - val_accuracy: 1.0000\n",
      "Epoch 1222/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 1.0000\n",
      "Epoch 1223/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 1.0000\n",
      "Epoch 1224/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0447 - accuracy: 1.0000 - val_loss: 0.0918 - val_accuracy: 1.0000\n",
      "Epoch 1225/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.0914 - val_accuracy: 1.0000\n",
      "Epoch 1226/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 1.0000\n",
      "Epoch 1227/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 1.0000\n",
      "Epoch 1228/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.0439 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 1.0000\n",
      "Epoch 1229/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.0896 - val_accuracy: 1.0000\n",
      "Epoch 1230/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.0891 - val_accuracy: 1.0000\n",
      "Epoch 1231/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 1.0000\n",
      "Epoch 1232/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 1.0000\n",
      "Epoch 1233/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 1.0000\n",
      "Epoch 1234/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 1.0000\n",
      "Epoch 1235/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 1.0000\n",
      "Epoch 1236/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 1.0000\n",
      "Epoch 1237/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 1.0000\n",
      "Epoch 1238/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 1.0000\n",
      "Epoch 1239/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 1.0000\n",
      "Epoch 1240/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.0848 - val_accuracy: 1.0000\n",
      "Epoch 1241/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 1.0000\n",
      "Epoch 1242/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 1.0000\n",
      "Epoch 1243/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 1.0000\n",
      "Epoch 1244/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 1.0000\n",
      "Epoch 1245/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.0827 - val_accuracy: 1.0000\n",
      "Epoch 1246/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.0823 - val_accuracy: 1.0000\n",
      "Epoch 1247/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.0819 - val_accuracy: 1.0000\n",
      "Epoch 1248/3000\n",
      "30/30 [==============================] - 0s 94us/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.0814 - val_accuracy: 1.0000\n",
      "Epoch 1249/3000\n",
      "30/30 [==============================] - 0s 93us/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 1.0000\n",
      "Epoch 1250/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 1.0000\n",
      "Epoch 1251/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 1.0000\n",
      "Epoch 1252/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 1.0000\n",
      "Epoch 1253/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.0794 - val_accuracy: 1.0000\n",
      "Epoch 1254/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 1.0000\n",
      "Epoch 1255/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 1.0000\n",
      "Epoch 1256/3000\n",
      "30/30 [==============================] - 0s 92us/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 1.0000\n",
      "Epoch 1257/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.0779 - val_accuracy: 1.0000\n",
      "Epoch 1258/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 1.0000\n",
      "Epoch 1259/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 1.0000\n",
      "Epoch 1260/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 1.0000\n",
      "Epoch 1261/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
      "Epoch 1262/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
      "Epoch 1263/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 1.0000\n",
      "Epoch 1264/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 1.0000\n",
      "Epoch 1265/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.0749 - val_accuracy: 1.0000\n",
      "Epoch 1266/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 1.0000\n",
      "Epoch 1267/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 1.0000\n",
      "Epoch 1268/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 1.0000\n",
      "Epoch 1269/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.0734 - val_accuracy: 1.0000\n",
      "Epoch 1270/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.0730 - val_accuracy: 1.0000\n",
      "Epoch 1271/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.0727 - val_accuracy: 1.0000\n",
      "Epoch 1272/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.0723 - val_accuracy: 1.0000\n",
      "Epoch 1273/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.0719 - val_accuracy: 1.0000\n",
      "Epoch 1274/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.0716 - val_accuracy: 1.0000\n",
      "Epoch 1275/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.0712 - val_accuracy: 1.0000\n",
      "Epoch 1276/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 1.0000\n",
      "Epoch 1277/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 1.0000\n",
      "Epoch 1278/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 1.0000\n",
      "Epoch 1279/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 1.0000\n",
      "Epoch 1280/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 1.0000\n",
      "Epoch 1281/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 1.0000\n",
      "Epoch 1282/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 1.0000\n",
      "Epoch 1283/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 1.0000\n",
      "Epoch 1284/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 1.0000\n",
      "Epoch 1285/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 1.0000\n",
      "Epoch 1286/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.0675 - val_accuracy: 1.0000\n",
      "Epoch 1287/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.0672 - val_accuracy: 1.0000\n",
      "Epoch 1288/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.0668 - val_accuracy: 1.0000\n",
      "Epoch 1289/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.0665 - val_accuracy: 1.0000\n",
      "Epoch 1290/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 1.0000\n",
      "Epoch 1291/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.0658 - val_accuracy: 1.0000\n",
      "Epoch 1292/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 1.0000\n",
      "Epoch 1293/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.0652 - val_accuracy: 1.0000\n",
      "Epoch 1294/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.0649 - val_accuracy: 1.0000\n",
      "Epoch 1295/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 1.0000\n",
      "Epoch 1296/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.0643 - val_accuracy: 1.0000\n",
      "Epoch 1297/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 1.0000\n",
      "Epoch 1298/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 1.0000\n",
      "Epoch 1299/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.0633 - val_accuracy: 1.0000\n",
      "Epoch 1300/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.0630 - val_accuracy: 1.0000\n",
      "Epoch 1301/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.0627 - val_accuracy: 1.0000\n",
      "Epoch 1302/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.0624 - val_accuracy: 1.0000\n",
      "Epoch 1303/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 1.0000\n",
      "Epoch 1304/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.0618 - val_accuracy: 1.0000\n",
      "Epoch 1305/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.0615 - val_accuracy: 1.0000\n",
      "Epoch 1306/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.0612 - val_accuracy: 1.0000\n",
      "Epoch 1307/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.0609 - val_accuracy: 1.0000\n",
      "Epoch 1308/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.0606 - val_accuracy: 1.0000\n",
      "Epoch 1309/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.0603 - val_accuracy: 1.0000\n",
      "Epoch 1310/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.0600 - val_accuracy: 1.0000\n",
      "Epoch 1311/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.0597 - val_accuracy: 1.0000\n",
      "Epoch 1312/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.0594 - val_accuracy: 1.0000\n",
      "Epoch 1313/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 1.0000\n",
      "Epoch 1314/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.0589 - val_accuracy: 1.0000\n",
      "Epoch 1315/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 1.0000\n",
      "Epoch 1316/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.0583 - val_accuracy: 1.0000\n",
      "Epoch 1317/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 1.0000\n",
      "Epoch 1318/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 1.0000\n",
      "Epoch 1319/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 1.0000\n",
      "Epoch 1320/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.0572 - val_accuracy: 1.0000\n",
      "Epoch 1321/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.0569 - val_accuracy: 1.0000\n",
      "Epoch 1322/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.0566 - val_accuracy: 1.0000\n",
      "Epoch 1323/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.0564 - val_accuracy: 1.0000\n",
      "Epoch 1324/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.0561 - val_accuracy: 1.0000\n",
      "Epoch 1325/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.0558 - val_accuracy: 1.0000\n",
      "Epoch 1326/3000\n",
      "30/30 [==============================] - 0s 151us/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 1.0000\n",
      "Epoch 1327/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.0553 - val_accuracy: 1.0000\n",
      "Epoch 1328/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.0550 - val_accuracy: 1.0000\n",
      "Epoch 1329/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 1.0000\n",
      "Epoch 1330/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 1.0000\n",
      "Epoch 1331/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 1.0000\n",
      "Epoch 1332/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 1.0000\n",
      "Epoch 1333/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 1.0000\n",
      "Epoch 1334/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 1.0000\n",
      "Epoch 1335/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 1.0000\n",
      "Epoch 1336/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 1.0000\n",
      "Epoch 1337/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 1.0000\n",
      "Epoch 1338/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 1.0000\n",
      "Epoch 1339/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 1.0000\n",
      "Epoch 1340/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 1.0000\n",
      "Epoch 1341/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 1.0000\n",
      "Epoch 1342/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 1.0000\n",
      "Epoch 1343/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 1.0000\n",
      "Epoch 1344/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 1.0000\n",
      "Epoch 1345/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 1.0000\n",
      "Epoch 1346/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 1.0000\n",
      "Epoch 1347/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 1.0000\n",
      "Epoch 1348/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 1.0000\n",
      "Epoch 1349/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 1.0000\n",
      "Epoch 1350/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 1.0000\n",
      "Epoch 1351/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 1.0000\n",
      "Epoch 1352/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
      "Epoch 1353/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 1.0000\n",
      "Epoch 1354/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 1.0000\n",
      "Epoch 1355/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 1.0000\n",
      "Epoch 1356/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 1.0000\n",
      "Epoch 1357/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 1.0000\n",
      "Epoch 1358/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 1.0000\n",
      "Epoch 1359/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 1.0000\n",
      "Epoch 1360/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 1.0000\n",
      "Epoch 1361/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 1.0000\n",
      "Epoch 1362/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 1.0000\n",
      "Epoch 1363/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 1.0000\n",
      "Epoch 1364/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 1.0000\n",
      "Epoch 1365/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 1.0000\n",
      "Epoch 1366/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 1.0000\n",
      "Epoch 1367/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 1.0000\n",
      "Epoch 1368/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 1.0000\n",
      "Epoch 1369/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 1.0000\n",
      "Epoch 1370/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 1.0000\n",
      "Epoch 1371/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 1.0000\n",
      "Epoch 1372/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 1.0000\n",
      "Epoch 1373/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 1.0000\n",
      "Epoch 1374/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 1.0000\n",
      "Epoch 1375/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 1.0000\n",
      "Epoch 1376/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 1.0000\n",
      "Epoch 1377/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 1.0000\n",
      "Epoch 1378/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 1.0000\n",
      "Epoch 1379/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 1.0000\n",
      "Epoch 1380/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 1.0000\n",
      "Epoch 1381/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 1.0000\n",
      "Epoch 1382/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 1.0000\n",
      "Epoch 1383/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 1.0000\n",
      "Epoch 1384/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 1.0000\n",
      "Epoch 1385/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
      "Epoch 1386/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 1.0000\n",
      "Epoch 1387/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 1.0000\n",
      "Epoch 1388/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 1.0000\n",
      "Epoch 1389/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 1.0000\n",
      "Epoch 1390/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 1.0000\n",
      "Epoch 1391/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 1.0000\n",
      "Epoch 1392/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 1.0000\n",
      "Epoch 1393/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 1.0000\n",
      "Epoch 1394/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 1.0000\n",
      "Epoch 1395/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 1.0000\n",
      "Epoch 1396/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 1.0000\n",
      "Epoch 1397/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 1.0000\n",
      "Epoch 1398/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 1.0000\n",
      "Epoch 1399/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 1.0000\n",
      "Epoch 1400/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 1401/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 1.0000\n",
      "Epoch 1402/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 1.0000\n",
      "Epoch 1403/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
      "Epoch 1404/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
      "Epoch 1405/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 1.0000\n",
      "Epoch 1406/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 1.0000\n",
      "Epoch 1407/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 1.0000\n",
      "Epoch 1408/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 1.0000\n",
      "Epoch 1409/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 1.0000\n",
      "Epoch 1410/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 1.0000\n",
      "Epoch 1411/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 1.0000\n",
      "Epoch 1412/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 1.0000\n",
      "Epoch 1413/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 1.0000\n",
      "Epoch 1414/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
      "Epoch 1415/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 1.0000\n",
      "Epoch 1416/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 1.0000\n",
      "Epoch 1417/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 1.0000\n",
      "Epoch 1418/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 1.0000\n",
      "Epoch 1419/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 1.0000\n",
      "Epoch 1420/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0363 - val_accuracy: 1.0000\n",
      "Epoch 1421/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 1.0000\n",
      "Epoch 1422/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0360 - val_accuracy: 1.0000\n",
      "Epoch 1423/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
      "Epoch 1424/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 1.0000\n",
      "Epoch 1425/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.0356 - val_accuracy: 1.0000\n",
      "Epoch 1426/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
      "Epoch 1427/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 1.0000\n",
      "Epoch 1428/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.0351 - val_accuracy: 1.0000\n",
      "Epoch 1429/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 1.0000\n",
      "Epoch 1430/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 1.0000\n",
      "Epoch 1431/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.0347 - val_accuracy: 1.0000\n",
      "Epoch 1432/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
      "Epoch 1433/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
      "Epoch 1434/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 1.0000\n",
      "Epoch 1435/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.0342 - val_accuracy: 1.0000\n",
      "Epoch 1436/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
      "Epoch 1437/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 1.0000\n",
      "Epoch 1438/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
      "Epoch 1439/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.0336 - val_accuracy: 1.0000\n",
      "Epoch 1440/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 1441/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 1.0000\n",
      "Epoch 1442/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
      "Epoch 1443/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
      "Epoch 1444/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 1.0000\n",
      "Epoch 1445/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 1.0000\n",
      "Epoch 1446/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
      "Epoch 1447/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
      "Epoch 1448/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 1.0000\n",
      "Epoch 1449/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
      "Epoch 1450/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
      "Epoch 1451/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 1.0000\n",
      "Epoch 1452/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 1.0000\n",
      "Epoch 1453/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 1454/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
      "Epoch 1455/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 1.0000\n",
      "Epoch 1456/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
      "Epoch 1457/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 1.0000\n",
      "Epoch 1458/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
      "Epoch 1459/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0310 - val_accuracy: 1.0000\n",
      "Epoch 1460/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0309 - val_accuracy: 1.0000\n",
      "Epoch 1461/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
      "Epoch 1462/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
      "Epoch 1463/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
      "Epoch 1464/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 1.0000\n",
      "Epoch 1465/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 1.0000\n",
      "Epoch 1466/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0302 - val_accuracy: 1.0000\n",
      "Epoch 1467/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
      "Epoch 1468/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 1469/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
      "Epoch 1470/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 1.0000\n",
      "Epoch 1471/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 1.0000\n",
      "Epoch 1472/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 1473/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
      "Epoch 1474/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
      "Epoch 1475/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 1.0000\n",
      "Epoch 1476/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
      "Epoch 1477/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 1.0000\n",
      "Epoch 1478/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
      "Epoch 1479/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
      "Epoch 1480/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
      "Epoch 1481/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
      "Epoch 1482/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
      "Epoch 1483/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
      "Epoch 1484/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Epoch 1485/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
      "Epoch 1486/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 1.0000\n",
      "Epoch 1487/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
      "Epoch 1488/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 1489/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
      "Epoch 1490/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
      "Epoch 1491/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 1492/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
      "Epoch 1493/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
      "Epoch 1494/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
      "Epoch 1495/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
      "Epoch 1496/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 1497/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
      "Epoch 1498/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
      "Epoch 1499/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
      "Epoch 1500/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
      "Epoch 1501/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
      "Epoch 1502/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 1.0000\n",
      "Epoch 1503/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
      "Epoch 1504/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "Epoch 1505/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
      "Epoch 1506/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
      "Epoch 1507/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
      "Epoch 1508/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 1509/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
      "Epoch 1510/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 1511/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 1512/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 1513/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
      "Epoch 1514/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 1515/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
      "Epoch 1516/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
      "Epoch 1517/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
      "Epoch 1518/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 1519/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 1520/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "Epoch 1521/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "Epoch 1522/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
      "Epoch 1523/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
      "Epoch 1524/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
      "Epoch 1525/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 1526/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
      "Epoch 1527/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 1528/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 1529/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 1.0000\n",
      "Epoch 1530/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
      "Epoch 1531/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
      "Epoch 1532/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
      "Epoch 1533/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 1.0000\n",
      "Epoch 1534/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 1.0000\n",
      "Epoch 1535/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
      "Epoch 1536/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 1537/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
      "Epoch 1538/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
      "Epoch 1539/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
      "Epoch 1540/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
      "Epoch 1541/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 1542/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
      "Epoch 1543/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 1544/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 1545/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
      "Epoch 1546/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
      "Epoch 1547/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
      "Epoch 1548/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
      "Epoch 1549/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 1550/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
      "Epoch 1551/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "Epoch 1552/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "Epoch 1553/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 1554/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 1555/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 1556/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 1557/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
      "Epoch 1558/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 1559/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 1560/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 1561/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 1562/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 1563/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 1564/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 1565/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 1566/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 1567/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 1568/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 1569/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 1570/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 1571/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 1572/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 1573/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 1574/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 1575/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 1576/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 1577/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 1578/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 1579/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 1580/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 1581/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 1582/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 1583/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 1584/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 1585/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 1586/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 1587/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
      "Epoch 1588/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
      "Epoch 1589/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
      "Epoch 1590/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
      "Epoch 1591/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "Epoch 1592/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
      "Epoch 1593/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
      "Epoch 1594/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 1595/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 1596/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 1597/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
      "Epoch 1598/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
      "Epoch 1599/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
      "Epoch 1600/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
      "Epoch 1601/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 1602/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 1603/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 1604/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
      "Epoch 1605/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
      "Epoch 1606/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
      "Epoch 1607/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 1608/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 1609/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 1610/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 1611/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
      "Epoch 1612/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
      "Epoch 1613/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
      "Epoch 1614/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 1615/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 1616/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 1617/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 1618/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 1619/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 1620/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 1621/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 1622/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
      "Epoch 1623/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
      "Epoch 1624/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 1625/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 1626/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 1627/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 1628/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 1629/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 1630/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 1631/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
      "Epoch 1632/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
      "Epoch 1633/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
      "Epoch 1634/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
      "Epoch 1635/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 1636/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 1637/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 1638/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 1639/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 1640/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 1641/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 1642/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 1643/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 1644/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 1645/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 1646/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 1647/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 1648/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 1649/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
      "Epoch 1650/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
      "Epoch 1651/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 1652/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 1653/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 1654/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 1655/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 1656/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 1657/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 1658/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 1659/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 1660/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 1661/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 1662/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 1663/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 1664/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 1665/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 1666/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
      "Epoch 1667/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
      "Epoch 1668/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
      "Epoch 1669/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
      "Epoch 1670/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
      "Epoch 1671/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 1672/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 1673/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 1674/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 1675/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 1676/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 1677/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 1678/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
      "Epoch 1679/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
      "Epoch 1680/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 1681/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 1682/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 1683/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 1684/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 1685/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 1686/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 1687/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 1688/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 1689/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 1690/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 1691/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 1692/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 1693/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 1694/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 1695/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 1696/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 1697/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 1698/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 1699/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 1700/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 1701/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 1702/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 1703/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 1704/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 1705/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 1706/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 1707/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 1708/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 1709/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 1710/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 1711/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 1712/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 1713/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 1714/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 1715/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 1716/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 1717/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 1718/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 1719/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 1720/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 1721/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
      "Epoch 1722/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
      "Epoch 1723/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 1724/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 1725/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 1726/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 1727/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 1728/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 1729/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 1730/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 1731/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 1732/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 1733/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 1734/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 1735/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "Epoch 1736/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "Epoch 1737/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "Epoch 1738/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 1739/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 1740/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 1741/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "Epoch 1742/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "Epoch 1743/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "Epoch 1744/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 1745/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 1746/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 1747/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 1748/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 1749/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 1750/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 1751/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 1752/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 1753/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 1754/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 1755/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 1756/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 1757/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 1758/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 1759/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 1760/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 1761/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 1762/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 1763/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 1764/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 1765/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 1766/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 1767/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 1768/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 1769/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 1770/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 1771/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 1772/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 1773/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 1774/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 1775/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 1776/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 1777/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 1778/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 1779/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
      "Epoch 1780/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
      "Epoch 1781/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
      "Epoch 1782/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 1783/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 1784/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 1785/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 1786/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 1787/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 1788/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 1789/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 1790/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 1791/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 1792/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 1793/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 1794/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 1795/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 1796/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 1797/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 1798/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 1799/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 1800/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 1801/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 1802/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 1803/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 1804/3000\n",
      "30/30 [==============================] - 0s 94us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 1805/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 1806/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 1807/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 1808/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 1809/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 1810/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 1811/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 1812/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
      "Epoch 1813/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
      "Epoch 1814/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
      "Epoch 1815/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
      "Epoch 1816/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 1817/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 1818/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 1819/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 1820/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 1821/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 1822/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 1823/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 1824/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 1825/3000\n",
      "30/30 [==============================] - 0s 94us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 1826/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 1827/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 1828/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 1829/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 1830/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 1831/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 1832/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 1833/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 1834/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 1835/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 1836/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 1837/3000\n",
      "30/30 [==============================] - 0s 92us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 1838/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 1839/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 1840/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 1841/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 1842/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 1843/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 1844/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 1845/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 1846/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 1847/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 1848/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 1849/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 1850/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 1851/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 1852/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 1853/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 1854/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 1855/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 1856/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 1857/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 1858/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 1859/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 1860/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 1861/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 1862/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 1863/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 1864/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 1865/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 1866/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 1867/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 1868/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 1869/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 1870/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 1871/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 1872/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 1873/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 1874/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 1875/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 1876/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 1877/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 1878/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 1879/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 1880/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 1881/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 1882/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 1883/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 1884/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 1885/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 1886/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 1887/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 1888/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 1889/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 1890/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 1891/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 1892/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 1893/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 1894/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 1895/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 1896/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 1897/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 1898/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 1899/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 1900/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 1901/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 1902/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 1903/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 1904/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 1905/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 1906/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 1907/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 1908/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 1909/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 1910/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 1911/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 1912/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 1913/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 1914/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 1915/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 1916/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 1917/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 1918/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 1919/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 1920/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 1921/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 1922/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 1923/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 1924/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 1925/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 1926/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 1927/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 1928/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 1929/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 1930/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 1931/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 1932/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 1933/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 1934/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 1935/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 1936/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 1937/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 1938/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 1939/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 1940/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 1941/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 1942/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 1943/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 1944/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 1945/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 1946/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 1947/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 1948/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 1949/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 1950/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 1951/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 1952/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 1953/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 1954/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 1955/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 1956/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 1957/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 1958/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 1959/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 1960/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 1961/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 1962/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 1963/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 1964/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 1965/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 1966/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 1967/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 1968/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 1969/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 1970/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 1971/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 1972/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 1973/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 1974/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 1975/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 1976/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 1977/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 1978/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 1979/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 1980/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 1981/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 1982/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 1983/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 1984/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 1985/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 1986/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 1987/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 1988/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 1989/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 1990/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 1991/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 1992/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 1993/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 1994/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 1995/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 1996/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 1997/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 1998/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 1999/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 2000/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 2001/3000\n",
      "30/30 [==============================] - 0s 93us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 2002/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 2003/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 2004/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 2005/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 2006/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 2007/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 2008/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 2009/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 2010/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 2011/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 2012/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 2013/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 2014/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 2015/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 2016/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 2017/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 2018/3000\n",
      "30/30 [==============================] - 0s 93us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 2019/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 2020/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 2021/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 2022/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 2023/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 2024/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 2025/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 2026/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 2027/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 2028/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 2029/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 2030/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 2031/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 2032/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 2033/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 2034/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 2035/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 2036/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 2037/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 2038/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 2039/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 2040/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 2041/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 2042/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 2043/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 2044/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 2045/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 2046/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 2047/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 2048/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 2049/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 2050/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 2051/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 2052/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 2053/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 2054/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 2055/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 2056/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 2057/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 2058/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 2059/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 2060/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 2061/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 2062/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 2063/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 2064/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 2065/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 2066/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 2067/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 2068/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 2069/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 2070/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 2071/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 2072/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 2073/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 2074/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 2075/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 2076/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 2077/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 2078/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 2079/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 2080/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 2081/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 2082/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 2083/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 2084/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 2085/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 2086/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 2087/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 2088/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 2089/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 2090/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 2091/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 2092/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 2093/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 2094/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 2095/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 2096/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 2097/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 2098/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 2099/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 2100/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 2101/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 2102/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 2103/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 2104/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 2105/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 2106/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 2107/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 2108/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 2109/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 2110/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 2111/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 2112/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 2113/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 2114/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 2115/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 2116/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 2117/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 2118/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 2119/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 2120/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 2121/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 2122/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 2123/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 2124/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 2125/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 2126/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 2127/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 2128/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 2129/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 2130/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 2131/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 2132/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 2133/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 2134/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 2135/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 2136/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 2137/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 2138/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 2139/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 2140/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 2141/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 2142/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 2143/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 2144/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 2145/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 2146/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 2147/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 2148/3000\n",
      "30/30 [==============================] - 0s 93us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 2149/3000\n",
      "30/30 [==============================] - 0s 92us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 2150/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 2151/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 2152/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 2153/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 2154/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 2155/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 2156/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 2157/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 2158/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 2159/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 2160/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 2161/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 2162/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 2163/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 2164/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 2165/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 2166/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 2167/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 2168/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 2169/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 2170/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 2171/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 2172/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 2173/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 2174/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 2175/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 2176/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 2177/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 2178/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 2179/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 2180/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 2181/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 2182/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 2183/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 2184/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 2185/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 2186/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 2187/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 2188/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 2189/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 2190/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 2191/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 2192/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 2193/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 2194/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 2195/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 2196/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 2197/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 2198/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 2199/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 2200/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 2201/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 2202/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 2203/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 2204/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 2205/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 2206/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 2207/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 2208/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 2209/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 2210/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 2211/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 2212/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 2213/3000\n",
      "30/30 [==============================] - 0s 93us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 2214/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 2215/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 2216/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 2217/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 2218/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 2219/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 2220/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 2221/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 2222/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 2223/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 2224/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 2225/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 2226/3000\n",
      "30/30 [==============================] - 0s 143us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 2227/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 2228/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 2229/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 2230/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 2231/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 2232/3000\n",
      "30/30 [==============================] - 0s 154us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 2233/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 2234/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 2235/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 2236/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 2237/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 2238/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 2239/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 2240/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 2241/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 2242/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 2243/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 2244/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 2245/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 2246/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 2247/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 2248/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 2249/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 2250/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 2251/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 2252/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 2253/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 2254/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 2255/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 2256/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 2257/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 2258/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 2259/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 2260/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 2261/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 2262/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 2263/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 2264/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 2265/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 2266/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 2267/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 2268/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 2269/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 2270/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 2271/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 2272/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 2273/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 2274/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 2275/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 2276/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 2277/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 2278/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 2279/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 2280/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 2281/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 2282/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 2283/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 2284/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 2285/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 2286/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 2287/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 2288/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 2289/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 2290/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 2291/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 2292/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 2293/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 2294/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 2295/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 2296/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 2297/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 2298/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 2299/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 2300/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 2301/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 2302/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 2303/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 2304/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 2305/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 2306/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 2307/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 2308/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 2309/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 2310/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 2311/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 2312/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 2313/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 2314/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 2315/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 2316/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 2317/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 2318/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 2319/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 2320/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 2321/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 2322/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 2323/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 2324/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 2325/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 2326/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 2327/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 2328/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 2329/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 2330/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 2331/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 2332/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 2333/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 2334/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 2335/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 2336/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 2337/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 2338/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 2339/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 2340/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 2341/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 2342/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 2343/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 2344/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 2345/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 2346/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 2347/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 2348/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 2349/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 2350/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 2351/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 2352/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 2353/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 2354/3000\n",
      "30/30 [==============================] - 0s 94us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 2355/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 2356/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 2357/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 2358/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 2359/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 2360/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 2361/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 2362/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 2363/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 2364/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 2365/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 2366/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 2367/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 2368/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 2369/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 2370/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 2371/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 2372/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 2373/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 2374/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 2375/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 2376/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 2377/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 2378/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 2379/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 2380/3000\n",
      "30/30 [==============================] - 0s 93us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 2381/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 2382/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 2383/3000\n",
      "30/30 [==============================] - 0s 92us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 2384/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 2385/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 2386/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 2387/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 2388/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 2389/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 2390/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 2391/3000\n",
      "30/30 [==============================] - 0s 94us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 2392/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 2393/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 2394/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 2395/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 2396/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 2397/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 2398/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 2399/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 2400/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 2401/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 2402/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 2403/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 2404/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 2405/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 2406/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 2407/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 2408/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 2409/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 2410/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 2411/3000\n",
      "30/30 [==============================] - 0s 91us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 2412/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 2413/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 2414/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 2415/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 2416/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 2417/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 2418/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 2419/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 2420/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 2421/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 2422/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 2423/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 2424/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 2425/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2426/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2427/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2428/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2429/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2430/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2431/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2432/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2433/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2434/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2435/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2436/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2437/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2438/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2439/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2440/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2441/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2442/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2443/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2444/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2445/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2446/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2447/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2448/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2449/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2450/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2451/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2452/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2453/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2454/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2455/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2456/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2457/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2458/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2459/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2460/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2461/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2462/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2463/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2464/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2465/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2466/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2467/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2468/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2469/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2470/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2471/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2472/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2473/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2474/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2475/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2476/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2477/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2478/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2479/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2480/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2481/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2482/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2483/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2484/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2485/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2486/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2487/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2488/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2489/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2490/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2491/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2492/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2493/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2494/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2495/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2496/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2497/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2498/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2499/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2500/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2501/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2502/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2503/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2504/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2505/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2506/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2507/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2508/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2509/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2510/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2511/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2512/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2513/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2514/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2515/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2516/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2517/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2518/3000\n",
      "30/30 [==============================] - 0s 146us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2519/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2520/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2521/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2522/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2523/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2524/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2525/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2526/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2527/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2528/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2529/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2530/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2531/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2532/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2533/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2534/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2535/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2536/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2537/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2538/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2539/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2540/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2541/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2542/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 2543/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2544/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2545/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2546/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2547/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2548/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2549/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2550/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2551/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2552/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2553/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2554/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2555/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2556/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2557/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2558/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2559/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2560/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2561/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 9.9902e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2562/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 9.9752e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2563/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 9.9602e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2564/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 9.9455e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2565/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 9.9307e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2566/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 9.9158e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2567/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 9.9010e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2568/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 9.8863e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2569/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 9.8716e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2570/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 9.8569e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2571/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 9.8421e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2572/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 9.8275e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2573/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 9.8129e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2574/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 9.7983e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2575/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 9.7837e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2576/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 9.7693e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2577/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 9.7549e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2578/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 9.7404e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2579/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 9.7259e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2580/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 9.7115e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2581/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 9.6972e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2582/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 9.6829e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2583/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 9.6686e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2584/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 9.6543e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2585/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 9.6400e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2586/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 9.6257e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2587/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 9.6116e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2588/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 9.5974e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2589/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 9.5834e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2590/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 9.5693e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2591/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 9.5551e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2592/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 9.5411e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2593/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 9.5271e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2594/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 9.5131e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2595/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 9.4993e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2596/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 9.4853e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2597/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 9.4714e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2598/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 9.4574e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2599/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 9.4436e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2600/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 9.4299e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2601/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 9.4160e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2602/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 9.4021e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2603/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 9.3885e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2604/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 9.3749e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2605/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 9.3612e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2606/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 9.3475e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2607/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 9.3339e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2608/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 9.3203e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2609/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 9.3067e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2610/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 9.2932e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2611/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 9.2796e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2612/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 9.2663e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2613/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 9.2527e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2614/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 9.2394e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2615/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 9.2259e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2616/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 9.2126e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2617/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 9.1992e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2618/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 9.1859e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2619/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 9.1726e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2620/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 9.1593e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2621/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 9.1461e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2622/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 9.1329e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2623/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 9.1197e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2624/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 9.1065e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2625/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 9.0934e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2626/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 9.0802e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2627/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 9.0671e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2628/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 9.0540e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 2629/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 9.0410e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2630/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 9.0280e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2631/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 9.0149e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2632/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 9.0020e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2633/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 8.9892e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2634/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 8.9761e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2635/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 8.9633e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2636/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 8.9504e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2637/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 8.9377e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2638/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 8.9247e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2639/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 8.9120e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2640/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 8.8992e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2641/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 8.8865e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2642/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 8.8737e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2643/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 8.8612e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2644/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 8.8485e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2645/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 8.8358e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2646/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 8.8233e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2647/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 8.8107e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2648/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 8.7981e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2649/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 8.7857e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2650/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 8.7732e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2651/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 8.7606e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2652/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 8.7481e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2653/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 8.7357e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2654/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 8.7233e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2655/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 8.7109e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2656/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 8.6986e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2657/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 8.6862e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2658/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 8.6740e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2659/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 8.6616e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2660/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 8.6495e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2661/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 8.6372e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2662/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 8.6249e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2663/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 8.6129e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2664/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 8.6005e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2665/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 8.5885e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2666/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 8.5763e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2667/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 8.5642e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2668/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 8.5521e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2669/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 8.5402e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2670/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 8.5281e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2671/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 8.5161e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2672/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 8.5041e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2673/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 8.4922e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2674/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 8.4802e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2675/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 8.4684e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2676/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 8.4565e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2677/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 8.4445e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2678/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 8.4326e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2679/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 8.4208e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2680/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 8.4091e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2681/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 8.3974e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2682/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 8.3855e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2683/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 8.3738e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2684/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 8.3621e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2685/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 8.3504e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2686/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 8.3388e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2687/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 8.3271e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2688/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 8.3155e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2689/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 8.3038e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2690/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 8.2923e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2691/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 8.2808e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2692/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 8.2692e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2693/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 8.2577e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2694/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 8.2461e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2695/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 8.2347e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2696/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 8.2234e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2697/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 8.2119e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2698/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 8.2006e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2699/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 8.1891e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2700/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 8.1777e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2701/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 8.1664e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2702/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 8.1551e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2703/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 8.1437e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2704/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 8.1326e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2705/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 8.1212e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2706/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 8.1100e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2707/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 8.0988e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2708/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 8.0877e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2709/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 8.0764e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2710/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 8.0653e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2711/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 8.0541e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2712/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 8.0431e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2713/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 8.0320e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2714/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 8.0209e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2715/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 8.0098e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2716/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 7.9989e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2717/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 7.9879e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2718/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 7.9769e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2719/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 7.9659e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2720/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 7.9550e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2721/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 7.9442e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2722/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 7.9331e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2723/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 7.9224e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2724/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 7.9115e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2725/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 7.9007e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2726/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 7.8899e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2727/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 7.8790e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2728/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 7.8682e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2729/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 7.8575e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2730/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 7.8468e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2731/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 7.8361e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2732/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 7.8254e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2733/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 7.8147e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2734/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 7.8041e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2735/3000\n",
      "30/30 [==============================] - 0s 93us/step - loss: 7.7934e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2736/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 7.7828e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2737/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 7.7721e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2738/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 7.7616e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2739/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 7.7512e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2740/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 7.7405e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2741/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 7.7300e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2742/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 7.7195e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2743/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 7.7090e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2744/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 7.6985e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2745/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 7.6882e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2746/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 7.6776e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2747/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 7.6672e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2748/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 7.6568e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2749/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 7.6465e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2750/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 7.6361e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2751/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 7.6259e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2752/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 7.6156e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2753/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 7.6052e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2754/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 7.5950e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2755/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 7.5847e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2756/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 7.5744e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2757/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 7.5643e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2758/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 7.5541e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2759/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 7.5439e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2760/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 7.5337e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2761/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 7.5236e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2762/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 7.5135e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2763/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 7.5034e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2764/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 7.4933e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2765/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 7.4832e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2766/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 7.4731e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2767/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 7.4632e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2768/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 7.4531e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2769/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 7.4431e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2770/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 7.4332e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2771/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 7.4232e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2772/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 7.4132e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2773/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 7.4033e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2774/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 7.3934e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2775/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 7.3835e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2776/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 7.3736e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2777/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 7.3638e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2778/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 7.3540e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2779/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 7.3442e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2780/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 7.3344e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2781/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 7.3246e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2782/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 7.3148e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2783/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 7.3052e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2784/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 7.2953e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2785/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 7.2856e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2786/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 7.2759e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2787/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 7.2663e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2788/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 7.2567e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2789/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 7.2470e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2790/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 7.2374e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2791/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 7.2278e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2792/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 7.2181e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2793/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 7.2086e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2794/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 7.1990e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2795/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 7.1895e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2796/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 7.1800e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2797/3000\n",
      "30/30 [==============================] - 0s 146us/step - loss: 7.1705e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2798/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 7.1610e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2799/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 7.1515e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2800/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 7.1421e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2801/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 7.1326e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2802/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 7.1232e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2803/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 7.1139e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2804/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 7.1044e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2805/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 7.0951e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2806/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 7.0858e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2807/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 7.0764e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2808/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 7.0671e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2809/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 7.0577e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2810/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 7.0484e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2811/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 7.0392e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2812/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 7.0299e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2813/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 7.0208e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2814/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 7.0114e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2815/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 7.0023e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2816/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 6.9931e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2817/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 6.9839e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2818/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 6.9748e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2819/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 6.9657e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2820/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 6.9565e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2821/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 6.9475e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2822/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 6.9383e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2823/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 6.9293e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2824/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 6.9203e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2825/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 6.9112e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2826/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 6.9022e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2827/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 6.8932e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2828/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 6.8842e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2829/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 6.8751e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2830/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 6.8662e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2831/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 6.8573e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2832/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 6.8484e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2833/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 6.8395e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2834/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 6.8305e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2835/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 6.8215e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2836/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 6.8128e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2837/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 6.8040e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2838/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 6.7951e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2839/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 6.7862e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2840/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 6.7775e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2841/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 6.7686e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2842/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 6.7600e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2843/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 6.7511e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2844/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 6.7423e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2845/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 6.7336e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2846/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 6.7250e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2847/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 6.7162e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2848/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 6.7075e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2849/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 6.6989e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2850/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 6.6902e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2851/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 6.6816e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2852/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 6.6730e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2853/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 6.6643e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2854/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 6.6558e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2855/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 6.6472e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2856/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 6.6386e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2857/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 6.6301e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2858/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 6.6215e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2859/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 6.6131e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2860/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 6.6045e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2861/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 6.5960e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2862/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 6.5876e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2863/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 6.5791e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2864/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 6.5706e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2865/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 6.5622e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2866/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 6.5538e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2867/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 6.5453e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2868/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 6.5370e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2869/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 6.5285e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2870/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 6.5202e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2871/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 6.5119e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2872/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 6.5035e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2873/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 6.4952e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2874/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 6.4869e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2875/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 6.4786e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2876/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 6.4704e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2877/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 6.4621e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2878/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 6.4538e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2879/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 6.4456e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2880/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 6.4374e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2881/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 6.4292e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2882/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 6.4208e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2883/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 6.4128e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2884/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 6.4046e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2885/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 6.3965e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2886/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 6.3883e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2887/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 6.3802e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2888/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 6.3720e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2889/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 6.3640e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2890/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 6.3559e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2891/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 6.3478e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2892/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 6.3397e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2893/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 6.3318e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2894/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 6.3237e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2895/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 6.3158e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2896/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 6.3078e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2897/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 6.2997e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2898/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 6.2918e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2899/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 6.2838e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2900/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 6.2759e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2901/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 6.2679e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2902/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 6.2600e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2903/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 6.2520e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2904/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 6.2442e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2905/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 6.2364e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2906/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 6.2284e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2907/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 6.2207e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2908/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 6.2127e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2909/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 6.2050e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2910/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 6.1972e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2911/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 6.1893e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2912/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 6.1815e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2913/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 6.1737e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2914/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 6.1660e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2915/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 6.1583e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2916/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 6.1505e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2917/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 6.1428e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2918/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 6.1351e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2919/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 6.1273e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2920/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 6.1198e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2921/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 6.1121e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2922/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 6.1044e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2923/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 6.0968e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2924/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 6.0891e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2925/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 6.0815e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2926/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 6.0739e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2927/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 6.0663e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2928/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 6.0587e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2929/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 6.0511e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2930/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 6.0435e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2931/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 6.0361e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2932/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 6.0285e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2933/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 6.0209e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2934/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 6.0135e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2935/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 6.0059e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2936/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 5.9985e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2937/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 5.9909e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2938/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 5.9835e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2939/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 5.9761e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2940/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 5.9687e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2941/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 5.9613e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2942/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 5.9538e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2943/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 5.9465e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2944/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 5.9390e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2945/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 5.9316e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2946/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 5.9244e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2947/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 5.9169e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2948/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 5.9096e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2949/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 5.9022e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2950/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 5.8950e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2951/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 5.8876e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2952/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 5.8803e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2953/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 5.8731e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2954/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 5.8658e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2955/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 5.8586e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2956/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 5.8513e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2957/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 5.8441e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2958/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 5.8370e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2959/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 5.8297e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2960/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 5.8224e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2961/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 5.8152e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2962/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 5.8081e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2963/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 5.8009e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2964/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 5.7938e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2965/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 5.7867e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2966/3000\n",
      "30/30 [==============================] - 0s 106us/step - loss: 5.7796e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2967/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 5.7724e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2968/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 5.7654e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2969/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 5.7582e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2970/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 5.7511e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2971/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 5.7441e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2972/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 5.7371e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2973/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 5.7300e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2974/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 5.7230e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2975/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 5.7160e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2976/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 5.7089e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2977/3000\n",
      "30/30 [==============================] - 0s 96us/step - loss: 5.7020e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2978/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 5.6951e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2979/3000\n",
      "30/30 [==============================] - 0s 95us/step - loss: 5.6880e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2980/3000\n",
      "30/30 [==============================] - 0s 98us/step - loss: 5.6811e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2981/3000\n",
      "30/30 [==============================] - 0s 102us/step - loss: 5.6740e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2982/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 5.6672e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2983/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 5.6602e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2984/3000\n",
      "30/30 [==============================] - 0s 94us/step - loss: 5.6533e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2985/3000\n",
      "30/30 [==============================] - 0s 97us/step - loss: 5.6464e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2986/3000\n",
      "30/30 [==============================] - 0s 99us/step - loss: 5.6395e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2987/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 5.6327e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2988/3000\n",
      "30/30 [==============================] - 0s 104us/step - loss: 5.6258e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2989/3000\n",
      "30/30 [==============================] - 0s 101us/step - loss: 5.6189e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2990/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 5.6121e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2991/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 5.6052e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2992/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 5.5984e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2993/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 5.5917e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2994/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 5.5847e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2995/3000\n",
      "30/30 [==============================] - 0s 109us/step - loss: 5.5780e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2996/3000\n",
      "30/30 [==============================] - 0s 105us/step - loss: 5.5711e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2997/3000\n",
      "30/30 [==============================] - 0s 110us/step - loss: 5.5644e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2998/3000\n",
      "30/30 [==============================] - 0s 100us/step - loss: 5.5577e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2999/3000\n",
      "30/30 [==============================] - 0s 107us/step - loss: 5.5508e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 3000/3000\n",
      "30/30 [==============================] - 0s 103us/step - loss: 5.5442e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'historyData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6r/qjkmb3mx55l9vc9x538f6ypr0000gn/T/ipykernel_3679/766508390.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m model_train = model.fit(train_X, train_label, epochs=3000, verbose=1,\n\u001b[1;32m     15\u001b[0m                         validation_data=(valid_X, valid_label))\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mloss_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistoryData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m#The above line will return a dictionary, access it's info like this:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mbest_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'historyData' is not defined"
     ]
    }
   ],
   "source": [
    "#TRAIN THE MODEL\n",
    "# Add an early stopping callback\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    mode='min', \n",
    "    patience = 2200, \n",
    "    restore_best_weights = True, \n",
    "    verbose=1)\n",
    "# Add a checkpoint where loss is minimum, and save that model\n",
    "mc = keras.callbacks.ModelCheckpoint('best_model.SB', monitor='loss', \n",
    "                     mode='min',  verbose=1, save_best_only=True)\n",
    "\n",
    "#COMPLETE THE model.fit STATEMENT BELOW\n",
    "model_train = model.fit(train_X, train_label, epochs=3000, verbose=1,\n",
    "                        validation_data=(valid_X, valid_label))\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(model_train.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f3a4f3-2983-41ea-a1a8-11cd35c113c2",
   "metadata": {},
   "source": [
    "#### g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af1d4162-8b32-4255-8496-b2fbd2d118a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row [ 0 ] data:  Ta=  1.0 , ID=  200.0  RL=  0.8181818181818182\n",
      " pred Mmax=  [9.9856073e-01 1.4392933e-03 3.0009309e-13]  Mmaxint =  0  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 1 ] data:  Ta=  1.0 , ID=  200.0  RL=  1.7441077441077442\n",
      " pred Mmax=  [9.1764936e-19 9.9709451e-01 2.9054612e-03]  Mmaxint =  1  data Mmax=  [0 1 0]\n",
      " \n",
      "row [ 2 ] data:  Ta=  1.0 , ID=  200.0  RL=  3.239057239057239\n",
      " pred Mmax=  [0.000000e+00 5.465525e-04 9.994535e-01]  Mmaxint =  2  data Mmax=  [0 0 1]\n",
      " \n",
      "row [ 3 ] data:  Ta=  1.0 , ID=  200.0  RL=  4.484848484848484\n",
      " pred Mmax=  [0.0000000e+00 1.5355738e-07 9.9999988e-01]  Mmaxint =  2  data Mmax=  [0 0 1]\n",
      " \n",
      "row [ 4 ] data:  Ta=  1.0 , ID=  200.0  RL=  5.7272727272727275\n",
      " pred Mmax=  [0.000000e+00 6.622289e-11 1.000000e+00]  Mmaxint =  2  data Mmax=  [0 0 1]\n",
      " \n",
      "row [ 5 ] data:  Ta=  1.0 , ID=  500.0  RL=  0.2356902356902357\n",
      " pred Mmax=  [1.0000000e+00 2.7020145e-13 3.7595828e-27]  Mmaxint =  0  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 6 ] data:  Ta=  1.0 , ID=  500.0  RL=  0.7138047138047138\n",
      " pred Mmax=  [1.5743022e-05 9.9998307e-01 1.1508490e-06]  Mmaxint =  1  data Mmax=  [0 1 0]\n",
      " \n",
      "row [ 7 ] data:  Ta=  1.0 , ID=  500.0  RL=  1.4545454545454546\n",
      " pred Mmax=  [1.0279256e-24 3.4828724e-03 9.9651706e-01]  Mmaxint =  2  data Mmax=  [0 0 1]\n",
      " \n",
      "row [ 8 ] data:  Ta=  1.0 , ID=  500.0  RL=  2.0606060606060606\n",
      " pred Mmax=  [2.8177514e-36 6.7176966e-06 9.9999332e-01]  Mmaxint =  2  data Mmax=  [0 0 1]\n",
      " \n",
      "row [ 9 ] data:  Ta=  1.0 , ID=  500.0  RL=  2.663299663299663\n",
      " pred Mmax=  [0.000000e+00 9.922175e-08 9.999999e-01]  Mmaxint =  2  data Mmax=  [0 0 1]\n",
      " \n",
      "row [ 10 ] data:  Ta=  1.0 , ID=  700.0  RL=  0.164983164983165\n",
      " pred Mmax=  [1.0000000e+00 1.4426339e-11 3.6548813e-25]  Mmaxint =  0  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 11 ] data:  Ta=  1.0 , ID=  700.0  RL=  0.4814814814814815\n",
      " pred Mmax=  [2.39759241e-03 9.97602284e-01 1.17175674e-07]  Mmaxint =  1  data Mmax=  [0 1 0]\n",
      " \n",
      "row [ 12 ] data:  Ta=  1.0 , ID=  700.0  RL=  1.0\n",
      " pred Mmax=  [3.8116522e-22 1.4537142e-03 9.9854636e-01]  Mmaxint =  2  data Mmax=  [0 0 1]\n",
      " \n",
      "row [ 13 ] data:  Ta=  1.0 , ID=  700.0  RL=  1.4444444444444444\n",
      " pred Mmax=  [5.9571545e-33 6.9032944e-07 9.9999928e-01]  Mmaxint =  2  data Mmax=  [0 0 1]\n",
      " \n",
      "row [ 14 ] data:  Ta=  1.0 , ID=  700.0  RL=  1.8619528619528618\n",
      " pred Mmax=  [0.0000000e+00 1.0143317e-08 1.0000000e+00]  Mmaxint =  2  data Mmax=  [0 0 1]\n",
      " \n",
      "row [ 15 ] data:  Ta=  1.0 , ID=  1000.0  RL=  0.13198653198653199\n",
      " pred Mmax=  [9.9783188e-01 2.1680971e-03 2.5636234e-13]  Mmaxint =  0  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 16 ] data:  Ta=  1.0 , ID=  1000.0  RL=  0.3939393939393939\n",
      " pred Mmax=  [1.1253308e-09 9.9960023e-01 3.9981998e-04]  Mmaxint =  1  data Mmax=  [0 1 0]\n",
      " \n",
      "row [ 17 ] data:  Ta=  1.0 , ID=  1000.0  RL=  0.8484848484848485\n",
      " pred Mmax=  [1.2119730e-29 3.8382802e-07 9.9999964e-01]  Mmaxint =  2  data Mmax=  [0 0 1]\n",
      " \n",
      "row [ 18 ] data:  Ta=  1.0 , ID=  1000.0  RL=  1.1245791245791246\n",
      " pred Mmax=  [1.1993295e-37 4.6866588e-10 1.0000000e+00]  Mmaxint =  2  data Mmax=  [0 0 1]\n",
      " \n",
      "row [ 19 ] data:  Ta=  1.0 , ID=  1000.0  RL=  1.4006734006734007\n",
      " pred Mmax=  [0.000000e+00 7.996321e-12 1.000000e+00]  Mmaxint =  2  data Mmax=  [0 0 1]\n",
      " \n",
      "row [ 20 ] data:  Ta=  1.81 , ID=  500.0  RL=  0.2356902356902357\n",
      " pred Mmax=  [1.0000000e+00 5.0029215e-14 5.4983308e-29]  Mmaxint =  0  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 21 ] data:  Ta=  1.85 , ID=  500.0  RL=  0.7138047138047138\n",
      " pred Mmax=  [3.4859146e-05 9.9996471e-01 4.8293902e-07]  Mmaxint =  1  data Mmax=  [0 1 0]\n",
      " \n",
      "row [ 22 ] data:  Ta=  1.9 , ID=  500.0  RL=  1.4545454545454546\n",
      " pred Mmax=  [3.4860161e-26 1.4861405e-03 9.9851388e-01]  Mmaxint =  2  data Mmax=  [0 0 1]\n",
      " \n",
      "row [ 23 ] data:  Ta=  1.86 , ID=  500.0  RL=  2.0606060606060606\n",
      " pred Mmax=  [2.9403482e-38 1.6922010e-06 9.9999833e-01]  Mmaxint =  2  data Mmax=  [0 0 1]\n",
      " \n",
      "row [ 24 ] data:  Ta=  1.8800000000000001 , ID=  500.0  RL=  2.663299663299663\n",
      " pred Mmax=  [0.0000000e+00 1.7902378e-08 1.0000000e+00]  Mmaxint =  2  data Mmax=  [0 0 1]\n",
      " \n",
      "row [ 25 ] data:  Ta=  0.21000000000000002 , ID=  1000.0  RL=  0.13198653198653199\n",
      " pred Mmax=  [9.9775583e-01 2.2442010e-03 5.1749176e-13]  Mmaxint =  0  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 26 ] data:  Ta=  0.2 , ID=  1000.0  RL=  0.3939393939393939\n",
      " pred Mmax=  [1.0279665e-09 9.9951017e-01 4.8985274e-04]  Mmaxint =  1  data Mmax=  [0 1 0]\n",
      " \n",
      "row [ 27 ] data:  Ta=  0.19 , ID=  1000.0  RL=  0.8484848484848485\n",
      " pred Mmax=  [5.5639288e-28 9.2608786e-07 9.9999905e-01]  Mmaxint =  2  data Mmax=  [0 0 1]\n",
      " \n",
      "row [ 28 ] data:  Ta=  0.22999999999999998 , ID=  1000.0  RL=  1.1245791245791246\n",
      " pred Mmax=  [2.8092725e-35 3.0385043e-09 1.0000000e+00]  Mmaxint =  2  data Mmax=  [0 0 1]\n",
      " \n",
      "row [ 29 ] data:  Ta=  0.24 , ID=  1000.0  RL=  1.4006734006734007\n",
      " pred Mmax=  [0.0000000e+00 6.0872786e-11 1.0000000e+00]  Mmaxint =  2  data Mmax=  [0 0 1]\n",
      " \n",
      "row [ 30 ] data:  Ta=  0.05 , ID=  700.0  RL=  0.164983164983165\n",
      " pred Mmax=  [1.0000000e+00 2.8291455e-10 2.2684396e-22]  Mmaxint =  0  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 31 ] data:  Ta=  0.06999999999999999 , ID=  700.0  RL=  0.4814814814814815\n",
      " pred Mmax=  [1.9568417e-03 9.9804294e-01 2.7414310e-07]  Mmaxint =  1  data Mmax=  [0 1 0]\n",
      " \n",
      "row [ 32 ] data:  Ta=  0.1 , ID=  700.0  RL=  1.0\n",
      " pred Mmax=  [1.3809095e-20 3.3195454e-03 9.9668050e-01]  Mmaxint =  2  data Mmax=  [0 0 1]\n",
      " \n",
      "row [ 33 ] data:  Ta=  0.08 , ID=  700.0  RL=  1.4444444444444444\n",
      " pred Mmax=  [2.0985049e-30 4.5213860e-06 9.9999547e-01]  Mmaxint =  2  data Mmax=  [0 0 1]\n",
      " \n",
      "row [ 34 ] data:  Ta=  0.02 , ID=  700.0  RL=  1.8619528619528618\n",
      " pred Mmax=  [6.9229402e-38 8.3741234e-08 9.9999988e-01]  Mmaxint =  2  data Mmax=  [0 0 1]\n",
      " \n",
      "row [ 35 ] data:  Ta=  1.52 , ID=  200.0  RL=  0.8181818181818182\n",
      " pred Mmax=  [9.9934846e-01 6.5154204e-04 3.6239719e-14]  Mmaxint =  0  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 36 ] data:  Ta=  1.54 , ID=  200.0  RL=  1.7441077441077442\n",
      " pred Mmax=  [2.7050241e-19 9.9608278e-01 3.9172266e-03]  Mmaxint =  1  data Mmax=  [0 1 0]\n",
      " \n",
      "row [ 37 ] data:  Ta=  2.12 , ID=  1000.0  RL=  0.13198653198653199\n",
      " pred Mmax=  [9.9618196e-01 3.8180470e-03 6.0269454e-13]  Mmaxint =  0  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 38 ] data:  Ta=  1.94 , ID=  1000.0  RL=  0.3939393939393939\n",
      " pred Mmax=  [8.2041296e-10 9.9944025e-01 5.5974151e-04]  Mmaxint =  1  data Mmax=  [0 1 0]\n",
      " \n",
      "row [ 39 ] data:  Ta=  1.92 , ID=  1000.0  RL=  0.8484848484848485\n",
      " pred Mmax=  [7.3625885e-31 3.1587999e-07 9.9999964e-01]  Mmaxint =  2  data Mmax=  [0 0 1]\n",
      " \n",
      " \n",
      "training versus validation comparisons\n",
      "30/30 [==============================] - 0s 34us/step\n",
      "train loss: 0.0005537353572435677\n",
      "train accuracy: 1.0\n",
      "10/10 [==============================] - 0s 91us/step\n",
      "validation loss: 0.001673692837357521\n",
      "validation accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "\n",
    "#first point (data row [0]) comparison of data and prediction\n",
    "\n",
    "#=====================\n",
    "#example code to convert one hot output to predicted Mmax integer\n",
    "for i in range(len(xarray)):\n",
    "    test = [] #specifies a test input data set\n",
    "    outpt=[] #output of model for test input\n",
    "    test = [[ xarray[i][0] , xarray[i][1] , xarray[i][2] ]]\n",
    "    testarray = np.array(test)\n",
    "    outpt = model.predict(testarray)\n",
    "    Mmaxint = np.argmax(np.round(outpt[0]))  # np.argmax returns the index of the maximum values along an axis\n",
    "    #first input data row:  normalized Air temp (degC), ID (W/sqm), load resistance (ohms)\n",
    "    print ('row [',i,'] data:  Ta= ', xarray[i][0]*Tamed, ', ID= ', xarray[i][1]*IDmed, \\\n",
    "    ' RL= ', xarray[i][2]*RLmed)\n",
    "    print (' pred Mmax= ', outpt[0],' Mmaxint = ', Mmaxint,' data Mmax= ', ydataCatOHEarray[i])\n",
    "    print (' ')\n",
    "'''#Predict Mmaxint for arbitray specified input data: \n",
    "print ('arbitrary input data:  Ta= ', 10., ', ID= ', 1000., ' RL= ', 41.6)\n",
    "test = [[ 10.0/Tamed, 1000.0/IDmed, 41.6/RLmed ]]\n",
    "testarray = np.array(test)\n",
    "outpt = model.predict(testarray)\n",
    "Mmaxint = np.argmax(np.round(outpt[0]))\n",
    "print (' pred Mmax= ', outpt[0],' Mmaxint = ', Mmaxint,)\n",
    "'''\n",
    "#=====================\n",
    "print (' ')\n",
    "print('training versus validation comparisons')\n",
    "\n",
    "#Model Evaluation on the Training Set\n",
    "train_eval = model.evaluate(train_X, train_label, verbose=1)  #changed to verbose=1 to show progress\n",
    "print('train loss:', train_eval[0])\n",
    "print('train accuracy:', train_eval[1])\n",
    "\n",
    "#Model Evaluation on the Validation Set\n",
    "test_eval = model.evaluate(valid_X, valid_label, verbose=1)  #changed to verbose=1 to show progress\n",
    "print('validation loss:', test_eval[0])\n",
    "print('validation accuracy:', test_eval[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7f8d8b-0b23-4ab7-991c-1ef56b1614a5",
   "metadata": {},
   "source": [
    "#### j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "722fe176-80de-4392-b8b5-d6ba77e23028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define neural network model\n",
    "#In the first layer, the input shape is provided, which is 3 in our case. \n",
    "#As seen below, we have included three dense layers. \n",
    "#The activation function we have chosen is elu, which stands for exponential linear unit. .\n",
    "\n",
    "from keras import backend as K\n",
    "#initialize weights with values between -0.2 and 0.5\n",
    "initializer = keras.initializers.RandomUniform(minval= -0.2, maxval=0.5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(16, activation=K.elu, input_shape=[3],kernel_initializer=initializer), \n",
    "    keras.layers.Dense(32, activation=K.elu, kernel_initializer=initializer), \n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Dense(16, activation=K.elu, kernel_initializer=initializer), \n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Dense(num_classes, activation='softmax')\n",
    "  ])\n",
    "#ADD OUTPUT LAYER, REMOVE DROPOUTS FOR FIRST PART, ADD LATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9be0c996-2039-4d41-b447-b3019a9416be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 1,187\n",
      "Trainable params: 1,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#COMPLIE THE MODEL\n",
    "'''After the model is created, you compile it using the Adam optimizer, one of the\n",
    "most popular optimization algorithms. \n",
    "\n",
    "Additionally, you specify the loss type which is categorical cross entropy which\n",
    "is used for multi-class classification.  Lastly, you specify the metrics as accuracy which you want to\n",
    "analyze while the model is training.'''\n",
    "#COMPLETE THE model.compile STATEMENT BELOW\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#SUMMARIZE MODEL\n",
    "'''To visualize the layers that created in the above step, use the summary function.\n",
    "This will show some parameters (weights and biases) in each layer and also the total parameters in your model.''' \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1aa0d29-11d4-48ff-93fc-0759c81ebb21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30 samples, validate on 10 samples\n",
      "Epoch 1/3000\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 8.3432 - accuracy: 0.3333 - val_loss: 2.8496 - val_accuracy: 0.2000\n",
      "Epoch 2/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 8.9099 - accuracy: 0.3667 - val_loss: 2.6095 - val_accuracy: 0.5000\n",
      "Epoch 3/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 7.8327 - accuracy: 0.4333 - val_loss: 2.5058 - val_accuracy: 0.6000\n",
      "Epoch 4/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 9.0988 - accuracy: 0.3000 - val_loss: 2.5092 - val_accuracy: 0.6000\n",
      "Epoch 5/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 6.1063 - accuracy: 0.5000 - val_loss: 2.5430 - val_accuracy: 0.6000\n",
      "Epoch 6/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 7.6708 - accuracy: 0.3667 - val_loss: 2.5877 - val_accuracy: 0.6000\n",
      "Epoch 7/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 6.6750 - accuracy: 0.2667 - val_loss: 2.6429 - val_accuracy: 0.6000\n",
      "Epoch 8/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 7.0198 - accuracy: 0.4333 - val_loss: 2.7043 - val_accuracy: 0.6000\n",
      "Epoch 9/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 8.5111 - accuracy: 0.3000 - val_loss: 2.7628 - val_accuracy: 0.6000\n",
      "Epoch 10/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 7.9165 - accuracy: 0.3333 - val_loss: 2.8107 - val_accuracy: 0.6000\n",
      "Epoch 11/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 4.2613 - accuracy: 0.4667 - val_loss: 2.8471 - val_accuracy: 0.6000\n",
      "Epoch 12/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 5.3543 - accuracy: 0.5000 - val_loss: 2.8783 - val_accuracy: 0.6000\n",
      "Epoch 13/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 4.7414 - accuracy: 0.5000 - val_loss: 2.9025 - val_accuracy: 0.6000\n",
      "Epoch 14/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 4.2541 - accuracy: 0.5333 - val_loss: 2.9247 - val_accuracy: 0.6000\n",
      "Epoch 15/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 5.5032 - accuracy: 0.4667 - val_loss: 2.9269 - val_accuracy: 0.6000\n",
      "Epoch 16/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 3.1808 - accuracy: 0.5000 - val_loss: 2.9190 - val_accuracy: 0.6000\n",
      "Epoch 17/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 3.7213 - accuracy: 0.3667 - val_loss: 2.9068 - val_accuracy: 0.6000\n",
      "Epoch 18/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 4.5737 - accuracy: 0.5000 - val_loss: 2.8815 - val_accuracy: 0.6000\n",
      "Epoch 19/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 4.8963 - accuracy: 0.4667 - val_loss: 2.8484 - val_accuracy: 0.6000\n",
      "Epoch 20/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 3.4326 - accuracy: 0.4000 - val_loss: 2.8172 - val_accuracy: 0.6000\n",
      "Epoch 21/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 5.5585 - accuracy: 0.3667 - val_loss: 2.7946 - val_accuracy: 0.6000\n",
      "Epoch 22/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 4.4218 - accuracy: 0.3333 - val_loss: 2.7681 - val_accuracy: 0.6000\n",
      "Epoch 23/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 3.7741 - accuracy: 0.4667 - val_loss: 2.7389 - val_accuracy: 0.6000\n",
      "Epoch 24/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 4.0499 - accuracy: 0.4333 - val_loss: 2.7084 - val_accuracy: 0.6000\n",
      "Epoch 25/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 3.5520 - accuracy: 0.4000 - val_loss: 2.6693 - val_accuracy: 0.6000\n",
      "Epoch 26/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 3.3198 - accuracy: 0.3333 - val_loss: 2.6318 - val_accuracy: 0.6000\n",
      "Epoch 27/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 6.2124 - accuracy: 0.3667 - val_loss: 2.5911 - val_accuracy: 0.6000\n",
      "Epoch 28/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 3.7899 - accuracy: 0.4333 - val_loss: 2.5491 - val_accuracy: 0.6000\n",
      "Epoch 29/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 3.6522 - accuracy: 0.5333 - val_loss: 2.5051 - val_accuracy: 0.6000\n",
      "Epoch 30/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 4.3835 - accuracy: 0.4333 - val_loss: 2.4625 - val_accuracy: 0.6000\n",
      "Epoch 31/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 3.7650 - accuracy: 0.3333 - val_loss: 2.4180 - val_accuracy: 0.6000\n",
      "Epoch 32/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 2.7478 - accuracy: 0.5333 - val_loss: 2.3721 - val_accuracy: 0.6000\n",
      "Epoch 33/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 2.8911 - accuracy: 0.3333 - val_loss: 2.3327 - val_accuracy: 0.6000\n",
      "Epoch 34/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 3.9649 - accuracy: 0.3667 - val_loss: 2.2913 - val_accuracy: 0.6000\n",
      "Epoch 35/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 2.7606 - accuracy: 0.5000 - val_loss: 2.2507 - val_accuracy: 0.6000\n",
      "Epoch 36/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 3.7707 - accuracy: 0.3333 - val_loss: 2.2126 - val_accuracy: 0.6000\n",
      "Epoch 37/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 2.6449 - accuracy: 0.4333 - val_loss: 2.1731 - val_accuracy: 0.6000\n",
      "Epoch 38/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 3.6275 - accuracy: 0.4000 - val_loss: 2.1372 - val_accuracy: 0.6000\n",
      "Epoch 39/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 3.3372 - accuracy: 0.4000 - val_loss: 2.1037 - val_accuracy: 0.6000\n",
      "Epoch 40/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 1.8179 - accuracy: 0.6000 - val_loss: 2.0691 - val_accuracy: 0.6000\n",
      "Epoch 41/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 4.2932 - accuracy: 0.3000 - val_loss: 2.0397 - val_accuracy: 0.6000\n",
      "Epoch 42/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 2.8178 - accuracy: 0.3333 - val_loss: 2.0138 - val_accuracy: 0.6000\n",
      "Epoch 43/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 2.5081 - accuracy: 0.3667 - val_loss: 1.9935 - val_accuracy: 0.6000\n",
      "Epoch 44/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 3.3743 - accuracy: 0.3667 - val_loss: 1.9759 - val_accuracy: 0.6000\n",
      "Epoch 45/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 3.2601 - accuracy: 0.3667 - val_loss: 1.9623 - val_accuracy: 0.6000\n",
      "Epoch 46/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 3.0675 - accuracy: 0.4000 - val_loss: 1.9496 - val_accuracy: 0.6000\n",
      "Epoch 47/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 2.5123 - accuracy: 0.5333 - val_loss: 1.9363 - val_accuracy: 0.6000\n",
      "Epoch 48/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 3.0341 - accuracy: 0.5333 - val_loss: 1.9192 - val_accuracy: 0.6000\n",
      "Epoch 49/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 2.7019 - accuracy: 0.3333 - val_loss: 1.9045 - val_accuracy: 0.6000\n",
      "Epoch 50/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 3.1167 - accuracy: 0.4000 - val_loss: 1.8860 - val_accuracy: 0.6000\n",
      "Epoch 51/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 2.3194 - accuracy: 0.5667 - val_loss: 1.8654 - val_accuracy: 0.6000\n",
      "Epoch 52/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 2.4778 - accuracy: 0.5000 - val_loss: 1.8457 - val_accuracy: 0.6000\n",
      "Epoch 53/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 2.3574 - accuracy: 0.4333 - val_loss: 1.8256 - val_accuracy: 0.6000\n",
      "Epoch 54/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 3.5228 - accuracy: 0.3667 - val_loss: 1.8079 - val_accuracy: 0.6000\n",
      "Epoch 55/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 1.8202 - accuracy: 0.5000 - val_loss: 1.7895 - val_accuracy: 0.6000\n",
      "Epoch 56/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 2.9122 - accuracy: 0.3000 - val_loss: 1.7732 - val_accuracy: 0.6000\n",
      "Epoch 57/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 2.6970 - accuracy: 0.4333 - val_loss: 1.7548 - val_accuracy: 0.6000\n",
      "Epoch 58/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 2.6274 - accuracy: 0.4000 - val_loss: 1.7364 - val_accuracy: 0.6000\n",
      "Epoch 59/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 2.7080 - accuracy: 0.5000 - val_loss: 1.7140 - val_accuracy: 0.6000\n",
      "Epoch 60/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 2.3493 - accuracy: 0.4333 - val_loss: 1.6924 - val_accuracy: 0.6000\n",
      "Epoch 61/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 2.0659 - accuracy: 0.5000 - val_loss: 1.6726 - val_accuracy: 0.6000\n",
      "Epoch 62/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 2.0337 - accuracy: 0.4667 - val_loss: 1.6507 - val_accuracy: 0.6000\n",
      "Epoch 63/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 2.4125 - accuracy: 0.4000 - val_loss: 1.6290 - val_accuracy: 0.6000\n",
      "Epoch 64/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 2.7710 - accuracy: 0.3333 - val_loss: 1.6083 - val_accuracy: 0.6000\n",
      "Epoch 65/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 1.7889 - accuracy: 0.3667 - val_loss: 1.5862 - val_accuracy: 0.6000\n",
      "Epoch 66/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 2.3296 - accuracy: 0.4000 - val_loss: 1.5668 - val_accuracy: 0.6000\n",
      "Epoch 67/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 2.1211 - accuracy: 0.4000 - val_loss: 1.5471 - val_accuracy: 0.6000\n",
      "Epoch 68/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 1.5722 - accuracy: 0.5333 - val_loss: 1.5252 - val_accuracy: 0.6000\n",
      "Epoch 69/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 1.1783 - accuracy: 0.5333 - val_loss: 1.5032 - val_accuracy: 0.6000\n",
      "Epoch 70/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 2.0328 - accuracy: 0.4333 - val_loss: 1.4803 - val_accuracy: 0.6000\n",
      "Epoch 71/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 2.1264 - accuracy: 0.4000 - val_loss: 1.4585 - val_accuracy: 0.6000\n",
      "Epoch 72/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 2.1007 - accuracy: 0.3667 - val_loss: 1.4359 - val_accuracy: 0.6000\n",
      "Epoch 73/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 2.1634 - accuracy: 0.5000 - val_loss: 1.4120 - val_accuracy: 0.6000\n",
      "Epoch 74/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 1.7447 - accuracy: 0.3667 - val_loss: 1.3888 - val_accuracy: 0.6000\n",
      "Epoch 75/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 1.4213 - accuracy: 0.6000 - val_loss: 1.3660 - val_accuracy: 0.6000\n",
      "Epoch 76/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 1.6684 - accuracy: 0.4667 - val_loss: 1.3457 - val_accuracy: 0.6000\n",
      "Epoch 77/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 1.8425 - accuracy: 0.3667 - val_loss: 1.3244 - val_accuracy: 0.6000\n",
      "Epoch 78/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 1.5628 - accuracy: 0.5000 - val_loss: 1.3027 - val_accuracy: 0.6000\n",
      "Epoch 79/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 1.7337 - accuracy: 0.5333 - val_loss: 1.2814 - val_accuracy: 0.6000\n",
      "Epoch 80/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 2.0202 - accuracy: 0.4333 - val_loss: 1.2612 - val_accuracy: 0.6000\n",
      "Epoch 81/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 2.2598 - accuracy: 0.3667 - val_loss: 1.2407 - val_accuracy: 0.6000\n",
      "Epoch 82/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 1.7398 - accuracy: 0.4333 - val_loss: 1.2206 - val_accuracy: 0.6000\n",
      "Epoch 83/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 1.8184 - accuracy: 0.5333 - val_loss: 1.1983 - val_accuracy: 0.6000\n",
      "Epoch 84/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 1.4551 - accuracy: 0.3667 - val_loss: 1.1765 - val_accuracy: 0.6000\n",
      "Epoch 85/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 1.3546 - accuracy: 0.4667 - val_loss: 1.1546 - val_accuracy: 0.6000\n",
      "Epoch 86/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 1.5409 - accuracy: 0.5333 - val_loss: 1.1316 - val_accuracy: 0.6000\n",
      "Epoch 87/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 1.7291 - accuracy: 0.3000 - val_loss: 1.1130 - val_accuracy: 0.6000\n",
      "Epoch 88/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 1.7153 - accuracy: 0.4667 - val_loss: 1.0966 - val_accuracy: 0.6000\n",
      "Epoch 89/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 1.4705 - accuracy: 0.5333 - val_loss: 1.0809 - val_accuracy: 0.6000\n",
      "Epoch 90/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 1.2934 - accuracy: 0.5333 - val_loss: 1.0661 - val_accuracy: 0.6000\n",
      "Epoch 91/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.9823 - accuracy: 0.5333 - val_loss: 1.0522 - val_accuracy: 0.6000\n",
      "Epoch 92/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 1.3866 - accuracy: 0.4667 - val_loss: 1.0371 - val_accuracy: 0.6000\n",
      "Epoch 93/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 1.1313 - accuracy: 0.5000 - val_loss: 1.0226 - val_accuracy: 0.6000\n",
      "Epoch 94/3000\n",
      "30/30 [==============================] - 0s 145us/step - loss: 1.2694 - accuracy: 0.5667 - val_loss: 1.0083 - val_accuracy: 0.6000\n",
      "Epoch 95/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 1.4732 - accuracy: 0.5000 - val_loss: 0.9942 - val_accuracy: 0.6000\n",
      "Epoch 96/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 1.3912 - accuracy: 0.4333 - val_loss: 0.9809 - val_accuracy: 0.6000\n",
      "Epoch 97/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 1.0005 - accuracy: 0.6333 - val_loss: 0.9677 - val_accuracy: 0.6000\n",
      "Epoch 98/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 1.2205 - accuracy: 0.4000 - val_loss: 0.9548 - val_accuracy: 0.6000\n",
      "Epoch 99/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 1.4138 - accuracy: 0.5000 - val_loss: 0.9438 - val_accuracy: 0.6000\n",
      "Epoch 100/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 1.3798 - accuracy: 0.5000 - val_loss: 0.9334 - val_accuracy: 0.6000\n",
      "Epoch 101/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 1.5664 - accuracy: 0.3000 - val_loss: 0.9232 - val_accuracy: 0.6000\n",
      "Epoch 102/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 1.4504 - accuracy: 0.5000 - val_loss: 0.9144 - val_accuracy: 0.6000\n",
      "Epoch 103/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.7477 - accuracy: 0.7000 - val_loss: 0.9065 - val_accuracy: 0.6000\n",
      "Epoch 104/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 1.5070 - accuracy: 0.3000 - val_loss: 0.8988 - val_accuracy: 0.6000\n",
      "Epoch 105/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.9056 - accuracy: 0.6333 - val_loss: 0.8926 - val_accuracy: 0.6000\n",
      "Epoch 106/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 1.0437 - accuracy: 0.4333 - val_loss: 0.8865 - val_accuracy: 0.6000\n",
      "Epoch 107/3000\n",
      "30/30 [==============================] - 0s 144us/step - loss: 1.0943 - accuracy: 0.5667 - val_loss: 0.8822 - val_accuracy: 0.6000\n",
      "Epoch 108/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 1.0233 - accuracy: 0.4667 - val_loss: 0.8782 - val_accuracy: 0.6000\n",
      "Epoch 109/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 1.0849 - accuracy: 0.5667 - val_loss: 0.8727 - val_accuracy: 0.6000\n",
      "Epoch 110/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 1.1833 - accuracy: 0.6000 - val_loss: 0.8669 - val_accuracy: 0.6000\n",
      "Epoch 111/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 1.0738 - accuracy: 0.6000 - val_loss: 0.8609 - val_accuracy: 0.6000\n",
      "Epoch 112/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 1.1900 - accuracy: 0.4333 - val_loss: 0.8549 - val_accuracy: 0.6000\n",
      "Epoch 113/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 1.3980 - accuracy: 0.4667 - val_loss: 0.8489 - val_accuracy: 0.6000\n",
      "Epoch 114/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.8113 - accuracy: 0.6000 - val_loss: 0.8429 - val_accuracy: 0.6000\n",
      "Epoch 115/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 1.3570 - accuracy: 0.3667 - val_loss: 0.8370 - val_accuracy: 0.6000\n",
      "Epoch 116/3000\n",
      "30/30 [==============================] - 0s 160us/step - loss: 1.2372 - accuracy: 0.4667 - val_loss: 0.8325 - val_accuracy: 0.6000\n",
      "Epoch 117/3000\n",
      "30/30 [==============================] - 0s 142us/step - loss: 0.8919 - accuracy: 0.5667 - val_loss: 0.8280 - val_accuracy: 0.6000\n",
      "Epoch 118/3000\n",
      "30/30 [==============================] - 0s 153us/step - loss: 0.8307 - accuracy: 0.5667 - val_loss: 0.8238 - val_accuracy: 0.6000\n",
      "Epoch 119/3000\n",
      "30/30 [==============================] - 0s 144us/step - loss: 0.9676 - accuracy: 0.5333 - val_loss: 0.8199 - val_accuracy: 0.6000\n",
      "Epoch 120/3000\n",
      "30/30 [==============================] - 0s 148us/step - loss: 0.9336 - accuracy: 0.5667 - val_loss: 0.8159 - val_accuracy: 0.6000\n",
      "Epoch 121/3000\n",
      "30/30 [==============================] - 0s 157us/step - loss: 0.9621 - accuracy: 0.5000 - val_loss: 0.8117 - val_accuracy: 0.6000\n",
      "Epoch 122/3000\n",
      "30/30 [==============================] - 0s 145us/step - loss: 0.7786 - accuracy: 0.6333 - val_loss: 0.8076 - val_accuracy: 0.6000\n",
      "Epoch 123/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.8099 - accuracy: 0.5000 - val_loss: 0.8041 - val_accuracy: 0.6000\n",
      "Epoch 124/3000\n",
      "30/30 [==============================] - 0s 139us/step - loss: 1.0457 - accuracy: 0.6000 - val_loss: 0.8015 - val_accuracy: 0.6000\n",
      "Epoch 125/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.9765 - accuracy: 0.5000 - val_loss: 0.7984 - val_accuracy: 0.6000\n",
      "Epoch 126/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 1.2521 - accuracy: 0.4667 - val_loss: 0.7962 - val_accuracy: 0.6000\n",
      "Epoch 127/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.9158 - accuracy: 0.5667 - val_loss: 0.7935 - val_accuracy: 0.6000\n",
      "Epoch 128/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.9174 - accuracy: 0.5333 - val_loss: 0.7901 - val_accuracy: 0.6000\n",
      "Epoch 129/3000\n",
      "30/30 [==============================] - 0s 155us/step - loss: 0.7764 - accuracy: 0.5000 - val_loss: 0.7869 - val_accuracy: 0.6000\n",
      "Epoch 130/3000\n",
      "30/30 [==============================] - 0s 142us/step - loss: 0.8249 - accuracy: 0.5667 - val_loss: 0.7833 - val_accuracy: 0.6000\n",
      "Epoch 131/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.8189 - accuracy: 0.6333 - val_loss: 0.7798 - val_accuracy: 0.6000\n",
      "Epoch 132/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.5906 - accuracy: 0.7667 - val_loss: 0.7767 - val_accuracy: 0.6000\n",
      "Epoch 133/3000\n",
      "30/30 [==============================] - 0s 141us/step - loss: 0.7207 - accuracy: 0.6667 - val_loss: 0.7737 - val_accuracy: 0.6000\n",
      "Epoch 134/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.7803 - accuracy: 0.7333 - val_loss: 0.7696 - val_accuracy: 0.6000\n",
      "Epoch 135/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.6841 - accuracy: 0.7667 - val_loss: 0.7655 - val_accuracy: 0.6000\n",
      "Epoch 136/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.8022 - accuracy: 0.5000 - val_loss: 0.7611 - val_accuracy: 0.6000\n",
      "Epoch 137/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.7189 - accuracy: 0.7333 - val_loss: 0.7569 - val_accuracy: 0.6000\n",
      "Epoch 138/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.7003 - accuracy: 0.7000 - val_loss: 0.7526 - val_accuracy: 0.6000\n",
      "Epoch 139/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.6702 - accuracy: 0.7333 - val_loss: 0.7487 - val_accuracy: 0.6000\n",
      "Epoch 140/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.7099 - accuracy: 0.6333 - val_loss: 0.7450 - val_accuracy: 0.6000\n",
      "Epoch 141/3000\n",
      "30/30 [==============================] - 0s 147us/step - loss: 0.9747 - accuracy: 0.5000 - val_loss: 0.7413 - val_accuracy: 0.6000\n",
      "Epoch 142/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.9127 - accuracy: 0.5333 - val_loss: 0.7380 - val_accuracy: 0.6000\n",
      "Epoch 143/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.8807 - accuracy: 0.6333 - val_loss: 0.7350 - val_accuracy: 0.6000\n",
      "Epoch 144/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.8001 - accuracy: 0.6333 - val_loss: 0.7327 - val_accuracy: 0.6000\n",
      "Epoch 145/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.8913 - accuracy: 0.6333 - val_loss: 0.7311 - val_accuracy: 0.6000\n",
      "Epoch 146/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.7786 - accuracy: 0.6000 - val_loss: 0.7295 - val_accuracy: 0.6000\n",
      "Epoch 147/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.7789 - accuracy: 0.6000 - val_loss: 0.7279 - val_accuracy: 0.6000\n",
      "Epoch 148/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.7556 - accuracy: 0.6333 - val_loss: 0.7265 - val_accuracy: 0.6000\n",
      "Epoch 149/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.7545 - accuracy: 0.7000 - val_loss: 0.7253 - val_accuracy: 0.6000\n",
      "Epoch 150/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.7019 - accuracy: 0.6667 - val_loss: 0.7241 - val_accuracy: 0.6000\n",
      "Epoch 151/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.8723 - accuracy: 0.5000 - val_loss: 0.7222 - val_accuracy: 0.6000\n",
      "Epoch 152/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 1.0051 - accuracy: 0.6667 - val_loss: 0.7204 - val_accuracy: 0.6000\n",
      "Epoch 153/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.6707 - accuracy: 0.8000 - val_loss: 0.7185 - val_accuracy: 0.6000\n",
      "Epoch 154/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.6418 - accuracy: 0.7000 - val_loss: 0.7167 - val_accuracy: 0.6000\n",
      "Epoch 155/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.6549 - accuracy: 0.7333 - val_loss: 0.7148 - val_accuracy: 0.6000\n",
      "Epoch 156/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.8142 - accuracy: 0.6667 - val_loss: 0.7127 - val_accuracy: 0.6000\n",
      "Epoch 157/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.7714 - accuracy: 0.6000 - val_loss: 0.7109 - val_accuracy: 0.6000\n",
      "Epoch 158/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.7098 - accuracy: 0.6000 - val_loss: 0.7094 - val_accuracy: 0.6000\n",
      "Epoch 159/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.8004 - accuracy: 0.6667 - val_loss: 0.7075 - val_accuracy: 0.6000\n",
      "Epoch 160/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.6520 - accuracy: 0.8333 - val_loss: 0.7058 - val_accuracy: 0.6000\n",
      "Epoch 161/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.6673 - accuracy: 0.8000 - val_loss: 0.7043 - val_accuracy: 0.6000\n",
      "Epoch 162/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.7816 - accuracy: 0.6667 - val_loss: 0.7033 - val_accuracy: 0.6000\n",
      "Epoch 163/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.6474 - accuracy: 0.6333 - val_loss: 0.7024 - val_accuracy: 0.6000\n",
      "Epoch 164/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.5834 - accuracy: 0.7333 - val_loss: 0.7015 - val_accuracy: 0.6000\n",
      "Epoch 165/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.6448 - accuracy: 0.7000 - val_loss: 0.7006 - val_accuracy: 0.6000\n",
      "Epoch 166/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.6587 - accuracy: 0.6667 - val_loss: 0.6995 - val_accuracy: 0.6000\n",
      "Epoch 167/3000\n",
      "30/30 [==============================] - 0s 146us/step - loss: 0.8167 - accuracy: 0.6333 - val_loss: 0.6986 - val_accuracy: 0.6000\n",
      "Epoch 168/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.6476 - accuracy: 0.7000 - val_loss: 0.6975 - val_accuracy: 0.6000\n",
      "Epoch 169/3000\n",
      "30/30 [==============================] - 0s 141us/step - loss: 0.5266 - accuracy: 0.8000 - val_loss: 0.6964 - val_accuracy: 0.6000\n",
      "Epoch 170/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.6390 - accuracy: 0.8000 - val_loss: 0.6952 - val_accuracy: 0.6000\n",
      "Epoch 171/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.7005 - accuracy: 0.7333 - val_loss: 0.6940 - val_accuracy: 0.6000\n",
      "Epoch 172/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.5120 - accuracy: 0.8333 - val_loss: 0.6929 - val_accuracy: 0.6000\n",
      "Epoch 173/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.6098 - accuracy: 0.7667 - val_loss: 0.6920 - val_accuracy: 0.6000\n",
      "Epoch 174/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.6332 - accuracy: 0.7333 - val_loss: 0.6912 - val_accuracy: 0.6000\n",
      "Epoch 175/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.6661 - accuracy: 0.7667 - val_loss: 0.6905 - val_accuracy: 0.6000\n",
      "Epoch 176/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.6883 - accuracy: 0.6667 - val_loss: 0.6899 - val_accuracy: 0.6000\n",
      "Epoch 177/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.6242 - accuracy: 0.7000 - val_loss: 0.6891 - val_accuracy: 0.6000\n",
      "Epoch 178/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.7468 - accuracy: 0.7000 - val_loss: 0.6883 - val_accuracy: 0.6000\n",
      "Epoch 179/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.8226 - accuracy: 0.6000 - val_loss: 0.6876 - val_accuracy: 0.6000\n",
      "Epoch 180/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.6363 - accuracy: 0.8000 - val_loss: 0.6872 - val_accuracy: 0.6000\n",
      "Epoch 181/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.7066 - accuracy: 0.7667 - val_loss: 0.6869 - val_accuracy: 0.6000\n",
      "Epoch 182/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.6776 - accuracy: 0.6333 - val_loss: 0.6867 - val_accuracy: 0.6000\n",
      "Epoch 183/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.5626 - accuracy: 0.7333 - val_loss: 0.6866 - val_accuracy: 0.6000\n",
      "Epoch 184/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.7198 - accuracy: 0.6667 - val_loss: 0.6861 - val_accuracy: 0.6000\n",
      "Epoch 185/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.6275 - accuracy: 0.6667 - val_loss: 0.6855 - val_accuracy: 0.6000\n",
      "Epoch 186/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.5898 - accuracy: 0.7667 - val_loss: 0.6849 - val_accuracy: 0.6000\n",
      "Epoch 187/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.5731 - accuracy: 0.7667 - val_loss: 0.6840 - val_accuracy: 0.6000\n",
      "Epoch 188/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.5863 - accuracy: 0.7333 - val_loss: 0.6832 - val_accuracy: 0.6000\n",
      "Epoch 189/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.5812 - accuracy: 0.8000 - val_loss: 0.6823 - val_accuracy: 0.6000\n",
      "Epoch 190/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.5673 - accuracy: 0.8333 - val_loss: 0.6813 - val_accuracy: 0.6000\n",
      "Epoch 191/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.6715 - accuracy: 0.7333 - val_loss: 0.6802 - val_accuracy: 0.6000\n",
      "Epoch 192/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.5729 - accuracy: 0.7333 - val_loss: 0.6792 - val_accuracy: 0.6000\n",
      "Epoch 193/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.5765 - accuracy: 0.8333 - val_loss: 0.6783 - val_accuracy: 0.6000\n",
      "Epoch 194/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.6631 - accuracy: 0.7667 - val_loss: 0.6774 - val_accuracy: 0.6000\n",
      "Epoch 195/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.5563 - accuracy: 0.7667 - val_loss: 0.6764 - val_accuracy: 0.6000\n",
      "Epoch 196/3000\n",
      "30/30 [==============================] - 0s 143us/step - loss: 0.5987 - accuracy: 0.7333 - val_loss: 0.6754 - val_accuracy: 0.6000\n",
      "Epoch 197/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.6349 - accuracy: 0.7667 - val_loss: 0.6745 - val_accuracy: 0.6000\n",
      "Epoch 198/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.6281 - accuracy: 0.7000 - val_loss: 0.6734 - val_accuracy: 0.6000\n",
      "Epoch 199/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.6121 - accuracy: 0.8667 - val_loss: 0.6720 - val_accuracy: 0.6000\n",
      "Epoch 200/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.6096 - accuracy: 0.7000 - val_loss: 0.6707 - val_accuracy: 0.6000\n",
      "Epoch 201/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.6498 - accuracy: 0.6333 - val_loss: 0.6691 - val_accuracy: 0.6000\n",
      "Epoch 202/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.6217 - accuracy: 0.7333 - val_loss: 0.6678 - val_accuracy: 0.6000\n",
      "Epoch 203/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.6424 - accuracy: 0.7667 - val_loss: 0.6667 - val_accuracy: 0.6000\n",
      "Epoch 204/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.6585 - accuracy: 0.7000 - val_loss: 0.6654 - val_accuracy: 0.6000\n",
      "Epoch 205/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.6182 - accuracy: 0.8000 - val_loss: 0.6644 - val_accuracy: 0.6000\n",
      "Epoch 206/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.6008 - accuracy: 0.7333 - val_loss: 0.6638 - val_accuracy: 0.6000\n",
      "Epoch 207/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.6072 - accuracy: 0.9000 - val_loss: 0.6628 - val_accuracy: 0.6000\n",
      "Epoch 208/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.5416 - accuracy: 0.8000 - val_loss: 0.6618 - val_accuracy: 0.6000\n",
      "Epoch 209/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.5550 - accuracy: 0.8333 - val_loss: 0.6610 - val_accuracy: 0.6000\n",
      "Epoch 210/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.6236 - accuracy: 0.7667 - val_loss: 0.6601 - val_accuracy: 0.6000\n",
      "Epoch 211/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.6172 - accuracy: 0.7333 - val_loss: 0.6591 - val_accuracy: 0.6000\n",
      "Epoch 212/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.6068 - accuracy: 0.8667 - val_loss: 0.6584 - val_accuracy: 0.6000\n",
      "Epoch 213/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.6612 - accuracy: 0.7333 - val_loss: 0.6580 - val_accuracy: 0.6000\n",
      "Epoch 214/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.6534 - accuracy: 0.7333 - val_loss: 0.6577 - val_accuracy: 0.6000\n",
      "Epoch 215/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.5634 - accuracy: 0.7333 - val_loss: 0.6575 - val_accuracy: 0.6000\n",
      "Epoch 216/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.5668 - accuracy: 0.7667 - val_loss: 0.6571 - val_accuracy: 0.6000\n",
      "Epoch 217/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.5382 - accuracy: 0.8000 - val_loss: 0.6569 - val_accuracy: 0.6000\n",
      "Epoch 218/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.5681 - accuracy: 0.8000 - val_loss: 0.6569 - val_accuracy: 0.6000\n",
      "Epoch 219/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.6871 - accuracy: 0.8333 - val_loss: 0.6568 - val_accuracy: 0.6000\n",
      "Epoch 220/3000\n",
      "30/30 [==============================] - 0s 141us/step - loss: 0.6941 - accuracy: 0.6667 - val_loss: 0.6565 - val_accuracy: 0.6000\n",
      "Epoch 221/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.5786 - accuracy: 0.8000 - val_loss: 0.6563 - val_accuracy: 0.6000\n",
      "Epoch 222/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.5510 - accuracy: 0.8667 - val_loss: 0.6562 - val_accuracy: 0.6000\n",
      "Epoch 223/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.5622 - accuracy: 0.7667 - val_loss: 0.6560 - val_accuracy: 0.6000\n",
      "Epoch 224/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.5384 - accuracy: 0.8667 - val_loss: 0.6559 - val_accuracy: 0.6000\n",
      "Epoch 225/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.6346 - accuracy: 0.7333 - val_loss: 0.6560 - val_accuracy: 0.6000\n",
      "Epoch 226/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.5669 - accuracy: 0.8333 - val_loss: 0.6559 - val_accuracy: 0.6000\n",
      "Epoch 227/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.6112 - accuracy: 0.8000 - val_loss: 0.6557 - val_accuracy: 0.6000\n",
      "Epoch 228/3000\n",
      "30/30 [==============================] - 0s 157us/step - loss: 0.6708 - accuracy: 0.7000 - val_loss: 0.6550 - val_accuracy: 0.6000\n",
      "Epoch 229/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.5861 - accuracy: 0.8000 - val_loss: 0.6540 - val_accuracy: 0.6000\n",
      "Epoch 230/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.5977 - accuracy: 0.7333 - val_loss: 0.6528 - val_accuracy: 0.6000\n",
      "Epoch 231/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.5010 - accuracy: 0.8333 - val_loss: 0.6517 - val_accuracy: 0.6000\n",
      "Epoch 232/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.5827 - accuracy: 0.7000 - val_loss: 0.6504 - val_accuracy: 0.6000\n",
      "Epoch 233/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.6562 - accuracy: 0.6667 - val_loss: 0.6495 - val_accuracy: 0.6000\n",
      "Epoch 234/3000\n",
      "30/30 [==============================] - 0s 112us/step - loss: 0.5861 - accuracy: 0.7667 - val_loss: 0.6487 - val_accuracy: 0.6000\n",
      "Epoch 235/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.5618 - accuracy: 0.7333 - val_loss: 0.6478 - val_accuracy: 0.6000\n",
      "Epoch 236/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.5585 - accuracy: 0.8000 - val_loss: 0.6469 - val_accuracy: 0.6000\n",
      "Epoch 237/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.4938 - accuracy: 0.9000 - val_loss: 0.6460 - val_accuracy: 0.6000\n",
      "Epoch 238/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.5708 - accuracy: 0.8333 - val_loss: 0.6453 - val_accuracy: 0.6000\n",
      "Epoch 239/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.5037 - accuracy: 0.7667 - val_loss: 0.6447 - val_accuracy: 0.6000\n",
      "Epoch 240/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.5734 - accuracy: 0.8333 - val_loss: 0.6439 - val_accuracy: 0.6000\n",
      "Epoch 241/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.5655 - accuracy: 0.7667 - val_loss: 0.6430 - val_accuracy: 0.6000\n",
      "Epoch 242/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.5430 - accuracy: 0.8000 - val_loss: 0.6422 - val_accuracy: 0.6000\n",
      "Epoch 243/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.5505 - accuracy: 0.8000 - val_loss: 0.6417 - val_accuracy: 0.6000\n",
      "Epoch 244/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.4742 - accuracy: 0.9000 - val_loss: 0.6416 - val_accuracy: 0.6000\n",
      "Epoch 245/3000\n",
      "30/30 [==============================] - 0s 142us/step - loss: 0.5934 - accuracy: 0.8000 - val_loss: 0.6413 - val_accuracy: 0.6000\n",
      "Epoch 246/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.5280 - accuracy: 0.8333 - val_loss: 0.6409 - val_accuracy: 0.6000\n",
      "Epoch 247/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.5770 - accuracy: 0.8333 - val_loss: 0.6404 - val_accuracy: 0.6000\n",
      "Epoch 248/3000\n",
      "30/30 [==============================] - 0s 162us/step - loss: 0.5047 - accuracy: 0.9000 - val_loss: 0.6404 - val_accuracy: 0.6000\n",
      "Epoch 249/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.6347 - accuracy: 0.7667 - val_loss: 0.6400 - val_accuracy: 0.6000\n",
      "Epoch 250/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.5589 - accuracy: 0.8333 - val_loss: 0.6395 - val_accuracy: 0.6000\n",
      "Epoch 251/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.5632 - accuracy: 0.8333 - val_loss: 0.6390 - val_accuracy: 0.6000\n",
      "Epoch 252/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.5265 - accuracy: 0.8000 - val_loss: 0.6385 - val_accuracy: 0.6000\n",
      "Epoch 253/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.5592 - accuracy: 0.8000 - val_loss: 0.6380 - val_accuracy: 0.6000\n",
      "Epoch 254/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.6082 - accuracy: 0.8333 - val_loss: 0.6373 - val_accuracy: 0.6000\n",
      "Epoch 255/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.5962 - accuracy: 0.8000 - val_loss: 0.6365 - val_accuracy: 0.6000\n",
      "Epoch 256/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.5363 - accuracy: 0.7333 - val_loss: 0.6354 - val_accuracy: 0.6000\n",
      "Epoch 257/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.5854 - accuracy: 0.7667 - val_loss: 0.6345 - val_accuracy: 0.6000\n",
      "Epoch 258/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.6048 - accuracy: 0.7667 - val_loss: 0.6338 - val_accuracy: 0.6000\n",
      "Epoch 259/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.5148 - accuracy: 0.8000 - val_loss: 0.6332 - val_accuracy: 0.6000\n",
      "Epoch 260/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.4992 - accuracy: 0.8000 - val_loss: 0.6326 - val_accuracy: 0.6000\n",
      "Epoch 261/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.4976 - accuracy: 0.8333 - val_loss: 0.6324 - val_accuracy: 0.6000\n",
      "Epoch 262/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.4914 - accuracy: 0.8333 - val_loss: 0.6320 - val_accuracy: 0.6000\n",
      "Epoch 263/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.5455 - accuracy: 0.8000 - val_loss: 0.6318 - val_accuracy: 0.6000\n",
      "Epoch 264/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.4591 - accuracy: 0.9000 - val_loss: 0.6317 - val_accuracy: 0.6000\n",
      "Epoch 265/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.5221 - accuracy: 0.8667 - val_loss: 0.6320 - val_accuracy: 0.6000\n",
      "Epoch 266/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.5744 - accuracy: 0.8333 - val_loss: 0.6324 - val_accuracy: 0.6000\n",
      "Epoch 267/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.4930 - accuracy: 0.8333 - val_loss: 0.6327 - val_accuracy: 0.6000\n",
      "Epoch 268/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.5462 - accuracy: 0.7667 - val_loss: 0.6328 - val_accuracy: 0.6000\n",
      "Epoch 269/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.5279 - accuracy: 0.9333 - val_loss: 0.6327 - val_accuracy: 0.6000\n",
      "Epoch 270/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.5922 - accuracy: 0.7667 - val_loss: 0.6332 - val_accuracy: 0.6000\n",
      "Epoch 271/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.5241 - accuracy: 0.8333 - val_loss: 0.6334 - val_accuracy: 0.6000\n",
      "Epoch 272/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.5123 - accuracy: 0.8333 - val_loss: 0.6333 - val_accuracy: 0.6000\n",
      "Epoch 273/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.4351 - accuracy: 0.9000 - val_loss: 0.6332 - val_accuracy: 0.6000\n",
      "Epoch 274/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.5834 - accuracy: 0.6667 - val_loss: 0.6325 - val_accuracy: 0.6000\n",
      "Epoch 275/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.5336 - accuracy: 0.8333 - val_loss: 0.6319 - val_accuracy: 0.6000\n",
      "Epoch 276/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.5832 - accuracy: 0.8667 - val_loss: 0.6311 - val_accuracy: 0.6000\n",
      "Epoch 277/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.5901 - accuracy: 0.7333 - val_loss: 0.6304 - val_accuracy: 0.6000\n",
      "Epoch 278/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.5078 - accuracy: 0.8000 - val_loss: 0.6296 - val_accuracy: 0.6000\n",
      "Epoch 279/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.5100 - accuracy: 0.7667 - val_loss: 0.6290 - val_accuracy: 0.6000\n",
      "Epoch 280/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.5495 - accuracy: 0.8667 - val_loss: 0.6284 - val_accuracy: 0.6000\n",
      "Epoch 281/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.5574 - accuracy: 0.8667 - val_loss: 0.6280 - val_accuracy: 0.6000\n",
      "Epoch 282/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.5050 - accuracy: 0.9000 - val_loss: 0.6276 - val_accuracy: 0.6000\n",
      "Epoch 283/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.5619 - accuracy: 0.8333 - val_loss: 0.6269 - val_accuracy: 0.6000\n",
      "Epoch 284/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.4568 - accuracy: 0.8667 - val_loss: 0.6261 - val_accuracy: 0.6000\n",
      "Epoch 285/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.5001 - accuracy: 0.8667 - val_loss: 0.6251 - val_accuracy: 0.6000\n",
      "Epoch 286/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.5095 - accuracy: 0.8667 - val_loss: 0.6245 - val_accuracy: 0.6000\n",
      "Epoch 287/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.5300 - accuracy: 0.8000 - val_loss: 0.6240 - val_accuracy: 0.6000\n",
      "Epoch 288/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.5647 - accuracy: 0.8333 - val_loss: 0.6235 - val_accuracy: 0.6000\n",
      "Epoch 289/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.6091 - accuracy: 0.7667 - val_loss: 0.6228 - val_accuracy: 0.6000\n",
      "Epoch 290/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.4616 - accuracy: 0.9000 - val_loss: 0.6222 - val_accuracy: 0.6000\n",
      "Epoch 291/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.4795 - accuracy: 0.8667 - val_loss: 0.6212 - val_accuracy: 0.6000\n",
      "Epoch 292/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.5432 - accuracy: 0.8000 - val_loss: 0.6201 - val_accuracy: 0.6000\n",
      "Epoch 293/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.5511 - accuracy: 0.7333 - val_loss: 0.6194 - val_accuracy: 0.6000\n",
      "Epoch 294/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.5078 - accuracy: 0.7667 - val_loss: 0.6188 - val_accuracy: 0.6000\n",
      "Epoch 295/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.6040 - accuracy: 0.8000 - val_loss: 0.6183 - val_accuracy: 0.6000\n",
      "Epoch 296/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.4841 - accuracy: 0.8667 - val_loss: 0.6177 - val_accuracy: 0.6000\n",
      "Epoch 297/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.5471 - accuracy: 0.9000 - val_loss: 0.6166 - val_accuracy: 0.6000\n",
      "Epoch 298/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.5992 - accuracy: 0.8000 - val_loss: 0.6158 - val_accuracy: 0.6000\n",
      "Epoch 299/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.5230 - accuracy: 0.8000 - val_loss: 0.6149 - val_accuracy: 0.6000\n",
      "Epoch 300/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.5012 - accuracy: 0.8333 - val_loss: 0.6143 - val_accuracy: 0.6000\n",
      "Epoch 301/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.5621 - accuracy: 0.8333 - val_loss: 0.6136 - val_accuracy: 0.6000\n",
      "Epoch 302/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.5648 - accuracy: 0.8333 - val_loss: 0.6131 - val_accuracy: 0.6000\n",
      "Epoch 303/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.5902 - accuracy: 0.9000 - val_loss: 0.6126 - val_accuracy: 0.6000\n",
      "Epoch 304/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.4890 - accuracy: 0.8333 - val_loss: 0.6119 - val_accuracy: 0.6000\n",
      "Epoch 305/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.4217 - accuracy: 0.9333 - val_loss: 0.6112 - val_accuracy: 0.6000\n",
      "Epoch 306/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.5836 - accuracy: 0.8333 - val_loss: 0.6105 - val_accuracy: 0.6000\n",
      "Epoch 307/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.5418 - accuracy: 0.8333 - val_loss: 0.6100 - val_accuracy: 0.6000\n",
      "Epoch 308/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.5659 - accuracy: 0.8000 - val_loss: 0.6095 - val_accuracy: 0.6000\n",
      "Epoch 309/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.4597 - accuracy: 0.8667 - val_loss: 0.6088 - val_accuracy: 0.6000\n",
      "Epoch 310/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.5384 - accuracy: 0.8333 - val_loss: 0.6082 - val_accuracy: 0.6000\n",
      "Epoch 311/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.5818 - accuracy: 0.9000 - val_loss: 0.6077 - val_accuracy: 0.6000\n",
      "Epoch 312/3000\n",
      "30/30 [==============================] - 0s 142us/step - loss: 0.5025 - accuracy: 0.8667 - val_loss: 0.6072 - val_accuracy: 0.6000\n",
      "Epoch 313/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.5514 - accuracy: 0.8333 - val_loss: 0.6061 - val_accuracy: 0.6000\n",
      "Epoch 314/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.5070 - accuracy: 0.9000 - val_loss: 0.6052 - val_accuracy: 0.6000\n",
      "Epoch 315/3000\n",
      "30/30 [==============================] - 0s 145us/step - loss: 0.4884 - accuracy: 0.8333 - val_loss: 0.6042 - val_accuracy: 0.6000\n",
      "Epoch 316/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.6081 - accuracy: 0.7333 - val_loss: 0.6037 - val_accuracy: 0.6000\n",
      "Epoch 317/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.5096 - accuracy: 0.8333 - val_loss: 0.6035 - val_accuracy: 0.6000\n",
      "Epoch 318/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.5480 - accuracy: 0.8000 - val_loss: 0.6034 - val_accuracy: 0.6000\n",
      "Epoch 319/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.5412 - accuracy: 0.8667 - val_loss: 0.6037 - val_accuracy: 0.6000\n",
      "Epoch 320/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.4067 - accuracy: 0.8333 - val_loss: 0.6040 - val_accuracy: 0.6000\n",
      "Epoch 321/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.4267 - accuracy: 0.9000 - val_loss: 0.6043 - val_accuracy: 0.6000\n",
      "Epoch 322/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.4571 - accuracy: 0.8667 - val_loss: 0.6043 - val_accuracy: 0.6000\n",
      "Epoch 323/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.5650 - accuracy: 0.8000 - val_loss: 0.6043 - val_accuracy: 0.6000\n",
      "Epoch 324/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.5170 - accuracy: 0.8333 - val_loss: 0.6043 - val_accuracy: 0.6000\n",
      "Epoch 325/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.4999 - accuracy: 0.8333 - val_loss: 0.6042 - val_accuracy: 0.6000\n",
      "Epoch 326/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.4279 - accuracy: 0.9333 - val_loss: 0.6040 - val_accuracy: 0.6000\n",
      "Epoch 327/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.4779 - accuracy: 0.9000 - val_loss: 0.6039 - val_accuracy: 0.6000\n",
      "Epoch 328/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.5134 - accuracy: 0.8667 - val_loss: 0.6040 - val_accuracy: 0.6000\n",
      "Epoch 329/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.4136 - accuracy: 0.9000 - val_loss: 0.6041 - val_accuracy: 0.6000\n",
      "Epoch 330/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.4892 - accuracy: 0.9000 - val_loss: 0.6044 - val_accuracy: 0.6000\n",
      "Epoch 331/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.6613 - accuracy: 0.6667 - val_loss: 0.6048 - val_accuracy: 0.6000\n",
      "Epoch 332/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.4551 - accuracy: 0.9333 - val_loss: 0.6049 - val_accuracy: 0.6000\n",
      "Epoch 333/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.5342 - accuracy: 0.8333 - val_loss: 0.6048 - val_accuracy: 0.6000\n",
      "Epoch 334/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.4543 - accuracy: 0.8667 - val_loss: 0.6044 - val_accuracy: 0.6000\n",
      "Epoch 335/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.4335 - accuracy: 0.9000 - val_loss: 0.6037 - val_accuracy: 0.6000\n",
      "Epoch 336/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.5677 - accuracy: 0.8000 - val_loss: 0.6032 - val_accuracy: 0.6000\n",
      "Epoch 337/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.4777 - accuracy: 0.9000 - val_loss: 0.6025 - val_accuracy: 0.6000\n",
      "Epoch 338/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.4339 - accuracy: 0.9000 - val_loss: 0.6020 - val_accuracy: 0.6000\n",
      "Epoch 339/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.5590 - accuracy: 0.8333 - val_loss: 0.6016 - val_accuracy: 0.6000\n",
      "Epoch 340/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.5244 - accuracy: 0.8667 - val_loss: 0.6010 - val_accuracy: 0.6000\n",
      "Epoch 341/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.4935 - accuracy: 0.8333 - val_loss: 0.6000 - val_accuracy: 0.6000\n",
      "Epoch 342/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.5166 - accuracy: 0.9000 - val_loss: 0.5987 - val_accuracy: 0.6000\n",
      "Epoch 343/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.4340 - accuracy: 0.9000 - val_loss: 0.5977 - val_accuracy: 0.6000\n",
      "Epoch 344/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.4591 - accuracy: 0.8667 - val_loss: 0.5967 - val_accuracy: 0.6000\n",
      "Epoch 345/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.4686 - accuracy: 0.9000 - val_loss: 0.5957 - val_accuracy: 0.6000\n",
      "Epoch 346/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.5437 - accuracy: 0.8333 - val_loss: 0.5951 - val_accuracy: 0.6000\n",
      "Epoch 347/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.5318 - accuracy: 0.8000 - val_loss: 0.5942 - val_accuracy: 0.6000\n",
      "Epoch 348/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.5671 - accuracy: 0.7333 - val_loss: 0.5937 - val_accuracy: 0.6000\n",
      "Epoch 349/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.4701 - accuracy: 0.9000 - val_loss: 0.5934 - val_accuracy: 0.7000\n",
      "Epoch 350/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.4952 - accuracy: 0.9000 - val_loss: 0.5926 - val_accuracy: 0.7000\n",
      "Epoch 351/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.4453 - accuracy: 0.9333 - val_loss: 0.5912 - val_accuracy: 0.7000\n",
      "Epoch 352/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.4234 - accuracy: 0.9000 - val_loss: 0.5906 - val_accuracy: 0.7000\n",
      "Epoch 353/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.4713 - accuracy: 0.8667 - val_loss: 0.5897 - val_accuracy: 0.7000\n",
      "Epoch 354/3000\n",
      "30/30 [==============================] - 0s 147us/step - loss: 0.4798 - accuracy: 0.8000 - val_loss: 0.5890 - val_accuracy: 0.7000\n",
      "Epoch 355/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.5009 - accuracy: 0.8667 - val_loss: 0.5881 - val_accuracy: 0.7000\n",
      "Epoch 356/3000\n",
      "30/30 [==============================] - 0s 141us/step - loss: 0.5093 - accuracy: 0.8000 - val_loss: 0.5867 - val_accuracy: 0.7000\n",
      "Epoch 357/3000\n",
      "30/30 [==============================] - 0s 144us/step - loss: 0.4966 - accuracy: 0.7667 - val_loss: 0.5857 - val_accuracy: 0.7000\n",
      "Epoch 358/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.5471 - accuracy: 0.7667 - val_loss: 0.5848 - val_accuracy: 0.7000\n",
      "Epoch 359/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.4963 - accuracy: 0.8000 - val_loss: 0.5847 - val_accuracy: 0.7000\n",
      "Epoch 360/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.4631 - accuracy: 0.8333 - val_loss: 0.5849 - val_accuracy: 0.7000\n",
      "Epoch 361/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.4129 - accuracy: 0.9000 - val_loss: 0.5852 - val_accuracy: 0.7000\n",
      "Epoch 362/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.4531 - accuracy: 0.9000 - val_loss: 0.5857 - val_accuracy: 0.7000\n",
      "Epoch 363/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.4464 - accuracy: 0.8333 - val_loss: 0.5860 - val_accuracy: 0.7000\n",
      "Epoch 364/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.4613 - accuracy: 0.8333 - val_loss: 0.5865 - val_accuracy: 0.7000\n",
      "Epoch 365/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.5098 - accuracy: 0.8667 - val_loss: 0.5870 - val_accuracy: 0.7000\n",
      "Epoch 366/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.5028 - accuracy: 0.8667 - val_loss: 0.5867 - val_accuracy: 0.7000\n",
      "Epoch 367/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.5087 - accuracy: 0.8000 - val_loss: 0.5862 - val_accuracy: 0.7000\n",
      "Epoch 368/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.4812 - accuracy: 0.8333 - val_loss: 0.5849 - val_accuracy: 0.7000\n",
      "Epoch 369/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.5263 - accuracy: 0.8000 - val_loss: 0.5835 - val_accuracy: 0.7000\n",
      "Epoch 370/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.4950 - accuracy: 0.8667 - val_loss: 0.5823 - val_accuracy: 0.7000\n",
      "Epoch 371/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.5125 - accuracy: 0.8333 - val_loss: 0.5815 - val_accuracy: 0.7000\n",
      "Epoch 372/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.4415 - accuracy: 0.8667 - val_loss: 0.5815 - val_accuracy: 0.7000\n",
      "Epoch 373/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.4692 - accuracy: 0.8333 - val_loss: 0.5809 - val_accuracy: 0.7000\n",
      "Epoch 374/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.4623 - accuracy: 0.8667 - val_loss: 0.5795 - val_accuracy: 0.7000\n",
      "Epoch 375/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.4847 - accuracy: 0.9333 - val_loss: 0.5778 - val_accuracy: 0.7000\n",
      "Epoch 376/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.4853 - accuracy: 0.8000 - val_loss: 0.5759 - val_accuracy: 0.7000\n",
      "Epoch 377/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.5014 - accuracy: 0.8333 - val_loss: 0.5738 - val_accuracy: 0.7000\n",
      "Epoch 378/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.4269 - accuracy: 0.8333 - val_loss: 0.5721 - val_accuracy: 0.7000\n",
      "Epoch 379/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.4697 - accuracy: 0.8333 - val_loss: 0.5701 - val_accuracy: 0.7000\n",
      "Epoch 380/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.5448 - accuracy: 0.7667 - val_loss: 0.5681 - val_accuracy: 0.7000\n",
      "Epoch 381/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.4158 - accuracy: 0.9000 - val_loss: 0.5660 - val_accuracy: 0.7000\n",
      "Epoch 382/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.4624 - accuracy: 0.8333 - val_loss: 0.5640 - val_accuracy: 0.7000\n",
      "Epoch 383/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.5672 - accuracy: 0.7000 - val_loss: 0.5619 - val_accuracy: 0.7000\n",
      "Epoch 384/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.4361 - accuracy: 0.9333 - val_loss: 0.5600 - val_accuracy: 0.7000\n",
      "Epoch 385/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.4830 - accuracy: 0.9000 - val_loss: 0.5581 - val_accuracy: 0.7000\n",
      "Epoch 386/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.4914 - accuracy: 0.8667 - val_loss: 0.5564 - val_accuracy: 0.7000\n",
      "Epoch 387/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.5394 - accuracy: 0.7333 - val_loss: 0.5546 - val_accuracy: 0.7000\n",
      "Epoch 388/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.4238 - accuracy: 0.9000 - val_loss: 0.5529 - val_accuracy: 0.7000\n",
      "Epoch 389/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.5073 - accuracy: 0.8000 - val_loss: 0.5513 - val_accuracy: 0.7000\n",
      "Epoch 390/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.4590 - accuracy: 0.8000 - val_loss: 0.5502 - val_accuracy: 0.7000\n",
      "Epoch 391/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.5119 - accuracy: 0.8333 - val_loss: 0.5498 - val_accuracy: 0.7000\n",
      "Epoch 392/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.5536 - accuracy: 0.8000 - val_loss: 0.5492 - val_accuracy: 0.7000\n",
      "Epoch 393/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.4704 - accuracy: 0.8333 - val_loss: 0.5487 - val_accuracy: 0.7000\n",
      "Epoch 394/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.4715 - accuracy: 0.8000 - val_loss: 0.5479 - val_accuracy: 0.7000\n",
      "Epoch 395/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.4762 - accuracy: 0.8333 - val_loss: 0.5475 - val_accuracy: 0.7000\n",
      "Epoch 396/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.5899 - accuracy: 0.8333 - val_loss: 0.5474 - val_accuracy: 0.7000\n",
      "Epoch 397/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.4267 - accuracy: 0.8333 - val_loss: 0.5479 - val_accuracy: 0.7000\n",
      "Epoch 398/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.4125 - accuracy: 0.9333 - val_loss: 0.5488 - val_accuracy: 0.7000\n",
      "Epoch 399/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.4255 - accuracy: 0.9000 - val_loss: 0.5501 - val_accuracy: 0.7000\n",
      "Epoch 400/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.4760 - accuracy: 0.8667 - val_loss: 0.5523 - val_accuracy: 0.7000\n",
      "Epoch 401/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.5151 - accuracy: 0.8333 - val_loss: 0.5548 - val_accuracy: 0.7000\n",
      "Epoch 402/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.4415 - accuracy: 0.9333 - val_loss: 0.5566 - val_accuracy: 0.7000\n",
      "Epoch 403/3000\n",
      "30/30 [==============================] - 0s 146us/step - loss: 0.4743 - accuracy: 0.8000 - val_loss: 0.5591 - val_accuracy: 0.7000\n",
      "Epoch 404/3000\n",
      "30/30 [==============================] - 0s 149us/step - loss: 0.4848 - accuracy: 0.8333 - val_loss: 0.5615 - val_accuracy: 0.7000\n",
      "Epoch 405/3000\n",
      "30/30 [==============================] - 0s 145us/step - loss: 0.4461 - accuracy: 0.8667 - val_loss: 0.5647 - val_accuracy: 0.7000\n",
      "Epoch 406/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.4326 - accuracy: 0.8000 - val_loss: 0.5678 - val_accuracy: 0.7000\n",
      "Epoch 407/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.4709 - accuracy: 0.8000 - val_loss: 0.5715 - val_accuracy: 0.7000\n",
      "Epoch 408/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.4475 - accuracy: 0.8667 - val_loss: 0.5747 - val_accuracy: 0.7000\n",
      "Epoch 409/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.4531 - accuracy: 0.8667 - val_loss: 0.5776 - val_accuracy: 0.7000\n",
      "Epoch 410/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.4387 - accuracy: 0.9000 - val_loss: 0.5795 - val_accuracy: 0.7000\n",
      "Epoch 411/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.4866 - accuracy: 0.8667 - val_loss: 0.5820 - val_accuracy: 0.7000\n",
      "Epoch 412/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.5104 - accuracy: 0.7333 - val_loss: 0.5840 - val_accuracy: 0.7000\n",
      "Epoch 413/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.4370 - accuracy: 0.9000 - val_loss: 0.5851 - val_accuracy: 0.7000\n",
      "Epoch 414/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.5049 - accuracy: 0.8667 - val_loss: 0.5858 - val_accuracy: 0.7000\n",
      "Epoch 415/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.4789 - accuracy: 0.8333 - val_loss: 0.5869 - val_accuracy: 0.7000\n",
      "Epoch 416/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.4223 - accuracy: 0.8667 - val_loss: 0.5881 - val_accuracy: 0.7000\n",
      "Epoch 417/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.4478 - accuracy: 0.9000 - val_loss: 0.5893 - val_accuracy: 0.7000\n",
      "Epoch 418/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.3767 - accuracy: 0.9000 - val_loss: 0.5898 - val_accuracy: 0.7000\n",
      "Epoch 419/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.4184 - accuracy: 0.8333 - val_loss: 0.5893 - val_accuracy: 0.7000\n",
      "Epoch 420/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.6253 - accuracy: 0.7667 - val_loss: 0.5868 - val_accuracy: 0.7000\n",
      "Epoch 421/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.4681 - accuracy: 0.9000 - val_loss: 0.5841 - val_accuracy: 0.7000\n",
      "Epoch 422/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.5189 - accuracy: 0.8000 - val_loss: 0.5814 - val_accuracy: 0.7000\n",
      "Epoch 423/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.3601 - accuracy: 0.9333 - val_loss: 0.5788 - val_accuracy: 0.7000\n",
      "Epoch 424/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.4871 - accuracy: 0.8000 - val_loss: 0.5757 - val_accuracy: 0.7000\n",
      "Epoch 425/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.4857 - accuracy: 0.8667 - val_loss: 0.5727 - val_accuracy: 0.7000\n",
      "Epoch 426/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.4187 - accuracy: 0.9000 - val_loss: 0.5702 - val_accuracy: 0.7000\n",
      "Epoch 427/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.5617 - accuracy: 0.7667 - val_loss: 0.5674 - val_accuracy: 0.7000\n",
      "Epoch 428/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.4247 - accuracy: 0.8333 - val_loss: 0.5644 - val_accuracy: 0.7000\n",
      "Epoch 429/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.4734 - accuracy: 0.7667 - val_loss: 0.5622 - val_accuracy: 0.7000\n",
      "Epoch 430/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3843 - accuracy: 0.9000 - val_loss: 0.5605 - val_accuracy: 0.7000\n",
      "Epoch 431/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.4397 - accuracy: 0.8667 - val_loss: 0.5585 - val_accuracy: 0.7000\n",
      "Epoch 432/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.4893 - accuracy: 0.8333 - val_loss: 0.5567 - val_accuracy: 0.7000\n",
      "Epoch 433/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.4696 - accuracy: 0.8333 - val_loss: 0.5545 - val_accuracy: 0.7000\n",
      "Epoch 434/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.4263 - accuracy: 0.9333 - val_loss: 0.5520 - val_accuracy: 0.7000\n",
      "Epoch 435/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.4720 - accuracy: 0.8333 - val_loss: 0.5496 - val_accuracy: 0.7000\n",
      "Epoch 436/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.4607 - accuracy: 0.9000 - val_loss: 0.5470 - val_accuracy: 0.7000\n",
      "Epoch 437/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.4559 - accuracy: 0.8333 - val_loss: 0.5456 - val_accuracy: 0.7000\n",
      "Epoch 438/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.4331 - accuracy: 0.8667 - val_loss: 0.5450 - val_accuracy: 0.7000\n",
      "Epoch 439/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.4676 - accuracy: 0.8333 - val_loss: 0.5459 - val_accuracy: 0.7000\n",
      "Epoch 440/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.4374 - accuracy: 0.9333 - val_loss: 0.5468 - val_accuracy: 0.7000\n",
      "Epoch 441/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.4987 - accuracy: 0.8000 - val_loss: 0.5487 - val_accuracy: 0.7000\n",
      "Epoch 442/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.4501 - accuracy: 0.8667 - val_loss: 0.5506 - val_accuracy: 0.7000\n",
      "Epoch 443/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.4502 - accuracy: 0.8667 - val_loss: 0.5529 - val_accuracy: 0.7000\n",
      "Epoch 444/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.3810 - accuracy: 0.9000 - val_loss: 0.5552 - val_accuracy: 0.7000\n",
      "Epoch 445/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.4622 - accuracy: 0.8000 - val_loss: 0.5581 - val_accuracy: 0.7000\n",
      "Epoch 446/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.4553 - accuracy: 0.7667 - val_loss: 0.5612 - val_accuracy: 0.7000\n",
      "Epoch 447/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.4369 - accuracy: 0.9333 - val_loss: 0.5632 - val_accuracy: 0.7000\n",
      "Epoch 448/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.3528 - accuracy: 0.9333 - val_loss: 0.5652 - val_accuracy: 0.7000\n",
      "Epoch 449/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.4131 - accuracy: 0.8333 - val_loss: 0.5667 - val_accuracy: 0.7000\n",
      "Epoch 450/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.4647 - accuracy: 0.8667 - val_loss: 0.5680 - val_accuracy: 0.7000\n",
      "Epoch 451/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.4198 - accuracy: 0.8667 - val_loss: 0.5687 - val_accuracy: 0.7000\n",
      "Epoch 452/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.4799 - accuracy: 0.8333 - val_loss: 0.5691 - val_accuracy: 0.7000\n",
      "Epoch 453/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.4400 - accuracy: 0.8333 - val_loss: 0.5691 - val_accuracy: 0.7000\n",
      "Epoch 454/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.4031 - accuracy: 0.8667 - val_loss: 0.5679 - val_accuracy: 0.7000\n",
      "Epoch 455/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.4077 - accuracy: 0.8333 - val_loss: 0.5669 - val_accuracy: 0.7000\n",
      "Epoch 456/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.4378 - accuracy: 0.8333 - val_loss: 0.5655 - val_accuracy: 0.7000\n",
      "Epoch 457/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.4370 - accuracy: 0.8333 - val_loss: 0.5642 - val_accuracy: 0.7000\n",
      "Epoch 458/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.3738 - accuracy: 0.9000 - val_loss: 0.5626 - val_accuracy: 0.7000\n",
      "Epoch 459/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.4363 - accuracy: 0.9000 - val_loss: 0.5602 - val_accuracy: 0.7000\n",
      "Epoch 460/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.4515 - accuracy: 0.8667 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 461/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.4359 - accuracy: 0.9000 - val_loss: 0.5537 - val_accuracy: 0.7000\n",
      "Epoch 462/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.3755 - accuracy: 0.9000 - val_loss: 0.5516 - val_accuracy: 0.7000\n",
      "Epoch 463/3000\n",
      "30/30 [==============================] - 0s 145us/step - loss: 0.3854 - accuracy: 0.8333 - val_loss: 0.5508 - val_accuracy: 0.7000\n",
      "Epoch 464/3000\n",
      "30/30 [==============================] - 0s 146us/step - loss: 0.4160 - accuracy: 0.8000 - val_loss: 0.5501 - val_accuracy: 0.7000\n",
      "Epoch 465/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.4071 - accuracy: 0.9000 - val_loss: 0.5495 - val_accuracy: 0.7000\n",
      "Epoch 466/3000\n",
      "30/30 [==============================] - 0s 150us/step - loss: 0.4014 - accuracy: 0.9000 - val_loss: 0.5487 - val_accuracy: 0.7000\n",
      "Epoch 467/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.4334 - accuracy: 0.9333 - val_loss: 0.5480 - val_accuracy: 0.7000\n",
      "Epoch 468/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.3950 - accuracy: 0.9333 - val_loss: 0.5476 - val_accuracy: 0.7000\n",
      "Epoch 469/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.3930 - accuracy: 0.9000 - val_loss: 0.5483 - val_accuracy: 0.7000\n",
      "Epoch 470/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.3777 - accuracy: 0.9000 - val_loss: 0.5490 - val_accuracy: 0.7000\n",
      "Epoch 471/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.4281 - accuracy: 0.8333 - val_loss: 0.5511 - val_accuracy: 0.7000\n",
      "Epoch 472/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.4679 - accuracy: 0.8667 - val_loss: 0.5522 - val_accuracy: 0.7000\n",
      "Epoch 473/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.4257 - accuracy: 0.9000 - val_loss: 0.5526 - val_accuracy: 0.7000\n",
      "Epoch 474/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.4171 - accuracy: 0.8667 - val_loss: 0.5533 - val_accuracy: 0.7000\n",
      "Epoch 475/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.4855 - accuracy: 0.8333 - val_loss: 0.5544 - val_accuracy: 0.7000\n",
      "Epoch 476/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.4557 - accuracy: 0.8333 - val_loss: 0.5549 - val_accuracy: 0.7000\n",
      "Epoch 477/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.3407 - accuracy: 0.9000 - val_loss: 0.5553 - val_accuracy: 0.7000\n",
      "Epoch 478/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.4254 - accuracy: 0.8667 - val_loss: 0.5561 - val_accuracy: 0.7000\n",
      "Epoch 479/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.4587 - accuracy: 0.9000 - val_loss: 0.5563 - val_accuracy: 0.7000\n",
      "Epoch 480/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3739 - accuracy: 0.9333 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 481/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.4207 - accuracy: 0.8333 - val_loss: 0.5569 - val_accuracy: 0.7000\n",
      "Epoch 482/3000\n",
      "30/30 [==============================] - 0s 139us/step - loss: 0.4136 - accuracy: 0.8333 - val_loss: 0.5569 - val_accuracy: 0.7000\n",
      "Epoch 483/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.4072 - accuracy: 0.8667 - val_loss: 0.5569 - val_accuracy: 0.7000\n",
      "Epoch 484/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.4385 - accuracy: 0.9000 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 485/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.4482 - accuracy: 0.8667 - val_loss: 0.5582 - val_accuracy: 0.7000\n",
      "Epoch 486/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.4586 - accuracy: 0.9000 - val_loss: 0.5594 - val_accuracy: 0.7000\n",
      "Epoch 487/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.3771 - accuracy: 0.9000 - val_loss: 0.5604 - val_accuracy: 0.7000\n",
      "Epoch 488/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.3578 - accuracy: 0.9333 - val_loss: 0.5619 - val_accuracy: 0.7000\n",
      "Epoch 489/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.4288 - accuracy: 0.9000 - val_loss: 0.5627 - val_accuracy: 0.7000\n",
      "Epoch 490/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.4406 - accuracy: 0.8667 - val_loss: 0.5624 - val_accuracy: 0.7000\n",
      "Epoch 491/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.4312 - accuracy: 0.9000 - val_loss: 0.5616 - val_accuracy: 0.7000\n",
      "Epoch 492/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.4559 - accuracy: 0.8000 - val_loss: 0.5598 - val_accuracy: 0.7000\n",
      "Epoch 493/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.4581 - accuracy: 0.8333 - val_loss: 0.5581 - val_accuracy: 0.7000\n",
      "Epoch 494/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.4649 - accuracy: 0.8333 - val_loss: 0.5560 - val_accuracy: 0.7000\n",
      "Epoch 495/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.4920 - accuracy: 0.8000 - val_loss: 0.5536 - val_accuracy: 0.7000\n",
      "Epoch 496/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.3599 - accuracy: 0.8667 - val_loss: 0.5522 - val_accuracy: 0.7000\n",
      "Epoch 497/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.4213 - accuracy: 0.8667 - val_loss: 0.5518 - val_accuracy: 0.7000\n",
      "Epoch 498/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.3549 - accuracy: 0.9333 - val_loss: 0.5511 - val_accuracy: 0.7000\n",
      "Epoch 499/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.3634 - accuracy: 0.9000 - val_loss: 0.5502 - val_accuracy: 0.7000\n",
      "Epoch 500/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.3628 - accuracy: 0.9333 - val_loss: 0.5507 - val_accuracy: 0.7000\n",
      "Epoch 501/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.4714 - accuracy: 0.8333 - val_loss: 0.5512 - val_accuracy: 0.7000\n",
      "Epoch 502/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.4164 - accuracy: 0.9000 - val_loss: 0.5514 - val_accuracy: 0.7000\n",
      "Epoch 503/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.3322 - accuracy: 0.9333 - val_loss: 0.5517 - val_accuracy: 0.7000\n",
      "Epoch 504/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.3740 - accuracy: 0.9000 - val_loss: 0.5514 - val_accuracy: 0.7000\n",
      "Epoch 505/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.4340 - accuracy: 0.9333 - val_loss: 0.5515 - val_accuracy: 0.7000\n",
      "Epoch 506/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.3791 - accuracy: 0.9333 - val_loss: 0.5516 - val_accuracy: 0.7000\n",
      "Epoch 507/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.4045 - accuracy: 0.9000 - val_loss: 0.5517 - val_accuracy: 0.7000\n",
      "Epoch 508/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.4472 - accuracy: 0.8000 - val_loss: 0.5526 - val_accuracy: 0.7000\n",
      "Epoch 509/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.4485 - accuracy: 0.9000 - val_loss: 0.5535 - val_accuracy: 0.7000\n",
      "Epoch 510/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.3670 - accuracy: 0.9333 - val_loss: 0.5546 - val_accuracy: 0.7000\n",
      "Epoch 511/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.4524 - accuracy: 0.9000 - val_loss: 0.5556 - val_accuracy: 0.7000\n",
      "Epoch 512/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.4068 - accuracy: 0.8667 - val_loss: 0.5563 - val_accuracy: 0.7000\n",
      "Epoch 513/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.4011 - accuracy: 0.9000 - val_loss: 0.5566 - val_accuracy: 0.7000\n",
      "Epoch 514/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.4010 - accuracy: 0.9000 - val_loss: 0.5559 - val_accuracy: 0.7000\n",
      "Epoch 515/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.4529 - accuracy: 0.8333 - val_loss: 0.5557 - val_accuracy: 0.7000\n",
      "Epoch 516/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.4030 - accuracy: 0.8667 - val_loss: 0.5553 - val_accuracy: 0.7000\n",
      "Epoch 517/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.3819 - accuracy: 0.9000 - val_loss: 0.5563 - val_accuracy: 0.7000\n",
      "Epoch 518/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.3693 - accuracy: 0.9000 - val_loss: 0.5563 - val_accuracy: 0.7000\n",
      "Epoch 519/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.3906 - accuracy: 0.9000 - val_loss: 0.5562 - val_accuracy: 0.7000\n",
      "Epoch 520/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3332 - accuracy: 0.9000 - val_loss: 0.5563 - val_accuracy: 0.7000\n",
      "Epoch 521/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.4205 - accuracy: 0.8333 - val_loss: 0.5562 - val_accuracy: 0.7000\n",
      "Epoch 522/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.4286 - accuracy: 0.8667 - val_loss: 0.5552 - val_accuracy: 0.7000\n",
      "Epoch 523/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.5060 - accuracy: 0.8333 - val_loss: 0.5539 - val_accuracy: 0.7000\n",
      "Epoch 524/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.3914 - accuracy: 0.9000 - val_loss: 0.5536 - val_accuracy: 0.7000\n",
      "Epoch 525/3000\n",
      "30/30 [==============================] - 0s 142us/step - loss: 0.4139 - accuracy: 0.8667 - val_loss: 0.5529 - val_accuracy: 0.7000\n",
      "Epoch 526/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.4084 - accuracy: 0.9333 - val_loss: 0.5540 - val_accuracy: 0.7000\n",
      "Epoch 527/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.3341 - accuracy: 0.9333 - val_loss: 0.5562 - val_accuracy: 0.7000\n",
      "Epoch 528/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.3942 - accuracy: 0.9333 - val_loss: 0.5582 - val_accuracy: 0.7000\n",
      "Epoch 529/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.3898 - accuracy: 0.9000 - val_loss: 0.5603 - val_accuracy: 0.7000\n",
      "Epoch 530/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.3882 - accuracy: 0.8667 - val_loss: 0.5619 - val_accuracy: 0.7000\n",
      "Epoch 531/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.3793 - accuracy: 0.8667 - val_loss: 0.5635 - val_accuracy: 0.7000\n",
      "Epoch 532/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.4341 - accuracy: 0.8000 - val_loss: 0.5644 - val_accuracy: 0.7000\n",
      "Epoch 533/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3746 - accuracy: 0.9333 - val_loss: 0.5639 - val_accuracy: 0.7000\n",
      "Epoch 534/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.3443 - accuracy: 0.9000 - val_loss: 0.5637 - val_accuracy: 0.7000\n",
      "Epoch 535/3000\n",
      "30/30 [==============================] - 0s 222us/step - loss: 0.3539 - accuracy: 0.9333 - val_loss: 0.5635 - val_accuracy: 0.7000\n",
      "Epoch 536/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.3694 - accuracy: 0.8667 - val_loss: 0.5641 - val_accuracy: 0.7000\n",
      "Epoch 537/3000\n",
      "30/30 [==============================] - 0s 150us/step - loss: 0.3571 - accuracy: 0.9000 - val_loss: 0.5633 - val_accuracy: 0.7000\n",
      "Epoch 538/3000\n",
      "30/30 [==============================] - 0s 151us/step - loss: 0.4118 - accuracy: 0.8000 - val_loss: 0.5615 - val_accuracy: 0.7000\n",
      "Epoch 539/3000\n",
      "30/30 [==============================] - 0s 250us/step - loss: 0.3998 - accuracy: 0.8667 - val_loss: 0.5592 - val_accuracy: 0.7000\n",
      "Epoch 540/3000\n",
      "30/30 [==============================] - 0s 146us/step - loss: 0.3783 - accuracy: 0.9333 - val_loss: 0.5559 - val_accuracy: 0.7000\n",
      "Epoch 541/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.4127 - accuracy: 0.9000 - val_loss: 0.5534 - val_accuracy: 0.7000\n",
      "Epoch 542/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.5094 - accuracy: 0.7667 - val_loss: 0.5521 - val_accuracy: 0.7000\n",
      "Epoch 543/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.3801 - accuracy: 0.9333 - val_loss: 0.5503 - val_accuracy: 0.7000\n",
      "Epoch 544/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.4303 - accuracy: 0.9000 - val_loss: 0.5480 - val_accuracy: 0.7000\n",
      "Epoch 545/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.3493 - accuracy: 0.9000 - val_loss: 0.5455 - val_accuracy: 0.7000\n",
      "Epoch 546/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.3584 - accuracy: 0.9000 - val_loss: 0.5436 - val_accuracy: 0.7000\n",
      "Epoch 547/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.3545 - accuracy: 0.9333 - val_loss: 0.5418 - val_accuracy: 0.7000\n",
      "Epoch 548/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.3399 - accuracy: 0.9333 - val_loss: 0.5402 - val_accuracy: 0.7000\n",
      "Epoch 549/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.3664 - accuracy: 0.9000 - val_loss: 0.5396 - val_accuracy: 0.7000\n",
      "Epoch 550/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.3653 - accuracy: 0.8667 - val_loss: 0.5401 - val_accuracy: 0.7000\n",
      "Epoch 551/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.3216 - accuracy: 0.9000 - val_loss: 0.5406 - val_accuracy: 0.7000\n",
      "Epoch 552/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.3922 - accuracy: 0.8667 - val_loss: 0.5421 - val_accuracy: 0.7000\n",
      "Epoch 553/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.3875 - accuracy: 0.9333 - val_loss: 0.5442 - val_accuracy: 0.7000\n",
      "Epoch 554/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.3942 - accuracy: 0.9000 - val_loss: 0.5469 - val_accuracy: 0.7000\n",
      "Epoch 555/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.4256 - accuracy: 0.8667 - val_loss: 0.5498 - val_accuracy: 0.7000\n",
      "Epoch 556/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.3663 - accuracy: 0.9000 - val_loss: 0.5525 - val_accuracy: 0.7000\n",
      "Epoch 557/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.4093 - accuracy: 0.8667 - val_loss: 0.5561 - val_accuracy: 0.7000\n",
      "Epoch 558/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.3812 - accuracy: 0.9333 - val_loss: 0.5592 - val_accuracy: 0.7000\n",
      "Epoch 559/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.3378 - accuracy: 0.9333 - val_loss: 0.5608 - val_accuracy: 0.7000\n",
      "Epoch 560/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.3970 - accuracy: 0.8667 - val_loss: 0.5620 - val_accuracy: 0.7000\n",
      "Epoch 561/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3583 - accuracy: 0.8667 - val_loss: 0.5631 - val_accuracy: 0.7000\n",
      "Epoch 562/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.3715 - accuracy: 0.8333 - val_loss: 0.5650 - val_accuracy: 0.7000\n",
      "Epoch 563/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3253 - accuracy: 0.9333 - val_loss: 0.5676 - val_accuracy: 0.7000\n",
      "Epoch 564/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.3886 - accuracy: 0.9333 - val_loss: 0.5699 - val_accuracy: 0.7000\n",
      "Epoch 565/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.3308 - accuracy: 0.9000 - val_loss: 0.5716 - val_accuracy: 0.7000\n",
      "Epoch 566/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.4174 - accuracy: 0.9000 - val_loss: 0.5706 - val_accuracy: 0.7000\n",
      "Epoch 567/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3164 - accuracy: 0.9333 - val_loss: 0.5690 - val_accuracy: 0.7000\n",
      "Epoch 568/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.4468 - accuracy: 0.8333 - val_loss: 0.5646 - val_accuracy: 0.7000\n",
      "Epoch 569/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.3834 - accuracy: 0.9000 - val_loss: 0.5599 - val_accuracy: 0.7000\n",
      "Epoch 570/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.3524 - accuracy: 0.9333 - val_loss: 0.5553 - val_accuracy: 0.7000\n",
      "Epoch 571/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.4316 - accuracy: 0.9000 - val_loss: 0.5501 - val_accuracy: 0.7000\n",
      "Epoch 572/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.3300 - accuracy: 0.9333 - val_loss: 0.5462 - val_accuracy: 0.7000\n",
      "Epoch 573/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.4475 - accuracy: 0.9000 - val_loss: 0.5430 - val_accuracy: 0.7000\n",
      "Epoch 574/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.3904 - accuracy: 0.9000 - val_loss: 0.5405 - val_accuracy: 0.7000\n",
      "Epoch 575/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.3744 - accuracy: 0.8333 - val_loss: 0.5389 - val_accuracy: 0.7000\n",
      "Epoch 576/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.4003 - accuracy: 0.8333 - val_loss: 0.5381 - val_accuracy: 0.7000\n",
      "Epoch 577/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.4383 - accuracy: 0.9000 - val_loss: 0.5376 - val_accuracy: 0.7000\n",
      "Epoch 578/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.4113 - accuracy: 0.8667 - val_loss: 0.5378 - val_accuracy: 0.7000\n",
      "Epoch 579/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.4034 - accuracy: 0.9000 - val_loss: 0.5387 - val_accuracy: 0.7000\n",
      "Epoch 580/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.4988 - accuracy: 0.8333 - val_loss: 0.5396 - val_accuracy: 0.7000\n",
      "Epoch 581/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.3499 - accuracy: 0.9333 - val_loss: 0.5422 - val_accuracy: 0.7000\n",
      "Epoch 582/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.3357 - accuracy: 0.9333 - val_loss: 0.5448 - val_accuracy: 0.7000\n",
      "Epoch 583/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.3700 - accuracy: 0.9333 - val_loss: 0.5463 - val_accuracy: 0.7000\n",
      "Epoch 584/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.3965 - accuracy: 0.9000 - val_loss: 0.5473 - val_accuracy: 0.7000\n",
      "Epoch 585/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.4044 - accuracy: 0.9000 - val_loss: 0.5485 - val_accuracy: 0.7000\n",
      "Epoch 586/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.3531 - accuracy: 0.9000 - val_loss: 0.5488 - val_accuracy: 0.7000\n",
      "Epoch 587/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.3944 - accuracy: 0.8667 - val_loss: 0.5488 - val_accuracy: 0.7000\n",
      "Epoch 588/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.4062 - accuracy: 0.9000 - val_loss: 0.5489 - val_accuracy: 0.7000\n",
      "Epoch 589/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.3053 - accuracy: 0.9667 - val_loss: 0.5479 - val_accuracy: 0.7000\n",
      "Epoch 590/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.3605 - accuracy: 0.9000 - val_loss: 0.5462 - val_accuracy: 0.7000\n",
      "Epoch 591/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.4344 - accuracy: 0.9000 - val_loss: 0.5448 - val_accuracy: 0.7000\n",
      "Epoch 592/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.3912 - accuracy: 0.8667 - val_loss: 0.5440 - val_accuracy: 0.7000\n",
      "Epoch 593/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.4177 - accuracy: 0.8333 - val_loss: 0.5438 - val_accuracy: 0.7000\n",
      "Epoch 594/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.3176 - accuracy: 0.9333 - val_loss: 0.5439 - val_accuracy: 0.7000\n",
      "Epoch 595/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.3139 - accuracy: 0.9333 - val_loss: 0.5444 - val_accuracy: 0.7000\n",
      "Epoch 596/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.4089 - accuracy: 0.9333 - val_loss: 0.5450 - val_accuracy: 0.7000\n",
      "Epoch 597/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.3710 - accuracy: 0.9000 - val_loss: 0.5450 - val_accuracy: 0.7000\n",
      "Epoch 598/3000\n",
      "30/30 [==============================] - 0s 141us/step - loss: 0.3974 - accuracy: 0.9333 - val_loss: 0.5439 - val_accuracy: 0.7000\n",
      "Epoch 599/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.4158 - accuracy: 0.8000 - val_loss: 0.5427 - val_accuracy: 0.7000\n",
      "Epoch 600/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.3992 - accuracy: 0.9333 - val_loss: 0.5414 - val_accuracy: 0.7000\n",
      "Epoch 601/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.3389 - accuracy: 0.8667 - val_loss: 0.5410 - val_accuracy: 0.7000\n",
      "Epoch 602/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.4287 - accuracy: 0.8667 - val_loss: 0.5407 - val_accuracy: 0.7000\n",
      "Epoch 603/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.4051 - accuracy: 0.9000 - val_loss: 0.5391 - val_accuracy: 0.7000\n",
      "Epoch 604/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.4094 - accuracy: 0.8667 - val_loss: 0.5378 - val_accuracy: 0.7000\n",
      "Epoch 605/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.3588 - accuracy: 0.8667 - val_loss: 0.5367 - val_accuracy: 0.7000\n",
      "Epoch 606/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.3532 - accuracy: 0.9333 - val_loss: 0.5362 - val_accuracy: 0.7000\n",
      "Epoch 607/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.4688 - accuracy: 0.8667 - val_loss: 0.5368 - val_accuracy: 0.7000\n",
      "Epoch 608/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.3837 - accuracy: 0.9333 - val_loss: 0.5380 - val_accuracy: 0.7000\n",
      "Epoch 609/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.3395 - accuracy: 0.9333 - val_loss: 0.5386 - val_accuracy: 0.7000\n",
      "Epoch 610/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.3290 - accuracy: 0.9333 - val_loss: 0.5401 - val_accuracy: 0.7000\n",
      "Epoch 611/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.4420 - accuracy: 0.9333 - val_loss: 0.5407 - val_accuracy: 0.7000\n",
      "Epoch 612/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.3348 - accuracy: 0.9000 - val_loss: 0.5422 - val_accuracy: 0.7000\n",
      "Epoch 613/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.3779 - accuracy: 0.8667 - val_loss: 0.5448 - val_accuracy: 0.7000\n",
      "Epoch 614/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.3063 - accuracy: 0.9333 - val_loss: 0.5475 - val_accuracy: 0.7000\n",
      "Epoch 615/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.4102 - accuracy: 0.8667 - val_loss: 0.5511 - val_accuracy: 0.7000\n",
      "Epoch 616/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.3763 - accuracy: 0.9000 - val_loss: 0.5544 - val_accuracy: 0.7000\n",
      "Epoch 617/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.3831 - accuracy: 0.9000 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 618/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.3615 - accuracy: 0.9000 - val_loss: 0.5593 - val_accuracy: 0.7000\n",
      "Epoch 619/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.4019 - accuracy: 0.9000 - val_loss: 0.5589 - val_accuracy: 0.7000\n",
      "Epoch 620/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.3335 - accuracy: 0.9000 - val_loss: 0.5591 - val_accuracy: 0.7000\n",
      "Epoch 621/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.3419 - accuracy: 0.8667 - val_loss: 0.5602 - val_accuracy: 0.7000\n",
      "Epoch 622/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.3613 - accuracy: 0.8667 - val_loss: 0.5606 - val_accuracy: 0.7000\n",
      "Epoch 623/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.3753 - accuracy: 0.9333 - val_loss: 0.5608 - val_accuracy: 0.7000\n",
      "Epoch 624/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.4223 - accuracy: 0.8333 - val_loss: 0.5597 - val_accuracy: 0.7000\n",
      "Epoch 625/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.3088 - accuracy: 0.9333 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 626/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.3801 - accuracy: 0.9000 - val_loss: 0.5536 - val_accuracy: 0.7000\n",
      "Epoch 627/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.3573 - accuracy: 0.9000 - val_loss: 0.5519 - val_accuracy: 0.7000\n",
      "Epoch 628/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3192 - accuracy: 0.9000 - val_loss: 0.5502 - val_accuracy: 0.7000\n",
      "Epoch 629/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.3564 - accuracy: 0.9333 - val_loss: 0.5484 - val_accuracy: 0.7000\n",
      "Epoch 630/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.4320 - accuracy: 0.8667 - val_loss: 0.5463 - val_accuracy: 0.7000\n",
      "Epoch 631/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.3255 - accuracy: 0.9000 - val_loss: 0.5460 - val_accuracy: 0.7000\n",
      "Epoch 632/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.4289 - accuracy: 0.9333 - val_loss: 0.5449 - val_accuracy: 0.7000\n",
      "Epoch 633/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.3709 - accuracy: 0.8333 - val_loss: 0.5445 - val_accuracy: 0.7000\n",
      "Epoch 634/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.3474 - accuracy: 0.9000 - val_loss: 0.5454 - val_accuracy: 0.7000\n",
      "Epoch 635/3000\n",
      "30/30 [==============================] - 0s 148us/step - loss: 0.4250 - accuracy: 0.9000 - val_loss: 0.5467 - val_accuracy: 0.7000\n",
      "Epoch 636/3000\n",
      "30/30 [==============================] - 0s 148us/step - loss: 0.4434 - accuracy: 0.9000 - val_loss: 0.5460 - val_accuracy: 0.7000\n",
      "Epoch 637/3000\n",
      "30/30 [==============================] - 0s 143us/step - loss: 0.3414 - accuracy: 0.9000 - val_loss: 0.5442 - val_accuracy: 0.7000\n",
      "Epoch 638/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.4083 - accuracy: 0.8333 - val_loss: 0.5421 - val_accuracy: 0.7000\n",
      "Epoch 639/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.3431 - accuracy: 0.9333 - val_loss: 0.5418 - val_accuracy: 0.7000\n",
      "Epoch 640/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.3423 - accuracy: 0.8667 - val_loss: 0.5424 - val_accuracy: 0.7000\n",
      "Epoch 641/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.3871 - accuracy: 0.8333 - val_loss: 0.5439 - val_accuracy: 0.7000\n",
      "Epoch 642/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2879 - accuracy: 0.9667 - val_loss: 0.5448 - val_accuracy: 0.7000\n",
      "Epoch 643/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3486 - accuracy: 0.8333 - val_loss: 0.5458 - val_accuracy: 0.7000\n",
      "Epoch 644/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.3597 - accuracy: 0.9000 - val_loss: 0.5488 - val_accuracy: 0.7000\n",
      "Epoch 645/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.3086 - accuracy: 0.9000 - val_loss: 0.5517 - val_accuracy: 0.7000\n",
      "Epoch 646/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3339 - accuracy: 0.9333 - val_loss: 0.5546 - val_accuracy: 0.7000\n",
      "Epoch 647/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.3649 - accuracy: 0.9000 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 648/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.3162 - accuracy: 0.9667 - val_loss: 0.5587 - val_accuracy: 0.7000\n",
      "Epoch 649/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.3785 - accuracy: 0.8667 - val_loss: 0.5598 - val_accuracy: 0.7000\n",
      "Epoch 650/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.4187 - accuracy: 0.9000 - val_loss: 0.5616 - val_accuracy: 0.7000\n",
      "Epoch 651/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.3769 - accuracy: 0.9000 - val_loss: 0.5606 - val_accuracy: 0.7000\n",
      "Epoch 652/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.3143 - accuracy: 0.9000 - val_loss: 0.5601 - val_accuracy: 0.7000\n",
      "Epoch 653/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.3613 - accuracy: 0.9333 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 654/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3326 - accuracy: 0.9000 - val_loss: 0.5548 - val_accuracy: 0.7000\n",
      "Epoch 655/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.4180 - accuracy: 0.8333 - val_loss: 0.5543 - val_accuracy: 0.7000\n",
      "Epoch 656/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.3695 - accuracy: 0.8667 - val_loss: 0.5521 - val_accuracy: 0.7000\n",
      "Epoch 657/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.3369 - accuracy: 0.9000 - val_loss: 0.5494 - val_accuracy: 0.7000\n",
      "Epoch 658/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.3753 - accuracy: 0.8667 - val_loss: 0.5484 - val_accuracy: 0.7000\n",
      "Epoch 659/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.3772 - accuracy: 0.8333 - val_loss: 0.5481 - val_accuracy: 0.7000\n",
      "Epoch 660/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.4006 - accuracy: 0.8667 - val_loss: 0.5482 - val_accuracy: 0.7000\n",
      "Epoch 661/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.3740 - accuracy: 0.9000 - val_loss: 0.5478 - val_accuracy: 0.7000\n",
      "Epoch 662/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3458 - accuracy: 0.8333 - val_loss: 0.5490 - val_accuracy: 0.7000\n",
      "Epoch 663/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.3414 - accuracy: 0.8667 - val_loss: 0.5518 - val_accuracy: 0.7000\n",
      "Epoch 664/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.2912 - accuracy: 0.9000 - val_loss: 0.5536 - val_accuracy: 0.7000\n",
      "Epoch 665/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.3429 - accuracy: 0.8667 - val_loss: 0.5557 - val_accuracy: 0.7000\n",
      "Epoch 666/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.3745 - accuracy: 0.9333 - val_loss: 0.5593 - val_accuracy: 0.7000\n",
      "Epoch 667/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.3679 - accuracy: 0.8333 - val_loss: 0.5618 - val_accuracy: 0.7000\n",
      "Epoch 668/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.3501 - accuracy: 0.8667 - val_loss: 0.5635 - val_accuracy: 0.7000\n",
      "Epoch 669/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.3527 - accuracy: 0.9333 - val_loss: 0.5649 - val_accuracy: 0.7000\n",
      "Epoch 670/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.3369 - accuracy: 0.8667 - val_loss: 0.5653 - val_accuracy: 0.7000\n",
      "Epoch 671/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.3757 - accuracy: 0.9000 - val_loss: 0.5636 - val_accuracy: 0.7000\n",
      "Epoch 672/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2769 - accuracy: 0.9667 - val_loss: 0.5617 - val_accuracy: 0.7000\n",
      "Epoch 673/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.3086 - accuracy: 0.9000 - val_loss: 0.5613 - val_accuracy: 0.7000\n",
      "Epoch 674/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.3272 - accuracy: 0.9333 - val_loss: 0.5607 - val_accuracy: 0.7000\n",
      "Epoch 675/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.3107 - accuracy: 0.9000 - val_loss: 0.5606 - val_accuracy: 0.7000\n",
      "Epoch 676/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.3258 - accuracy: 0.8667 - val_loss: 0.5614 - val_accuracy: 0.7000\n",
      "Epoch 677/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.3391 - accuracy: 0.9000 - val_loss: 0.5610 - val_accuracy: 0.7000\n",
      "Epoch 678/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.3428 - accuracy: 0.9000 - val_loss: 0.5594 - val_accuracy: 0.7000\n",
      "Epoch 679/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.3664 - accuracy: 0.8667 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 680/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.4277 - accuracy: 0.8333 - val_loss: 0.5551 - val_accuracy: 0.7000\n",
      "Epoch 681/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.3393 - accuracy: 0.9000 - val_loss: 0.5527 - val_accuracy: 0.7000\n",
      "Epoch 682/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.3236 - accuracy: 0.9000 - val_loss: 0.5500 - val_accuracy: 0.7000\n",
      "Epoch 683/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.3405 - accuracy: 0.9000 - val_loss: 0.5476 - val_accuracy: 0.7000\n",
      "Epoch 684/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.3804 - accuracy: 0.9000 - val_loss: 0.5443 - val_accuracy: 0.7000\n",
      "Epoch 685/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.3844 - accuracy: 0.8667 - val_loss: 0.5418 - val_accuracy: 0.7000\n",
      "Epoch 686/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.3341 - accuracy: 0.9333 - val_loss: 0.5393 - val_accuracy: 0.7000\n",
      "Epoch 687/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3807 - accuracy: 0.8333 - val_loss: 0.5380 - val_accuracy: 0.7000\n",
      "Epoch 688/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.3534 - accuracy: 0.9000 - val_loss: 0.5361 - val_accuracy: 0.7000\n",
      "Epoch 689/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.3774 - accuracy: 0.9333 - val_loss: 0.5340 - val_accuracy: 0.7000\n",
      "Epoch 690/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.3239 - accuracy: 0.8667 - val_loss: 0.5341 - val_accuracy: 0.7000\n",
      "Epoch 691/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.3246 - accuracy: 0.9000 - val_loss: 0.5353 - val_accuracy: 0.7000\n",
      "Epoch 692/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.3251 - accuracy: 0.8667 - val_loss: 0.5365 - val_accuracy: 0.7000\n",
      "Epoch 693/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.3326 - accuracy: 0.9333 - val_loss: 0.5383 - val_accuracy: 0.7000\n",
      "Epoch 694/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3939 - accuracy: 0.9000 - val_loss: 0.5413 - val_accuracy: 0.7000\n",
      "Epoch 695/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.3933 - accuracy: 0.9000 - val_loss: 0.5430 - val_accuracy: 0.7000\n",
      "Epoch 696/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.3356 - accuracy: 0.9333 - val_loss: 0.5453 - val_accuracy: 0.7000\n",
      "Epoch 697/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2828 - accuracy: 0.9000 - val_loss: 0.5475 - val_accuracy: 0.7000\n",
      "Epoch 698/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.3545 - accuracy: 0.9000 - val_loss: 0.5479 - val_accuracy: 0.7000\n",
      "Epoch 699/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.3427 - accuracy: 0.9000 - val_loss: 0.5465 - val_accuracy: 0.7000\n",
      "Epoch 700/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.2863 - accuracy: 0.9000 - val_loss: 0.5438 - val_accuracy: 0.7000\n",
      "Epoch 701/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.3174 - accuracy: 0.9333 - val_loss: 0.5418 - val_accuracy: 0.7000\n",
      "Epoch 702/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.3450 - accuracy: 0.9000 - val_loss: 0.5411 - val_accuracy: 0.7000\n",
      "Epoch 703/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.3531 - accuracy: 0.9000 - val_loss: 0.5390 - val_accuracy: 0.7000\n",
      "Epoch 704/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.3288 - accuracy: 0.9667 - val_loss: 0.5350 - val_accuracy: 0.7000\n",
      "Epoch 705/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.3485 - accuracy: 0.8000 - val_loss: 0.5308 - val_accuracy: 0.7000\n",
      "Epoch 706/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.4103 - accuracy: 0.8000 - val_loss: 0.5232 - val_accuracy: 0.7000\n",
      "Epoch 707/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.3774 - accuracy: 0.8667 - val_loss: 0.5180 - val_accuracy: 0.7000\n",
      "Epoch 708/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.3712 - accuracy: 0.8333 - val_loss: 0.5135 - val_accuracy: 0.7000\n",
      "Epoch 709/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2792 - accuracy: 0.9333 - val_loss: 0.5118 - val_accuracy: 0.7000\n",
      "Epoch 710/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.3483 - accuracy: 0.8667 - val_loss: 0.5118 - val_accuracy: 0.7000\n",
      "Epoch 711/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.3024 - accuracy: 0.9000 - val_loss: 0.5136 - val_accuracy: 0.7000\n",
      "Epoch 712/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.4217 - accuracy: 0.8000 - val_loss: 0.5158 - val_accuracy: 0.7000\n",
      "Epoch 713/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.3338 - accuracy: 0.9000 - val_loss: 0.5190 - val_accuracy: 0.7000\n",
      "Epoch 714/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.4108 - accuracy: 0.7667 - val_loss: 0.5223 - val_accuracy: 0.7000\n",
      "Epoch 715/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.3327 - accuracy: 0.8667 - val_loss: 0.5264 - val_accuracy: 0.7000\n",
      "Epoch 716/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.3883 - accuracy: 0.9333 - val_loss: 0.5311 - val_accuracy: 0.7000\n",
      "Epoch 717/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.3100 - accuracy: 0.9333 - val_loss: 0.5350 - val_accuracy: 0.7000\n",
      "Epoch 718/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.3312 - accuracy: 0.9000 - val_loss: 0.5395 - val_accuracy: 0.7000\n",
      "Epoch 719/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3909 - accuracy: 0.8000 - val_loss: 0.5427 - val_accuracy: 0.7000\n",
      "Epoch 720/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.3822 - accuracy: 0.9000 - val_loss: 0.5476 - val_accuracy: 0.7000\n",
      "Epoch 721/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.3803 - accuracy: 0.9333 - val_loss: 0.5515 - val_accuracy: 0.7000\n",
      "Epoch 722/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.3339 - accuracy: 0.9667 - val_loss: 0.5557 - val_accuracy: 0.7000\n",
      "Epoch 723/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.4067 - accuracy: 0.8667 - val_loss: 0.5599 - val_accuracy: 0.7000\n",
      "Epoch 724/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.3257 - accuracy: 0.9000 - val_loss: 0.5651 - val_accuracy: 0.7000\n",
      "Epoch 725/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.3232 - accuracy: 0.8333 - val_loss: 0.5712 - val_accuracy: 0.7000\n",
      "Epoch 726/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2836 - accuracy: 0.9333 - val_loss: 0.5778 - val_accuracy: 0.7000\n",
      "Epoch 727/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3078 - accuracy: 0.9000 - val_loss: 0.5835 - val_accuracy: 0.7000\n",
      "Epoch 728/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.3865 - accuracy: 0.8667 - val_loss: 0.5869 - val_accuracy: 0.7000\n",
      "Epoch 729/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2942 - accuracy: 0.9000 - val_loss: 0.5897 - val_accuracy: 0.7000\n",
      "Epoch 730/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.3444 - accuracy: 0.9333 - val_loss: 0.5947 - val_accuracy: 0.7000\n",
      "Epoch 731/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2847 - accuracy: 0.9000 - val_loss: 0.5961 - val_accuracy: 0.7000\n",
      "Epoch 732/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.3216 - accuracy: 0.8333 - val_loss: 0.5961 - val_accuracy: 0.7000\n",
      "Epoch 733/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.3238 - accuracy: 0.9000 - val_loss: 0.5928 - val_accuracy: 0.7000\n",
      "Epoch 734/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.3754 - accuracy: 0.8333 - val_loss: 0.5886 - val_accuracy: 0.7000\n",
      "Epoch 735/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.3190 - accuracy: 0.9000 - val_loss: 0.5838 - val_accuracy: 0.7000\n",
      "Epoch 736/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2925 - accuracy: 0.9000 - val_loss: 0.5791 - val_accuracy: 0.7000\n",
      "Epoch 737/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.2630 - accuracy: 0.9667 - val_loss: 0.5749 - val_accuracy: 0.7000\n",
      "Epoch 738/3000\n",
      "30/30 [==============================] - 0s 143us/step - loss: 0.3564 - accuracy: 0.8667 - val_loss: 0.5715 - val_accuracy: 0.7000\n",
      "Epoch 739/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2967 - accuracy: 0.9000 - val_loss: 0.5701 - val_accuracy: 0.7000\n",
      "Epoch 740/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.3476 - accuracy: 0.9000 - val_loss: 0.5654 - val_accuracy: 0.7000\n",
      "Epoch 741/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3753 - accuracy: 0.8667 - val_loss: 0.5586 - val_accuracy: 0.7000\n",
      "Epoch 742/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.4214 - accuracy: 0.8333 - val_loss: 0.5540 - val_accuracy: 0.7000\n",
      "Epoch 743/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2745 - accuracy: 0.9000 - val_loss: 0.5499 - val_accuracy: 0.7000\n",
      "Epoch 744/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.3261 - accuracy: 0.8667 - val_loss: 0.5460 - val_accuracy: 0.7000\n",
      "Epoch 745/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.3567 - accuracy: 0.9000 - val_loss: 0.5432 - val_accuracy: 0.7000\n",
      "Epoch 746/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.2919 - accuracy: 0.9333 - val_loss: 0.5401 - val_accuracy: 0.7000\n",
      "Epoch 747/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.3450 - accuracy: 0.8333 - val_loss: 0.5376 - val_accuracy: 0.7000\n",
      "Epoch 748/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.3428 - accuracy: 0.9667 - val_loss: 0.5342 - val_accuracy: 0.7000\n",
      "Epoch 749/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.3100 - accuracy: 0.9000 - val_loss: 0.5326 - val_accuracy: 0.7000\n",
      "Epoch 750/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.3152 - accuracy: 0.8667 - val_loss: 0.5326 - val_accuracy: 0.7000\n",
      "Epoch 751/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.3065 - accuracy: 0.9000 - val_loss: 0.5343 - val_accuracy: 0.7000\n",
      "Epoch 752/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.3283 - accuracy: 0.8667 - val_loss: 0.5384 - val_accuracy: 0.7000\n",
      "Epoch 753/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.3278 - accuracy: 0.9000 - val_loss: 0.5455 - val_accuracy: 0.7000\n",
      "Epoch 754/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.3481 - accuracy: 0.9000 - val_loss: 0.5518 - val_accuracy: 0.7000\n",
      "Epoch 755/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.3624 - accuracy: 0.8333 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 756/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.3244 - accuracy: 0.9000 - val_loss: 0.5630 - val_accuracy: 0.7000\n",
      "Epoch 757/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.3292 - accuracy: 0.9000 - val_loss: 0.5658 - val_accuracy: 0.7000\n",
      "Epoch 758/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.3372 - accuracy: 0.8667 - val_loss: 0.5704 - val_accuracy: 0.7000\n",
      "Epoch 759/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.3444 - accuracy: 0.9000 - val_loss: 0.5721 - val_accuracy: 0.7000\n",
      "Epoch 760/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.3447 - accuracy: 0.9000 - val_loss: 0.5723 - val_accuracy: 0.7000\n",
      "Epoch 761/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.3016 - accuracy: 0.9000 - val_loss: 0.5730 - val_accuracy: 0.7000\n",
      "Epoch 762/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.3147 - accuracy: 0.9000 - val_loss: 0.5748 - val_accuracy: 0.7000\n",
      "Epoch 763/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.3369 - accuracy: 0.9000 - val_loss: 0.5740 - val_accuracy: 0.7000\n",
      "Epoch 764/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2702 - accuracy: 0.9000 - val_loss: 0.5725 - val_accuracy: 0.7000\n",
      "Epoch 765/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.3363 - accuracy: 0.9000 - val_loss: 0.5701 - val_accuracy: 0.7000\n",
      "Epoch 766/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.3101 - accuracy: 0.9333 - val_loss: 0.5676 - val_accuracy: 0.7000\n",
      "Epoch 767/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2739 - accuracy: 0.9333 - val_loss: 0.5644 - val_accuracy: 0.7000\n",
      "Epoch 768/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.3387 - accuracy: 0.8667 - val_loss: 0.5640 - val_accuracy: 0.7000\n",
      "Epoch 769/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.3018 - accuracy: 0.8667 - val_loss: 0.5631 - val_accuracy: 0.7000\n",
      "Epoch 770/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2876 - accuracy: 0.8667 - val_loss: 0.5609 - val_accuracy: 0.7000\n",
      "Epoch 771/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2580 - accuracy: 0.9333 - val_loss: 0.5602 - val_accuracy: 0.7000\n",
      "Epoch 772/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3099 - accuracy: 0.9333 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 773/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.3114 - accuracy: 0.9333 - val_loss: 0.5543 - val_accuracy: 0.7000\n",
      "Epoch 774/3000\n",
      "30/30 [==============================] - 0s 141us/step - loss: 0.2919 - accuracy: 0.8667 - val_loss: 0.5505 - val_accuracy: 0.7000\n",
      "Epoch 775/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2732 - accuracy: 0.9333 - val_loss: 0.5485 - val_accuracy: 0.7000\n",
      "Epoch 776/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2697 - accuracy: 0.9333 - val_loss: 0.5456 - val_accuracy: 0.7000\n",
      "Epoch 777/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3686 - accuracy: 0.9333 - val_loss: 0.5428 - val_accuracy: 0.7000\n",
      "Epoch 778/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.3286 - accuracy: 0.9000 - val_loss: 0.5420 - val_accuracy: 0.7000\n",
      "Epoch 779/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2740 - accuracy: 0.9333 - val_loss: 0.5420 - val_accuracy: 0.7000\n",
      "Epoch 780/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.3493 - accuracy: 0.8667 - val_loss: 0.5436 - val_accuracy: 0.7000\n",
      "Epoch 781/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2651 - accuracy: 0.9000 - val_loss: 0.5458 - val_accuracy: 0.7000\n",
      "Epoch 782/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2886 - accuracy: 0.8667 - val_loss: 0.5472 - val_accuracy: 0.7000\n",
      "Epoch 783/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.3328 - accuracy: 0.9000 - val_loss: 0.5481 - val_accuracy: 0.7000\n",
      "Epoch 784/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2735 - accuracy: 0.9333 - val_loss: 0.5522 - val_accuracy: 0.7000\n",
      "Epoch 785/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.3187 - accuracy: 0.9000 - val_loss: 0.5559 - val_accuracy: 0.7000\n",
      "Epoch 786/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3693 - accuracy: 0.8333 - val_loss: 0.5608 - val_accuracy: 0.7000\n",
      "Epoch 787/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3094 - accuracy: 0.8667 - val_loss: 0.5657 - val_accuracy: 0.7000\n",
      "Epoch 788/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.2768 - accuracy: 0.9000 - val_loss: 0.5707 - val_accuracy: 0.7000\n",
      "Epoch 789/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.2927 - accuracy: 0.9000 - val_loss: 0.5762 - val_accuracy: 0.7000\n",
      "Epoch 790/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.3111 - accuracy: 0.9333 - val_loss: 0.5794 - val_accuracy: 0.7000\n",
      "Epoch 791/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.4024 - accuracy: 0.8667 - val_loss: 0.5841 - val_accuracy: 0.7000\n",
      "Epoch 792/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.3231 - accuracy: 0.9000 - val_loss: 0.5837 - val_accuracy: 0.7000\n",
      "Epoch 793/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2809 - accuracy: 0.8667 - val_loss: 0.5834 - val_accuracy: 0.7000\n",
      "Epoch 794/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2562 - accuracy: 0.9333 - val_loss: 0.5828 - val_accuracy: 0.7000\n",
      "Epoch 795/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2825 - accuracy: 0.9333 - val_loss: 0.5811 - val_accuracy: 0.7000\n",
      "Epoch 796/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.2755 - accuracy: 0.9000 - val_loss: 0.5784 - val_accuracy: 0.7000\n",
      "Epoch 797/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.3500 - accuracy: 0.9333 - val_loss: 0.5730 - val_accuracy: 0.7000\n",
      "Epoch 798/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2822 - accuracy: 0.9000 - val_loss: 0.5666 - val_accuracy: 0.7000\n",
      "Epoch 799/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.3348 - accuracy: 0.9000 - val_loss: 0.5579 - val_accuracy: 0.7000\n",
      "Epoch 800/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3179 - accuracy: 0.8667 - val_loss: 0.5497 - val_accuracy: 0.7000\n",
      "Epoch 801/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2859 - accuracy: 0.9000 - val_loss: 0.5430 - val_accuracy: 0.7000\n",
      "Epoch 802/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2846 - accuracy: 0.9333 - val_loss: 0.5353 - val_accuracy: 0.7000\n",
      "Epoch 803/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.3440 - accuracy: 0.9000 - val_loss: 0.5285 - val_accuracy: 0.7000\n",
      "Epoch 804/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.2785 - accuracy: 0.9667 - val_loss: 0.5218 - val_accuracy: 0.7000\n",
      "Epoch 805/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.3447 - accuracy: 0.9333 - val_loss: 0.5185 - val_accuracy: 0.7000\n",
      "Epoch 806/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2366 - accuracy: 0.9667 - val_loss: 0.5166 - val_accuracy: 0.7000\n",
      "Epoch 807/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.3093 - accuracy: 0.8667 - val_loss: 0.5144 - val_accuracy: 0.7000\n",
      "Epoch 808/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.2725 - accuracy: 0.9333 - val_loss: 0.5144 - val_accuracy: 0.7000\n",
      "Epoch 809/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2789 - accuracy: 0.8333 - val_loss: 0.5171 - val_accuracy: 0.7000\n",
      "Epoch 810/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2959 - accuracy: 0.9333 - val_loss: 0.5236 - val_accuracy: 0.7000\n",
      "Epoch 811/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2843 - accuracy: 0.9000 - val_loss: 0.5313 - val_accuracy: 0.7000\n",
      "Epoch 812/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.3148 - accuracy: 0.9000 - val_loss: 0.5394 - val_accuracy: 0.7000\n",
      "Epoch 813/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.3632 - accuracy: 0.8667 - val_loss: 0.5502 - val_accuracy: 0.7000\n",
      "Epoch 814/3000\n",
      "30/30 [==============================] - 0s 147us/step - loss: 0.3526 - accuracy: 0.9000 - val_loss: 0.5596 - val_accuracy: 0.7000\n",
      "Epoch 815/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2871 - accuracy: 0.9333 - val_loss: 0.5723 - val_accuracy: 0.7000\n",
      "Epoch 816/3000\n",
      "30/30 [==============================] - 0s 148us/step - loss: 0.3134 - accuracy: 0.8667 - val_loss: 0.5811 - val_accuracy: 0.7000\n",
      "Epoch 817/3000\n",
      "30/30 [==============================] - 0s 141us/step - loss: 0.3354 - accuracy: 0.9333 - val_loss: 0.5894 - val_accuracy: 0.7000\n",
      "Epoch 818/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.2900 - accuracy: 0.9333 - val_loss: 0.5966 - val_accuracy: 0.7000\n",
      "Epoch 819/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.2976 - accuracy: 0.9333 - val_loss: 0.6050 - val_accuracy: 0.7000\n",
      "Epoch 820/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.2696 - accuracy: 0.9333 - val_loss: 0.6138 - val_accuracy: 0.7000\n",
      "Epoch 821/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.2547 - accuracy: 0.9333 - val_loss: 0.6194 - val_accuracy: 0.7000\n",
      "Epoch 822/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.3143 - accuracy: 0.8667 - val_loss: 0.6223 - val_accuracy: 0.7000\n",
      "Epoch 823/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.3684 - accuracy: 0.9000 - val_loss: 0.6189 - val_accuracy: 0.7000\n",
      "Epoch 824/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2712 - accuracy: 0.9333 - val_loss: 0.6100 - val_accuracy: 0.7000\n",
      "Epoch 825/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.3059 - accuracy: 0.9000 - val_loss: 0.6035 - val_accuracy: 0.7000\n",
      "Epoch 826/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3460 - accuracy: 0.8667 - val_loss: 0.5955 - val_accuracy: 0.7000\n",
      "Epoch 827/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.3016 - accuracy: 0.9333 - val_loss: 0.5862 - val_accuracy: 0.7000\n",
      "Epoch 828/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2611 - accuracy: 0.9333 - val_loss: 0.5746 - val_accuracy: 0.7000\n",
      "Epoch 829/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.3112 - accuracy: 0.9000 - val_loss: 0.5644 - val_accuracy: 0.7000\n",
      "Epoch 830/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.3403 - accuracy: 0.8333 - val_loss: 0.5557 - val_accuracy: 0.7000\n",
      "Epoch 831/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.3046 - accuracy: 0.8667 - val_loss: 0.5478 - val_accuracy: 0.7000\n",
      "Epoch 832/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2795 - accuracy: 0.9333 - val_loss: 0.5391 - val_accuracy: 0.7000\n",
      "Epoch 833/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2821 - accuracy: 0.8667 - val_loss: 0.5332 - val_accuracy: 0.7000\n",
      "Epoch 834/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.3523 - accuracy: 0.9000 - val_loss: 0.5289 - val_accuracy: 0.7000\n",
      "Epoch 835/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.3030 - accuracy: 0.8667 - val_loss: 0.5258 - val_accuracy: 0.7000\n",
      "Epoch 836/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.3213 - accuracy: 0.9000 - val_loss: 0.5234 - val_accuracy: 0.7000\n",
      "Epoch 837/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2627 - accuracy: 0.9000 - val_loss: 0.5226 - val_accuracy: 0.7000\n",
      "Epoch 838/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2606 - accuracy: 0.9333 - val_loss: 0.5227 - val_accuracy: 0.7000\n",
      "Epoch 839/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.3295 - accuracy: 0.9000 - val_loss: 0.5231 - val_accuracy: 0.7000\n",
      "Epoch 840/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2893 - accuracy: 0.9000 - val_loss: 0.5234 - val_accuracy: 0.7000\n",
      "Epoch 841/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.3268 - accuracy: 0.8667 - val_loss: 0.5252 - val_accuracy: 0.7000\n",
      "Epoch 842/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3247 - accuracy: 0.9000 - val_loss: 0.5283 - val_accuracy: 0.7000\n",
      "Epoch 843/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2689 - accuracy: 0.9000 - val_loss: 0.5341 - val_accuracy: 0.7000\n",
      "Epoch 844/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.3101 - accuracy: 0.9333 - val_loss: 0.5383 - val_accuracy: 0.7000\n",
      "Epoch 845/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2609 - accuracy: 0.9667 - val_loss: 0.5429 - val_accuracy: 0.7000\n",
      "Epoch 846/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2704 - accuracy: 0.9667 - val_loss: 0.5488 - val_accuracy: 0.7000\n",
      "Epoch 847/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.3010 - accuracy: 0.9333 - val_loss: 0.5543 - val_accuracy: 0.7000\n",
      "Epoch 848/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2471 - accuracy: 0.9333 - val_loss: 0.5578 - val_accuracy: 0.7000\n",
      "Epoch 849/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.3035 - accuracy: 0.9000 - val_loss: 0.5603 - val_accuracy: 0.7000\n",
      "Epoch 850/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2977 - accuracy: 0.9333 - val_loss: 0.5619 - val_accuracy: 0.7000\n",
      "Epoch 851/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.2683 - accuracy: 0.9333 - val_loss: 0.5646 - val_accuracy: 0.7000\n",
      "Epoch 852/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.4069 - accuracy: 0.9000 - val_loss: 0.5641 - val_accuracy: 0.7000\n",
      "Epoch 853/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.4244 - accuracy: 0.8000 - val_loss: 0.5613 - val_accuracy: 0.7000\n",
      "Epoch 854/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2938 - accuracy: 0.9000 - val_loss: 0.5569 - val_accuracy: 0.7000\n",
      "Epoch 855/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2670 - accuracy: 0.9667 - val_loss: 0.5529 - val_accuracy: 0.7000\n",
      "Epoch 856/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.3275 - accuracy: 0.9000 - val_loss: 0.5512 - val_accuracy: 0.7000\n",
      "Epoch 857/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.2838 - accuracy: 0.9000 - val_loss: 0.5502 - val_accuracy: 0.7000\n",
      "Epoch 858/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.3761 - accuracy: 0.9000 - val_loss: 0.5499 - val_accuracy: 0.7000\n",
      "Epoch 859/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.3020 - accuracy: 0.9000 - val_loss: 0.5477 - val_accuracy: 0.7000\n",
      "Epoch 860/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.3205 - accuracy: 0.9333 - val_loss: 0.5424 - val_accuracy: 0.7000\n",
      "Epoch 861/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2676 - accuracy: 0.9000 - val_loss: 0.5381 - val_accuracy: 0.7000\n",
      "Epoch 862/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2899 - accuracy: 0.9000 - val_loss: 0.5328 - val_accuracy: 0.7000\n",
      "Epoch 863/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2721 - accuracy: 0.9000 - val_loss: 0.5290 - val_accuracy: 0.7000\n",
      "Epoch 864/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.3246 - accuracy: 0.9333 - val_loss: 0.5243 - val_accuracy: 0.7000\n",
      "Epoch 865/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2579 - accuracy: 1.0000 - val_loss: 0.5224 - val_accuracy: 0.7000\n",
      "Epoch 866/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.3053 - accuracy: 0.9000 - val_loss: 0.5186 - val_accuracy: 0.7000\n",
      "Epoch 867/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2790 - accuracy: 0.8333 - val_loss: 0.5168 - val_accuracy: 0.7000\n",
      "Epoch 868/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.3122 - accuracy: 0.8667 - val_loss: 0.5162 - val_accuracy: 0.7000\n",
      "Epoch 869/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.3266 - accuracy: 0.8333 - val_loss: 0.5165 - val_accuracy: 0.7000\n",
      "Epoch 870/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.3175 - accuracy: 0.8667 - val_loss: 0.5184 - val_accuracy: 0.7000\n",
      "Epoch 871/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.3314 - accuracy: 0.8667 - val_loss: 0.5206 - val_accuracy: 0.7000\n",
      "Epoch 872/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3871 - accuracy: 0.8333 - val_loss: 0.5240 - val_accuracy: 0.7000\n",
      "Epoch 873/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.3303 - accuracy: 0.8333 - val_loss: 0.5286 - val_accuracy: 0.7000\n",
      "Epoch 874/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2527 - accuracy: 0.9000 - val_loss: 0.5354 - val_accuracy: 0.7000\n",
      "Epoch 875/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2711 - accuracy: 0.9000 - val_loss: 0.5418 - val_accuracy: 0.7000\n",
      "Epoch 876/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2979 - accuracy: 0.9000 - val_loss: 0.5513 - val_accuracy: 0.7000\n",
      "Epoch 877/3000\n",
      "30/30 [==============================] - 0s 147us/step - loss: 0.3824 - accuracy: 0.8667 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 878/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2812 - accuracy: 0.9000 - val_loss: 0.5625 - val_accuracy: 0.7000\n",
      "Epoch 879/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.3498 - accuracy: 0.9333 - val_loss: 0.5654 - val_accuracy: 0.7000\n",
      "Epoch 880/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.3096 - accuracy: 0.9000 - val_loss: 0.5671 - val_accuracy: 0.7000\n",
      "Epoch 881/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.2713 - accuracy: 0.9333 - val_loss: 0.5667 - val_accuracy: 0.7000\n",
      "Epoch 882/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2641 - accuracy: 0.8667 - val_loss: 0.5702 - val_accuracy: 0.7000\n",
      "Epoch 883/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2746 - accuracy: 0.9333 - val_loss: 0.5728 - val_accuracy: 0.7000\n",
      "Epoch 884/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.2935 - accuracy: 0.8333 - val_loss: 0.5754 - val_accuracy: 0.7000\n",
      "Epoch 885/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2344 - accuracy: 0.9667 - val_loss: 0.5781 - val_accuracy: 0.7000\n",
      "Epoch 886/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2894 - accuracy: 0.9333 - val_loss: 0.5825 - val_accuracy: 0.7000\n",
      "Epoch 887/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.3269 - accuracy: 0.9000 - val_loss: 0.5855 - val_accuracy: 0.7000\n",
      "Epoch 888/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.3246 - accuracy: 0.9000 - val_loss: 0.5864 - val_accuracy: 0.7000\n",
      "Epoch 889/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.2906 - accuracy: 0.9000 - val_loss: 0.5824 - val_accuracy: 0.7000\n",
      "Epoch 890/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2780 - accuracy: 0.9000 - val_loss: 0.5785 - val_accuracy: 0.7000\n",
      "Epoch 891/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2364 - accuracy: 0.9333 - val_loss: 0.5787 - val_accuracy: 0.7000\n",
      "Epoch 892/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2742 - accuracy: 0.8667 - val_loss: 0.5789 - val_accuracy: 0.7000\n",
      "Epoch 893/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.2807 - accuracy: 0.9000 - val_loss: 0.5738 - val_accuracy: 0.7000\n",
      "Epoch 894/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2933 - accuracy: 0.9667 - val_loss: 0.5652 - val_accuracy: 0.7000\n",
      "Epoch 895/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2374 - accuracy: 0.9000 - val_loss: 0.5601 - val_accuracy: 0.7000\n",
      "Epoch 896/3000\n",
      "30/30 [==============================] - 0s 150us/step - loss: 0.2762 - accuracy: 0.9667 - val_loss: 0.5558 - val_accuracy: 0.7000\n",
      "Epoch 897/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2913 - accuracy: 0.9333 - val_loss: 0.5559 - val_accuracy: 0.7000\n",
      "Epoch 898/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2845 - accuracy: 0.9333 - val_loss: 0.5597 - val_accuracy: 0.7000\n",
      "Epoch 899/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2937 - accuracy: 0.8333 - val_loss: 0.5653 - val_accuracy: 0.7000\n",
      "Epoch 900/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.3802 - accuracy: 0.8667 - val_loss: 0.5692 - val_accuracy: 0.7000\n",
      "Epoch 901/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.3031 - accuracy: 0.8667 - val_loss: 0.5724 - val_accuracy: 0.7000\n",
      "Epoch 902/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.3395 - accuracy: 0.8667 - val_loss: 0.5742 - val_accuracy: 0.7000\n",
      "Epoch 903/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2496 - accuracy: 0.9667 - val_loss: 0.5730 - val_accuracy: 0.7000\n",
      "Epoch 904/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2915 - accuracy: 0.9333 - val_loss: 0.5712 - val_accuracy: 0.7000\n",
      "Epoch 905/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2284 - accuracy: 0.9667 - val_loss: 0.5696 - val_accuracy: 0.7000\n",
      "Epoch 906/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2633 - accuracy: 0.9333 - val_loss: 0.5680 - val_accuracy: 0.7000\n",
      "Epoch 907/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2709 - accuracy: 0.8667 - val_loss: 0.5672 - val_accuracy: 0.7000\n",
      "Epoch 908/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2699 - accuracy: 0.9000 - val_loss: 0.5709 - val_accuracy: 0.7000\n",
      "Epoch 909/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.3061 - accuracy: 0.9000 - val_loss: 0.5773 - val_accuracy: 0.7000\n",
      "Epoch 910/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2684 - accuracy: 0.9333 - val_loss: 0.5832 - val_accuracy: 0.7000\n",
      "Epoch 911/3000\n",
      "30/30 [==============================] - 0s 145us/step - loss: 0.3120 - accuracy: 0.9333 - val_loss: 0.5860 - val_accuracy: 0.7000\n",
      "Epoch 912/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2530 - accuracy: 0.9000 - val_loss: 0.5882 - val_accuracy: 0.7000\n",
      "Epoch 913/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.3493 - accuracy: 0.8333 - val_loss: 0.5855 - val_accuracy: 0.7000\n",
      "Epoch 914/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.3271 - accuracy: 0.9000 - val_loss: 0.5805 - val_accuracy: 0.7000\n",
      "Epoch 915/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.2433 - accuracy: 0.9333 - val_loss: 0.5772 - val_accuracy: 0.7000\n",
      "Epoch 916/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2254 - accuracy: 0.9667 - val_loss: 0.5751 - val_accuracy: 0.7000\n",
      "Epoch 917/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.3072 - accuracy: 0.8667 - val_loss: 0.5738 - val_accuracy: 0.7000\n",
      "Epoch 918/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2618 - accuracy: 0.9000 - val_loss: 0.5709 - val_accuracy: 0.7000\n",
      "Epoch 919/3000\n",
      "30/30 [==============================] - 0s 146us/step - loss: 0.3133 - accuracy: 0.8333 - val_loss: 0.5699 - val_accuracy: 0.7000\n",
      "Epoch 920/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.3371 - accuracy: 0.8333 - val_loss: 0.5693 - val_accuracy: 0.7000\n",
      "Epoch 921/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.3182 - accuracy: 0.8667 - val_loss: 0.5726 - val_accuracy: 0.7000\n",
      "Epoch 922/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2701 - accuracy: 0.9667 - val_loss: 0.5764 - val_accuracy: 0.7000\n",
      "Epoch 923/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.3097 - accuracy: 0.9000 - val_loss: 0.5797 - val_accuracy: 0.7000\n",
      "Epoch 924/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2780 - accuracy: 0.9333 - val_loss: 0.5803 - val_accuracy: 0.7000\n",
      "Epoch 925/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2852 - accuracy: 0.9000 - val_loss: 0.5795 - val_accuracy: 0.7000\n",
      "Epoch 926/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.2780 - accuracy: 0.9667 - val_loss: 0.5797 - val_accuracy: 0.7000\n",
      "Epoch 927/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2545 - accuracy: 0.9000 - val_loss: 0.5830 - val_accuracy: 0.7000\n",
      "Epoch 928/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2916 - accuracy: 0.9667 - val_loss: 0.5828 - val_accuracy: 0.7000\n",
      "Epoch 929/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2897 - accuracy: 0.8667 - val_loss: 0.5849 - val_accuracy: 0.7000\n",
      "Epoch 930/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2520 - accuracy: 0.9667 - val_loss: 0.5876 - val_accuracy: 0.7000\n",
      "Epoch 931/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.3021 - accuracy: 0.9000 - val_loss: 0.5934 - val_accuracy: 0.7000\n",
      "Epoch 932/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.3657 - accuracy: 0.8333 - val_loss: 0.5995 - val_accuracy: 0.7000\n",
      "Epoch 933/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2897 - accuracy: 0.9000 - val_loss: 0.6051 - val_accuracy: 0.7000\n",
      "Epoch 934/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2141 - accuracy: 0.9333 - val_loss: 0.6124 - val_accuracy: 0.7000\n",
      "Epoch 935/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2663 - accuracy: 0.8667 - val_loss: 0.6223 - val_accuracy: 0.7000\n",
      "Epoch 936/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.2991 - accuracy: 0.9333 - val_loss: 0.6310 - val_accuracy: 0.7000\n",
      "Epoch 937/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2954 - accuracy: 0.8667 - val_loss: 0.6374 - val_accuracy: 0.7000\n",
      "Epoch 938/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2213 - accuracy: 0.9333 - val_loss: 0.6415 - val_accuracy: 0.7000\n",
      "Epoch 939/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2995 - accuracy: 0.9000 - val_loss: 0.6432 - val_accuracy: 0.7000\n",
      "Epoch 940/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2768 - accuracy: 0.9000 - val_loss: 0.6429 - val_accuracy: 0.7000\n",
      "Epoch 941/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2974 - accuracy: 0.9000 - val_loss: 0.6363 - val_accuracy: 0.7000\n",
      "Epoch 942/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.2467 - accuracy: 0.9333 - val_loss: 0.6295 - val_accuracy: 0.7000\n",
      "Epoch 943/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.3375 - accuracy: 0.8667 - val_loss: 0.6235 - val_accuracy: 0.7000\n",
      "Epoch 944/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.3116 - accuracy: 0.9000 - val_loss: 0.6166 - val_accuracy: 0.7000\n",
      "Epoch 945/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.2373 - accuracy: 0.9000 - val_loss: 0.6127 - val_accuracy: 0.7000\n",
      "Epoch 946/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2331 - accuracy: 0.9000 - val_loss: 0.6084 - val_accuracy: 0.7000\n",
      "Epoch 947/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2437 - accuracy: 0.9000 - val_loss: 0.6026 - val_accuracy: 0.7000\n",
      "Epoch 948/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2788 - accuracy: 0.9000 - val_loss: 0.5967 - val_accuracy: 0.7000\n",
      "Epoch 949/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.3264 - accuracy: 0.8667 - val_loss: 0.5903 - val_accuracy: 0.7000\n",
      "Epoch 950/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.3607 - accuracy: 0.8667 - val_loss: 0.5883 - val_accuracy: 0.7000\n",
      "Epoch 951/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.1946 - accuracy: 0.9667 - val_loss: 0.5841 - val_accuracy: 0.7000\n",
      "Epoch 952/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.3273 - accuracy: 0.9000 - val_loss: 0.5810 - val_accuracy: 0.7000\n",
      "Epoch 953/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2822 - accuracy: 0.9000 - val_loss: 0.5796 - val_accuracy: 0.7000\n",
      "Epoch 954/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2880 - accuracy: 0.8667 - val_loss: 0.5777 - val_accuracy: 0.7000\n",
      "Epoch 955/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.3077 - accuracy: 0.9333 - val_loss: 0.5728 - val_accuracy: 0.7000\n",
      "Epoch 956/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2601 - accuracy: 0.9333 - val_loss: 0.5741 - val_accuracy: 0.7000\n",
      "Epoch 957/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2661 - accuracy: 0.9000 - val_loss: 0.5767 - val_accuracy: 0.7000\n",
      "Epoch 958/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2783 - accuracy: 0.9000 - val_loss: 0.5807 - val_accuracy: 0.7000\n",
      "Epoch 959/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2969 - accuracy: 0.9333 - val_loss: 0.5856 - val_accuracy: 0.7000\n",
      "Epoch 960/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.2030 - accuracy: 0.9667 - val_loss: 0.5897 - val_accuracy: 0.7000\n",
      "Epoch 961/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.3227 - accuracy: 0.8333 - val_loss: 0.5945 - val_accuracy: 0.7000\n",
      "Epoch 962/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.2034 - accuracy: 0.9333 - val_loss: 0.5990 - val_accuracy: 0.7000\n",
      "Epoch 963/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.3155 - accuracy: 0.9333 - val_loss: 0.6030 - val_accuracy: 0.7000\n",
      "Epoch 964/3000\n",
      "30/30 [==============================] - 0s 139us/step - loss: 0.2871 - accuracy: 0.9000 - val_loss: 0.6076 - val_accuracy: 0.7000\n",
      "Epoch 965/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2842 - accuracy: 0.9000 - val_loss: 0.6091 - val_accuracy: 0.7000\n",
      "Epoch 966/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.2983 - accuracy: 0.9000 - val_loss: 0.6076 - val_accuracy: 0.7000\n",
      "Epoch 967/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2683 - accuracy: 0.9000 - val_loss: 0.6065 - val_accuracy: 0.7000\n",
      "Epoch 968/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2127 - accuracy: 0.9333 - val_loss: 0.6067 - val_accuracy: 0.7000\n",
      "Epoch 969/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2538 - accuracy: 0.9333 - val_loss: 0.6032 - val_accuracy: 0.7000\n",
      "Epoch 970/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.3636 - accuracy: 0.8333 - val_loss: 0.5930 - val_accuracy: 0.7000\n",
      "Epoch 971/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.2642 - accuracy: 0.9000 - val_loss: 0.5848 - val_accuracy: 0.7000\n",
      "Epoch 972/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2637 - accuracy: 0.9333 - val_loss: 0.5760 - val_accuracy: 0.7000\n",
      "Epoch 973/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.2654 - accuracy: 0.9333 - val_loss: 0.5700 - val_accuracy: 0.7000\n",
      "Epoch 974/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2344 - accuracy: 0.9333 - val_loss: 0.5642 - val_accuracy: 0.7000\n",
      "Epoch 975/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2886 - accuracy: 0.9000 - val_loss: 0.5620 - val_accuracy: 0.7000\n",
      "Epoch 976/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.2361 - accuracy: 0.9667 - val_loss: 0.5629 - val_accuracy: 0.7000\n",
      "Epoch 977/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.2450 - accuracy: 0.9667 - val_loss: 0.5665 - val_accuracy: 0.7000\n",
      "Epoch 978/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2618 - accuracy: 0.9000 - val_loss: 0.5690 - val_accuracy: 0.7000\n",
      "Epoch 979/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2793 - accuracy: 0.8667 - val_loss: 0.5747 - val_accuracy: 0.7000\n",
      "Epoch 980/3000\n",
      "30/30 [==============================] - 0s 142us/step - loss: 0.2530 - accuracy: 0.9333 - val_loss: 0.5758 - val_accuracy: 0.7000\n",
      "Epoch 981/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.2143 - accuracy: 0.9667 - val_loss: 0.5785 - val_accuracy: 0.7000\n",
      "Epoch 982/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.2703 - accuracy: 0.9000 - val_loss: 0.5772 - val_accuracy: 0.7000\n",
      "Epoch 983/3000\n",
      "30/30 [==============================] - 0s 142us/step - loss: 0.1689 - accuracy: 0.9667 - val_loss: 0.5762 - val_accuracy: 0.7000\n",
      "Epoch 984/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.3318 - accuracy: 0.8667 - val_loss: 0.5776 - val_accuracy: 0.7000\n",
      "Epoch 985/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.2778 - accuracy: 0.9000 - val_loss: 0.5787 - val_accuracy: 0.7000\n",
      "Epoch 986/3000\n",
      "30/30 [==============================] - 0s 197us/step - loss: 0.2287 - accuracy: 0.9000 - val_loss: 0.5836 - val_accuracy: 0.7000\n",
      "Epoch 987/3000\n",
      "30/30 [==============================] - 0s 167us/step - loss: 0.2845 - accuracy: 0.8667 - val_loss: 0.5918 - val_accuracy: 0.7000\n",
      "Epoch 988/3000\n",
      "30/30 [==============================] - 0s 155us/step - loss: 0.3066 - accuracy: 0.8667 - val_loss: 0.6019 - val_accuracy: 0.7000\n",
      "Epoch 989/3000\n",
      "30/30 [==============================] - 0s 155us/step - loss: 0.2168 - accuracy: 0.9333 - val_loss: 0.6082 - val_accuracy: 0.7000\n",
      "Epoch 990/3000\n",
      "30/30 [==============================] - 0s 146us/step - loss: 0.2610 - accuracy: 0.9000 - val_loss: 0.6162 - val_accuracy: 0.7000\n",
      "Epoch 991/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.2789 - accuracy: 0.8667 - val_loss: 0.6199 - val_accuracy: 0.7000\n",
      "Epoch 992/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.2463 - accuracy: 0.9000 - val_loss: 0.6181 - val_accuracy: 0.7000\n",
      "Epoch 993/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2916 - accuracy: 0.9333 - val_loss: 0.6085 - val_accuracy: 0.7000\n",
      "Epoch 994/3000\n",
      "30/30 [==============================] - 0s 144us/step - loss: 0.3076 - accuracy: 0.9000 - val_loss: 0.5954 - val_accuracy: 0.7000\n",
      "Epoch 995/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2692 - accuracy: 0.9333 - val_loss: 0.5788 - val_accuracy: 0.7000\n",
      "Epoch 996/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2720 - accuracy: 0.8667 - val_loss: 0.5669 - val_accuracy: 0.7000\n",
      "Epoch 997/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2181 - accuracy: 0.9333 - val_loss: 0.5603 - val_accuracy: 0.7000\n",
      "Epoch 998/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2811 - accuracy: 0.9000 - val_loss: 0.5557 - val_accuracy: 0.7000\n",
      "Epoch 999/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.3533 - accuracy: 0.8333 - val_loss: 0.5557 - val_accuracy: 0.7000\n",
      "Epoch 1000/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2716 - accuracy: 0.9333 - val_loss: 0.5556 - val_accuracy: 0.7000\n",
      "Epoch 1001/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2366 - accuracy: 0.9333 - val_loss: 0.5549 - val_accuracy: 0.7000\n",
      "Epoch 1002/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2048 - accuracy: 0.9000 - val_loss: 0.5539 - val_accuracy: 0.7000\n",
      "Epoch 1003/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2696 - accuracy: 0.8667 - val_loss: 0.5563 - val_accuracy: 0.7000\n",
      "Epoch 1004/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2673 - accuracy: 0.9333 - val_loss: 0.5610 - val_accuracy: 0.7000\n",
      "Epoch 1005/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2514 - accuracy: 0.9000 - val_loss: 0.5716 - val_accuracy: 0.7000\n",
      "Epoch 1006/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2044 - accuracy: 0.9667 - val_loss: 0.5841 - val_accuracy: 0.7000\n",
      "Epoch 1007/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.3176 - accuracy: 0.9333 - val_loss: 0.5954 - val_accuracy: 0.7000\n",
      "Epoch 1008/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2901 - accuracy: 0.9333 - val_loss: 0.6054 - val_accuracy: 0.7000\n",
      "Epoch 1009/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.2566 - accuracy: 0.9000 - val_loss: 0.6155 - val_accuracy: 0.7000\n",
      "Epoch 1010/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2716 - accuracy: 0.9667 - val_loss: 0.6240 - val_accuracy: 0.7000\n",
      "Epoch 1011/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2752 - accuracy: 0.8000 - val_loss: 0.6294 - val_accuracy: 0.7000\n",
      "Epoch 1012/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2392 - accuracy: 0.9000 - val_loss: 0.6314 - val_accuracy: 0.7000\n",
      "Epoch 1013/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2890 - accuracy: 0.9000 - val_loss: 0.6322 - val_accuracy: 0.7000\n",
      "Epoch 1014/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2874 - accuracy: 0.9333 - val_loss: 0.6282 - val_accuracy: 0.7000\n",
      "Epoch 1015/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2295 - accuracy: 0.9000 - val_loss: 0.6207 - val_accuracy: 0.7000\n",
      "Epoch 1016/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2721 - accuracy: 0.9000 - val_loss: 0.6126 - val_accuracy: 0.7000\n",
      "Epoch 1017/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2480 - accuracy: 0.9000 - val_loss: 0.6022 - val_accuracy: 0.7000\n",
      "Epoch 1018/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2161 - accuracy: 0.9333 - val_loss: 0.5958 - val_accuracy: 0.7000\n",
      "Epoch 1019/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.2904 - accuracy: 0.8667 - val_loss: 0.5872 - val_accuracy: 0.7000\n",
      "Epoch 1020/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.2250 - accuracy: 0.9333 - val_loss: 0.5819 - val_accuracy: 0.7000\n",
      "Epoch 1021/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2692 - accuracy: 0.9333 - val_loss: 0.5778 - val_accuracy: 0.7000\n",
      "Epoch 1022/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2168 - accuracy: 0.9000 - val_loss: 0.5744 - val_accuracy: 0.7000\n",
      "Epoch 1023/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3082 - accuracy: 0.8667 - val_loss: 0.5726 - val_accuracy: 0.7000\n",
      "Epoch 1024/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.3311 - accuracy: 0.9000 - val_loss: 0.5710 - val_accuracy: 0.7000\n",
      "Epoch 1025/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.3116 - accuracy: 0.9000 - val_loss: 0.5697 - val_accuracy: 0.7000\n",
      "Epoch 1026/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2666 - accuracy: 0.8667 - val_loss: 0.5680 - val_accuracy: 0.7000\n",
      "Epoch 1027/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2301 - accuracy: 0.9333 - val_loss: 0.5666 - val_accuracy: 0.7000\n",
      "Epoch 1028/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2831 - accuracy: 0.9000 - val_loss: 0.5630 - val_accuracy: 0.7000\n",
      "Epoch 1029/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3811 - accuracy: 0.8667 - val_loss: 0.5613 - val_accuracy: 0.7000\n",
      "Epoch 1030/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2058 - accuracy: 0.9667 - val_loss: 0.5619 - val_accuracy: 0.7000\n",
      "Epoch 1031/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2152 - accuracy: 0.9667 - val_loss: 0.5640 - val_accuracy: 0.7000\n",
      "Epoch 1032/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2421 - accuracy: 0.9667 - val_loss: 0.5682 - val_accuracy: 0.7000\n",
      "Epoch 1033/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2742 - accuracy: 0.9333 - val_loss: 0.5774 - val_accuracy: 0.7000\n",
      "Epoch 1034/3000\n",
      "30/30 [==============================] - 0s 144us/step - loss: 0.2346 - accuracy: 0.9000 - val_loss: 0.5887 - val_accuracy: 0.7000\n",
      "Epoch 1035/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.2070 - accuracy: 0.9667 - val_loss: 0.6007 - val_accuracy: 0.7000\n",
      "Epoch 1036/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.2605 - accuracy: 0.9000 - val_loss: 0.6164 - val_accuracy: 0.7000\n",
      "Epoch 1037/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2540 - accuracy: 0.9333 - val_loss: 0.6272 - val_accuracy: 0.7000\n",
      "Epoch 1038/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2738 - accuracy: 0.9000 - val_loss: 0.6350 - val_accuracy: 0.7000\n",
      "Epoch 1039/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2226 - accuracy: 0.9333 - val_loss: 0.6391 - val_accuracy: 0.7000\n",
      "Epoch 1040/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.2443 - accuracy: 0.9000 - val_loss: 0.6405 - val_accuracy: 0.7000\n",
      "Epoch 1041/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2796 - accuracy: 0.8667 - val_loss: 0.6377 - val_accuracy: 0.7000\n",
      "Epoch 1042/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2381 - accuracy: 0.9333 - val_loss: 0.6298 - val_accuracy: 0.7000\n",
      "Epoch 1043/3000\n",
      "30/30 [==============================] - 0s 147us/step - loss: 0.2340 - accuracy: 0.9000 - val_loss: 0.6254 - val_accuracy: 0.7000\n",
      "Epoch 1044/3000\n",
      "30/30 [==============================] - 0s 146us/step - loss: 0.2070 - accuracy: 0.9333 - val_loss: 0.6199 - val_accuracy: 0.7000\n",
      "Epoch 1045/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2089 - accuracy: 0.9333 - val_loss: 0.6161 - val_accuracy: 0.7000\n",
      "Epoch 1046/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2821 - accuracy: 0.8667 - val_loss: 0.6125 - val_accuracy: 0.7000\n",
      "Epoch 1047/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2102 - accuracy: 0.9000 - val_loss: 0.6104 - val_accuracy: 0.7000\n",
      "Epoch 1048/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2628 - accuracy: 0.9333 - val_loss: 0.6069 - val_accuracy: 0.7000\n",
      "Epoch 1049/3000\n",
      "30/30 [==============================] - 0s 146us/step - loss: 0.2775 - accuracy: 0.8667 - val_loss: 0.6030 - val_accuracy: 0.7000\n",
      "Epoch 1050/3000\n",
      "30/30 [==============================] - 0s 151us/step - loss: 0.2572 - accuracy: 0.9333 - val_loss: 0.5992 - val_accuracy: 0.7000\n",
      "Epoch 1051/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.3213 - accuracy: 0.8667 - val_loss: 0.5979 - val_accuracy: 0.7000\n",
      "Epoch 1052/3000\n",
      "30/30 [==============================] - 0s 165us/step - loss: 0.2515 - accuracy: 0.8667 - val_loss: 0.5941 - val_accuracy: 0.7000\n",
      "Epoch 1053/3000\n",
      "30/30 [==============================] - 0s 155us/step - loss: 0.2560 - accuracy: 0.9000 - val_loss: 0.5935 - val_accuracy: 0.7000\n",
      "Epoch 1054/3000\n",
      "30/30 [==============================] - 0s 141us/step - loss: 0.2056 - accuracy: 0.9333 - val_loss: 0.5945 - val_accuracy: 0.7000\n",
      "Epoch 1055/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.3381 - accuracy: 0.9000 - val_loss: 0.5934 - val_accuracy: 0.7000\n",
      "Epoch 1056/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.2351 - accuracy: 0.9000 - val_loss: 0.5932 - val_accuracy: 0.7000\n",
      "Epoch 1057/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.3031 - accuracy: 0.9333 - val_loss: 0.5889 - val_accuracy: 0.7000\n",
      "Epoch 1058/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2630 - accuracy: 0.8667 - val_loss: 0.5855 - val_accuracy: 0.7000\n",
      "Epoch 1059/3000\n",
      "30/30 [==============================] - 0s 148us/step - loss: 0.2452 - accuracy: 0.8333 - val_loss: 0.5823 - val_accuracy: 0.7000\n",
      "Epoch 1060/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1883 - accuracy: 1.0000 - val_loss: 0.5794 - val_accuracy: 0.7000\n",
      "Epoch 1061/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2112 - accuracy: 0.9333 - val_loss: 0.5787 - val_accuracy: 0.7000\n",
      "Epoch 1062/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2479 - accuracy: 0.9333 - val_loss: 0.5765 - val_accuracy: 0.7000\n",
      "Epoch 1063/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.2792 - accuracy: 0.8333 - val_loss: 0.5722 - val_accuracy: 0.7000\n",
      "Epoch 1064/3000\n",
      "30/30 [==============================] - 0s 139us/step - loss: 0.2128 - accuracy: 0.9333 - val_loss: 0.5696 - val_accuracy: 0.7000\n",
      "Epoch 1065/3000\n",
      "30/30 [==============================] - 0s 144us/step - loss: 0.3272 - accuracy: 0.8667 - val_loss: 0.5639 - val_accuracy: 0.7000\n",
      "Epoch 1066/3000\n",
      "30/30 [==============================] - 0s 154us/step - loss: 0.2530 - accuracy: 0.9333 - val_loss: 0.5611 - val_accuracy: 0.7000\n",
      "Epoch 1067/3000\n",
      "30/30 [==============================] - 0s 145us/step - loss: 0.3228 - accuracy: 0.8000 - val_loss: 0.5637 - val_accuracy: 0.7000\n",
      "Epoch 1068/3000\n",
      "30/30 [==============================] - 0s 146us/step - loss: 0.2242 - accuracy: 0.9000 - val_loss: 0.5661 - val_accuracy: 0.7000\n",
      "Epoch 1069/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.2714 - accuracy: 0.9333 - val_loss: 0.5712 - val_accuracy: 0.7000\n",
      "Epoch 1070/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1990 - accuracy: 0.9667 - val_loss: 0.5766 - val_accuracy: 0.7000\n",
      "Epoch 1071/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2903 - accuracy: 0.8667 - val_loss: 0.5816 - val_accuracy: 0.7000\n",
      "Epoch 1072/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.3093 - accuracy: 0.8333 - val_loss: 0.5892 - val_accuracy: 0.7000\n",
      "Epoch 1073/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2713 - accuracy: 0.9000 - val_loss: 0.5980 - val_accuracy: 0.7000\n",
      "Epoch 1074/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.3025 - accuracy: 0.8667 - val_loss: 0.6092 - val_accuracy: 0.7000\n",
      "Epoch 1075/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.3024 - accuracy: 0.8667 - val_loss: 0.6215 - val_accuracy: 0.7000\n",
      "Epoch 1076/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2515 - accuracy: 0.9333 - val_loss: 0.6284 - val_accuracy: 0.7000\n",
      "Epoch 1077/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2150 - accuracy: 0.9667 - val_loss: 0.6315 - val_accuracy: 0.7000\n",
      "Epoch 1078/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.2672 - accuracy: 0.9000 - val_loss: 0.6316 - val_accuracy: 0.7000\n",
      "Epoch 1079/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.2451 - accuracy: 0.9000 - val_loss: 0.6313 - val_accuracy: 0.7000\n",
      "Epoch 1080/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2275 - accuracy: 0.9000 - val_loss: 0.6318 - val_accuracy: 0.7000\n",
      "Epoch 1081/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2435 - accuracy: 0.9333 - val_loss: 0.6354 - val_accuracy: 0.7000\n",
      "Epoch 1082/3000\n",
      "30/30 [==============================] - 0s 142us/step - loss: 0.2568 - accuracy: 0.9333 - val_loss: 0.6308 - val_accuracy: 0.7000\n",
      "Epoch 1083/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2684 - accuracy: 0.9000 - val_loss: 0.6270 - val_accuracy: 0.7000\n",
      "Epoch 1084/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1954 - accuracy: 0.9667 - val_loss: 0.6181 - val_accuracy: 0.7000\n",
      "Epoch 1085/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2588 - accuracy: 0.9333 - val_loss: 0.6048 - val_accuracy: 0.7000\n",
      "Epoch 1086/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.2323 - accuracy: 0.9667 - val_loss: 0.5897 - val_accuracy: 0.7000\n",
      "Epoch 1087/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.3019 - accuracy: 0.9000 - val_loss: 0.5714 - val_accuracy: 0.7000\n",
      "Epoch 1088/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.2547 - accuracy: 0.9333 - val_loss: 0.5557 - val_accuracy: 0.7000\n",
      "Epoch 1089/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2174 - accuracy: 0.9333 - val_loss: 0.5416 - val_accuracy: 0.7000\n",
      "Epoch 1090/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2782 - accuracy: 0.9000 - val_loss: 0.5323 - val_accuracy: 0.7000\n",
      "Epoch 1091/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1937 - accuracy: 0.9667 - val_loss: 0.5233 - val_accuracy: 0.7000\n",
      "Epoch 1092/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2361 - accuracy: 0.9000 - val_loss: 0.5154 - val_accuracy: 0.7000\n",
      "Epoch 1093/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2492 - accuracy: 0.9333 - val_loss: 0.5113 - val_accuracy: 0.7000\n",
      "Epoch 1094/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2537 - accuracy: 0.8667 - val_loss: 0.5102 - val_accuracy: 0.7000\n",
      "Epoch 1095/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3112 - accuracy: 0.8667 - val_loss: 0.5158 - val_accuracy: 0.7000\n",
      "Epoch 1096/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.2757 - accuracy: 0.9000 - val_loss: 0.5194 - val_accuracy: 0.7000\n",
      "Epoch 1097/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2374 - accuracy: 0.9333 - val_loss: 0.5252 - val_accuracy: 0.7000\n",
      "Epoch 1098/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2446 - accuracy: 0.9000 - val_loss: 0.5378 - val_accuracy: 0.7000\n",
      "Epoch 1099/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2328 - accuracy: 0.9000 - val_loss: 0.5527 - val_accuracy: 0.7000\n",
      "Epoch 1100/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2689 - accuracy: 0.9000 - val_loss: 0.5691 - val_accuracy: 0.7000\n",
      "Epoch 1101/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.3192 - accuracy: 0.9000 - val_loss: 0.5878 - val_accuracy: 0.7000\n",
      "Epoch 1102/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.3507 - accuracy: 0.8667 - val_loss: 0.6015 - val_accuracy: 0.7000\n",
      "Epoch 1103/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.3140 - accuracy: 0.8667 - val_loss: 0.6054 - val_accuracy: 0.7000\n",
      "Epoch 1104/3000\n",
      "30/30 [==============================] - 0s 141us/step - loss: 0.2783 - accuracy: 0.9000 - val_loss: 0.6087 - val_accuracy: 0.7000\n",
      "Epoch 1105/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.2657 - accuracy: 0.9000 - val_loss: 0.6096 - val_accuracy: 0.7000\n",
      "Epoch 1106/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2842 - accuracy: 0.8667 - val_loss: 0.6096 - val_accuracy: 0.7000\n",
      "Epoch 1107/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2277 - accuracy: 0.9000 - val_loss: 0.6067 - val_accuracy: 0.7000\n",
      "Epoch 1108/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2466 - accuracy: 0.9000 - val_loss: 0.6057 - val_accuracy: 0.7000\n",
      "Epoch 1109/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2168 - accuracy: 0.9667 - val_loss: 0.6034 - val_accuracy: 0.7000\n",
      "Epoch 1110/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2909 - accuracy: 0.9333 - val_loss: 0.5963 - val_accuracy: 0.7000\n",
      "Epoch 1111/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.2853 - accuracy: 0.9333 - val_loss: 0.5901 - val_accuracy: 0.7000\n",
      "Epoch 1112/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.1935 - accuracy: 0.9667 - val_loss: 0.5829 - val_accuracy: 0.7000\n",
      "Epoch 1113/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2293 - accuracy: 0.9333 - val_loss: 0.5737 - val_accuracy: 0.7000\n",
      "Epoch 1114/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2520 - accuracy: 0.9000 - val_loss: 0.5677 - val_accuracy: 0.7000\n",
      "Epoch 1115/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.2524 - accuracy: 0.9333 - val_loss: 0.5621 - val_accuracy: 0.7000\n",
      "Epoch 1116/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2524 - accuracy: 0.9000 - val_loss: 0.5549 - val_accuracy: 0.7000\n",
      "Epoch 1117/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2141 - accuracy: 0.9333 - val_loss: 0.5524 - val_accuracy: 0.7000\n",
      "Epoch 1118/3000\n",
      "30/30 [==============================] - 0s 158us/step - loss: 0.2724 - accuracy: 0.9000 - val_loss: 0.5503 - val_accuracy: 0.7000\n",
      "Epoch 1119/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.2132 - accuracy: 0.9667 - val_loss: 0.5497 - val_accuracy: 0.7000\n",
      "Epoch 1120/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2298 - accuracy: 0.9667 - val_loss: 0.5510 - val_accuracy: 0.7000\n",
      "Epoch 1121/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.2271 - accuracy: 0.9000 - val_loss: 0.5539 - val_accuracy: 0.7000\n",
      "Epoch 1122/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.3020 - accuracy: 0.9000 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1123/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2920 - accuracy: 0.8667 - val_loss: 0.5593 - val_accuracy: 0.7000\n",
      "Epoch 1124/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.2450 - accuracy: 0.9000 - val_loss: 0.5628 - val_accuracy: 0.7000\n",
      "Epoch 1125/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2726 - accuracy: 0.9000 - val_loss: 0.5711 - val_accuracy: 0.7000\n",
      "Epoch 1126/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2181 - accuracy: 0.9333 - val_loss: 0.5810 - val_accuracy: 0.7000\n",
      "Epoch 1127/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2292 - accuracy: 0.9000 - val_loss: 0.5917 - val_accuracy: 0.7000\n",
      "Epoch 1128/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.3194 - accuracy: 0.9000 - val_loss: 0.6008 - val_accuracy: 0.7000\n",
      "Epoch 1129/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2361 - accuracy: 0.9333 - val_loss: 0.6062 - val_accuracy: 0.7000\n",
      "Epoch 1130/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2453 - accuracy: 0.9333 - val_loss: 0.6130 - val_accuracy: 0.7000\n",
      "Epoch 1131/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1923 - accuracy: 0.9667 - val_loss: 0.6188 - val_accuracy: 0.7000\n",
      "Epoch 1132/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.2303 - accuracy: 0.9000 - val_loss: 0.6202 - val_accuracy: 0.7000\n",
      "Epoch 1133/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2796 - accuracy: 0.9000 - val_loss: 0.6198 - val_accuracy: 0.7000\n",
      "Epoch 1134/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.2827 - accuracy: 0.9000 - val_loss: 0.6201 - val_accuracy: 0.7000\n",
      "Epoch 1135/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2906 - accuracy: 0.8333 - val_loss: 0.6203 - val_accuracy: 0.7000\n",
      "Epoch 1136/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2806 - accuracy: 0.9667 - val_loss: 0.6216 - val_accuracy: 0.7000\n",
      "Epoch 1137/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2053 - accuracy: 0.9333 - val_loss: 0.6261 - val_accuracy: 0.7000\n",
      "Epoch 1138/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2571 - accuracy: 0.9000 - val_loss: 0.6286 - val_accuracy: 0.7000\n",
      "Epoch 1139/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2384 - accuracy: 0.9000 - val_loss: 0.6278 - val_accuracy: 0.7000\n",
      "Epoch 1140/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2200 - accuracy: 0.9333 - val_loss: 0.6279 - val_accuracy: 0.7000\n",
      "Epoch 1141/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.2652 - accuracy: 0.9000 - val_loss: 0.6327 - val_accuracy: 0.7000\n",
      "Epoch 1142/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1775 - accuracy: 0.9333 - val_loss: 0.6396 - val_accuracy: 0.7000\n",
      "Epoch 1143/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2301 - accuracy: 0.9333 - val_loss: 0.6491 - val_accuracy: 0.7000\n",
      "Epoch 1144/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2503 - accuracy: 0.9000 - val_loss: 0.6618 - val_accuracy: 0.7000\n",
      "Epoch 1145/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2121 - accuracy: 0.9333 - val_loss: 0.6739 - val_accuracy: 0.7000\n",
      "Epoch 1146/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2901 - accuracy: 0.8333 - val_loss: 0.6790 - val_accuracy: 0.7000\n",
      "Epoch 1147/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2689 - accuracy: 0.9000 - val_loss: 0.6746 - val_accuracy: 0.7000\n",
      "Epoch 1148/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.3503 - accuracy: 0.8333 - val_loss: 0.6617 - val_accuracy: 0.7000\n",
      "Epoch 1149/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2153 - accuracy: 0.9667 - val_loss: 0.6503 - val_accuracy: 0.7000\n",
      "Epoch 1150/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2274 - accuracy: 0.9000 - val_loss: 0.6405 - val_accuracy: 0.7000\n",
      "Epoch 1151/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2391 - accuracy: 0.9333 - val_loss: 0.6365 - val_accuracy: 0.7000\n",
      "Epoch 1152/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2329 - accuracy: 0.9000 - val_loss: 0.6354 - val_accuracy: 0.7000\n",
      "Epoch 1153/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2304 - accuracy: 0.8667 - val_loss: 0.6366 - val_accuracy: 0.7000\n",
      "Epoch 1154/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2662 - accuracy: 0.9000 - val_loss: 0.6371 - val_accuracy: 0.7000\n",
      "Epoch 1155/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.1582 - accuracy: 1.0000 - val_loss: 0.6395 - val_accuracy: 0.7000\n",
      "Epoch 1156/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1963 - accuracy: 0.9333 - val_loss: 0.6383 - val_accuracy: 0.7000\n",
      "Epoch 1157/3000\n",
      "30/30 [==============================] - 0s 141us/step - loss: 0.1879 - accuracy: 0.9333 - val_loss: 0.6391 - val_accuracy: 0.7000\n",
      "Epoch 1158/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2483 - accuracy: 0.9000 - val_loss: 0.6450 - val_accuracy: 0.7000\n",
      "Epoch 1159/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.2544 - accuracy: 0.9000 - val_loss: 0.6463 - val_accuracy: 0.7000\n",
      "Epoch 1160/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2227 - accuracy: 0.8667 - val_loss: 0.6436 - val_accuracy: 0.7000\n",
      "Epoch 1161/3000\n",
      "30/30 [==============================] - 0s 139us/step - loss: 0.1973 - accuracy: 0.9000 - val_loss: 0.6377 - val_accuracy: 0.7000\n",
      "Epoch 1162/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2083 - accuracy: 0.9333 - val_loss: 0.6354 - val_accuracy: 0.7000\n",
      "Epoch 1163/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2926 - accuracy: 0.8667 - val_loss: 0.6300 - val_accuracy: 0.7000\n",
      "Epoch 1164/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2108 - accuracy: 0.9333 - val_loss: 0.6251 - val_accuracy: 0.7000\n",
      "Epoch 1165/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2022 - accuracy: 0.9667 - val_loss: 0.6189 - val_accuracy: 0.7000\n",
      "Epoch 1166/3000\n",
      "30/30 [==============================] - 0s 143us/step - loss: 0.2449 - accuracy: 0.9000 - val_loss: 0.6179 - val_accuracy: 0.7000\n",
      "Epoch 1167/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.2347 - accuracy: 0.9000 - val_loss: 0.6188 - val_accuracy: 0.7000\n",
      "Epoch 1168/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2371 - accuracy: 0.9333 - val_loss: 0.6117 - val_accuracy: 0.7000\n",
      "Epoch 1169/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2897 - accuracy: 0.8667 - val_loss: 0.6030 - val_accuracy: 0.7000\n",
      "Epoch 1170/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2799 - accuracy: 0.8667 - val_loss: 0.5928 - val_accuracy: 0.7000\n",
      "Epoch 1171/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.2366 - accuracy: 0.8667 - val_loss: 0.5859 - val_accuracy: 0.7000\n",
      "Epoch 1172/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.2471 - accuracy: 0.9333 - val_loss: 0.5827 - val_accuracy: 0.7000\n",
      "Epoch 1173/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1848 - accuracy: 0.9667 - val_loss: 0.5850 - val_accuracy: 0.7000\n",
      "Epoch 1174/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2214 - accuracy: 0.9000 - val_loss: 0.5852 - val_accuracy: 0.7000\n",
      "Epoch 1175/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2407 - accuracy: 0.9333 - val_loss: 0.5826 - val_accuracy: 0.7000\n",
      "Epoch 1176/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2796 - accuracy: 0.8667 - val_loss: 0.5796 - val_accuracy: 0.7000\n",
      "Epoch 1177/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1929 - accuracy: 0.9333 - val_loss: 0.5793 - val_accuracy: 0.7000\n",
      "Epoch 1178/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2272 - accuracy: 0.9000 - val_loss: 0.5799 - val_accuracy: 0.7000\n",
      "Epoch 1179/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2989 - accuracy: 0.9333 - val_loss: 0.5792 - val_accuracy: 0.7000\n",
      "Epoch 1180/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1894 - accuracy: 0.9333 - val_loss: 0.5763 - val_accuracy: 0.7000\n",
      "Epoch 1181/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2996 - accuracy: 0.8667 - val_loss: 0.5733 - val_accuracy: 0.7000\n",
      "Epoch 1182/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2272 - accuracy: 0.9000 - val_loss: 0.5700 - val_accuracy: 0.7000\n",
      "Epoch 1183/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2866 - accuracy: 0.8667 - val_loss: 0.5686 - val_accuracy: 0.7000\n",
      "Epoch 1184/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2064 - accuracy: 0.9333 - val_loss: 0.5705 - val_accuracy: 0.7000\n",
      "Epoch 1185/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2022 - accuracy: 0.9000 - val_loss: 0.5721 - val_accuracy: 0.7000\n",
      "Epoch 1186/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2124 - accuracy: 0.9000 - val_loss: 0.5749 - val_accuracy: 0.7000\n",
      "Epoch 1187/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.1665 - accuracy: 0.9667 - val_loss: 0.5803 - val_accuracy: 0.7000\n",
      "Epoch 1188/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2448 - accuracy: 0.9000 - val_loss: 0.5889 - val_accuracy: 0.7000\n",
      "Epoch 1189/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2145 - accuracy: 0.8667 - val_loss: 0.6012 - val_accuracy: 0.7000\n",
      "Epoch 1190/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2173 - accuracy: 0.9333 - val_loss: 0.6154 - val_accuracy: 0.7000\n",
      "Epoch 1191/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.2404 - accuracy: 0.9333 - val_loss: 0.6298 - val_accuracy: 0.7000\n",
      "Epoch 1192/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1965 - accuracy: 0.9667 - val_loss: 0.6430 - val_accuracy: 0.7000\n",
      "Epoch 1193/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2734 - accuracy: 0.9000 - val_loss: 0.6536 - val_accuracy: 0.7000\n",
      "Epoch 1194/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2448 - accuracy: 0.9333 - val_loss: 0.6599 - val_accuracy: 0.7000\n",
      "Epoch 1195/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2190 - accuracy: 0.9333 - val_loss: 0.6647 - val_accuracy: 0.7000\n",
      "Epoch 1196/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2237 - accuracy: 0.9000 - val_loss: 0.6701 - val_accuracy: 0.7000\n",
      "Epoch 1197/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2941 - accuracy: 0.8333 - val_loss: 0.6780 - val_accuracy: 0.7000\n",
      "Epoch 1198/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.2320 - accuracy: 0.9000 - val_loss: 0.6834 - val_accuracy: 0.7000\n",
      "Epoch 1199/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1927 - accuracy: 0.9000 - val_loss: 0.6861 - val_accuracy: 0.7000\n",
      "Epoch 1200/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2443 - accuracy: 0.9000 - val_loss: 0.6898 - val_accuracy: 0.7000\n",
      "Epoch 1201/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2362 - accuracy: 0.9000 - val_loss: 0.6918 - val_accuracy: 0.7000\n",
      "Epoch 1202/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1621 - accuracy: 0.9667 - val_loss: 0.6917 - val_accuracy: 0.7000\n",
      "Epoch 1203/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1957 - accuracy: 0.9333 - val_loss: 0.6893 - val_accuracy: 0.7000\n",
      "Epoch 1204/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2822 - accuracy: 0.8333 - val_loss: 0.6818 - val_accuracy: 0.7000\n",
      "Epoch 1205/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2560 - accuracy: 0.9000 - val_loss: 0.6791 - val_accuracy: 0.7000\n",
      "Epoch 1206/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2132 - accuracy: 0.9333 - val_loss: 0.6733 - val_accuracy: 0.7000\n",
      "Epoch 1207/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.3114 - accuracy: 0.9000 - val_loss: 0.6667 - val_accuracy: 0.7000\n",
      "Epoch 1208/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2626 - accuracy: 0.9000 - val_loss: 0.6596 - val_accuracy: 0.7000\n",
      "Epoch 1209/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1945 - accuracy: 0.9333 - val_loss: 0.6535 - val_accuracy: 0.7000\n",
      "Epoch 1210/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2084 - accuracy: 0.9333 - val_loss: 0.6468 - val_accuracy: 0.7000\n",
      "Epoch 1211/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2418 - accuracy: 0.9333 - val_loss: 0.6323 - val_accuracy: 0.7000\n",
      "Epoch 1212/3000\n",
      "30/30 [==============================] - 0s 139us/step - loss: 0.3096 - accuracy: 0.8667 - val_loss: 0.6139 - val_accuracy: 0.7000\n",
      "Epoch 1213/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2685 - accuracy: 0.9000 - val_loss: 0.5937 - val_accuracy: 0.7000\n",
      "Epoch 1214/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.2523 - accuracy: 0.8667 - val_loss: 0.5787 - val_accuracy: 0.7000\n",
      "Epoch 1215/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2342 - accuracy: 0.9000 - val_loss: 0.5663 - val_accuracy: 0.7000\n",
      "Epoch 1216/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2862 - accuracy: 0.8667 - val_loss: 0.5640 - val_accuracy: 0.7000\n",
      "Epoch 1217/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.2021 - accuracy: 0.9000 - val_loss: 0.5628 - val_accuracy: 0.7000\n",
      "Epoch 1218/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.1992 - accuracy: 0.9667 - val_loss: 0.5689 - val_accuracy: 0.7000\n",
      "Epoch 1219/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1821 - accuracy: 0.9333 - val_loss: 0.5778 - val_accuracy: 0.7000\n",
      "Epoch 1220/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1582 - accuracy: 1.0000 - val_loss: 0.5901 - val_accuracy: 0.7000\n",
      "Epoch 1221/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2558 - accuracy: 0.9000 - val_loss: 0.6014 - val_accuracy: 0.7000\n",
      "Epoch 1222/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.2540 - accuracy: 0.8667 - val_loss: 0.6148 - val_accuracy: 0.7000\n",
      "Epoch 1223/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.2492 - accuracy: 0.9333 - val_loss: 0.6276 - val_accuracy: 0.7000\n",
      "Epoch 1224/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2291 - accuracy: 0.9000 - val_loss: 0.6410 - val_accuracy: 0.7000\n",
      "Epoch 1225/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2024 - accuracy: 0.9333 - val_loss: 0.6491 - val_accuracy: 0.7000\n",
      "Epoch 1226/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1960 - accuracy: 0.9333 - val_loss: 0.6588 - val_accuracy: 0.7000\n",
      "Epoch 1227/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2049 - accuracy: 0.9333 - val_loss: 0.6664 - val_accuracy: 0.7000\n",
      "Epoch 1228/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2545 - accuracy: 0.9333 - val_loss: 0.6648 - val_accuracy: 0.7000\n",
      "Epoch 1229/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1650 - accuracy: 1.0000 - val_loss: 0.6609 - val_accuracy: 0.7000\n",
      "Epoch 1230/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2729 - accuracy: 0.9000 - val_loss: 0.6497 - val_accuracy: 0.7000\n",
      "Epoch 1231/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1857 - accuracy: 0.9333 - val_loss: 0.6383 - val_accuracy: 0.7000\n",
      "Epoch 1232/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.2930 - accuracy: 0.9000 - val_loss: 0.6288 - val_accuracy: 0.7000\n",
      "Epoch 1233/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2726 - accuracy: 0.8667 - val_loss: 0.6102 - val_accuracy: 0.7000\n",
      "Epoch 1234/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2359 - accuracy: 0.9333 - val_loss: 0.5883 - val_accuracy: 0.7000\n",
      "Epoch 1235/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2537 - accuracy: 0.8333 - val_loss: 0.5683 - val_accuracy: 0.7000\n",
      "Epoch 1236/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2926 - accuracy: 0.8667 - val_loss: 0.5546 - val_accuracy: 0.7000\n",
      "Epoch 1237/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2504 - accuracy: 0.8667 - val_loss: 0.5504 - val_accuracy: 0.7000\n",
      "Epoch 1238/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2627 - accuracy: 0.8667 - val_loss: 0.5508 - val_accuracy: 0.7000\n",
      "Epoch 1239/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2334 - accuracy: 0.8000 - val_loss: 0.5541 - val_accuracy: 0.7000\n",
      "Epoch 1240/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2578 - accuracy: 0.8667 - val_loss: 0.5599 - val_accuracy: 0.7000\n",
      "Epoch 1241/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2192 - accuracy: 0.9333 - val_loss: 0.5717 - val_accuracy: 0.7000\n",
      "Epoch 1242/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2236 - accuracy: 0.9000 - val_loss: 0.5831 - val_accuracy: 0.7000\n",
      "Epoch 1243/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2238 - accuracy: 0.9667 - val_loss: 0.5993 - val_accuracy: 0.7000\n",
      "Epoch 1244/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1980 - accuracy: 0.9667 - val_loss: 0.6127 - val_accuracy: 0.7000\n",
      "Epoch 1245/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2858 - accuracy: 0.8000 - val_loss: 0.6262 - val_accuracy: 0.7000\n",
      "Epoch 1246/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2849 - accuracy: 0.8667 - val_loss: 0.6351 - val_accuracy: 0.7000\n",
      "Epoch 1247/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1848 - accuracy: 0.9667 - val_loss: 0.6429 - val_accuracy: 0.7000\n",
      "Epoch 1248/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2455 - accuracy: 0.9667 - val_loss: 0.6540 - val_accuracy: 0.7000\n",
      "Epoch 1249/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1847 - accuracy: 0.9667 - val_loss: 0.6584 - val_accuracy: 0.7000\n",
      "Epoch 1250/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2930 - accuracy: 0.9333 - val_loss: 0.6598 - val_accuracy: 0.7000\n",
      "Epoch 1251/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2166 - accuracy: 0.9333 - val_loss: 0.6546 - val_accuracy: 0.7000\n",
      "Epoch 1252/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2493 - accuracy: 0.9333 - val_loss: 0.6530 - val_accuracy: 0.7000\n",
      "Epoch 1253/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1704 - accuracy: 0.9667 - val_loss: 0.6518 - val_accuracy: 0.7000\n",
      "Epoch 1254/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2969 - accuracy: 0.8667 - val_loss: 0.6506 - val_accuracy: 0.7000\n",
      "Epoch 1255/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2167 - accuracy: 0.9333 - val_loss: 0.6469 - val_accuracy: 0.7000\n",
      "Epoch 1256/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1873 - accuracy: 0.9667 - val_loss: 0.6365 - val_accuracy: 0.7000\n",
      "Epoch 1257/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2622 - accuracy: 0.9000 - val_loss: 0.6264 - val_accuracy: 0.7000\n",
      "Epoch 1258/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.2420 - accuracy: 0.9000 - val_loss: 0.6202 - val_accuracy: 0.7000\n",
      "Epoch 1259/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.2097 - accuracy: 0.9333 - val_loss: 0.6163 - val_accuracy: 0.7000\n",
      "Epoch 1260/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2220 - accuracy: 0.9000 - val_loss: 0.6072 - val_accuracy: 0.7000\n",
      "Epoch 1261/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.2863 - accuracy: 0.9000 - val_loss: 0.5965 - val_accuracy: 0.7000\n",
      "Epoch 1262/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1471 - accuracy: 0.9667 - val_loss: 0.5913 - val_accuracy: 0.7000\n",
      "Epoch 1263/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.3025 - accuracy: 0.8333 - val_loss: 0.5894 - val_accuracy: 0.7000\n",
      "Epoch 1264/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2302 - accuracy: 0.9000 - val_loss: 0.5831 - val_accuracy: 0.7000\n",
      "Epoch 1265/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2624 - accuracy: 0.9000 - val_loss: 0.5774 - val_accuracy: 0.7000\n",
      "Epoch 1266/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2258 - accuracy: 0.9000 - val_loss: 0.5763 - val_accuracy: 0.7000\n",
      "Epoch 1267/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.3501 - accuracy: 0.8667 - val_loss: 0.5734 - val_accuracy: 0.7000\n",
      "Epoch 1268/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2115 - accuracy: 0.9333 - val_loss: 0.5777 - val_accuracy: 0.7000\n",
      "Epoch 1269/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2086 - accuracy: 0.9000 - val_loss: 0.5884 - val_accuracy: 0.7000\n",
      "Epoch 1270/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2060 - accuracy: 0.9333 - val_loss: 0.6055 - val_accuracy: 0.7000\n",
      "Epoch 1271/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.2753 - accuracy: 0.8333 - val_loss: 0.6227 - val_accuracy: 0.7000\n",
      "Epoch 1272/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2371 - accuracy: 0.9000 - val_loss: 0.6394 - val_accuracy: 0.7000\n",
      "Epoch 1273/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.2094 - accuracy: 0.9000 - val_loss: 0.6505 - val_accuracy: 0.7000\n",
      "Epoch 1274/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2535 - accuracy: 0.9000 - val_loss: 0.6577 - val_accuracy: 0.7000\n",
      "Epoch 1275/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.2313 - accuracy: 0.9000 - val_loss: 0.6647 - val_accuracy: 0.7000\n",
      "Epoch 1276/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.2086 - accuracy: 0.9667 - val_loss: 0.6696 - val_accuracy: 0.7000\n",
      "Epoch 1277/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2081 - accuracy: 0.9333 - val_loss: 0.6754 - val_accuracy: 0.7000\n",
      "Epoch 1278/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2222 - accuracy: 0.9333 - val_loss: 0.6750 - val_accuracy: 0.7000\n",
      "Epoch 1279/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2123 - accuracy: 0.9333 - val_loss: 0.6695 - val_accuracy: 0.7000\n",
      "Epoch 1280/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.2034 - accuracy: 0.9667 - val_loss: 0.6555 - val_accuracy: 0.7000\n",
      "Epoch 1281/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.1964 - accuracy: 0.9333 - val_loss: 0.6401 - val_accuracy: 0.7000\n",
      "Epoch 1282/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2034 - accuracy: 0.9333 - val_loss: 0.6209 - val_accuracy: 0.7000\n",
      "Epoch 1283/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.2437 - accuracy: 0.8333 - val_loss: 0.6009 - val_accuracy: 0.7000\n",
      "Epoch 1284/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2802 - accuracy: 0.9000 - val_loss: 0.5787 - val_accuracy: 0.7000\n",
      "Epoch 1285/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2684 - accuracy: 0.8667 - val_loss: 0.5581 - val_accuracy: 0.7000\n",
      "Epoch 1286/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1679 - accuracy: 0.9667 - val_loss: 0.5463 - val_accuracy: 0.7000\n",
      "Epoch 1287/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2556 - accuracy: 0.8333 - val_loss: 0.5421 - val_accuracy: 0.7000\n",
      "Epoch 1288/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2004 - accuracy: 0.9000 - val_loss: 0.5411 - val_accuracy: 0.7000\n",
      "Epoch 1289/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2361 - accuracy: 0.9000 - val_loss: 0.5479 - val_accuracy: 0.7000\n",
      "Epoch 1290/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2905 - accuracy: 0.9333 - val_loss: 0.5540 - val_accuracy: 0.7000\n",
      "Epoch 1291/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2532 - accuracy: 0.9000 - val_loss: 0.5665 - val_accuracy: 0.7000\n",
      "Epoch 1292/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2328 - accuracy: 0.9000 - val_loss: 0.5758 - val_accuracy: 0.7000\n",
      "Epoch 1293/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.2399 - accuracy: 0.9333 - val_loss: 0.5860 - val_accuracy: 0.7000\n",
      "Epoch 1294/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.1825 - accuracy: 0.9333 - val_loss: 0.5959 - val_accuracy: 0.7000\n",
      "Epoch 1295/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1833 - accuracy: 1.0000 - val_loss: 0.6036 - val_accuracy: 0.7000\n",
      "Epoch 1296/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2223 - accuracy: 0.9333 - val_loss: 0.6107 - val_accuracy: 0.7000\n",
      "Epoch 1297/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2116 - accuracy: 0.9000 - val_loss: 0.6185 - val_accuracy: 0.7000\n",
      "Epoch 1298/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2176 - accuracy: 0.9000 - val_loss: 0.6228 - val_accuracy: 0.7000\n",
      "Epoch 1299/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1869 - accuracy: 0.9667 - val_loss: 0.6240 - val_accuracy: 0.7000\n",
      "Epoch 1300/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2115 - accuracy: 0.9333 - val_loss: 0.6242 - val_accuracy: 0.7000\n",
      "Epoch 1301/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2354 - accuracy: 0.9000 - val_loss: 0.6252 - val_accuracy: 0.7000\n",
      "Epoch 1302/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.1957 - accuracy: 0.9667 - val_loss: 0.6208 - val_accuracy: 0.7000\n",
      "Epoch 1303/3000\n",
      "30/30 [==============================] - 0s 141us/step - loss: 0.2205 - accuracy: 0.8667 - val_loss: 0.6147 - val_accuracy: 0.7000\n",
      "Epoch 1304/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1662 - accuracy: 0.9667 - val_loss: 0.6130 - val_accuracy: 0.7000\n",
      "Epoch 1305/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2540 - accuracy: 0.9000 - val_loss: 0.6128 - val_accuracy: 0.7000\n",
      "Epoch 1306/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.1792 - accuracy: 0.9667 - val_loss: 0.6121 - val_accuracy: 0.7000\n",
      "Epoch 1307/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1723 - accuracy: 0.9000 - val_loss: 0.6124 - val_accuracy: 0.7000\n",
      "Epoch 1308/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2241 - accuracy: 0.9333 - val_loss: 0.6102 - val_accuracy: 0.7000\n",
      "Epoch 1309/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.3000 - accuracy: 0.9000 - val_loss: 0.6058 - val_accuracy: 0.7000\n",
      "Epoch 1310/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2404 - accuracy: 0.8667 - val_loss: 0.6045 - val_accuracy: 0.7000\n",
      "Epoch 1311/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2385 - accuracy: 0.9333 - val_loss: 0.6034 - val_accuracy: 0.7000\n",
      "Epoch 1312/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1468 - accuracy: 1.0000 - val_loss: 0.6039 - val_accuracy: 0.7000\n",
      "Epoch 1313/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2461 - accuracy: 0.9000 - val_loss: 0.6079 - val_accuracy: 0.7000\n",
      "Epoch 1314/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1969 - accuracy: 0.9333 - val_loss: 0.6116 - val_accuracy: 0.7000\n",
      "Epoch 1315/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.2529 - accuracy: 0.9000 - val_loss: 0.6076 - val_accuracy: 0.7000\n",
      "Epoch 1316/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2704 - accuracy: 0.9667 - val_loss: 0.6002 - val_accuracy: 0.7000\n",
      "Epoch 1317/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2072 - accuracy: 0.8667 - val_loss: 0.5954 - val_accuracy: 0.7000\n",
      "Epoch 1318/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2153 - accuracy: 0.9333 - val_loss: 0.5920 - val_accuracy: 0.7000\n",
      "Epoch 1319/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1919 - accuracy: 0.9000 - val_loss: 0.5892 - val_accuracy: 0.7000\n",
      "Epoch 1320/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2090 - accuracy: 0.9333 - val_loss: 0.5843 - val_accuracy: 0.7000\n",
      "Epoch 1321/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.1904 - accuracy: 0.9000 - val_loss: 0.5784 - val_accuracy: 0.7000\n",
      "Epoch 1322/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2022 - accuracy: 0.9333 - val_loss: 0.5767 - val_accuracy: 0.7000\n",
      "Epoch 1323/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2361 - accuracy: 0.9000 - val_loss: 0.5780 - val_accuracy: 0.7000\n",
      "Epoch 1324/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2046 - accuracy: 0.9000 - val_loss: 0.5784 - val_accuracy: 0.7000\n",
      "Epoch 1325/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1817 - accuracy: 0.9333 - val_loss: 0.5853 - val_accuracy: 0.7000\n",
      "Epoch 1326/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.2225 - accuracy: 0.9333 - val_loss: 0.5912 - val_accuracy: 0.7000\n",
      "Epoch 1327/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1585 - accuracy: 0.9667 - val_loss: 0.5957 - val_accuracy: 0.7000\n",
      "Epoch 1328/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2170 - accuracy: 0.9333 - val_loss: 0.6063 - val_accuracy: 0.7000\n",
      "Epoch 1329/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.3482 - accuracy: 0.8333 - val_loss: 0.6100 - val_accuracy: 0.7000\n",
      "Epoch 1330/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.2663 - accuracy: 0.9000 - val_loss: 0.6090 - val_accuracy: 0.7000\n",
      "Epoch 1331/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.1597 - accuracy: 1.0000 - val_loss: 0.6114 - val_accuracy: 0.7000\n",
      "Epoch 1332/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.1738 - accuracy: 0.9333 - val_loss: 0.6148 - val_accuracy: 0.7000\n",
      "Epoch 1333/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1850 - accuracy: 0.9333 - val_loss: 0.6184 - val_accuracy: 0.7000\n",
      "Epoch 1334/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.1738 - accuracy: 0.9333 - val_loss: 0.6187 - val_accuracy: 0.7000\n",
      "Epoch 1335/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.1926 - accuracy: 0.9667 - val_loss: 0.6105 - val_accuracy: 0.7000\n",
      "Epoch 1336/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1689 - accuracy: 0.9333 - val_loss: 0.5981 - val_accuracy: 0.7000\n",
      "Epoch 1337/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2328 - accuracy: 0.8667 - val_loss: 0.5867 - val_accuracy: 0.7000\n",
      "Epoch 1338/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2290 - accuracy: 0.9333 - val_loss: 0.5783 - val_accuracy: 0.7000\n",
      "Epoch 1339/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.2568 - accuracy: 0.9000 - val_loss: 0.5759 - val_accuracy: 0.7000\n",
      "Epoch 1340/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2260 - accuracy: 0.9000 - val_loss: 0.5771 - val_accuracy: 0.7000\n",
      "Epoch 1341/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1685 - accuracy: 0.9667 - val_loss: 0.5839 - val_accuracy: 0.7000\n",
      "Epoch 1342/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1829 - accuracy: 0.9667 - val_loss: 0.5922 - val_accuracy: 0.7000\n",
      "Epoch 1343/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1844 - accuracy: 0.9667 - val_loss: 0.6068 - val_accuracy: 0.7000\n",
      "Epoch 1344/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.2254 - accuracy: 0.9333 - val_loss: 0.6213 - val_accuracy: 0.7000\n",
      "Epoch 1345/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1833 - accuracy: 0.9667 - val_loss: 0.6300 - val_accuracy: 0.7000\n",
      "Epoch 1346/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2048 - accuracy: 0.9333 - val_loss: 0.6378 - val_accuracy: 0.7000\n",
      "Epoch 1347/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2028 - accuracy: 0.9667 - val_loss: 0.6486 - val_accuracy: 0.7000\n",
      "Epoch 1348/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1481 - accuracy: 1.0000 - val_loss: 0.6591 - val_accuracy: 0.7000\n",
      "Epoch 1349/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.2040 - accuracy: 0.9000 - val_loss: 0.6661 - val_accuracy: 0.7000\n",
      "Epoch 1350/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.2135 - accuracy: 0.9000 - val_loss: 0.6704 - val_accuracy: 0.7000\n",
      "Epoch 1351/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2855 - accuracy: 0.8667 - val_loss: 0.6675 - val_accuracy: 0.7000\n",
      "Epoch 1352/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1840 - accuracy: 0.9333 - val_loss: 0.6567 - val_accuracy: 0.7000\n",
      "Epoch 1353/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2555 - accuracy: 0.9000 - val_loss: 0.6431 - val_accuracy: 0.7000\n",
      "Epoch 1354/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.2171 - accuracy: 0.9333 - val_loss: 0.6293 - val_accuracy: 0.7000\n",
      "Epoch 1355/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1971 - accuracy: 0.9333 - val_loss: 0.6102 - val_accuracy: 0.7000\n",
      "Epoch 1356/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.1882 - accuracy: 0.9000 - val_loss: 0.5963 - val_accuracy: 0.7000\n",
      "Epoch 1357/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1561 - accuracy: 0.9667 - val_loss: 0.5845 - val_accuracy: 0.7000\n",
      "Epoch 1358/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2326 - accuracy: 0.9333 - val_loss: 0.5730 - val_accuracy: 0.7000\n",
      "Epoch 1359/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2104 - accuracy: 0.9000 - val_loss: 0.5697 - val_accuracy: 0.7000\n",
      "Epoch 1360/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2781 - accuracy: 0.8333 - val_loss: 0.5687 - val_accuracy: 0.7000\n",
      "Epoch 1361/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2125 - accuracy: 0.9333 - val_loss: 0.5717 - val_accuracy: 0.7000\n",
      "Epoch 1362/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.2771 - accuracy: 0.8667 - val_loss: 0.5745 - val_accuracy: 0.7000\n",
      "Epoch 1363/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2740 - accuracy: 0.8667 - val_loss: 0.5747 - val_accuracy: 0.7000\n",
      "Epoch 1364/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1575 - accuracy: 0.9667 - val_loss: 0.5807 - val_accuracy: 0.7000\n",
      "Epoch 1365/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.1860 - accuracy: 0.9333 - val_loss: 0.5841 - val_accuracy: 0.7000\n",
      "Epoch 1366/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1796 - accuracy: 0.9667 - val_loss: 0.5909 - val_accuracy: 0.7000\n",
      "Epoch 1367/3000\n",
      "30/30 [==============================] - 0s 141us/step - loss: 0.2072 - accuracy: 0.9667 - val_loss: 0.5989 - val_accuracy: 0.7000\n",
      "Epoch 1368/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.2783 - accuracy: 0.8667 - val_loss: 0.6099 - val_accuracy: 0.7000\n",
      "Epoch 1369/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1645 - accuracy: 0.9333 - val_loss: 0.6210 - val_accuracy: 0.7000\n",
      "Epoch 1370/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2048 - accuracy: 0.9333 - val_loss: 0.6328 - val_accuracy: 0.7000\n",
      "Epoch 1371/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.1656 - accuracy: 0.9333 - val_loss: 0.6432 - val_accuracy: 0.7000\n",
      "Epoch 1372/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.1941 - accuracy: 0.9667 - val_loss: 0.6562 - val_accuracy: 0.7000\n",
      "Epoch 1373/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.2143 - accuracy: 0.9000 - val_loss: 0.6596 - val_accuracy: 0.7000\n",
      "Epoch 1374/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1857 - accuracy: 0.9667 - val_loss: 0.6538 - val_accuracy: 0.7000\n",
      "Epoch 1375/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1684 - accuracy: 0.9667 - val_loss: 0.6434 - val_accuracy: 0.7000\n",
      "Epoch 1376/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.1723 - accuracy: 0.9333 - val_loss: 0.6269 - val_accuracy: 0.7000\n",
      "Epoch 1377/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1737 - accuracy: 0.9667 - val_loss: 0.6127 - val_accuracy: 0.7000\n",
      "Epoch 1378/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.1769 - accuracy: 0.9667 - val_loss: 0.5956 - val_accuracy: 0.7000\n",
      "Epoch 1379/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2004 - accuracy: 0.9333 - val_loss: 0.5753 - val_accuracy: 0.7000\n",
      "Epoch 1380/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1881 - accuracy: 0.9667 - val_loss: 0.5584 - val_accuracy: 0.7000\n",
      "Epoch 1381/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1985 - accuracy: 0.9333 - val_loss: 0.5461 - val_accuracy: 0.7000\n",
      "Epoch 1382/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1389 - accuracy: 1.0000 - val_loss: 0.5392 - val_accuracy: 0.8000\n",
      "Epoch 1383/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.3050 - accuracy: 0.8667 - val_loss: 0.5350 - val_accuracy: 0.8000\n",
      "Epoch 1384/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1692 - accuracy: 0.9333 - val_loss: 0.5346 - val_accuracy: 0.8000\n",
      "Epoch 1385/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2172 - accuracy: 0.9000 - val_loss: 0.5458 - val_accuracy: 0.7000\n",
      "Epoch 1386/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1720 - accuracy: 0.9000 - val_loss: 0.5583 - val_accuracy: 0.7000\n",
      "Epoch 1387/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.1847 - accuracy: 0.9667 - val_loss: 0.5722 - val_accuracy: 0.7000\n",
      "Epoch 1388/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.1686 - accuracy: 0.9667 - val_loss: 0.5843 - val_accuracy: 0.7000\n",
      "Epoch 1389/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.2861 - accuracy: 0.8667 - val_loss: 0.5975 - val_accuracy: 0.7000\n",
      "Epoch 1390/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.1939 - accuracy: 0.9000 - val_loss: 0.6131 - val_accuracy: 0.7000\n",
      "Epoch 1391/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2091 - accuracy: 0.9333 - val_loss: 0.6322 - val_accuracy: 0.7000\n",
      "Epoch 1392/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1756 - accuracy: 0.9333 - val_loss: 0.6485 - val_accuracy: 0.7000\n",
      "Epoch 1393/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1802 - accuracy: 0.9667 - val_loss: 0.6588 - val_accuracy: 0.7000\n",
      "Epoch 1394/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2292 - accuracy: 0.9333 - val_loss: 0.6651 - val_accuracy: 0.7000\n",
      "Epoch 1395/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1374 - accuracy: 0.9667 - val_loss: 0.6682 - val_accuracy: 0.7000\n",
      "Epoch 1396/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1533 - accuracy: 0.9667 - val_loss: 0.6738 - val_accuracy: 0.7000\n",
      "Epoch 1397/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.2455 - accuracy: 0.9000 - val_loss: 0.6716 - val_accuracy: 0.7000\n",
      "Epoch 1398/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1739 - accuracy: 0.9333 - val_loss: 0.6620 - val_accuracy: 0.7000\n",
      "Epoch 1399/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2140 - accuracy: 0.9000 - val_loss: 0.6520 - val_accuracy: 0.7000\n",
      "Epoch 1400/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2463 - accuracy: 0.8667 - val_loss: 0.6389 - val_accuracy: 0.7000\n",
      "Epoch 1401/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2170 - accuracy: 0.9333 - val_loss: 0.6256 - val_accuracy: 0.7000\n",
      "Epoch 1402/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2347 - accuracy: 0.9333 - val_loss: 0.6084 - val_accuracy: 0.7000\n",
      "Epoch 1403/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1474 - accuracy: 1.0000 - val_loss: 0.5956 - val_accuracy: 0.7000\n",
      "Epoch 1404/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2295 - accuracy: 0.8667 - val_loss: 0.5882 - val_accuracy: 0.7000\n",
      "Epoch 1405/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1972 - accuracy: 0.9333 - val_loss: 0.5798 - val_accuracy: 0.7000\n",
      "Epoch 1406/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2340 - accuracy: 0.9000 - val_loss: 0.5797 - val_accuracy: 0.7000\n",
      "Epoch 1407/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.1537 - accuracy: 0.9333 - val_loss: 0.5796 - val_accuracy: 0.7000\n",
      "Epoch 1408/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.2378 - accuracy: 0.8667 - val_loss: 0.5831 - val_accuracy: 0.7000\n",
      "Epoch 1409/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2356 - accuracy: 0.9000 - val_loss: 0.5884 - val_accuracy: 0.7000\n",
      "Epoch 1410/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1547 - accuracy: 1.0000 - val_loss: 0.5959 - val_accuracy: 0.7000\n",
      "Epoch 1411/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2028 - accuracy: 0.9333 - val_loss: 0.6075 - val_accuracy: 0.7000\n",
      "Epoch 1412/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2557 - accuracy: 0.8667 - val_loss: 0.6150 - val_accuracy: 0.7000\n",
      "Epoch 1413/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.2488 - accuracy: 0.9333 - val_loss: 0.6216 - val_accuracy: 0.7000\n",
      "Epoch 1414/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2042 - accuracy: 0.9333 - val_loss: 0.6232 - val_accuracy: 0.7000\n",
      "Epoch 1415/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1935 - accuracy: 0.9333 - val_loss: 0.6248 - val_accuracy: 0.7000\n",
      "Epoch 1416/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1772 - accuracy: 0.9333 - val_loss: 0.6199 - val_accuracy: 0.7000\n",
      "Epoch 1417/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1501 - accuracy: 0.9333 - val_loss: 0.6178 - val_accuracy: 0.7000\n",
      "Epoch 1418/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2035 - accuracy: 0.9667 - val_loss: 0.6138 - val_accuracy: 0.7000\n",
      "Epoch 1419/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1567 - accuracy: 0.9667 - val_loss: 0.6028 - val_accuracy: 0.7000\n",
      "Epoch 1420/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1900 - accuracy: 0.9667 - val_loss: 0.5919 - val_accuracy: 0.7000\n",
      "Epoch 1421/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1852 - accuracy: 0.9333 - val_loss: 0.5833 - val_accuracy: 0.7000\n",
      "Epoch 1422/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1813 - accuracy: 0.9333 - val_loss: 0.5786 - val_accuracy: 0.7000\n",
      "Epoch 1423/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2328 - accuracy: 0.9000 - val_loss: 0.5722 - val_accuracy: 0.7000\n",
      "Epoch 1424/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1848 - accuracy: 0.9667 - val_loss: 0.5680 - val_accuracy: 0.7000\n",
      "Epoch 1425/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2324 - accuracy: 0.9333 - val_loss: 0.5606 - val_accuracy: 0.7000\n",
      "Epoch 1426/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2199 - accuracy: 0.8667 - val_loss: 0.5534 - val_accuracy: 0.7000\n",
      "Epoch 1427/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1652 - accuracy: 0.9333 - val_loss: 0.5502 - val_accuracy: 0.7000\n",
      "Epoch 1428/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1677 - accuracy: 1.0000 - val_loss: 0.5485 - val_accuracy: 0.7000\n",
      "Epoch 1429/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2189 - accuracy: 0.9333 - val_loss: 0.5422 - val_accuracy: 0.7000\n",
      "Epoch 1430/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1857 - accuracy: 0.9667 - val_loss: 0.5447 - val_accuracy: 0.7000\n",
      "Epoch 1431/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1757 - accuracy: 0.9333 - val_loss: 0.5479 - val_accuracy: 0.7000\n",
      "Epoch 1432/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.2096 - accuracy: 0.9333 - val_loss: 0.5524 - val_accuracy: 0.7000\n",
      "Epoch 1433/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2271 - accuracy: 0.9333 - val_loss: 0.5517 - val_accuracy: 0.7000\n",
      "Epoch 1434/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1943 - accuracy: 0.9333 - val_loss: 0.5514 - val_accuracy: 0.7000\n",
      "Epoch 1435/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.2226 - accuracy: 0.8667 - val_loss: 0.5511 - val_accuracy: 0.7000\n",
      "Epoch 1436/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2476 - accuracy: 0.8333 - val_loss: 0.5582 - val_accuracy: 0.7000\n",
      "Epoch 1437/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1750 - accuracy: 0.9667 - val_loss: 0.5693 - val_accuracy: 0.7000\n",
      "Epoch 1438/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1801 - accuracy: 0.9667 - val_loss: 0.5801 - val_accuracy: 0.7000\n",
      "Epoch 1439/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1904 - accuracy: 0.9333 - val_loss: 0.5943 - val_accuracy: 0.7000\n",
      "Epoch 1440/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1667 - accuracy: 0.9667 - val_loss: 0.6090 - val_accuracy: 0.7000\n",
      "Epoch 1441/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1673 - accuracy: 0.9333 - val_loss: 0.6159 - val_accuracy: 0.7000\n",
      "Epoch 1442/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1955 - accuracy: 0.9333 - val_loss: 0.6220 - val_accuracy: 0.7000\n",
      "Epoch 1443/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1903 - accuracy: 0.9333 - val_loss: 0.6239 - val_accuracy: 0.7000\n",
      "Epoch 1444/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1973 - accuracy: 0.9333 - val_loss: 0.6298 - val_accuracy: 0.7000\n",
      "Epoch 1445/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1666 - accuracy: 0.9000 - val_loss: 0.6367 - val_accuracy: 0.7000\n",
      "Epoch 1446/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1761 - accuracy: 0.9333 - val_loss: 0.6344 - val_accuracy: 0.7000\n",
      "Epoch 1447/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1368 - accuracy: 1.0000 - val_loss: 0.6314 - val_accuracy: 0.7000\n",
      "Epoch 1448/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1704 - accuracy: 0.9667 - val_loss: 0.6301 - val_accuracy: 0.7000\n",
      "Epoch 1449/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1727 - accuracy: 0.9667 - val_loss: 0.6225 - val_accuracy: 0.7000\n",
      "Epoch 1450/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.2491 - accuracy: 0.9000 - val_loss: 0.6122 - val_accuracy: 0.7000\n",
      "Epoch 1451/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.2237 - accuracy: 0.9333 - val_loss: 0.5988 - val_accuracy: 0.7000\n",
      "Epoch 1452/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2114 - accuracy: 0.9000 - val_loss: 0.5840 - val_accuracy: 0.7000\n",
      "Epoch 1453/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2012 - accuracy: 0.9667 - val_loss: 0.5666 - val_accuracy: 0.7000\n",
      "Epoch 1454/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2844 - accuracy: 0.8667 - val_loss: 0.5423 - val_accuracy: 0.7000\n",
      "Epoch 1455/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1783 - accuracy: 0.9333 - val_loss: 0.5235 - val_accuracy: 0.7000\n",
      "Epoch 1456/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2487 - accuracy: 0.9000 - val_loss: 0.5060 - val_accuracy: 0.7000\n",
      "Epoch 1457/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2054 - accuracy: 0.9333 - val_loss: 0.4932 - val_accuracy: 0.7000\n",
      "Epoch 1458/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.2217 - accuracy: 0.9333 - val_loss: 0.4846 - val_accuracy: 0.7000\n",
      "Epoch 1459/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2439 - accuracy: 0.9000 - val_loss: 0.4798 - val_accuracy: 0.7000\n",
      "Epoch 1460/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2298 - accuracy: 0.9000 - val_loss: 0.4829 - val_accuracy: 0.7000\n",
      "Epoch 1461/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1842 - accuracy: 0.9333 - val_loss: 0.4980 - val_accuracy: 0.7000\n",
      "Epoch 1462/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2413 - accuracy: 0.9000 - val_loss: 0.5130 - val_accuracy: 0.7000\n",
      "Epoch 1463/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1677 - accuracy: 0.9333 - val_loss: 0.5304 - val_accuracy: 0.7000\n",
      "Epoch 1464/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.2154 - accuracy: 0.9333 - val_loss: 0.5524 - val_accuracy: 0.7000\n",
      "Epoch 1465/3000\n",
      "30/30 [==============================] - 0s 145us/step - loss: 0.2003 - accuracy: 0.9667 - val_loss: 0.5808 - val_accuracy: 0.7000\n",
      "Epoch 1466/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.1841 - accuracy: 0.9333 - val_loss: 0.6068 - val_accuracy: 0.7000\n",
      "Epoch 1467/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1970 - accuracy: 0.9667 - val_loss: 0.6340 - val_accuracy: 0.7000\n",
      "Epoch 1468/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2168 - accuracy: 0.9333 - val_loss: 0.6489 - val_accuracy: 0.7000\n",
      "Epoch 1469/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1993 - accuracy: 0.9333 - val_loss: 0.6622 - val_accuracy: 0.7000\n",
      "Epoch 1470/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1186 - accuracy: 1.0000 - val_loss: 0.6717 - val_accuracy: 0.7000\n",
      "Epoch 1471/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.1700 - accuracy: 0.9333 - val_loss: 0.6659 - val_accuracy: 0.7000\n",
      "Epoch 1472/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.2306 - accuracy: 0.9333 - val_loss: 0.6541 - val_accuracy: 0.7000\n",
      "Epoch 1473/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.2171 - accuracy: 0.9333 - val_loss: 0.6431 - val_accuracy: 0.7000\n",
      "Epoch 1474/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1885 - accuracy: 0.9000 - val_loss: 0.6320 - val_accuracy: 0.7000\n",
      "Epoch 1475/3000\n",
      "30/30 [==============================] - 0s 141us/step - loss: 0.1636 - accuracy: 0.9333 - val_loss: 0.6181 - val_accuracy: 0.7000\n",
      "Epoch 1476/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.1940 - accuracy: 0.9667 - val_loss: 0.6123 - val_accuracy: 0.7000\n",
      "Epoch 1477/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1961 - accuracy: 0.9333 - val_loss: 0.6065 - val_accuracy: 0.7000\n",
      "Epoch 1478/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.2127 - accuracy: 0.9333 - val_loss: 0.6047 - val_accuracy: 0.7000\n",
      "Epoch 1479/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.3228 - accuracy: 0.8667 - val_loss: 0.6068 - val_accuracy: 0.7000\n",
      "Epoch 1480/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2053 - accuracy: 0.9333 - val_loss: 0.6057 - val_accuracy: 0.7000\n",
      "Epoch 1481/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1817 - accuracy: 0.9000 - val_loss: 0.6116 - val_accuracy: 0.7000\n",
      "Epoch 1482/3000\n",
      "30/30 [==============================] - 0s 149us/step - loss: 0.1744 - accuracy: 0.9000 - val_loss: 0.6140 - val_accuracy: 0.7000\n",
      "Epoch 1483/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1511 - accuracy: 0.9333 - val_loss: 0.6192 - val_accuracy: 0.7000\n",
      "Epoch 1484/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2048 - accuracy: 0.9333 - val_loss: 0.6306 - val_accuracy: 0.7000\n",
      "Epoch 1485/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1606 - accuracy: 0.9667 - val_loss: 0.6395 - val_accuracy: 0.7000\n",
      "Epoch 1486/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2601 - accuracy: 0.8667 - val_loss: 0.6457 - val_accuracy: 0.7000\n",
      "Epoch 1487/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1907 - accuracy: 0.9333 - val_loss: 0.6570 - val_accuracy: 0.7000\n",
      "Epoch 1488/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1398 - accuracy: 1.0000 - val_loss: 0.6675 - val_accuracy: 0.7000\n",
      "Epoch 1489/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1255 - accuracy: 1.0000 - val_loss: 0.6690 - val_accuracy: 0.7000\n",
      "Epoch 1490/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.2010 - accuracy: 0.9333 - val_loss: 0.6680 - val_accuracy: 0.7000\n",
      "Epoch 1491/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2128 - accuracy: 0.8667 - val_loss: 0.6661 - val_accuracy: 0.7000\n",
      "Epoch 1492/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1939 - accuracy: 0.9667 - val_loss: 0.6667 - val_accuracy: 0.7000\n",
      "Epoch 1493/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.2327 - accuracy: 0.8667 - val_loss: 0.6618 - val_accuracy: 0.7000\n",
      "Epoch 1494/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1687 - accuracy: 0.9333 - val_loss: 0.6503 - val_accuracy: 0.7000\n",
      "Epoch 1495/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1685 - accuracy: 0.9333 - val_loss: 0.6419 - val_accuracy: 0.7000\n",
      "Epoch 1496/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.2438 - accuracy: 0.9000 - val_loss: 0.6277 - val_accuracy: 0.7000\n",
      "Epoch 1497/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2180 - accuracy: 0.9333 - val_loss: 0.6163 - val_accuracy: 0.7000\n",
      "Epoch 1498/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2431 - accuracy: 0.9000 - val_loss: 0.6035 - val_accuracy: 0.7000\n",
      "Epoch 1499/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1781 - accuracy: 0.9333 - val_loss: 0.5851 - val_accuracy: 0.7000\n",
      "Epoch 1500/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2306 - accuracy: 0.9667 - val_loss: 0.5680 - val_accuracy: 0.7000\n",
      "Epoch 1501/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1587 - accuracy: 0.9667 - val_loss: 0.5549 - val_accuracy: 0.7000\n",
      "Epoch 1502/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1478 - accuracy: 1.0000 - val_loss: 0.5429 - val_accuracy: 0.7000\n",
      "Epoch 1503/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1930 - accuracy: 0.9333 - val_loss: 0.5315 - val_accuracy: 0.7000\n",
      "Epoch 1504/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1690 - accuracy: 0.9667 - val_loss: 0.5237 - val_accuracy: 0.7000\n",
      "Epoch 1505/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1716 - accuracy: 0.9333 - val_loss: 0.5183 - val_accuracy: 0.7000\n",
      "Epoch 1506/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.1819 - accuracy: 0.9667 - val_loss: 0.5100 - val_accuracy: 0.7000\n",
      "Epoch 1507/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1421 - accuracy: 1.0000 - val_loss: 0.5098 - val_accuracy: 0.7000\n",
      "Epoch 1508/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.1513 - accuracy: 1.0000 - val_loss: 0.5147 - val_accuracy: 0.7000\n",
      "Epoch 1509/3000\n",
      "30/30 [==============================] - 0s 142us/step - loss: 0.1412 - accuracy: 0.9667 - val_loss: 0.5221 - val_accuracy: 0.7000\n",
      "Epoch 1510/3000\n",
      "30/30 [==============================] - 0s 150us/step - loss: 0.1523 - accuracy: 0.9333 - val_loss: 0.5264 - val_accuracy: 0.7000\n",
      "Epoch 1511/3000\n",
      "30/30 [==============================] - 0s 139us/step - loss: 0.1995 - accuracy: 0.9667 - val_loss: 0.5348 - val_accuracy: 0.7000\n",
      "Epoch 1512/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.2010 - accuracy: 0.9333 - val_loss: 0.5447 - val_accuracy: 0.7000\n",
      "Epoch 1513/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1637 - accuracy: 0.9333 - val_loss: 0.5580 - val_accuracy: 0.7000\n",
      "Epoch 1514/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2167 - accuracy: 0.9333 - val_loss: 0.5717 - val_accuracy: 0.7000\n",
      "Epoch 1515/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1884 - accuracy: 0.9667 - val_loss: 0.5853 - val_accuracy: 0.7000\n",
      "Epoch 1516/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1529 - accuracy: 0.9667 - val_loss: 0.5968 - val_accuracy: 0.7000\n",
      "Epoch 1517/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1754 - accuracy: 0.9333 - val_loss: 0.6032 - val_accuracy: 0.7000\n",
      "Epoch 1518/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1594 - accuracy: 0.9667 - val_loss: 0.6087 - val_accuracy: 0.7000\n",
      "Epoch 1519/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.1316 - accuracy: 0.9667 - val_loss: 0.6104 - val_accuracy: 0.7000\n",
      "Epoch 1520/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.2942 - accuracy: 0.9000 - val_loss: 0.6094 - val_accuracy: 0.7000\n",
      "Epoch 1521/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1847 - accuracy: 0.9333 - val_loss: 0.6083 - val_accuracy: 0.7000\n",
      "Epoch 1522/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1591 - accuracy: 0.9333 - val_loss: 0.6036 - val_accuracy: 0.7000\n",
      "Epoch 1523/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1825 - accuracy: 0.9667 - val_loss: 0.5989 - val_accuracy: 0.7000\n",
      "Epoch 1524/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2091 - accuracy: 0.9333 - val_loss: 0.5922 - val_accuracy: 0.7000\n",
      "Epoch 1525/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1462 - accuracy: 1.0000 - val_loss: 0.5868 - val_accuracy: 0.7000\n",
      "Epoch 1526/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1590 - accuracy: 0.9333 - val_loss: 0.5866 - val_accuracy: 0.7000\n",
      "Epoch 1527/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1652 - accuracy: 0.9333 - val_loss: 0.5864 - val_accuracy: 0.7000\n",
      "Epoch 1528/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2242 - accuracy: 0.9000 - val_loss: 0.5849 - val_accuracy: 0.7000\n",
      "Epoch 1529/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.2032 - accuracy: 0.9333 - val_loss: 0.5831 - val_accuracy: 0.7000\n",
      "Epoch 1530/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2926 - accuracy: 0.9333 - val_loss: 0.5746 - val_accuracy: 0.7000\n",
      "Epoch 1531/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2935 - accuracy: 0.8667 - val_loss: 0.5683 - val_accuracy: 0.7000\n",
      "Epoch 1532/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2068 - accuracy: 0.9333 - val_loss: 0.5737 - val_accuracy: 0.7000\n",
      "Epoch 1533/3000\n",
      "30/30 [==============================] - 0s 144us/step - loss: 0.2049 - accuracy: 0.9000 - val_loss: 0.5778 - val_accuracy: 0.7000\n",
      "Epoch 1534/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1635 - accuracy: 0.9333 - val_loss: 0.5823 - val_accuracy: 0.7000\n",
      "Epoch 1535/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1177 - accuracy: 0.9667 - val_loss: 0.5909 - val_accuracy: 0.7000\n",
      "Epoch 1536/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1609 - accuracy: 0.9667 - val_loss: 0.5969 - val_accuracy: 0.7000\n",
      "Epoch 1537/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1683 - accuracy: 0.9333 - val_loss: 0.5945 - val_accuracy: 0.7000\n",
      "Epoch 1538/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1915 - accuracy: 0.9000 - val_loss: 0.5884 - val_accuracy: 0.7000\n",
      "Epoch 1539/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2744 - accuracy: 0.9000 - val_loss: 0.5690 - val_accuracy: 0.7000\n",
      "Epoch 1540/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1907 - accuracy: 0.9667 - val_loss: 0.5530 - val_accuracy: 0.8000\n",
      "Epoch 1541/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1796 - accuracy: 0.9333 - val_loss: 0.5415 - val_accuracy: 0.8000\n",
      "Epoch 1542/3000\n",
      "30/30 [==============================] - 0s 139us/step - loss: 0.1340 - accuracy: 1.0000 - val_loss: 0.5347 - val_accuracy: 0.8000\n",
      "Epoch 1543/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1780 - accuracy: 0.9667 - val_loss: 0.5282 - val_accuracy: 0.8000\n",
      "Epoch 1544/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.1872 - accuracy: 0.9333 - val_loss: 0.5250 - val_accuracy: 0.8000\n",
      "Epoch 1545/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1531 - accuracy: 0.9333 - val_loss: 0.5232 - val_accuracy: 0.8000\n",
      "Epoch 1546/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1605 - accuracy: 0.9333 - val_loss: 0.5309 - val_accuracy: 0.8000\n",
      "Epoch 1547/3000\n",
      "30/30 [==============================] - 0s 141us/step - loss: 0.1641 - accuracy: 0.9667 - val_loss: 0.5389 - val_accuracy: 0.8000\n",
      "Epoch 1548/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.2134 - accuracy: 0.9333 - val_loss: 0.5455 - val_accuracy: 0.7000\n",
      "Epoch 1549/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1586 - accuracy: 0.9667 - val_loss: 0.5549 - val_accuracy: 0.7000\n",
      "Epoch 1550/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1587 - accuracy: 0.9667 - val_loss: 0.5686 - val_accuracy: 0.7000\n",
      "Epoch 1551/3000\n",
      "30/30 [==============================] - 0s 139us/step - loss: 0.2095 - accuracy: 0.8667 - val_loss: 0.5767 - val_accuracy: 0.7000\n",
      "Epoch 1552/3000\n",
      "30/30 [==============================] - 0s 139us/step - loss: 0.1912 - accuracy: 0.9000 - val_loss: 0.5785 - val_accuracy: 0.7000\n",
      "Epoch 1553/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1719 - accuracy: 0.9667 - val_loss: 0.5860 - val_accuracy: 0.7000\n",
      "Epoch 1554/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.1302 - accuracy: 0.9667 - val_loss: 0.5983 - val_accuracy: 0.7000\n",
      "Epoch 1555/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.1728 - accuracy: 0.9667 - val_loss: 0.6080 - val_accuracy: 0.7000\n",
      "Epoch 1556/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1895 - accuracy: 0.9667 - val_loss: 0.6129 - val_accuracy: 0.7000\n",
      "Epoch 1557/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1637 - accuracy: 0.9000 - val_loss: 0.6127 - val_accuracy: 0.7000\n",
      "Epoch 1558/3000\n",
      "30/30 [==============================] - 0s 146us/step - loss: 0.1642 - accuracy: 0.9333 - val_loss: 0.6108 - val_accuracy: 0.7000\n",
      "Epoch 1559/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.1598 - accuracy: 0.9333 - val_loss: 0.6040 - val_accuracy: 0.7000\n",
      "Epoch 1560/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2606 - accuracy: 0.8333 - val_loss: 0.5897 - val_accuracy: 0.7000\n",
      "Epoch 1561/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.2506 - accuracy: 0.9333 - val_loss: 0.5727 - val_accuracy: 0.7000\n",
      "Epoch 1562/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.1300 - accuracy: 0.9333 - val_loss: 0.5524 - val_accuracy: 0.7000\n",
      "Epoch 1563/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1986 - accuracy: 0.9000 - val_loss: 0.5333 - val_accuracy: 0.7000\n",
      "Epoch 1564/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1817 - accuracy: 0.9333 - val_loss: 0.5240 - val_accuracy: 0.7000\n",
      "Epoch 1565/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.1539 - accuracy: 0.9667 - val_loss: 0.5173 - val_accuracy: 0.7000\n",
      "Epoch 1566/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1694 - accuracy: 0.9333 - val_loss: 0.5074 - val_accuracy: 0.7000\n",
      "Epoch 1567/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1977 - accuracy: 0.9333 - val_loss: 0.4955 - val_accuracy: 0.7000\n",
      "Epoch 1568/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1720 - accuracy: 0.9000 - val_loss: 0.4884 - val_accuracy: 0.7000\n",
      "Epoch 1569/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.1972 - accuracy: 0.9000 - val_loss: 0.4847 - val_accuracy: 0.7000\n",
      "Epoch 1570/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.2481 - accuracy: 0.9000 - val_loss: 0.4890 - val_accuracy: 0.7000\n",
      "Epoch 1571/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2255 - accuracy: 0.9000 - val_loss: 0.4934 - val_accuracy: 0.7000\n",
      "Epoch 1572/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1947 - accuracy: 0.9333 - val_loss: 0.4963 - val_accuracy: 0.7000\n",
      "Epoch 1573/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2175 - accuracy: 0.8667 - val_loss: 0.4938 - val_accuracy: 0.7000\n",
      "Epoch 1574/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1446 - accuracy: 0.9667 - val_loss: 0.4893 - val_accuracy: 0.7000\n",
      "Epoch 1575/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1474 - accuracy: 0.9667 - val_loss: 0.4935 - val_accuracy: 0.7000\n",
      "Epoch 1576/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1970 - accuracy: 0.9333 - val_loss: 0.4999 - val_accuracy: 0.7000\n",
      "Epoch 1577/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1394 - accuracy: 0.9333 - val_loss: 0.5091 - val_accuracy: 0.7000\n",
      "Epoch 1578/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1645 - accuracy: 0.9333 - val_loss: 0.5243 - val_accuracy: 0.7000\n",
      "Epoch 1579/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.2397 - accuracy: 0.9000 - val_loss: 0.5309 - val_accuracy: 0.7000\n",
      "Epoch 1580/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2350 - accuracy: 0.9000 - val_loss: 0.5201 - val_accuracy: 0.7000\n",
      "Epoch 1581/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1688 - accuracy: 0.9333 - val_loss: 0.5071 - val_accuracy: 0.7000\n",
      "Epoch 1582/3000\n",
      "30/30 [==============================] - 0s 146us/step - loss: 0.1757 - accuracy: 0.9667 - val_loss: 0.4979 - val_accuracy: 0.7000\n",
      "Epoch 1583/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.2259 - accuracy: 0.9333 - val_loss: 0.4960 - val_accuracy: 0.7000\n",
      "Epoch 1584/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1224 - accuracy: 1.0000 - val_loss: 0.4937 - val_accuracy: 0.7000\n",
      "Epoch 1585/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1977 - accuracy: 0.9333 - val_loss: 0.4868 - val_accuracy: 0.7000\n",
      "Epoch 1586/3000\n",
      "30/30 [==============================] - 0s 139us/step - loss: 0.1653 - accuracy: 0.9333 - val_loss: 0.4921 - val_accuracy: 0.7000\n",
      "Epoch 1587/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.2011 - accuracy: 0.9333 - val_loss: 0.4981 - val_accuracy: 0.7000\n",
      "Epoch 1588/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1810 - accuracy: 0.9667 - val_loss: 0.5070 - val_accuracy: 0.7000\n",
      "Epoch 1589/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1307 - accuracy: 0.9667 - val_loss: 0.5146 - val_accuracy: 0.7000\n",
      "Epoch 1590/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1150 - accuracy: 1.0000 - val_loss: 0.5248 - val_accuracy: 0.7000\n",
      "Epoch 1591/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1944 - accuracy: 0.9333 - val_loss: 0.5407 - val_accuracy: 0.7000\n",
      "Epoch 1592/3000\n",
      "30/30 [==============================] - 0s 144us/step - loss: 0.2433 - accuracy: 0.9000 - val_loss: 0.5511 - val_accuracy: 0.7000\n",
      "Epoch 1593/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.1384 - accuracy: 0.9667 - val_loss: 0.5591 - val_accuracy: 0.7000\n",
      "Epoch 1594/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.1638 - accuracy: 0.9333 - val_loss: 0.5627 - val_accuracy: 0.7000\n",
      "Epoch 1595/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.2043 - accuracy: 0.9000 - val_loss: 0.5689 - val_accuracy: 0.7000\n",
      "Epoch 1596/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2039 - accuracy: 0.9333 - val_loss: 0.5694 - val_accuracy: 0.7000\n",
      "Epoch 1597/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1885 - accuracy: 0.9333 - val_loss: 0.5656 - val_accuracy: 0.7000\n",
      "Epoch 1598/3000\n",
      "30/30 [==============================] - 0s 141us/step - loss: 0.2136 - accuracy: 0.8667 - val_loss: 0.5514 - val_accuracy: 0.7000\n",
      "Epoch 1599/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.1977 - accuracy: 0.9333 - val_loss: 0.5395 - val_accuracy: 0.7000\n",
      "Epoch 1600/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2294 - accuracy: 0.8667 - val_loss: 0.5287 - val_accuracy: 0.7000\n",
      "Epoch 1601/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.2155 - accuracy: 0.9000 - val_loss: 0.5162 - val_accuracy: 0.7000\n",
      "Epoch 1602/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1879 - accuracy: 0.9333 - val_loss: 0.5147 - val_accuracy: 0.7000\n",
      "Epoch 1603/3000\n",
      "30/30 [==============================] - 0s 147us/step - loss: 0.2363 - accuracy: 0.9000 - val_loss: 0.5058 - val_accuracy: 0.7000\n",
      "Epoch 1604/3000\n",
      "30/30 [==============================] - 0s 147us/step - loss: 0.2016 - accuracy: 0.9333 - val_loss: 0.5083 - val_accuracy: 0.7000\n",
      "Epoch 1605/3000\n",
      "30/30 [==============================] - 0s 146us/step - loss: 0.2090 - accuracy: 0.9333 - val_loss: 0.5024 - val_accuracy: 0.7000\n",
      "Epoch 1606/3000\n",
      "30/30 [==============================] - 0s 143us/step - loss: 0.1685 - accuracy: 0.9333 - val_loss: 0.5006 - val_accuracy: 0.7000\n",
      "Epoch 1607/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1527 - accuracy: 0.9667 - val_loss: 0.4995 - val_accuracy: 0.7000\n",
      "Epoch 1608/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1813 - accuracy: 0.9333 - val_loss: 0.5028 - val_accuracy: 0.7000\n",
      "Epoch 1609/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.1229 - accuracy: 1.0000 - val_loss: 0.5032 - val_accuracy: 0.7000\n",
      "Epoch 1610/3000\n",
      "30/30 [==============================] - 0s 142us/step - loss: 0.2023 - accuracy: 0.9333 - val_loss: 0.4937 - val_accuracy: 0.7000\n",
      "Epoch 1611/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1599 - accuracy: 0.9667 - val_loss: 0.4896 - val_accuracy: 0.7000\n",
      "Epoch 1612/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1792 - accuracy: 0.9667 - val_loss: 0.4866 - val_accuracy: 0.7000\n",
      "Epoch 1613/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1221 - accuracy: 1.0000 - val_loss: 0.4868 - val_accuracy: 0.7000\n",
      "Epoch 1614/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1751 - accuracy: 0.9333 - val_loss: 0.4866 - val_accuracy: 0.7000\n",
      "Epoch 1615/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2158 - accuracy: 0.9000 - val_loss: 0.4982 - val_accuracy: 0.7000\n",
      "Epoch 1616/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1871 - accuracy: 0.9667 - val_loss: 0.5174 - val_accuracy: 0.7000\n",
      "Epoch 1617/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1639 - accuracy: 0.9667 - val_loss: 0.5365 - val_accuracy: 0.7000\n",
      "Epoch 1618/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1852 - accuracy: 0.9000 - val_loss: 0.5584 - val_accuracy: 0.7000\n",
      "Epoch 1619/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1098 - accuracy: 0.9667 - val_loss: 0.5699 - val_accuracy: 0.7000\n",
      "Epoch 1620/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1639 - accuracy: 0.9667 - val_loss: 0.5792 - val_accuracy: 0.7000\n",
      "Epoch 1621/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2070 - accuracy: 0.9333 - val_loss: 0.5714 - val_accuracy: 0.7000\n",
      "Epoch 1622/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2291 - accuracy: 0.9667 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1623/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1496 - accuracy: 0.9667 - val_loss: 0.5377 - val_accuracy: 0.7000\n",
      "Epoch 1624/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1805 - accuracy: 0.9333 - val_loss: 0.5215 - val_accuracy: 0.7000\n",
      "Epoch 1625/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1397 - accuracy: 1.0000 - val_loss: 0.5158 - val_accuracy: 0.7000\n",
      "Epoch 1626/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2009 - accuracy: 0.9667 - val_loss: 0.5058 - val_accuracy: 0.8000\n",
      "Epoch 1627/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1299 - accuracy: 1.0000 - val_loss: 0.4993 - val_accuracy: 0.8000\n",
      "Epoch 1628/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1713 - accuracy: 0.9333 - val_loss: 0.4935 - val_accuracy: 0.8000\n",
      "Epoch 1629/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1996 - accuracy: 0.9333 - val_loss: 0.4981 - val_accuracy: 0.8000\n",
      "Epoch 1630/3000\n",
      "30/30 [==============================] - 0s 142us/step - loss: 0.1779 - accuracy: 0.9000 - val_loss: 0.5049 - val_accuracy: 0.8000\n",
      "Epoch 1631/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1745 - accuracy: 0.9333 - val_loss: 0.5137 - val_accuracy: 0.8000\n",
      "Epoch 1632/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1625 - accuracy: 0.9333 - val_loss: 0.5262 - val_accuracy: 0.7000\n",
      "Epoch 1633/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1638 - accuracy: 0.9667 - val_loss: 0.5499 - val_accuracy: 0.7000\n",
      "Epoch 1634/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1552 - accuracy: 0.9333 - val_loss: 0.5708 - val_accuracy: 0.7000\n",
      "Epoch 1635/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1461 - accuracy: 0.9667 - val_loss: 0.5936 - val_accuracy: 0.7000\n",
      "Epoch 1636/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1912 - accuracy: 0.8667 - val_loss: 0.6094 - val_accuracy: 0.7000\n",
      "Epoch 1637/3000\n",
      "30/30 [==============================] - 0s 139us/step - loss: 0.1864 - accuracy: 0.9333 - val_loss: 0.6215 - val_accuracy: 0.7000\n",
      "Epoch 1638/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1475 - accuracy: 1.0000 - val_loss: 0.6356 - val_accuracy: 0.7000\n",
      "Epoch 1639/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2650 - accuracy: 0.9333 - val_loss: 0.6222 - val_accuracy: 0.7000\n",
      "Epoch 1640/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1599 - accuracy: 0.9667 - val_loss: 0.6061 - val_accuracy: 0.7000\n",
      "Epoch 1641/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1456 - accuracy: 0.9667 - val_loss: 0.5839 - val_accuracy: 0.7000\n",
      "Epoch 1642/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.1639 - accuracy: 0.9333 - val_loss: 0.5617 - val_accuracy: 0.7000\n",
      "Epoch 1643/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1768 - accuracy: 0.9000 - val_loss: 0.5417 - val_accuracy: 0.7000\n",
      "Epoch 1644/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1758 - accuracy: 0.9333 - val_loss: 0.5280 - val_accuracy: 0.7000\n",
      "Epoch 1645/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1569 - accuracy: 1.0000 - val_loss: 0.5187 - val_accuracy: 0.7000\n",
      "Epoch 1646/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1599 - accuracy: 0.9667 - val_loss: 0.5185 - val_accuracy: 0.8000\n",
      "Epoch 1647/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1523 - accuracy: 0.9667 - val_loss: 0.5229 - val_accuracy: 0.8000\n",
      "Epoch 1648/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1301 - accuracy: 0.9667 - val_loss: 0.5296 - val_accuracy: 0.8000\n",
      "Epoch 1649/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1480 - accuracy: 0.9333 - val_loss: 0.5337 - val_accuracy: 0.8000\n",
      "Epoch 1650/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1711 - accuracy: 0.9333 - val_loss: 0.5398 - val_accuracy: 0.8000\n",
      "Epoch 1651/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1516 - accuracy: 0.9667 - val_loss: 0.5428 - val_accuracy: 0.8000\n",
      "Epoch 1652/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1459 - accuracy: 0.9667 - val_loss: 0.5483 - val_accuracy: 0.8000\n",
      "Epoch 1653/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1861 - accuracy: 0.9000 - val_loss: 0.5540 - val_accuracy: 0.8000\n",
      "Epoch 1654/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1352 - accuracy: 0.9667 - val_loss: 0.5679 - val_accuracy: 0.8000\n",
      "Epoch 1655/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1639 - accuracy: 0.9333 - val_loss: 0.5743 - val_accuracy: 0.8000\n",
      "Epoch 1656/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1746 - accuracy: 0.9333 - val_loss: 0.5738 - val_accuracy: 0.8000\n",
      "Epoch 1657/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1364 - accuracy: 0.9333 - val_loss: 0.5603 - val_accuracy: 0.8000\n",
      "Epoch 1658/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1517 - accuracy: 0.9333 - val_loss: 0.5467 - val_accuracy: 0.8000\n",
      "Epoch 1659/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1917 - accuracy: 0.9333 - val_loss: 0.5393 - val_accuracy: 0.8000\n",
      "Epoch 1660/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.1559 - accuracy: 0.9667 - val_loss: 0.5352 - val_accuracy: 0.8000\n",
      "Epoch 1661/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2068 - accuracy: 0.9333 - val_loss: 0.5276 - val_accuracy: 0.8000\n",
      "Epoch 1662/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1340 - accuracy: 1.0000 - val_loss: 0.5244 - val_accuracy: 0.8000\n",
      "Epoch 1663/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0975 - accuracy: 1.0000 - val_loss: 0.5229 - val_accuracy: 0.8000\n",
      "Epoch 1664/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1850 - accuracy: 0.9333 - val_loss: 0.5229 - val_accuracy: 0.8000\n",
      "Epoch 1665/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1724 - accuracy: 0.9667 - val_loss: 0.5294 - val_accuracy: 0.8000\n",
      "Epoch 1666/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1721 - accuracy: 0.9333 - val_loss: 0.5446 - val_accuracy: 0.8000\n",
      "Epoch 1667/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1680 - accuracy: 0.9333 - val_loss: 0.5584 - val_accuracy: 0.8000\n",
      "Epoch 1668/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1883 - accuracy: 0.9333 - val_loss: 0.5683 - val_accuracy: 0.8000\n",
      "Epoch 1669/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1879 - accuracy: 0.9000 - val_loss: 0.5752 - val_accuracy: 0.8000\n",
      "Epoch 1670/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1636 - accuracy: 0.9333 - val_loss: 0.5902 - val_accuracy: 0.8000\n",
      "Epoch 1671/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.1983 - accuracy: 0.8667 - val_loss: 0.5830 - val_accuracy: 0.8000\n",
      "Epoch 1672/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1781 - accuracy: 0.9333 - val_loss: 0.5707 - val_accuracy: 0.8000\n",
      "Epoch 1673/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1362 - accuracy: 0.9667 - val_loss: 0.5613 - val_accuracy: 0.8000\n",
      "Epoch 1674/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.1541 - accuracy: 0.9000 - val_loss: 0.5407 - val_accuracy: 0.8000\n",
      "Epoch 1675/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1600 - accuracy: 0.9667 - val_loss: 0.5300 - val_accuracy: 0.8000\n",
      "Epoch 1676/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.1687 - accuracy: 0.9667 - val_loss: 0.5310 - val_accuracy: 0.8000\n",
      "Epoch 1677/3000\n",
      "30/30 [==============================] - 0s 139us/step - loss: 0.1476 - accuracy: 0.9333 - val_loss: 0.5317 - val_accuracy: 0.8000\n",
      "Epoch 1678/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2357 - accuracy: 0.9000 - val_loss: 0.5372 - val_accuracy: 0.8000\n",
      "Epoch 1679/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2330 - accuracy: 0.9000 - val_loss: 0.5355 - val_accuracy: 0.8000\n",
      "Epoch 1680/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1693 - accuracy: 0.9667 - val_loss: 0.5383 - val_accuracy: 0.8000\n",
      "Epoch 1681/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1696 - accuracy: 0.9000 - val_loss: 0.5365 - val_accuracy: 0.8000\n",
      "Epoch 1682/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.1865 - accuracy: 0.9000 - val_loss: 0.5337 - val_accuracy: 0.8000\n",
      "Epoch 1683/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1490 - accuracy: 0.9667 - val_loss: 0.5271 - val_accuracy: 0.8000\n",
      "Epoch 1684/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0959 - accuracy: 1.0000 - val_loss: 0.5206 - val_accuracy: 0.8000\n",
      "Epoch 1685/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1681 - accuracy: 0.9333 - val_loss: 0.5107 - val_accuracy: 0.8000\n",
      "Epoch 1686/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1771 - accuracy: 0.9000 - val_loss: 0.4955 - val_accuracy: 0.8000\n",
      "Epoch 1687/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.2193 - accuracy: 0.9333 - val_loss: 0.4896 - val_accuracy: 0.8000\n",
      "Epoch 1688/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2191 - accuracy: 0.9000 - val_loss: 0.4836 - val_accuracy: 0.8000\n",
      "Epoch 1689/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1741 - accuracy: 0.9333 - val_loss: 0.4798 - val_accuracy: 0.8000\n",
      "Epoch 1690/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1787 - accuracy: 0.9000 - val_loss: 0.4790 - val_accuracy: 0.8000\n",
      "Epoch 1691/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1532 - accuracy: 1.0000 - val_loss: 0.4849 - val_accuracy: 0.8000\n",
      "Epoch 1692/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.2154 - accuracy: 0.9000 - val_loss: 0.5012 - val_accuracy: 0.7000\n",
      "Epoch 1693/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1752 - accuracy: 0.9333 - val_loss: 0.5191 - val_accuracy: 0.7000\n",
      "Epoch 1694/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2304 - accuracy: 0.8333 - val_loss: 0.5296 - val_accuracy: 0.7000\n",
      "Epoch 1695/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1669 - accuracy: 0.9000 - val_loss: 0.5346 - val_accuracy: 0.7000\n",
      "Epoch 1696/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1609 - accuracy: 0.9333 - val_loss: 0.5362 - val_accuracy: 0.7000\n",
      "Epoch 1697/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1173 - accuracy: 0.9667 - val_loss: 0.5391 - val_accuracy: 0.7000\n",
      "Epoch 1698/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1980 - accuracy: 0.9000 - val_loss: 0.5401 - val_accuracy: 0.7000\n",
      "Epoch 1699/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1112 - accuracy: 1.0000 - val_loss: 0.5402 - val_accuracy: 0.7000\n",
      "Epoch 1700/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1550 - accuracy: 0.9667 - val_loss: 0.5355 - val_accuracy: 0.7000\n",
      "Epoch 1701/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1895 - accuracy: 0.9333 - val_loss: 0.5228 - val_accuracy: 0.7000\n",
      "Epoch 1702/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2423 - accuracy: 0.9333 - val_loss: 0.5013 - val_accuracy: 0.7000\n",
      "Epoch 1703/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1306 - accuracy: 0.9667 - val_loss: 0.4777 - val_accuracy: 0.7000\n",
      "Epoch 1704/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1295 - accuracy: 0.9667 - val_loss: 0.4622 - val_accuracy: 0.8000\n",
      "Epoch 1705/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1862 - accuracy: 0.9000 - val_loss: 0.4524 - val_accuracy: 0.8000\n",
      "Epoch 1706/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1625 - accuracy: 0.9667 - val_loss: 0.4435 - val_accuracy: 0.9000\n",
      "Epoch 1707/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.2011 - accuracy: 0.9000 - val_loss: 0.4396 - val_accuracy: 0.9000\n",
      "Epoch 1708/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1423 - accuracy: 1.0000 - val_loss: 0.4463 - val_accuracy: 0.9000\n",
      "Epoch 1709/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1194 - accuracy: 0.9667 - val_loss: 0.4612 - val_accuracy: 0.9000\n",
      "Epoch 1710/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1996 - accuracy: 0.9000 - val_loss: 0.4901 - val_accuracy: 0.8000\n",
      "Epoch 1711/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1224 - accuracy: 1.0000 - val_loss: 0.5204 - val_accuracy: 0.8000\n",
      "Epoch 1712/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2195 - accuracy: 0.9667 - val_loss: 0.5533 - val_accuracy: 0.7000\n",
      "Epoch 1713/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1256 - accuracy: 0.9667 - val_loss: 0.5843 - val_accuracy: 0.7000\n",
      "Epoch 1714/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1605 - accuracy: 0.9667 - val_loss: 0.6112 - val_accuracy: 0.7000\n",
      "Epoch 1715/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1512 - accuracy: 0.9667 - val_loss: 0.6317 - val_accuracy: 0.7000\n",
      "Epoch 1716/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1794 - accuracy: 0.9000 - val_loss: 0.6399 - val_accuracy: 0.7000\n",
      "Epoch 1717/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1538 - accuracy: 0.9333 - val_loss: 0.6368 - val_accuracy: 0.7000\n",
      "Epoch 1718/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1668 - accuracy: 0.9333 - val_loss: 0.6213 - val_accuracy: 0.7000\n",
      "Epoch 1719/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1118 - accuracy: 0.9667 - val_loss: 0.6015 - val_accuracy: 0.7000\n",
      "Epoch 1720/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1317 - accuracy: 0.9667 - val_loss: 0.5748 - val_accuracy: 0.7000\n",
      "Epoch 1721/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1947 - accuracy: 0.9667 - val_loss: 0.5458 - val_accuracy: 0.7000\n",
      "Epoch 1722/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.1568 - accuracy: 1.0000 - val_loss: 0.5191 - val_accuracy: 0.7000\n",
      "Epoch 1723/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1689 - accuracy: 0.9333 - val_loss: 0.4984 - val_accuracy: 0.7000\n",
      "Epoch 1724/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.2175 - accuracy: 0.8667 - val_loss: 0.4784 - val_accuracy: 0.8000\n",
      "Epoch 1725/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1392 - accuracy: 0.9333 - val_loss: 0.4585 - val_accuracy: 0.9000\n",
      "Epoch 1726/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1158 - accuracy: 1.0000 - val_loss: 0.4432 - val_accuracy: 0.9000\n",
      "Epoch 1727/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1503 - accuracy: 0.9667 - val_loss: 0.4304 - val_accuracy: 0.9000\n",
      "Epoch 1728/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.1502 - accuracy: 0.9667 - val_loss: 0.4249 - val_accuracy: 0.9000\n",
      "Epoch 1729/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1849 - accuracy: 0.9000 - val_loss: 0.4239 - val_accuracy: 0.9000\n",
      "Epoch 1730/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2314 - accuracy: 0.9333 - val_loss: 0.4216 - val_accuracy: 0.9000\n",
      "Epoch 1731/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2147 - accuracy: 0.9000 - val_loss: 0.4293 - val_accuracy: 0.9000\n",
      "Epoch 1732/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1486 - accuracy: 0.9333 - val_loss: 0.4377 - val_accuracy: 0.9000\n",
      "Epoch 1733/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.1724 - accuracy: 0.9333 - val_loss: 0.4519 - val_accuracy: 0.8000\n",
      "Epoch 1734/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1610 - accuracy: 0.9667 - val_loss: 0.4670 - val_accuracy: 0.8000\n",
      "Epoch 1735/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1573 - accuracy: 0.9667 - val_loss: 0.4751 - val_accuracy: 0.7000\n",
      "Epoch 1736/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1733 - accuracy: 0.9667 - val_loss: 0.4778 - val_accuracy: 0.7000\n",
      "Epoch 1737/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1275 - accuracy: 1.0000 - val_loss: 0.4776 - val_accuracy: 0.7000\n",
      "Epoch 1738/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1125 - accuracy: 0.9667 - val_loss: 0.4777 - val_accuracy: 0.7000\n",
      "Epoch 1739/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1539 - accuracy: 0.9667 - val_loss: 0.4786 - val_accuracy: 0.7000\n",
      "Epoch 1740/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1451 - accuracy: 0.9333 - val_loss: 0.4790 - val_accuracy: 0.7000\n",
      "Epoch 1741/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1739 - accuracy: 0.9667 - val_loss: 0.4784 - val_accuracy: 0.7000\n",
      "Epoch 1742/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1851 - accuracy: 0.9333 - val_loss: 0.4851 - val_accuracy: 0.7000\n",
      "Epoch 1743/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1175 - accuracy: 1.0000 - val_loss: 0.4958 - val_accuracy: 0.7000\n",
      "Epoch 1744/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1347 - accuracy: 1.0000 - val_loss: 0.5039 - val_accuracy: 0.7000\n",
      "Epoch 1745/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1957 - accuracy: 0.9333 - val_loss: 0.5019 - val_accuracy: 0.7000\n",
      "Epoch 1746/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1378 - accuracy: 0.9333 - val_loss: 0.4915 - val_accuracy: 0.7000\n",
      "Epoch 1747/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1264 - accuracy: 0.9667 - val_loss: 0.4837 - val_accuracy: 0.7000\n",
      "Epoch 1748/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1635 - accuracy: 0.9667 - val_loss: 0.4831 - val_accuracy: 0.7000\n",
      "Epoch 1749/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1957 - accuracy: 0.9333 - val_loss: 0.4788 - val_accuracy: 0.7000\n",
      "Epoch 1750/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2058 - accuracy: 0.9333 - val_loss: 0.4657 - val_accuracy: 0.7000\n",
      "Epoch 1751/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2407 - accuracy: 0.9333 - val_loss: 0.4538 - val_accuracy: 0.8000\n",
      "Epoch 1752/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1318 - accuracy: 0.9667 - val_loss: 0.4360 - val_accuracy: 0.9000\n",
      "Epoch 1753/3000\n",
      "30/30 [==============================] - 0s 154us/step - loss: 0.1623 - accuracy: 0.9333 - val_loss: 0.4251 - val_accuracy: 0.9000\n",
      "Epoch 1754/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1424 - accuracy: 0.9333 - val_loss: 0.4211 - val_accuracy: 0.9000\n",
      "Epoch 1755/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1708 - accuracy: 0.9667 - val_loss: 0.4218 - val_accuracy: 0.9000\n",
      "Epoch 1756/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1402 - accuracy: 0.9667 - val_loss: 0.4247 - val_accuracy: 0.9000\n",
      "Epoch 1757/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1986 - accuracy: 0.9333 - val_loss: 0.4295 - val_accuracy: 0.9000\n",
      "Epoch 1758/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1688 - accuracy: 0.9333 - val_loss: 0.4427 - val_accuracy: 0.8000\n",
      "Epoch 1759/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1753 - accuracy: 0.9333 - val_loss: 0.4612 - val_accuracy: 0.8000\n",
      "Epoch 1760/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1825 - accuracy: 0.9333 - val_loss: 0.4724 - val_accuracy: 0.8000\n",
      "Epoch 1761/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1639 - accuracy: 0.9333 - val_loss: 0.4932 - val_accuracy: 0.8000\n",
      "Epoch 1762/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1331 - accuracy: 0.9333 - val_loss: 0.5157 - val_accuracy: 0.8000\n",
      "Epoch 1763/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.1483 - accuracy: 0.9667 - val_loss: 0.5380 - val_accuracy: 0.7000\n",
      "Epoch 1764/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1606 - accuracy: 0.9333 - val_loss: 0.5557 - val_accuracy: 0.7000\n",
      "Epoch 1765/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1998 - accuracy: 0.9333 - val_loss: 0.5530 - val_accuracy: 0.7000\n",
      "Epoch 1766/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1708 - accuracy: 0.9000 - val_loss: 0.5430 - val_accuracy: 0.7000\n",
      "Epoch 1767/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1541 - accuracy: 0.9333 - val_loss: 0.5296 - val_accuracy: 0.7000\n",
      "Epoch 1768/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1290 - accuracy: 0.9667 - val_loss: 0.5061 - val_accuracy: 0.7000\n",
      "Epoch 1769/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1306 - accuracy: 0.9667 - val_loss: 0.4752 - val_accuracy: 0.7000\n",
      "Epoch 1770/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1878 - accuracy: 0.9333 - val_loss: 0.4479 - val_accuracy: 0.8000\n",
      "Epoch 1771/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1453 - accuracy: 0.9667 - val_loss: 0.4319 - val_accuracy: 0.9000\n",
      "Epoch 1772/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1952 - accuracy: 0.9333 - val_loss: 0.4215 - val_accuracy: 0.9000\n",
      "Epoch 1773/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1216 - accuracy: 0.9667 - val_loss: 0.4140 - val_accuracy: 0.9000\n",
      "Epoch 1774/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1910 - accuracy: 0.9333 - val_loss: 0.4069 - val_accuracy: 0.9000\n",
      "Epoch 1775/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1678 - accuracy: 0.9333 - val_loss: 0.4075 - val_accuracy: 0.9000\n",
      "Epoch 1776/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2020 - accuracy: 0.9333 - val_loss: 0.4119 - val_accuracy: 0.9000\n",
      "Epoch 1777/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1503 - accuracy: 0.9333 - val_loss: 0.4241 - val_accuracy: 0.9000\n",
      "Epoch 1778/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1509 - accuracy: 0.9333 - val_loss: 0.4369 - val_accuracy: 0.8000\n",
      "Epoch 1779/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1258 - accuracy: 0.9667 - val_loss: 0.4482 - val_accuracy: 0.8000\n",
      "Epoch 1780/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.2466 - accuracy: 0.9000 - val_loss: 0.4463 - val_accuracy: 0.8000\n",
      "Epoch 1781/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.1391 - accuracy: 0.9667 - val_loss: 0.4516 - val_accuracy: 0.8000\n",
      "Epoch 1782/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.0895 - accuracy: 1.0000 - val_loss: 0.4562 - val_accuracy: 0.7000\n",
      "Epoch 1783/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1421 - accuracy: 0.9333 - val_loss: 0.4598 - val_accuracy: 0.7000\n",
      "Epoch 1784/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1413 - accuracy: 0.9667 - val_loss: 0.4637 - val_accuracy: 0.7000\n",
      "Epoch 1785/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1227 - accuracy: 0.9667 - val_loss: 0.4710 - val_accuracy: 0.7000\n",
      "Epoch 1786/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1580 - accuracy: 0.9667 - val_loss: 0.4771 - val_accuracy: 0.7000\n",
      "Epoch 1787/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1857 - accuracy: 0.9667 - val_loss: 0.4764 - val_accuracy: 0.7000\n",
      "Epoch 1788/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1939 - accuracy: 0.9667 - val_loss: 0.4674 - val_accuracy: 0.7000\n",
      "Epoch 1789/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1512 - accuracy: 0.9667 - val_loss: 0.4559 - val_accuracy: 0.9000\n",
      "Epoch 1790/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1764 - accuracy: 0.9000 - val_loss: 0.4465 - val_accuracy: 0.9000\n",
      "Epoch 1791/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1517 - accuracy: 1.0000 - val_loss: 0.4395 - val_accuracy: 0.9000\n",
      "Epoch 1792/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1832 - accuracy: 0.8667 - val_loss: 0.4372 - val_accuracy: 0.9000\n",
      "Epoch 1793/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1495 - accuracy: 0.9667 - val_loss: 0.4382 - val_accuracy: 0.9000\n",
      "Epoch 1794/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1620 - accuracy: 0.9333 - val_loss: 0.4464 - val_accuracy: 0.9000\n",
      "Epoch 1795/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1162 - accuracy: 0.9667 - val_loss: 0.4601 - val_accuracy: 0.8000\n",
      "Epoch 1796/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.1503 - accuracy: 0.9667 - val_loss: 0.4707 - val_accuracy: 0.8000\n",
      "Epoch 1797/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1725 - accuracy: 0.9333 - val_loss: 0.4756 - val_accuracy: 0.8000\n",
      "Epoch 1798/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1290 - accuracy: 0.9667 - val_loss: 0.4815 - val_accuracy: 0.8000\n",
      "Epoch 1799/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1320 - accuracy: 0.9333 - val_loss: 0.4900 - val_accuracy: 0.7000\n",
      "Epoch 1800/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.1741 - accuracy: 0.9667 - val_loss: 0.4890 - val_accuracy: 0.7000\n",
      "Epoch 1801/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1209 - accuracy: 1.0000 - val_loss: 0.4880 - val_accuracy: 0.7000\n",
      "Epoch 1802/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1692 - accuracy: 0.9333 - val_loss: 0.4797 - val_accuracy: 0.8000\n",
      "Epoch 1803/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1508 - accuracy: 0.9667 - val_loss: 0.4740 - val_accuracy: 0.8000\n",
      "Epoch 1804/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1136 - accuracy: 1.0000 - val_loss: 0.4717 - val_accuracy: 0.8000\n",
      "Epoch 1805/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1148 - accuracy: 0.9667 - val_loss: 0.4770 - val_accuracy: 0.7000\n",
      "Epoch 1806/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1873 - accuracy: 0.9000 - val_loss: 0.4790 - val_accuracy: 0.7000\n",
      "Epoch 1807/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1348 - accuracy: 0.9333 - val_loss: 0.4799 - val_accuracy: 0.7000\n",
      "Epoch 1808/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1182 - accuracy: 1.0000 - val_loss: 0.4774 - val_accuracy: 0.7000\n",
      "Epoch 1809/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1302 - accuracy: 0.9333 - val_loss: 0.4787 - val_accuracy: 0.7000\n",
      "Epoch 1810/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1448 - accuracy: 0.9667 - val_loss: 0.4781 - val_accuracy: 0.7000\n",
      "Epoch 1811/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1391 - accuracy: 0.9667 - val_loss: 0.4827 - val_accuracy: 0.7000\n",
      "Epoch 1812/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1358 - accuracy: 0.9333 - val_loss: 0.4869 - val_accuracy: 0.7000\n",
      "Epoch 1813/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0953 - accuracy: 1.0000 - val_loss: 0.4838 - val_accuracy: 0.7000\n",
      "Epoch 1814/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1324 - accuracy: 0.9667 - val_loss: 0.4768 - val_accuracy: 0.7000\n",
      "Epoch 1815/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1524 - accuracy: 0.9667 - val_loss: 0.4659 - val_accuracy: 0.7000\n",
      "Epoch 1816/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1741 - accuracy: 0.9667 - val_loss: 0.4494 - val_accuracy: 0.8000\n",
      "Epoch 1817/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.2234 - accuracy: 0.9000 - val_loss: 0.4349 - val_accuracy: 0.8000\n",
      "Epoch 1818/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2475 - accuracy: 0.9333 - val_loss: 0.4142 - val_accuracy: 0.9000\n",
      "Epoch 1819/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1599 - accuracy: 0.9000 - val_loss: 0.4022 - val_accuracy: 0.9000\n",
      "Epoch 1820/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1658 - accuracy: 0.9000 - val_loss: 0.4025 - val_accuracy: 0.9000\n",
      "Epoch 1821/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0803 - accuracy: 1.0000 - val_loss: 0.4008 - val_accuracy: 0.9000\n",
      "Epoch 1822/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1226 - accuracy: 0.9667 - val_loss: 0.4040 - val_accuracy: 0.9000\n",
      "Epoch 1823/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.2010 - accuracy: 0.9333 - val_loss: 0.4134 - val_accuracy: 0.9000\n",
      "Epoch 1824/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.0957 - accuracy: 1.0000 - val_loss: 0.4229 - val_accuracy: 0.8000\n",
      "Epoch 1825/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1329 - accuracy: 1.0000 - val_loss: 0.4394 - val_accuracy: 0.8000\n",
      "Epoch 1826/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.2061 - accuracy: 0.9333 - val_loss: 0.4724 - val_accuracy: 0.8000\n",
      "Epoch 1827/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1355 - accuracy: 0.9667 - val_loss: 0.5051 - val_accuracy: 0.7000\n",
      "Epoch 1828/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2195 - accuracy: 0.9000 - val_loss: 0.5058 - val_accuracy: 0.7000\n",
      "Epoch 1829/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1732 - accuracy: 0.9333 - val_loss: 0.4993 - val_accuracy: 0.7000\n",
      "Epoch 1830/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1442 - accuracy: 0.9333 - val_loss: 0.4867 - val_accuracy: 0.7000\n",
      "Epoch 1831/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1649 - accuracy: 0.9667 - val_loss: 0.4621 - val_accuracy: 0.8000\n",
      "Epoch 1832/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1752 - accuracy: 0.9333 - val_loss: 0.4269 - val_accuracy: 0.8000\n",
      "Epoch 1833/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1674 - accuracy: 0.9333 - val_loss: 0.3968 - val_accuracy: 0.9000\n",
      "Epoch 1834/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1453 - accuracy: 0.9333 - val_loss: 0.3729 - val_accuracy: 0.9000\n",
      "Epoch 1835/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1522 - accuracy: 0.9333 - val_loss: 0.3502 - val_accuracy: 0.9000\n",
      "Epoch 1836/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1598 - accuracy: 0.9000 - val_loss: 0.3313 - val_accuracy: 0.9000\n",
      "Epoch 1837/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2139 - accuracy: 0.9333 - val_loss: 0.3242 - val_accuracy: 0.9000\n",
      "Epoch 1838/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1257 - accuracy: 1.0000 - val_loss: 0.3227 - val_accuracy: 0.9000\n",
      "Epoch 1839/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.2060 - accuracy: 0.9000 - val_loss: 0.3364 - val_accuracy: 0.9000\n",
      "Epoch 1840/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1454 - accuracy: 0.9333 - val_loss: 0.3571 - val_accuracy: 0.9000\n",
      "Epoch 1841/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.2025 - accuracy: 0.9000 - val_loss: 0.3905 - val_accuracy: 0.9000\n",
      "Epoch 1842/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1577 - accuracy: 0.9333 - val_loss: 0.4224 - val_accuracy: 0.8000\n",
      "Epoch 1843/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1529 - accuracy: 0.9333 - val_loss: 0.4494 - val_accuracy: 0.7000\n",
      "Epoch 1844/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1421 - accuracy: 0.9667 - val_loss: 0.4794 - val_accuracy: 0.7000\n",
      "Epoch 1845/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1599 - accuracy: 0.9667 - val_loss: 0.5069 - val_accuracy: 0.7000\n",
      "Epoch 1846/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1893 - accuracy: 0.9667 - val_loss: 0.5243 - val_accuracy: 0.7000\n",
      "Epoch 1847/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1477 - accuracy: 0.9333 - val_loss: 0.5197 - val_accuracy: 0.7000\n",
      "Epoch 1848/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.0967 - accuracy: 0.9667 - val_loss: 0.4980 - val_accuracy: 0.7000\n",
      "Epoch 1849/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.2219 - accuracy: 0.9000 - val_loss: 0.4681 - val_accuracy: 0.7000\n",
      "Epoch 1850/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1407 - accuracy: 0.9667 - val_loss: 0.4381 - val_accuracy: 0.7000\n",
      "Epoch 1851/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0988 - accuracy: 1.0000 - val_loss: 0.4036 - val_accuracy: 0.9000\n",
      "Epoch 1852/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1874 - accuracy: 0.9333 - val_loss: 0.3749 - val_accuracy: 0.9000\n",
      "Epoch 1853/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1269 - accuracy: 0.9667 - val_loss: 0.3562 - val_accuracy: 0.9000\n",
      "Epoch 1854/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1803 - accuracy: 0.9333 - val_loss: 0.3467 - val_accuracy: 0.9000\n",
      "Epoch 1855/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1909 - accuracy: 0.9667 - val_loss: 0.3447 - val_accuracy: 0.9000\n",
      "Epoch 1856/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1796 - accuracy: 0.9333 - val_loss: 0.3449 - val_accuracy: 0.9000\n",
      "Epoch 1857/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.2444 - accuracy: 0.9333 - val_loss: 0.3499 - val_accuracy: 0.8000\n",
      "Epoch 1858/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1127 - accuracy: 1.0000 - val_loss: 0.3584 - val_accuracy: 0.8000\n",
      "Epoch 1859/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1556 - accuracy: 0.9333 - val_loss: 0.3748 - val_accuracy: 0.9000\n",
      "Epoch 1860/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1751 - accuracy: 0.9333 - val_loss: 0.3926 - val_accuracy: 0.9000\n",
      "Epoch 1861/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1600 - accuracy: 0.9333 - val_loss: 0.4094 - val_accuracy: 0.9000\n",
      "Epoch 1862/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1334 - accuracy: 0.9667 - val_loss: 0.4284 - val_accuracy: 0.9000\n",
      "Epoch 1863/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.1183 - accuracy: 1.0000 - val_loss: 0.4478 - val_accuracy: 0.8000\n",
      "Epoch 1864/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1934 - accuracy: 0.9667 - val_loss: 0.4653 - val_accuracy: 0.8000\n",
      "Epoch 1865/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1941 - accuracy: 0.9333 - val_loss: 0.4726 - val_accuracy: 0.8000\n",
      "Epoch 1866/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1515 - accuracy: 0.9667 - val_loss: 0.4847 - val_accuracy: 0.8000\n",
      "Epoch 1867/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1045 - accuracy: 0.9667 - val_loss: 0.4941 - val_accuracy: 0.8000\n",
      "Epoch 1868/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1356 - accuracy: 1.0000 - val_loss: 0.4982 - val_accuracy: 0.8000\n",
      "Epoch 1869/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1484 - accuracy: 0.9667 - val_loss: 0.5103 - val_accuracy: 0.8000\n",
      "Epoch 1870/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1625 - accuracy: 0.9667 - val_loss: 0.5192 - val_accuracy: 0.7000\n",
      "Epoch 1871/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1613 - accuracy: 0.9333 - val_loss: 0.5069 - val_accuracy: 0.7000\n",
      "Epoch 1872/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0958 - accuracy: 1.0000 - val_loss: 0.4969 - val_accuracy: 0.7000\n",
      "Epoch 1873/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.1509 - accuracy: 0.9333 - val_loss: 0.4791 - val_accuracy: 0.8000\n",
      "Epoch 1874/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1603 - accuracy: 0.9667 - val_loss: 0.4567 - val_accuracy: 0.8000\n",
      "Epoch 1875/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1324 - accuracy: 0.9333 - val_loss: 0.4367 - val_accuracy: 0.9000\n",
      "Epoch 1876/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1361 - accuracy: 0.9667 - val_loss: 0.4171 - val_accuracy: 0.9000\n",
      "Epoch 1877/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.1331 - accuracy: 0.9333 - val_loss: 0.4000 - val_accuracy: 0.9000\n",
      "Epoch 1878/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1367 - accuracy: 0.9667 - val_loss: 0.3887 - val_accuracy: 0.9000\n",
      "Epoch 1879/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1282 - accuracy: 0.9667 - val_loss: 0.3818 - val_accuracy: 0.9000\n",
      "Epoch 1880/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1427 - accuracy: 1.0000 - val_loss: 0.3845 - val_accuracy: 0.9000\n",
      "Epoch 1881/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1546 - accuracy: 0.9667 - val_loss: 0.3862 - val_accuracy: 0.9000\n",
      "Epoch 1882/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1605 - accuracy: 0.9667 - val_loss: 0.3984 - val_accuracy: 0.9000\n",
      "Epoch 1883/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1567 - accuracy: 0.9000 - val_loss: 0.4166 - val_accuracy: 0.9000\n",
      "Epoch 1884/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1104 - accuracy: 0.9667 - val_loss: 0.4373 - val_accuracy: 0.8000\n",
      "Epoch 1885/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1658 - accuracy: 0.9333 - val_loss: 0.4524 - val_accuracy: 0.7000\n",
      "Epoch 1886/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1296 - accuracy: 0.9667 - val_loss: 0.4701 - val_accuracy: 0.7000\n",
      "Epoch 1887/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1262 - accuracy: 0.9667 - val_loss: 0.4861 - val_accuracy: 0.7000\n",
      "Epoch 1888/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1268 - accuracy: 0.9667 - val_loss: 0.4989 - val_accuracy: 0.7000\n",
      "Epoch 1889/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1739 - accuracy: 0.9333 - val_loss: 0.5046 - val_accuracy: 0.7000\n",
      "Epoch 1890/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1327 - accuracy: 0.9667 - val_loss: 0.4923 - val_accuracy: 0.7000\n",
      "Epoch 1891/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1359 - accuracy: 0.9667 - val_loss: 0.4628 - val_accuracy: 0.7000\n",
      "Epoch 1892/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1078 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.8000\n",
      "Epoch 1893/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1237 - accuracy: 0.9333 - val_loss: 0.4069 - val_accuracy: 0.8000\n",
      "Epoch 1894/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1690 - accuracy: 0.9333 - val_loss: 0.3736 - val_accuracy: 0.9000\n",
      "Epoch 1895/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1696 - accuracy: 0.9667 - val_loss: 0.3445 - val_accuracy: 0.9000\n",
      "Epoch 1896/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1868 - accuracy: 0.9000 - val_loss: 0.3271 - val_accuracy: 0.9000\n",
      "Epoch 1897/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1252 - accuracy: 0.9667 - val_loss: 0.3203 - val_accuracy: 0.9000\n",
      "Epoch 1898/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1403 - accuracy: 0.9333 - val_loss: 0.3197 - val_accuracy: 0.9000\n",
      "Epoch 1899/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1207 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.9000\n",
      "Epoch 1900/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.2165 - accuracy: 0.9000 - val_loss: 0.3499 - val_accuracy: 0.9000\n",
      "Epoch 1901/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1952 - accuracy: 0.9000 - val_loss: 0.3721 - val_accuracy: 0.9000\n",
      "Epoch 1902/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1596 - accuracy: 0.9333 - val_loss: 0.3956 - val_accuracy: 0.9000\n",
      "Epoch 1903/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1398 - accuracy: 0.9667 - val_loss: 0.4232 - val_accuracy: 0.9000\n",
      "Epoch 1904/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1085 - accuracy: 0.9667 - val_loss: 0.4513 - val_accuracy: 0.8000\n",
      "Epoch 1905/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1212 - accuracy: 0.9667 - val_loss: 0.4709 - val_accuracy: 0.7000\n",
      "Epoch 1906/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1467 - accuracy: 0.9667 - val_loss: 0.4800 - val_accuracy: 0.8000\n",
      "Epoch 1907/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1134 - accuracy: 1.0000 - val_loss: 0.4907 - val_accuracy: 0.7000\n",
      "Epoch 1908/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1891 - accuracy: 0.9667 - val_loss: 0.4913 - val_accuracy: 0.8000\n",
      "Epoch 1909/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0913 - accuracy: 0.9667 - val_loss: 0.4853 - val_accuracy: 0.8000\n",
      "Epoch 1910/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1530 - accuracy: 0.9333 - val_loss: 0.4767 - val_accuracy: 0.8000\n",
      "Epoch 1911/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1297 - accuracy: 0.9667 - val_loss: 0.4661 - val_accuracy: 0.8000\n",
      "Epoch 1912/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.0980 - accuracy: 1.0000 - val_loss: 0.4519 - val_accuracy: 0.8000\n",
      "Epoch 1913/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1364 - accuracy: 0.9667 - val_loss: 0.4378 - val_accuracy: 0.8000\n",
      "Epoch 1914/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1312 - accuracy: 0.9667 - val_loss: 0.4187 - val_accuracy: 0.9000\n",
      "Epoch 1915/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1816 - accuracy: 0.9000 - val_loss: 0.3977 - val_accuracy: 0.9000\n",
      "Epoch 1916/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1272 - accuracy: 1.0000 - val_loss: 0.3836 - val_accuracy: 0.9000\n",
      "Epoch 1917/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1546 - accuracy: 0.9333 - val_loss: 0.3736 - val_accuracy: 0.8000\n",
      "Epoch 1918/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0962 - accuracy: 0.9667 - val_loss: 0.3664 - val_accuracy: 0.8000\n",
      "Epoch 1919/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1340 - accuracy: 0.9667 - val_loss: 0.3676 - val_accuracy: 0.8000\n",
      "Epoch 1920/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1179 - accuracy: 0.9667 - val_loss: 0.3705 - val_accuracy: 0.8000\n",
      "Epoch 1921/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1569 - accuracy: 0.9667 - val_loss: 0.3778 - val_accuracy: 0.9000\n",
      "Epoch 1922/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1543 - accuracy: 0.9000 - val_loss: 0.3866 - val_accuracy: 0.9000\n",
      "Epoch 1923/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1400 - accuracy: 0.9667 - val_loss: 0.4040 - val_accuracy: 0.9000\n",
      "Epoch 1924/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1612 - accuracy: 0.9000 - val_loss: 0.4294 - val_accuracy: 0.9000\n",
      "Epoch 1925/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1746 - accuracy: 0.9333 - val_loss: 0.4550 - val_accuracy: 0.8000\n",
      "Epoch 1926/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1765 - accuracy: 0.9333 - val_loss: 0.4717 - val_accuracy: 0.8000\n",
      "Epoch 1927/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1616 - accuracy: 0.9333 - val_loss: 0.4840 - val_accuracy: 0.7000\n",
      "Epoch 1928/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1231 - accuracy: 0.9667 - val_loss: 0.4933 - val_accuracy: 0.7000\n",
      "Epoch 1929/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1466 - accuracy: 0.9667 - val_loss: 0.4980 - val_accuracy: 0.7000\n",
      "Epoch 1930/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1724 - accuracy: 0.9333 - val_loss: 0.4853 - val_accuracy: 0.7000\n",
      "Epoch 1931/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1625 - accuracy: 0.9000 - val_loss: 0.4597 - val_accuracy: 0.7000\n",
      "Epoch 1932/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1414 - accuracy: 0.9333 - val_loss: 0.4253 - val_accuracy: 0.9000\n",
      "Epoch 1933/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1707 - accuracy: 0.9333 - val_loss: 0.3898 - val_accuracy: 0.9000\n",
      "Epoch 1934/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1450 - accuracy: 0.9333 - val_loss: 0.3572 - val_accuracy: 0.9000\n",
      "Epoch 1935/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1079 - accuracy: 0.9667 - val_loss: 0.3337 - val_accuracy: 0.9000\n",
      "Epoch 1936/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1372 - accuracy: 0.9667 - val_loss: 0.3137 - val_accuracy: 0.9000\n",
      "Epoch 1937/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1770 - accuracy: 0.9667 - val_loss: 0.2996 - val_accuracy: 0.9000\n",
      "Epoch 1938/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1758 - accuracy: 0.9000 - val_loss: 0.3022 - val_accuracy: 0.9000\n",
      "Epoch 1939/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1490 - accuracy: 0.9333 - val_loss: 0.3143 - val_accuracy: 0.9000\n",
      "Epoch 1940/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1493 - accuracy: 0.9667 - val_loss: 0.3331 - val_accuracy: 0.9000\n",
      "Epoch 1941/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0996 - accuracy: 0.9667 - val_loss: 0.3532 - val_accuracy: 0.9000\n",
      "Epoch 1942/3000\n",
      "30/30 [==============================] - 0s 148us/step - loss: 0.1998 - accuracy: 0.9333 - val_loss: 0.3712 - val_accuracy: 0.9000\n",
      "Epoch 1943/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1878 - accuracy: 0.9333 - val_loss: 0.3829 - val_accuracy: 0.9000\n",
      "Epoch 1944/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1795 - accuracy: 0.9333 - val_loss: 0.4008 - val_accuracy: 0.9000\n",
      "Epoch 1945/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1290 - accuracy: 1.0000 - val_loss: 0.4251 - val_accuracy: 0.8000\n",
      "Epoch 1946/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1290 - accuracy: 0.9667 - val_loss: 0.4379 - val_accuracy: 0.8000\n",
      "Epoch 1947/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1487 - accuracy: 0.9667 - val_loss: 0.4395 - val_accuracy: 0.8000\n",
      "Epoch 1948/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1405 - accuracy: 0.9333 - val_loss: 0.4374 - val_accuracy: 0.8000\n",
      "Epoch 1949/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1909 - accuracy: 0.9000 - val_loss: 0.4244 - val_accuracy: 0.8000\n",
      "Epoch 1950/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1603 - accuracy: 0.9667 - val_loss: 0.3986 - val_accuracy: 0.9000\n",
      "Epoch 1951/3000\n",
      "30/30 [==============================] - 0s 147us/step - loss: 0.1690 - accuracy: 0.9333 - val_loss: 0.3683 - val_accuracy: 0.9000\n",
      "Epoch 1952/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1517 - accuracy: 0.9333 - val_loss: 0.3441 - val_accuracy: 0.9000\n",
      "Epoch 1953/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1115 - accuracy: 0.9667 - val_loss: 0.3275 - val_accuracy: 0.9000\n",
      "Epoch 1954/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0906 - accuracy: 1.0000 - val_loss: 0.3151 - val_accuracy: 0.9000\n",
      "Epoch 1955/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1540 - accuracy: 0.9667 - val_loss: 0.3084 - val_accuracy: 0.9000\n",
      "Epoch 1956/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1731 - accuracy: 0.9000 - val_loss: 0.3120 - val_accuracy: 0.9000\n",
      "Epoch 1957/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1219 - accuracy: 0.9667 - val_loss: 0.3241 - val_accuracy: 0.9000\n",
      "Epoch 1958/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1330 - accuracy: 0.9333 - val_loss: 0.3427 - val_accuracy: 0.9000\n",
      "Epoch 1959/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0962 - accuracy: 1.0000 - val_loss: 0.3653 - val_accuracy: 0.9000\n",
      "Epoch 1960/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1126 - accuracy: 0.9667 - val_loss: 0.3937 - val_accuracy: 0.9000\n",
      "Epoch 1961/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1837 - accuracy: 0.9000 - val_loss: 0.4236 - val_accuracy: 0.8000\n",
      "Epoch 1962/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1900 - accuracy: 0.9333 - val_loss: 0.4359 - val_accuracy: 0.8000\n",
      "Epoch 1963/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1648 - accuracy: 0.9667 - val_loss: 0.4313 - val_accuracy: 0.8000\n",
      "Epoch 1964/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1463 - accuracy: 0.9667 - val_loss: 0.4180 - val_accuracy: 0.8000\n",
      "Epoch 1965/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1030 - accuracy: 0.9667 - val_loss: 0.4059 - val_accuracy: 0.9000\n",
      "Epoch 1966/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1521 - accuracy: 0.9333 - val_loss: 0.3910 - val_accuracy: 0.9000\n",
      "Epoch 1967/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0804 - accuracy: 1.0000 - val_loss: 0.3756 - val_accuracy: 0.9000\n",
      "Epoch 1968/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1482 - accuracy: 0.9333 - val_loss: 0.3636 - val_accuracy: 0.9000\n",
      "Epoch 1969/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1543 - accuracy: 0.9667 - val_loss: 0.3554 - val_accuracy: 0.9000\n",
      "Epoch 1970/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1501 - accuracy: 0.9333 - val_loss: 0.3521 - val_accuracy: 0.9000\n",
      "Epoch 1971/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1123 - accuracy: 0.9667 - val_loss: 0.3569 - val_accuracy: 0.9000\n",
      "Epoch 1972/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1199 - accuracy: 0.9667 - val_loss: 0.3628 - val_accuracy: 0.9000\n",
      "Epoch 1973/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2067 - accuracy: 0.9333 - val_loss: 0.3721 - val_accuracy: 0.9000\n",
      "Epoch 1974/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1317 - accuracy: 0.9333 - val_loss: 0.3772 - val_accuracy: 0.9000\n",
      "Epoch 1975/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1083 - accuracy: 0.9667 - val_loss: 0.3871 - val_accuracy: 0.9000\n",
      "Epoch 1976/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0888 - accuracy: 0.9667 - val_loss: 0.3981 - val_accuracy: 0.9000\n",
      "Epoch 1977/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1298 - accuracy: 0.9667 - val_loss: 0.4069 - val_accuracy: 0.9000\n",
      "Epoch 1978/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1470 - accuracy: 0.9667 - val_loss: 0.4063 - val_accuracy: 0.8000\n",
      "Epoch 1979/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1384 - accuracy: 0.9333 - val_loss: 0.4003 - val_accuracy: 0.9000\n",
      "Epoch 1980/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1280 - accuracy: 0.9667 - val_loss: 0.3961 - val_accuracy: 0.9000\n",
      "Epoch 1981/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1216 - accuracy: 0.9333 - val_loss: 0.3921 - val_accuracy: 0.9000\n",
      "Epoch 1982/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1086 - accuracy: 0.9667 - val_loss: 0.3854 - val_accuracy: 0.9000\n",
      "Epoch 1983/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1334 - accuracy: 0.9667 - val_loss: 0.3824 - val_accuracy: 0.9000\n",
      "Epoch 1984/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1676 - accuracy: 0.9333 - val_loss: 0.3712 - val_accuracy: 0.9000\n",
      "Epoch 1985/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1051 - accuracy: 0.9667 - val_loss: 0.3613 - val_accuracy: 0.9000\n",
      "Epoch 1986/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1162 - accuracy: 0.9667 - val_loss: 0.3507 - val_accuracy: 0.9000\n",
      "Epoch 1987/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1314 - accuracy: 1.0000 - val_loss: 0.3371 - val_accuracy: 0.9000\n",
      "Epoch 1988/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1823 - accuracy: 0.9333 - val_loss: 0.3254 - val_accuracy: 0.9000\n",
      "Epoch 1989/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1424 - accuracy: 0.9667 - val_loss: 0.3196 - val_accuracy: 0.9000\n",
      "Epoch 1990/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1575 - accuracy: 0.9333 - val_loss: 0.3179 - val_accuracy: 0.9000\n",
      "Epoch 1991/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1272 - accuracy: 0.9333 - val_loss: 0.3170 - val_accuracy: 0.9000\n",
      "Epoch 1992/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1029 - accuracy: 0.9667 - val_loss: 0.3228 - val_accuracy: 0.9000\n",
      "Epoch 1993/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0917 - accuracy: 1.0000 - val_loss: 0.3299 - val_accuracy: 0.9000\n",
      "Epoch 1994/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1237 - accuracy: 0.9667 - val_loss: 0.3380 - val_accuracy: 0.9000\n",
      "Epoch 1995/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1119 - accuracy: 1.0000 - val_loss: 0.3459 - val_accuracy: 0.9000\n",
      "Epoch 1996/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1693 - accuracy: 0.9000 - val_loss: 0.3504 - val_accuracy: 0.8000\n",
      "Epoch 1997/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1308 - accuracy: 0.9667 - val_loss: 0.3504 - val_accuracy: 0.8000\n",
      "Epoch 1998/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0938 - accuracy: 1.0000 - val_loss: 0.3458 - val_accuracy: 0.8000\n",
      "Epoch 1999/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1341 - accuracy: 0.9667 - val_loss: 0.3370 - val_accuracy: 0.8000\n",
      "Epoch 2000/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1530 - accuracy: 0.9667 - val_loss: 0.3317 - val_accuracy: 0.8000\n",
      "Epoch 2001/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1272 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.8000\n",
      "Epoch 2002/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1491 - accuracy: 0.9333 - val_loss: 0.3374 - val_accuracy: 0.8000\n",
      "Epoch 2003/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1728 - accuracy: 0.9333 - val_loss: 0.3482 - val_accuracy: 0.8000\n",
      "Epoch 2004/3000\n",
      "30/30 [==============================] - 0s 160us/step - loss: 0.1279 - accuracy: 0.9667 - val_loss: 0.3545 - val_accuracy: 0.8000\n",
      "Epoch 2005/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1278 - accuracy: 0.9667 - val_loss: 0.3516 - val_accuracy: 0.8000\n",
      "Epoch 2006/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1307 - accuracy: 0.9333 - val_loss: 0.3433 - val_accuracy: 0.8000\n",
      "Epoch 2007/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1530 - accuracy: 0.9333 - val_loss: 0.3393 - val_accuracy: 0.8000\n",
      "Epoch 2008/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1460 - accuracy: 0.9333 - val_loss: 0.3283 - val_accuracy: 0.8000\n",
      "Epoch 2009/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1695 - accuracy: 0.9333 - val_loss: 0.3149 - val_accuracy: 0.9000\n",
      "Epoch 2010/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1545 - accuracy: 0.9333 - val_loss: 0.3058 - val_accuracy: 0.9000\n",
      "Epoch 2011/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1539 - accuracy: 0.9333 - val_loss: 0.2976 - val_accuracy: 0.9000\n",
      "Epoch 2012/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1435 - accuracy: 0.9667 - val_loss: 0.2937 - val_accuracy: 0.9000\n",
      "Epoch 2013/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1705 - accuracy: 0.9333 - val_loss: 0.2839 - val_accuracy: 0.9000\n",
      "Epoch 2014/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1918 - accuracy: 0.9000 - val_loss: 0.2827 - val_accuracy: 0.9000\n",
      "Epoch 2015/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1310 - accuracy: 0.9667 - val_loss: 0.2885 - val_accuracy: 0.9000\n",
      "Epoch 2016/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1760 - accuracy: 0.9333 - val_loss: 0.2966 - val_accuracy: 0.9000\n",
      "Epoch 2017/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1519 - accuracy: 0.9333 - val_loss: 0.3168 - val_accuracy: 0.9000\n",
      "Epoch 2018/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1767 - accuracy: 0.9333 - val_loss: 0.3415 - val_accuracy: 0.9000\n",
      "Epoch 2019/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1433 - accuracy: 0.9667 - val_loss: 0.3680 - val_accuracy: 0.9000\n",
      "Epoch 2020/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1620 - accuracy: 0.9333 - val_loss: 0.3861 - val_accuracy: 0.8000\n",
      "Epoch 2021/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1303 - accuracy: 0.9333 - val_loss: 0.3958 - val_accuracy: 0.8000\n",
      "Epoch 2022/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1254 - accuracy: 0.9667 - val_loss: 0.3925 - val_accuracy: 0.9000\n",
      "Epoch 2023/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1109 - accuracy: 1.0000 - val_loss: 0.3842 - val_accuracy: 0.9000\n",
      "Epoch 2024/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1322 - accuracy: 1.0000 - val_loss: 0.3726 - val_accuracy: 0.9000\n",
      "Epoch 2025/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1132 - accuracy: 0.9667 - val_loss: 0.3591 - val_accuracy: 0.9000\n",
      "Epoch 2026/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1293 - accuracy: 0.9667 - val_loss: 0.3385 - val_accuracy: 0.9000\n",
      "Epoch 2027/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1292 - accuracy: 0.9667 - val_loss: 0.3272 - val_accuracy: 0.9000\n",
      "Epoch 2028/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1471 - accuracy: 0.9333 - val_loss: 0.3151 - val_accuracy: 0.9000\n",
      "Epoch 2029/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1176 - accuracy: 0.9667 - val_loss: 0.3128 - val_accuracy: 0.9000\n",
      "Epoch 2030/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1557 - accuracy: 0.9000 - val_loss: 0.3154 - val_accuracy: 0.9000\n",
      "Epoch 2031/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1142 - accuracy: 0.9333 - val_loss: 0.3216 - val_accuracy: 0.9000\n",
      "Epoch 2032/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1235 - accuracy: 0.9667 - val_loss: 0.3271 - val_accuracy: 0.9000\n",
      "Epoch 2033/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1221 - accuracy: 0.9667 - val_loss: 0.3413 - val_accuracy: 0.9000\n",
      "Epoch 2034/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1168 - accuracy: 0.9333 - val_loss: 0.3475 - val_accuracy: 0.9000\n",
      "Epoch 2035/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1131 - accuracy: 0.9667 - val_loss: 0.3530 - val_accuracy: 0.9000\n",
      "Epoch 2036/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1770 - accuracy: 0.9333 - val_loss: 0.3694 - val_accuracy: 0.9000\n",
      "Epoch 2037/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1362 - accuracy: 1.0000 - val_loss: 0.3777 - val_accuracy: 0.9000\n",
      "Epoch 2038/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1317 - accuracy: 0.9667 - val_loss: 0.3734 - val_accuracy: 0.9000\n",
      "Epoch 2039/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1418 - accuracy: 0.9333 - val_loss: 0.3631 - val_accuracy: 0.9000\n",
      "Epoch 2040/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1498 - accuracy: 0.9333 - val_loss: 0.3569 - val_accuracy: 0.9000\n",
      "Epoch 2041/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1444 - accuracy: 0.9333 - val_loss: 0.3453 - val_accuracy: 0.9000\n",
      "Epoch 2042/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1856 - accuracy: 0.9333 - val_loss: 0.3342 - val_accuracy: 0.9000\n",
      "Epoch 2043/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1598 - accuracy: 0.9333 - val_loss: 0.3171 - val_accuracy: 0.9000\n",
      "Epoch 2044/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0853 - accuracy: 1.0000 - val_loss: 0.3039 - val_accuracy: 0.9000\n",
      "Epoch 2045/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0963 - accuracy: 0.9667 - val_loss: 0.2973 - val_accuracy: 0.9000\n",
      "Epoch 2046/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1123 - accuracy: 0.9333 - val_loss: 0.2955 - val_accuracy: 0.9000\n",
      "Epoch 2047/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.2303 - accuracy: 0.8333 - val_loss: 0.2874 - val_accuracy: 0.9000\n",
      "Epoch 2048/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1189 - accuracy: 0.9667 - val_loss: 0.2802 - val_accuracy: 0.9000\n",
      "Epoch 2049/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1494 - accuracy: 0.9333 - val_loss: 0.2728 - val_accuracy: 0.9000\n",
      "Epoch 2050/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1695 - accuracy: 0.9333 - val_loss: 0.2698 - val_accuracy: 0.9000\n",
      "Epoch 2051/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1147 - accuracy: 0.9333 - val_loss: 0.2674 - val_accuracy: 0.9000\n",
      "Epoch 2052/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1287 - accuracy: 0.9667 - val_loss: 0.2762 - val_accuracy: 0.9000\n",
      "Epoch 2053/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1379 - accuracy: 0.9333 - val_loss: 0.2879 - val_accuracy: 0.9000\n",
      "Epoch 2054/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1133 - accuracy: 0.9667 - val_loss: 0.2979 - val_accuracy: 0.9000\n",
      "Epoch 2055/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1540 - accuracy: 1.0000 - val_loss: 0.3074 - val_accuracy: 0.9000\n",
      "Epoch 2056/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1604 - accuracy: 0.9000 - val_loss: 0.3168 - val_accuracy: 0.9000\n",
      "Epoch 2057/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1012 - accuracy: 1.0000 - val_loss: 0.3298 - val_accuracy: 0.9000\n",
      "Epoch 2058/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1222 - accuracy: 0.9667 - val_loss: 0.3418 - val_accuracy: 0.9000\n",
      "Epoch 2059/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1615 - accuracy: 0.9333 - val_loss: 0.3496 - val_accuracy: 0.9000\n",
      "Epoch 2060/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.2245 - accuracy: 0.8667 - val_loss: 0.3551 - val_accuracy: 0.9000\n",
      "Epoch 2061/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1680 - accuracy: 0.9000 - val_loss: 0.3562 - val_accuracy: 0.9000\n",
      "Epoch 2062/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1069 - accuracy: 0.9333 - val_loss: 0.3515 - val_accuracy: 0.9000\n",
      "Epoch 2063/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1571 - accuracy: 0.9333 - val_loss: 0.3507 - val_accuracy: 0.9000\n",
      "Epoch 2064/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1203 - accuracy: 0.9667 - val_loss: 0.3593 - val_accuracy: 0.9000\n",
      "Epoch 2065/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1600 - accuracy: 0.9667 - val_loss: 0.3655 - val_accuracy: 0.9000\n",
      "Epoch 2066/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1108 - accuracy: 0.9667 - val_loss: 0.3697 - val_accuracy: 0.9000\n",
      "Epoch 2067/3000\n",
      "30/30 [==============================] - 0s 148us/step - loss: 0.1182 - accuracy: 0.9667 - val_loss: 0.3708 - val_accuracy: 0.9000\n",
      "Epoch 2068/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1396 - accuracy: 0.9333 - val_loss: 0.3668 - val_accuracy: 0.9000\n",
      "Epoch 2069/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0909 - accuracy: 0.9667 - val_loss: 0.3641 - val_accuracy: 0.9000\n",
      "Epoch 2070/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1259 - accuracy: 1.0000 - val_loss: 0.3630 - val_accuracy: 0.9000\n",
      "Epoch 2071/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1681 - accuracy: 0.9000 - val_loss: 0.3622 - val_accuracy: 0.9000\n",
      "Epoch 2072/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0823 - accuracy: 1.0000 - val_loss: 0.3607 - val_accuracy: 0.9000\n",
      "Epoch 2073/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1192 - accuracy: 0.9667 - val_loss: 0.3692 - val_accuracy: 0.9000\n",
      "Epoch 2074/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1016 - accuracy: 0.9667 - val_loss: 0.3747 - val_accuracy: 0.9000\n",
      "Epoch 2075/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1576 - accuracy: 0.9333 - val_loss: 0.3710 - val_accuracy: 0.9000\n",
      "Epoch 2076/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1147 - accuracy: 0.9667 - val_loss: 0.3616 - val_accuracy: 0.9000\n",
      "Epoch 2077/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1077 - accuracy: 0.9667 - val_loss: 0.3476 - val_accuracy: 0.9000\n",
      "Epoch 2078/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1347 - accuracy: 0.9333 - val_loss: 0.3350 - val_accuracy: 0.9000\n",
      "Epoch 2079/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.0707 - accuracy: 1.0000 - val_loss: 0.3249 - val_accuracy: 0.9000\n",
      "Epoch 2080/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1122 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.9000\n",
      "Epoch 2081/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1883 - accuracy: 0.9333 - val_loss: 0.3070 - val_accuracy: 0.9000\n",
      "Epoch 2082/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1342 - accuracy: 0.9667 - val_loss: 0.2971 - val_accuracy: 0.9000\n",
      "Epoch 2083/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1228 - accuracy: 0.9667 - val_loss: 0.2859 - val_accuracy: 0.9000\n",
      "Epoch 2084/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1384 - accuracy: 0.9667 - val_loss: 0.2827 - val_accuracy: 0.9000\n",
      "Epoch 2085/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1239 - accuracy: 0.9667 - val_loss: 0.2795 - val_accuracy: 0.9000\n",
      "Epoch 2086/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1766 - accuracy: 0.9667 - val_loss: 0.2778 - val_accuracy: 0.9000\n",
      "Epoch 2087/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1368 - accuracy: 0.9667 - val_loss: 0.2821 - val_accuracy: 0.9000\n",
      "Epoch 2088/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1117 - accuracy: 0.9667 - val_loss: 0.2852 - val_accuracy: 0.9000\n",
      "Epoch 2089/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1183 - accuracy: 1.0000 - val_loss: 0.2874 - val_accuracy: 0.9000\n",
      "Epoch 2090/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.1170 - accuracy: 0.9333 - val_loss: 0.2984 - val_accuracy: 0.9000\n",
      "Epoch 2091/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1470 - accuracy: 0.9667 - val_loss: 0.3090 - val_accuracy: 0.9000\n",
      "Epoch 2092/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1279 - accuracy: 0.9667 - val_loss: 0.3181 - val_accuracy: 0.9000\n",
      "Epoch 2093/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1397 - accuracy: 0.9667 - val_loss: 0.3280 - val_accuracy: 0.9000\n",
      "Epoch 2094/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.1285 - accuracy: 0.9667 - val_loss: 0.3404 - val_accuracy: 0.9000\n",
      "Epoch 2095/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1575 - accuracy: 0.9333 - val_loss: 0.3493 - val_accuracy: 0.9000\n",
      "Epoch 2096/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1650 - accuracy: 0.9667 - val_loss: 0.3590 - val_accuracy: 0.9000\n",
      "Epoch 2097/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1236 - accuracy: 0.9667 - val_loss: 0.3644 - val_accuracy: 0.9000\n",
      "Epoch 2098/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.1039 - accuracy: 1.0000 - val_loss: 0.3634 - val_accuracy: 0.9000\n",
      "Epoch 2099/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1508 - accuracy: 0.9333 - val_loss: 0.3614 - val_accuracy: 0.9000\n",
      "Epoch 2100/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0920 - accuracy: 1.0000 - val_loss: 0.3593 - val_accuracy: 0.9000\n",
      "Epoch 2101/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1412 - accuracy: 0.9333 - val_loss: 0.3537 - val_accuracy: 0.9000\n",
      "Epoch 2102/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1434 - accuracy: 0.9333 - val_loss: 0.3420 - val_accuracy: 0.9000\n",
      "Epoch 2103/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0981 - accuracy: 1.0000 - val_loss: 0.3299 - val_accuracy: 0.9000\n",
      "Epoch 2104/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0935 - accuracy: 0.9667 - val_loss: 0.3270 - val_accuracy: 0.8000\n",
      "Epoch 2105/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1044 - accuracy: 1.0000 - val_loss: 0.3277 - val_accuracy: 0.8000\n",
      "Epoch 2106/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.0886 - accuracy: 0.9667 - val_loss: 0.3303 - val_accuracy: 0.8000\n",
      "Epoch 2107/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1435 - accuracy: 0.9333 - val_loss: 0.3358 - val_accuracy: 0.9000\n",
      "Epoch 2108/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1024 - accuracy: 0.9667 - val_loss: 0.3436 - val_accuracy: 0.9000\n",
      "Epoch 2109/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1352 - accuracy: 1.0000 - val_loss: 0.3562 - val_accuracy: 0.9000\n",
      "Epoch 2110/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.1149 - accuracy: 0.9667 - val_loss: 0.3632 - val_accuracy: 0.9000\n",
      "Epoch 2111/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.0938 - accuracy: 0.9667 - val_loss: 0.3688 - val_accuracy: 0.9000\n",
      "Epoch 2112/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1440 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.9000\n",
      "Epoch 2113/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0866 - accuracy: 1.0000 - val_loss: 0.3759 - val_accuracy: 0.9000\n",
      "Epoch 2114/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1450 - accuracy: 0.9000 - val_loss: 0.3728 - val_accuracy: 0.9000\n",
      "Epoch 2115/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1120 - accuracy: 0.9333 - val_loss: 0.3675 - val_accuracy: 0.9000\n",
      "Epoch 2116/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1512 - accuracy: 0.9667 - val_loss: 0.3465 - val_accuracy: 0.9000\n",
      "Epoch 2117/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1409 - accuracy: 0.9667 - val_loss: 0.3336 - val_accuracy: 0.9000\n",
      "Epoch 2118/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0845 - accuracy: 1.0000 - val_loss: 0.3233 - val_accuracy: 0.9000\n",
      "Epoch 2119/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1313 - accuracy: 0.9333 - val_loss: 0.3125 - val_accuracy: 0.9000\n",
      "Epoch 2120/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1105 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.9000\n",
      "Epoch 2121/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.0949 - accuracy: 0.9667 - val_loss: 0.3090 - val_accuracy: 0.9000\n",
      "Epoch 2122/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1587 - accuracy: 0.9667 - val_loss: 0.3093 - val_accuracy: 0.9000\n",
      "Epoch 2123/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1374 - accuracy: 0.9333 - val_loss: 0.3075 - val_accuracy: 0.9000\n",
      "Epoch 2124/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1182 - accuracy: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.9000\n",
      "Epoch 2125/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1018 - accuracy: 1.0000 - val_loss: 0.3211 - val_accuracy: 0.9000\n",
      "Epoch 2126/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1803 - accuracy: 0.9333 - val_loss: 0.3241 - val_accuracy: 0.9000\n",
      "Epoch 2127/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1016 - accuracy: 1.0000 - val_loss: 0.3184 - val_accuracy: 0.9000\n",
      "Epoch 2128/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1220 - accuracy: 0.9667 - val_loss: 0.3135 - val_accuracy: 0.9000\n",
      "Epoch 2129/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.1031 - accuracy: 0.9667 - val_loss: 0.3106 - val_accuracy: 0.9000\n",
      "Epoch 2130/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1373 - accuracy: 0.9667 - val_loss: 0.3107 - val_accuracy: 0.9000\n",
      "Epoch 2131/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1395 - accuracy: 0.9333 - val_loss: 0.3043 - val_accuracy: 0.9000\n",
      "Epoch 2132/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.0795 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 0.9000\n",
      "Epoch 2133/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1105 - accuracy: 0.9667 - val_loss: 0.3016 - val_accuracy: 0.9000\n",
      "Epoch 2134/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1134 - accuracy: 0.9667 - val_loss: 0.3121 - val_accuracy: 0.9000\n",
      "Epoch 2135/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1193 - accuracy: 0.9667 - val_loss: 0.3250 - val_accuracy: 0.9000\n",
      "Epoch 2136/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1127 - accuracy: 0.9667 - val_loss: 0.3439 - val_accuracy: 0.8000\n",
      "Epoch 2137/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1222 - accuracy: 0.9667 - val_loss: 0.3554 - val_accuracy: 0.8000\n",
      "Epoch 2138/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1629 - accuracy: 0.9667 - val_loss: 0.3478 - val_accuracy: 0.9000\n",
      "Epoch 2139/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1007 - accuracy: 0.9667 - val_loss: 0.3384 - val_accuracy: 0.9000\n",
      "Epoch 2140/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1321 - accuracy: 0.9333 - val_loss: 0.3222 - val_accuracy: 0.9000\n",
      "Epoch 2141/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0886 - accuracy: 1.0000 - val_loss: 0.3062 - val_accuracy: 0.9000\n",
      "Epoch 2142/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1481 - accuracy: 0.9333 - val_loss: 0.2987 - val_accuracy: 0.9000\n",
      "Epoch 2143/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1489 - accuracy: 0.9333 - val_loss: 0.2873 - val_accuracy: 0.9000\n",
      "Epoch 2144/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1140 - accuracy: 0.9667 - val_loss: 0.2821 - val_accuracy: 0.9000\n",
      "Epoch 2145/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1331 - accuracy: 0.9667 - val_loss: 0.2768 - val_accuracy: 0.9000\n",
      "Epoch 2146/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1143 - accuracy: 0.9667 - val_loss: 0.2650 - val_accuracy: 0.9000\n",
      "Epoch 2147/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0894 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.9000\n",
      "Epoch 2148/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.1341 - accuracy: 0.9333 - val_loss: 0.2646 - val_accuracy: 0.9000\n",
      "Epoch 2149/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1274 - accuracy: 0.9667 - val_loss: 0.2684 - val_accuracy: 0.9000\n",
      "Epoch 2150/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1181 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.9000\n",
      "Epoch 2151/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1153 - accuracy: 0.9667 - val_loss: 0.2878 - val_accuracy: 0.9000\n",
      "Epoch 2152/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0961 - accuracy: 1.0000 - val_loss: 0.2903 - val_accuracy: 0.9000\n",
      "Epoch 2153/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1385 - accuracy: 0.9667 - val_loss: 0.2883 - val_accuracy: 0.9000\n",
      "Epoch 2154/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1563 - accuracy: 0.9333 - val_loss: 0.2911 - val_accuracy: 0.9000\n",
      "Epoch 2155/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1454 - accuracy: 0.9333 - val_loss: 0.2948 - val_accuracy: 0.9000\n",
      "Epoch 2156/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.1119 - accuracy: 0.9667 - val_loss: 0.2964 - val_accuracy: 0.9000\n",
      "Epoch 2157/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1431 - accuracy: 0.9333 - val_loss: 0.2902 - val_accuracy: 0.9000\n",
      "Epoch 2158/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.0921 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9000\n",
      "Epoch 2159/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1031 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9000\n",
      "Epoch 2160/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.0976 - accuracy: 0.9667 - val_loss: 0.2585 - val_accuracy: 0.9000\n",
      "Epoch 2161/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1305 - accuracy: 0.9667 - val_loss: 0.2506 - val_accuracy: 0.9000\n",
      "Epoch 2162/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.0957 - accuracy: 0.9667 - val_loss: 0.2521 - val_accuracy: 0.9000\n",
      "Epoch 2163/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1035 - accuracy: 0.9667 - val_loss: 0.2577 - val_accuracy: 0.9000\n",
      "Epoch 2164/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1010 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9000\n",
      "Epoch 2165/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.1098 - accuracy: 0.9667 - val_loss: 0.2762 - val_accuracy: 0.9000\n",
      "Epoch 2166/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1088 - accuracy: 0.9667 - val_loss: 0.2881 - val_accuracy: 0.9000\n",
      "Epoch 2167/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1358 - accuracy: 0.9667 - val_loss: 0.2971 - val_accuracy: 0.9000\n",
      "Epoch 2168/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.1160 - accuracy: 0.9667 - val_loss: 0.3117 - val_accuracy: 0.9000\n",
      "Epoch 2169/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.0927 - accuracy: 0.9667 - val_loss: 0.3243 - val_accuracy: 0.9000\n",
      "Epoch 2170/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1095 - accuracy: 0.9667 - val_loss: 0.3374 - val_accuracy: 0.9000\n",
      "Epoch 2171/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1100 - accuracy: 0.9667 - val_loss: 0.3417 - val_accuracy: 0.9000\n",
      "Epoch 2172/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1056 - accuracy: 0.9667 - val_loss: 0.3418 - val_accuracy: 0.9000\n",
      "Epoch 2173/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1053 - accuracy: 0.9667 - val_loss: 0.3398 - val_accuracy: 0.9000\n",
      "Epoch 2174/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.0751 - accuracy: 1.0000 - val_loss: 0.3369 - val_accuracy: 0.9000\n",
      "Epoch 2175/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0834 - accuracy: 0.9667 - val_loss: 0.3322 - val_accuracy: 0.9000\n",
      "Epoch 2176/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1086 - accuracy: 0.9333 - val_loss: 0.3190 - val_accuracy: 0.9000\n",
      "Epoch 2177/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1265 - accuracy: 0.9333 - val_loss: 0.2960 - val_accuracy: 0.9000\n",
      "Epoch 2178/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1237 - accuracy: 1.0000 - val_loss: 0.2767 - val_accuracy: 0.9000\n",
      "Epoch 2179/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1271 - accuracy: 0.9667 - val_loss: 0.2699 - val_accuracy: 0.9000\n",
      "Epoch 2180/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1495 - accuracy: 0.9667 - val_loss: 0.2650 - val_accuracy: 0.9000\n",
      "Epoch 2181/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1413 - accuracy: 0.9333 - val_loss: 0.2601 - val_accuracy: 0.9000\n",
      "Epoch 2182/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0958 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 0.9000\n",
      "Epoch 2183/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1129 - accuracy: 0.9667 - val_loss: 0.2633 - val_accuracy: 0.9000\n",
      "Epoch 2184/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1145 - accuracy: 0.9667 - val_loss: 0.2768 - val_accuracy: 0.9000\n",
      "Epoch 2185/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1057 - accuracy: 0.9667 - val_loss: 0.2856 - val_accuracy: 0.9000\n",
      "Epoch 2186/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1244 - accuracy: 0.9667 - val_loss: 0.2977 - val_accuracy: 0.9000\n",
      "Epoch 2187/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1422 - accuracy: 0.9667 - val_loss: 0.3166 - val_accuracy: 0.9000\n",
      "Epoch 2188/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1374 - accuracy: 0.9667 - val_loss: 0.3282 - val_accuracy: 0.9000\n",
      "Epoch 2189/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1838 - accuracy: 0.9667 - val_loss: 0.3301 - val_accuracy: 0.9000\n",
      "Epoch 2190/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1262 - accuracy: 1.0000 - val_loss: 0.3302 - val_accuracy: 0.9000\n",
      "Epoch 2191/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1531 - accuracy: 0.9333 - val_loss: 0.3266 - val_accuracy: 0.9000\n",
      "Epoch 2192/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0999 - accuracy: 1.0000 - val_loss: 0.3225 - val_accuracy: 0.9000\n",
      "Epoch 2193/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.0796 - accuracy: 1.0000 - val_loss: 0.3199 - val_accuracy: 0.9000\n",
      "Epoch 2194/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1443 - accuracy: 0.9333 - val_loss: 0.3072 - val_accuracy: 0.9000\n",
      "Epoch 2195/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1790 - accuracy: 0.9000 - val_loss: 0.2929 - val_accuracy: 0.9000\n",
      "Epoch 2196/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0955 - accuracy: 0.9667 - val_loss: 0.2800 - val_accuracy: 0.9000\n",
      "Epoch 2197/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.1272 - accuracy: 0.9333 - val_loss: 0.2679 - val_accuracy: 0.9000\n",
      "Epoch 2198/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1449 - accuracy: 0.9333 - val_loss: 0.2605 - val_accuracy: 0.9000\n",
      "Epoch 2199/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1240 - accuracy: 0.9333 - val_loss: 0.2553 - val_accuracy: 0.9000\n",
      "Epoch 2200/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0915 - accuracy: 0.9667 - val_loss: 0.2578 - val_accuracy: 0.9000\n",
      "Epoch 2201/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1270 - accuracy: 0.9667 - val_loss: 0.2614 - val_accuracy: 0.9000\n",
      "Epoch 2202/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1104 - accuracy: 0.9667 - val_loss: 0.2652 - val_accuracy: 0.9000\n",
      "Epoch 2203/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0789 - accuracy: 1.0000 - val_loss: 0.2703 - val_accuracy: 0.9000\n",
      "Epoch 2204/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1229 - accuracy: 0.9333 - val_loss: 0.2799 - val_accuracy: 0.9000\n",
      "Epoch 2205/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1244 - accuracy: 0.9667 - val_loss: 0.2970 - val_accuracy: 0.9000\n",
      "Epoch 2206/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.1072 - accuracy: 0.9667 - val_loss: 0.3169 - val_accuracy: 0.9000\n",
      "Epoch 2207/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1182 - accuracy: 0.9667 - val_loss: 0.3340 - val_accuracy: 0.9000\n",
      "Epoch 2208/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1589 - accuracy: 0.9333 - val_loss: 0.3634 - val_accuracy: 0.9000\n",
      "Epoch 2209/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0977 - accuracy: 1.0000 - val_loss: 0.3826 - val_accuracy: 0.9000\n",
      "Epoch 2210/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0975 - accuracy: 1.0000 - val_loss: 0.3899 - val_accuracy: 0.9000\n",
      "Epoch 2211/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0943 - accuracy: 1.0000 - val_loss: 0.3924 - val_accuracy: 0.9000\n",
      "Epoch 2212/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1411 - accuracy: 0.9333 - val_loss: 0.3972 - val_accuracy: 0.9000\n",
      "Epoch 2213/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.1081 - accuracy: 0.9667 - val_loss: 0.3956 - val_accuracy: 0.9000\n",
      "Epoch 2214/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1795 - accuracy: 0.9000 - val_loss: 0.3743 - val_accuracy: 0.9000\n",
      "Epoch 2215/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1297 - accuracy: 0.9333 - val_loss: 0.3477 - val_accuracy: 0.9000\n",
      "Epoch 2216/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0863 - accuracy: 1.0000 - val_loss: 0.3204 - val_accuracy: 0.9000\n",
      "Epoch 2217/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.1218 - accuracy: 0.9667 - val_loss: 0.2924 - val_accuracy: 0.9000\n",
      "Epoch 2218/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0993 - accuracy: 0.9667 - val_loss: 0.2700 - val_accuracy: 0.9000\n",
      "Epoch 2219/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1250 - accuracy: 0.9667 - val_loss: 0.2599 - val_accuracy: 0.9000\n",
      "Epoch 2220/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1230 - accuracy: 0.9333 - val_loss: 0.2517 - val_accuracy: 0.9000\n",
      "Epoch 2221/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1297 - accuracy: 0.9333 - val_loss: 0.2506 - val_accuracy: 0.9000\n",
      "Epoch 2222/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1027 - accuracy: 0.9667 - val_loss: 0.2601 - val_accuracy: 0.9000\n",
      "Epoch 2223/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1121 - accuracy: 0.9667 - val_loss: 0.2679 - val_accuracy: 0.9000\n",
      "Epoch 2224/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1534 - accuracy: 0.9667 - val_loss: 0.2813 - val_accuracy: 0.9000\n",
      "Epoch 2225/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1181 - accuracy: 0.9667 - val_loss: 0.3078 - val_accuracy: 0.9000\n",
      "Epoch 2226/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1119 - accuracy: 0.9667 - val_loss: 0.3296 - val_accuracy: 0.9000\n",
      "Epoch 2227/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1398 - accuracy: 0.9333 - val_loss: 0.3470 - val_accuracy: 0.9000\n",
      "Epoch 2228/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1055 - accuracy: 1.0000 - val_loss: 0.3626 - val_accuracy: 0.9000\n",
      "Epoch 2229/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1089 - accuracy: 0.9667 - val_loss: 0.3757 - val_accuracy: 0.9000\n",
      "Epoch 2230/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1398 - accuracy: 0.9333 - val_loss: 0.3807 - val_accuracy: 0.9000\n",
      "Epoch 2231/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1357 - accuracy: 0.9667 - val_loss: 0.3843 - val_accuracy: 0.9000\n",
      "Epoch 2232/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1159 - accuracy: 0.9667 - val_loss: 0.3945 - val_accuracy: 0.9000\n",
      "Epoch 2233/3000\n",
      "30/30 [==============================] - 0s 113us/step - loss: 0.1122 - accuracy: 1.0000 - val_loss: 0.4018 - val_accuracy: 0.9000\n",
      "Epoch 2234/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1205 - accuracy: 0.9333 - val_loss: 0.4024 - val_accuracy: 0.9000\n",
      "Epoch 2235/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0759 - accuracy: 1.0000 - val_loss: 0.3960 - val_accuracy: 0.9000\n",
      "Epoch 2236/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0973 - accuracy: 0.9667 - val_loss: 0.3775 - val_accuracy: 0.9000\n",
      "Epoch 2237/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1653 - accuracy: 0.9000 - val_loss: 0.3622 - val_accuracy: 0.9000\n",
      "Epoch 2238/3000\n",
      "30/30 [==============================] - 0s 114us/step - loss: 0.1430 - accuracy: 0.9333 - val_loss: 0.3556 - val_accuracy: 0.9000\n",
      "Epoch 2239/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0865 - accuracy: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.9000\n",
      "Epoch 2240/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.1184 - accuracy: 0.9667 - val_loss: 0.3561 - val_accuracy: 0.8000\n",
      "Epoch 2241/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.1324 - accuracy: 0.9333 - val_loss: 0.3584 - val_accuracy: 0.8000\n",
      "Epoch 2242/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1038 - accuracy: 0.9667 - val_loss: 0.3622 - val_accuracy: 0.8000\n",
      "Epoch 2243/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1004 - accuracy: 0.9667 - val_loss: 0.3719 - val_accuracy: 0.8000\n",
      "Epoch 2244/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1476 - accuracy: 0.9667 - val_loss: 0.3830 - val_accuracy: 0.8000\n",
      "Epoch 2245/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1379 - accuracy: 0.9333 - val_loss: 0.3992 - val_accuracy: 0.9000\n",
      "Epoch 2246/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1183 - accuracy: 0.9667 - val_loss: 0.4109 - val_accuracy: 0.9000\n",
      "Epoch 2247/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1244 - accuracy: 0.9333 - val_loss: 0.4259 - val_accuracy: 0.9000\n",
      "Epoch 2248/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1085 - accuracy: 0.9667 - val_loss: 0.4325 - val_accuracy: 0.9000\n",
      "Epoch 2249/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1381 - accuracy: 0.9667 - val_loss: 0.4408 - val_accuracy: 0.9000\n",
      "Epoch 2250/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.0884 - accuracy: 1.0000 - val_loss: 0.4500 - val_accuracy: 0.8000\n",
      "Epoch 2251/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1155 - accuracy: 0.9667 - val_loss: 0.4434 - val_accuracy: 0.8000\n",
      "Epoch 2252/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0911 - accuracy: 0.9667 - val_loss: 0.4248 - val_accuracy: 0.8000\n",
      "Epoch 2253/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1191 - accuracy: 0.9000 - val_loss: 0.3971 - val_accuracy: 0.9000\n",
      "Epoch 2254/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1272 - accuracy: 0.9667 - val_loss: 0.3733 - val_accuracy: 0.9000\n",
      "Epoch 2255/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1210 - accuracy: 0.9667 - val_loss: 0.3616 - val_accuracy: 0.9000\n",
      "Epoch 2256/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0868 - accuracy: 1.0000 - val_loss: 0.3527 - val_accuracy: 0.9000\n",
      "Epoch 2257/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1357 - accuracy: 0.9333 - val_loss: 0.3440 - val_accuracy: 0.9000\n",
      "Epoch 2258/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1082 - accuracy: 0.9667 - val_loss: 0.3379 - val_accuracy: 0.9000\n",
      "Epoch 2259/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1563 - accuracy: 0.9000 - val_loss: 0.3429 - val_accuracy: 0.9000\n",
      "Epoch 2260/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1104 - accuracy: 0.9667 - val_loss: 0.3509 - val_accuracy: 0.9000\n",
      "Epoch 2261/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1074 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.8000\n",
      "Epoch 2262/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1417 - accuracy: 0.9333 - val_loss: 0.3846 - val_accuracy: 0.8000\n",
      "Epoch 2263/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.0990 - accuracy: 0.9667 - val_loss: 0.3917 - val_accuracy: 0.8000\n",
      "Epoch 2264/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 0.3945 - val_accuracy: 0.8000\n",
      "Epoch 2265/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1133 - accuracy: 1.0000 - val_loss: 0.3946 - val_accuracy: 0.8000\n",
      "Epoch 2266/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1191 - accuracy: 1.0000 - val_loss: 0.3932 - val_accuracy: 0.8000\n",
      "Epoch 2267/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1297 - accuracy: 1.0000 - val_loss: 0.3794 - val_accuracy: 0.8000\n",
      "Epoch 2268/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1215 - accuracy: 0.9667 - val_loss: 0.3516 - val_accuracy: 0.9000\n",
      "Epoch 2269/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0995 - accuracy: 0.9667 - val_loss: 0.3270 - val_accuracy: 0.9000\n",
      "Epoch 2270/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1093 - accuracy: 0.9667 - val_loss: 0.2962 - val_accuracy: 0.9000\n",
      "Epoch 2271/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1304 - accuracy: 0.9333 - val_loss: 0.2721 - val_accuracy: 0.9000\n",
      "Epoch 2272/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0953 - accuracy: 0.9667 - val_loss: 0.2565 - val_accuracy: 0.9000\n",
      "Epoch 2273/3000\n",
      "30/30 [==============================] - 0s 139us/step - loss: 0.0997 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.8000\n",
      "Epoch 2274/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1362 - accuracy: 0.9333 - val_loss: 0.2512 - val_accuracy: 0.8000\n",
      "Epoch 2275/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.0910 - accuracy: 1.0000 - val_loss: 0.2567 - val_accuracy: 0.8000\n",
      "Epoch 2276/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.0989 - accuracy: 0.9667 - val_loss: 0.2644 - val_accuracy: 0.9000\n",
      "Epoch 2277/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.0806 - accuracy: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9000\n",
      "Epoch 2278/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.1273 - accuracy: 0.9667 - val_loss: 0.2873 - val_accuracy: 0.9000\n",
      "Epoch 2279/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.1101 - accuracy: 0.9667 - val_loss: 0.3078 - val_accuracy: 0.9000\n",
      "Epoch 2280/3000\n",
      "30/30 [==============================] - 0s 152us/step - loss: 0.1254 - accuracy: 0.9333 - val_loss: 0.3200 - val_accuracy: 0.9000\n",
      "Epoch 2281/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0866 - accuracy: 1.0000 - val_loss: 0.3280 - val_accuracy: 0.9000\n",
      "Epoch 2282/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1079 - accuracy: 0.9667 - val_loss: 0.3215 - val_accuracy: 0.9000\n",
      "Epoch 2283/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1116 - accuracy: 0.9667 - val_loss: 0.3124 - val_accuracy: 0.9000\n",
      "Epoch 2284/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1015 - accuracy: 0.9667 - val_loss: 0.2958 - val_accuracy: 0.9000\n",
      "Epoch 2285/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.0921 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9000\n",
      "Epoch 2286/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1742 - accuracy: 0.9000 - val_loss: 0.2553 - val_accuracy: 0.9000\n",
      "Epoch 2287/3000\n",
      "30/30 [==============================] - 0s 111us/step - loss: 0.0828 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9000\n",
      "Epoch 2288/3000\n",
      "30/30 [==============================] - 0s 108us/step - loss: 0.0927 - accuracy: 0.9667 - val_loss: 0.2255 - val_accuracy: 0.9000\n",
      "Epoch 2289/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.0765 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9000\n",
      "Epoch 2290/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0989 - accuracy: 0.9667 - val_loss: 0.2087 - val_accuracy: 0.9000\n",
      "Epoch 2291/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0837 - accuracy: 0.9667 - val_loss: 0.2045 - val_accuracy: 0.9000\n",
      "Epoch 2292/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0960 - accuracy: 0.9667 - val_loss: 0.1987 - val_accuracy: 0.9000\n",
      "Epoch 2293/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1373 - accuracy: 0.9000 - val_loss: 0.1939 - val_accuracy: 1.0000\n",
      "Epoch 2294/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1372 - accuracy: 0.9667 - val_loss: 0.1884 - val_accuracy: 1.0000\n",
      "Epoch 2295/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0888 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 1.0000\n",
      "Epoch 2296/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0848 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9000\n",
      "Epoch 2297/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1057 - accuracy: 0.9667 - val_loss: 0.2053 - val_accuracy: 0.9000\n",
      "Epoch 2298/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0864 - accuracy: 0.9667 - val_loss: 0.2157 - val_accuracy: 0.9000\n",
      "Epoch 2299/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1257 - accuracy: 0.9333 - val_loss: 0.2266 - val_accuracy: 0.9000\n",
      "Epoch 2300/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1025 - accuracy: 0.9667 - val_loss: 0.2461 - val_accuracy: 0.9000\n",
      "Epoch 2301/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0782 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9000\n",
      "Epoch 2302/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1174 - accuracy: 0.9333 - val_loss: 0.2795 - val_accuracy: 0.9000\n",
      "Epoch 2303/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1178 - accuracy: 0.9667 - val_loss: 0.2784 - val_accuracy: 0.9000\n",
      "Epoch 2304/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1206 - accuracy: 0.9667 - val_loss: 0.2750 - val_accuracy: 0.9000\n",
      "Epoch 2305/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1141 - accuracy: 0.9667 - val_loss: 0.2672 - val_accuracy: 0.9000\n",
      "Epoch 2306/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1219 - accuracy: 0.9667 - val_loss: 0.2540 - val_accuracy: 0.9000\n",
      "Epoch 2307/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0922 - accuracy: 0.9667 - val_loss: 0.2428 - val_accuracy: 0.9000\n",
      "Epoch 2308/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1022 - accuracy: 0.9667 - val_loss: 0.2420 - val_accuracy: 0.9000\n",
      "Epoch 2309/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9000\n",
      "Epoch 2310/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1230 - accuracy: 0.9333 - val_loss: 0.2423 - val_accuracy: 0.9000\n",
      "Epoch 2311/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1316 - accuracy: 0.9667 - val_loss: 0.2403 - val_accuracy: 0.9000\n",
      "Epoch 2312/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1004 - accuracy: 0.9667 - val_loss: 0.2448 - val_accuracy: 0.9000\n",
      "Epoch 2313/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1281 - accuracy: 0.9000 - val_loss: 0.2465 - val_accuracy: 0.9000\n",
      "Epoch 2314/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0687 - accuracy: 1.0000 - val_loss: 0.2503 - val_accuracy: 0.9000\n",
      "Epoch 2315/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0740 - accuracy: 1.0000 - val_loss: 0.2514 - val_accuracy: 0.9000\n",
      "Epoch 2316/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1400 - accuracy: 0.9333 - val_loss: 0.2492 - val_accuracy: 0.9000\n",
      "Epoch 2317/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0752 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9000\n",
      "Epoch 2318/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1220 - accuracy: 0.9333 - val_loss: 0.2358 - val_accuracy: 0.9000\n",
      "Epoch 2319/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0916 - accuracy: 0.9667 - val_loss: 0.2251 - val_accuracy: 0.9000\n",
      "Epoch 2320/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.1300 - accuracy: 0.9333 - val_loss: 0.2190 - val_accuracy: 0.9000\n",
      "Epoch 2321/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1345 - accuracy: 0.9333 - val_loss: 0.2106 - val_accuracy: 0.9000\n",
      "Epoch 2322/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1013 - accuracy: 0.9333 - val_loss: 0.2005 - val_accuracy: 0.9000\n",
      "Epoch 2323/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1195 - accuracy: 0.9667 - val_loss: 0.1971 - val_accuracy: 0.9000\n",
      "Epoch 2324/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1266 - accuracy: 0.9667 - val_loss: 0.1947 - val_accuracy: 0.9000\n",
      "Epoch 2325/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0777 - accuracy: 0.9667 - val_loss: 0.1910 - val_accuracy: 1.0000\n",
      "Epoch 2326/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1301 - accuracy: 0.9333 - val_loss: 0.1904 - val_accuracy: 1.0000\n",
      "Epoch 2327/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1152 - accuracy: 0.9667 - val_loss: 0.1922 - val_accuracy: 1.0000\n",
      "Epoch 2328/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1276 - accuracy: 0.9667 - val_loss: 0.1978 - val_accuracy: 0.9000\n",
      "Epoch 2329/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1458 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9000\n",
      "Epoch 2330/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1010 - accuracy: 0.9333 - val_loss: 0.2204 - val_accuracy: 0.9000\n",
      "Epoch 2331/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1538 - accuracy: 0.9333 - val_loss: 0.2402 - val_accuracy: 0.9000\n",
      "Epoch 2332/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.0951 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9000\n",
      "Epoch 2333/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1158 - accuracy: 0.9667 - val_loss: 0.2693 - val_accuracy: 0.8000\n",
      "Epoch 2334/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0913 - accuracy: 0.9667 - val_loss: 0.2833 - val_accuracy: 0.8000\n",
      "Epoch 2335/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0769 - accuracy: 1.0000 - val_loss: 0.2945 - val_accuracy: 0.8000\n",
      "Epoch 2336/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1051 - accuracy: 0.9667 - val_loss: 0.2969 - val_accuracy: 0.8000\n",
      "Epoch 2337/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1136 - accuracy: 0.9667 - val_loss: 0.2857 - val_accuracy: 0.8000\n",
      "Epoch 2338/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1045 - accuracy: 0.9667 - val_loss: 0.2619 - val_accuracy: 0.9000\n",
      "Epoch 2339/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1375 - accuracy: 0.9667 - val_loss: 0.2413 - val_accuracy: 0.9000\n",
      "Epoch 2340/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1179 - accuracy: 0.9667 - val_loss: 0.2241 - val_accuracy: 0.9000\n",
      "Epoch 2341/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1122 - accuracy: 0.9667 - val_loss: 0.2170 - val_accuracy: 0.9000\n",
      "Epoch 2342/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1169 - accuracy: 0.9667 - val_loss: 0.2166 - val_accuracy: 0.9000\n",
      "Epoch 2343/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.0970 - accuracy: 0.9667 - val_loss: 0.2211 - val_accuracy: 0.9000\n",
      "Epoch 2344/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0978 - accuracy: 0.9333 - val_loss: 0.2267 - val_accuracy: 0.9000\n",
      "Epoch 2345/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1262 - accuracy: 0.9333 - val_loss: 0.2351 - val_accuracy: 0.9000\n",
      "Epoch 2346/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0779 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.9000\n",
      "Epoch 2347/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.0882 - accuracy: 0.9667 - val_loss: 0.2621 - val_accuracy: 0.9000\n",
      "Epoch 2348/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.2760 - val_accuracy: 0.9000\n",
      "Epoch 2349/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1276 - accuracy: 0.9333 - val_loss: 0.2821 - val_accuracy: 0.9000\n",
      "Epoch 2350/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1212 - accuracy: 0.9667 - val_loss: 0.2941 - val_accuracy: 0.9000\n",
      "Epoch 2351/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1124 - accuracy: 0.9667 - val_loss: 0.3098 - val_accuracy: 0.9000\n",
      "Epoch 2352/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1089 - accuracy: 0.9667 - val_loss: 0.3196 - val_accuracy: 0.9000\n",
      "Epoch 2353/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1004 - accuracy: 0.9667 - val_loss: 0.3108 - val_accuracy: 0.9000\n",
      "Epoch 2354/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0995 - accuracy: 0.9667 - val_loss: 0.2995 - val_accuracy: 0.9000\n",
      "Epoch 2355/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1517 - accuracy: 0.9667 - val_loss: 0.2764 - val_accuracy: 0.9000\n",
      "Epoch 2356/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1085 - accuracy: 0.9667 - val_loss: 0.2543 - val_accuracy: 0.9000\n",
      "Epoch 2357/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1009 - accuracy: 0.9667 - val_loss: 0.2341 - val_accuracy: 0.9000\n",
      "Epoch 2358/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1531 - accuracy: 0.9333 - val_loss: 0.2133 - val_accuracy: 0.9000\n",
      "Epoch 2359/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1328 - accuracy: 0.9667 - val_loss: 0.2047 - val_accuracy: 0.9000\n",
      "Epoch 2360/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1239 - accuracy: 0.9667 - val_loss: 0.1996 - val_accuracy: 0.9000\n",
      "Epoch 2361/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0845 - accuracy: 0.9667 - val_loss: 0.1957 - val_accuracy: 0.9000\n",
      "Epoch 2362/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1325 - accuracy: 0.9333 - val_loss: 0.1977 - val_accuracy: 0.9000\n",
      "Epoch 2363/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0755 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9000\n",
      "Epoch 2364/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1243 - accuracy: 0.9333 - val_loss: 0.2146 - val_accuracy: 0.9000\n",
      "Epoch 2365/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1473 - accuracy: 0.9333 - val_loss: 0.2368 - val_accuracy: 0.9000\n",
      "Epoch 2366/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1087 - accuracy: 0.9333 - val_loss: 0.2539 - val_accuracy: 0.9000\n",
      "Epoch 2367/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0832 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.9000\n",
      "Epoch 2368/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.0937 - accuracy: 0.9667 - val_loss: 0.2853 - val_accuracy: 0.9000\n",
      "Epoch 2369/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1163 - accuracy: 0.9667 - val_loss: 0.2896 - val_accuracy: 0.9000\n",
      "Epoch 2370/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0983 - accuracy: 1.0000 - val_loss: 0.2746 - val_accuracy: 0.9000\n",
      "Epoch 2371/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.1283 - accuracy: 0.9667 - val_loss: 0.2518 - val_accuracy: 0.9000\n",
      "Epoch 2372/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1208 - accuracy: 0.9667 - val_loss: 0.2343 - val_accuracy: 0.9000\n",
      "Epoch 2373/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0841 - accuracy: 0.9667 - val_loss: 0.2233 - val_accuracy: 0.9000\n",
      "Epoch 2374/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1534 - accuracy: 0.9667 - val_loss: 0.2159 - val_accuracy: 0.9000\n",
      "Epoch 2375/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0849 - accuracy: 0.9667 - val_loss: 0.2123 - val_accuracy: 0.9000\n",
      "Epoch 2376/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9000\n",
      "Epoch 2377/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1240 - accuracy: 0.9333 - val_loss: 0.2150 - val_accuracy: 0.8000\n",
      "Epoch 2378/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1192 - accuracy: 0.9667 - val_loss: 0.2207 - val_accuracy: 0.8000\n",
      "Epoch 2379/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1042 - accuracy: 0.9667 - val_loss: 0.2332 - val_accuracy: 0.9000\n",
      "Epoch 2380/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.1124 - accuracy: 0.9667 - val_loss: 0.2497 - val_accuracy: 0.9000\n",
      "Epoch 2381/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1045 - accuracy: 0.9667 - val_loss: 0.2712 - val_accuracy: 0.9000\n",
      "Epoch 2382/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1045 - accuracy: 0.9667 - val_loss: 0.2961 - val_accuracy: 0.9000\n",
      "Epoch 2383/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.3245 - val_accuracy: 0.9000\n",
      "Epoch 2384/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1000 - accuracy: 0.9667 - val_loss: 0.3387 - val_accuracy: 0.9000\n",
      "Epoch 2385/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.0775 - accuracy: 1.0000 - val_loss: 0.3486 - val_accuracy: 0.9000\n",
      "Epoch 2386/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0791 - accuracy: 1.0000 - val_loss: 0.3468 - val_accuracy: 0.9000\n",
      "Epoch 2387/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0794 - accuracy: 1.0000 - val_loss: 0.3423 - val_accuracy: 0.9000\n",
      "Epoch 2388/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1171 - accuracy: 0.9333 - val_loss: 0.3229 - val_accuracy: 0.9000\n",
      "Epoch 2389/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1052 - accuracy: 0.9667 - val_loss: 0.2988 - val_accuracy: 0.9000\n",
      "Epoch 2390/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1189 - accuracy: 0.9333 - val_loss: 0.2711 - val_accuracy: 0.9000\n",
      "Epoch 2391/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1015 - accuracy: 0.9667 - val_loss: 0.2467 - val_accuracy: 0.9000\n",
      "Epoch 2392/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1174 - accuracy: 0.9667 - val_loss: 0.2256 - val_accuracy: 0.9000\n",
      "Epoch 2393/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1010 - accuracy: 0.9333 - val_loss: 0.2082 - val_accuracy: 0.9000\n",
      "Epoch 2394/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1222 - accuracy: 0.9667 - val_loss: 0.1970 - val_accuracy: 0.9000\n",
      "Epoch 2395/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1250 - accuracy: 0.9333 - val_loss: 0.1940 - val_accuracy: 0.9000\n",
      "Epoch 2396/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1181 - accuracy: 0.9333 - val_loss: 0.1953 - val_accuracy: 0.9000\n",
      "Epoch 2397/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0980 - accuracy: 0.9667 - val_loss: 0.2025 - val_accuracy: 0.9000\n",
      "Epoch 2398/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1374 - accuracy: 0.9000 - val_loss: 0.2097 - val_accuracy: 0.9000\n",
      "Epoch 2399/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1352 - accuracy: 0.9333 - val_loss: 0.2134 - val_accuracy: 0.9000\n",
      "Epoch 2400/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1104 - accuracy: 0.9333 - val_loss: 0.2167 - val_accuracy: 0.9000\n",
      "Epoch 2401/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1602 - accuracy: 0.9667 - val_loss: 0.2224 - val_accuracy: 0.9000\n",
      "Epoch 2402/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0709 - accuracy: 1.0000 - val_loss: 0.2329 - val_accuracy: 0.9000\n",
      "Epoch 2403/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0648 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9000\n",
      "Epoch 2404/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0854 - accuracy: 0.9667 - val_loss: 0.2594 - val_accuracy: 0.9000\n",
      "Epoch 2405/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.1503 - accuracy: 0.9000 - val_loss: 0.2619 - val_accuracy: 0.9000\n",
      "Epoch 2406/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1216 - accuracy: 0.9667 - val_loss: 0.2600 - val_accuracy: 0.9000\n",
      "Epoch 2407/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0878 - accuracy: 0.9667 - val_loss: 0.2509 - val_accuracy: 0.9000\n",
      "Epoch 2408/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.0859 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9000\n",
      "Epoch 2409/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0981 - accuracy: 0.9667 - val_loss: 0.2314 - val_accuracy: 0.9000\n",
      "Epoch 2410/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0964 - accuracy: 0.9667 - val_loss: 0.2280 - val_accuracy: 0.9000\n",
      "Epoch 2411/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0729 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9000\n",
      "Epoch 2412/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1157 - accuracy: 0.9667 - val_loss: 0.2430 - val_accuracy: 0.9000\n",
      "Epoch 2413/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0947 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9000\n",
      "Epoch 2414/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1097 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9000\n",
      "Epoch 2415/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0755 - accuracy: 1.0000 - val_loss: 0.2651 - val_accuracy: 0.9000\n",
      "Epoch 2416/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1199 - accuracy: 0.9667 - val_loss: 0.2707 - val_accuracy: 0.9000\n",
      "Epoch 2417/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0705 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9000\n",
      "Epoch 2418/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.0921 - accuracy: 0.9667 - val_loss: 0.2690 - val_accuracy: 0.9000\n",
      "Epoch 2419/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0724 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9000\n",
      "Epoch 2420/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0808 - accuracy: 0.9667 - val_loss: 0.2494 - val_accuracy: 0.9000\n",
      "Epoch 2421/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0848 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9000\n",
      "Epoch 2422/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1023 - accuracy: 0.9667 - val_loss: 0.2318 - val_accuracy: 0.9000\n",
      "Epoch 2423/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1407 - accuracy: 0.9000 - val_loss: 0.2271 - val_accuracy: 0.9000\n",
      "Epoch 2424/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1523 - accuracy: 0.9333 - val_loss: 0.2246 - val_accuracy: 0.9000\n",
      "Epoch 2425/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1442 - accuracy: 0.9667 - val_loss: 0.2287 - val_accuracy: 0.9000\n",
      "Epoch 2426/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0838 - accuracy: 0.9667 - val_loss: 0.2335 - val_accuracy: 0.9000\n",
      "Epoch 2427/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0893 - accuracy: 0.9667 - val_loss: 0.2386 - val_accuracy: 0.9000\n",
      "Epoch 2428/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0626 - accuracy: 1.0000 - val_loss: 0.2473 - val_accuracy: 0.9000\n",
      "Epoch 2429/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.9000\n",
      "Epoch 2430/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1366 - accuracy: 0.9333 - val_loss: 0.2631 - val_accuracy: 0.9000\n",
      "Epoch 2431/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1237 - accuracy: 0.9667 - val_loss: 0.2648 - val_accuracy: 0.9000\n",
      "Epoch 2432/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0846 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 0.9000\n",
      "Epoch 2433/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0959 - accuracy: 0.9667 - val_loss: 0.2422 - val_accuracy: 0.9000\n",
      "Epoch 2434/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.0966 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9000\n",
      "Epoch 2435/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1905 - accuracy: 0.9000 - val_loss: 0.2177 - val_accuracy: 0.9000\n",
      "Epoch 2436/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1090 - accuracy: 0.9667 - val_loss: 0.2135 - val_accuracy: 0.9000\n",
      "Epoch 2437/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1155 - accuracy: 0.9667 - val_loss: 0.2090 - val_accuracy: 0.9000\n",
      "Epoch 2438/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1085 - accuracy: 0.9667 - val_loss: 0.2129 - val_accuracy: 0.9000\n",
      "Epoch 2439/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1071 - accuracy: 0.9667 - val_loss: 0.2211 - val_accuracy: 0.9000\n",
      "Epoch 2440/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1011 - accuracy: 0.9667 - val_loss: 0.2294 - val_accuracy: 0.9000\n",
      "Epoch 2441/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1002 - accuracy: 1.0000 - val_loss: 0.2341 - val_accuracy: 0.9000\n",
      "Epoch 2442/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0795 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9000\n",
      "Epoch 2443/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0911 - accuracy: 0.9667 - val_loss: 0.2353 - val_accuracy: 0.9000\n",
      "Epoch 2444/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1232 - accuracy: 0.9333 - val_loss: 0.2260 - val_accuracy: 0.9000\n",
      "Epoch 2445/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0894 - accuracy: 0.9667 - val_loss: 0.2214 - val_accuracy: 0.9000\n",
      "Epoch 2446/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9000\n",
      "Epoch 2447/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1054 - accuracy: 0.9667 - val_loss: 0.1987 - val_accuracy: 0.9000\n",
      "Epoch 2448/3000\n",
      "30/30 [==============================] - 0s 139us/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 0.1846 - val_accuracy: 0.9000\n",
      "Epoch 2449/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1050 - accuracy: 0.9333 - val_loss: 0.1781 - val_accuracy: 1.0000\n",
      "Epoch 2450/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1035 - accuracy: 0.9667 - val_loss: 0.1770 - val_accuracy: 1.0000\n",
      "Epoch 2451/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1216 - accuracy: 0.9333 - val_loss: 0.1844 - val_accuracy: 1.0000\n",
      "Epoch 2452/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1056 - accuracy: 0.9667 - val_loss: 0.1922 - val_accuracy: 0.9000\n",
      "Epoch 2453/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0925 - accuracy: 0.9667 - val_loss: 0.2016 - val_accuracy: 0.9000\n",
      "Epoch 2454/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1334 - accuracy: 0.9667 - val_loss: 0.2066 - val_accuracy: 0.9000\n",
      "Epoch 2455/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.0795 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9000\n",
      "Epoch 2456/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0881 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9000\n",
      "Epoch 2457/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1002 - accuracy: 0.9667 - val_loss: 0.2502 - val_accuracy: 0.9000\n",
      "Epoch 2458/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.1639 - accuracy: 0.9333 - val_loss: 0.2548 - val_accuracy: 0.9000\n",
      "Epoch 2459/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0988 - accuracy: 1.0000 - val_loss: 0.2547 - val_accuracy: 0.9000\n",
      "Epoch 2460/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0985 - accuracy: 0.9667 - val_loss: 0.2403 - val_accuracy: 0.9000\n",
      "Epoch 2461/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0998 - accuracy: 0.9667 - val_loss: 0.2296 - val_accuracy: 0.9000\n",
      "Epoch 2462/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9000\n",
      "Epoch 2463/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1052 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9000\n",
      "Epoch 2464/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1016 - accuracy: 0.9667 - val_loss: 0.2081 - val_accuracy: 0.9000\n",
      "Epoch 2465/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1066 - accuracy: 0.9667 - val_loss: 0.2071 - val_accuracy: 0.9000\n",
      "Epoch 2466/3000\n",
      "30/30 [==============================] - 0s 144us/step - loss: 0.1132 - accuracy: 0.9667 - val_loss: 0.2069 - val_accuracy: 0.9000\n",
      "Epoch 2467/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.0864 - accuracy: 0.9667 - val_loss: 0.2097 - val_accuracy: 0.9000\n",
      "Epoch 2468/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1302 - accuracy: 0.9333 - val_loss: 0.2118 - val_accuracy: 0.9000\n",
      "Epoch 2469/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0823 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9000\n",
      "Epoch 2470/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0831 - accuracy: 1.0000 - val_loss: 0.2149 - val_accuracy: 0.9000\n",
      "Epoch 2471/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0761 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9000\n",
      "Epoch 2472/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0807 - accuracy: 0.9667 - val_loss: 0.2055 - val_accuracy: 0.9000\n",
      "Epoch 2473/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0908 - accuracy: 0.9667 - val_loss: 0.2020 - val_accuracy: 0.9000\n",
      "Epoch 2474/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0824 - accuracy: 0.9667 - val_loss: 0.2010 - val_accuracy: 0.9000\n",
      "Epoch 2475/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0961 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9000\n",
      "Epoch 2476/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0943 - accuracy: 0.9333 - val_loss: 0.2078 - val_accuracy: 0.9000\n",
      "Epoch 2477/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1231 - accuracy: 0.9667 - val_loss: 0.2133 - val_accuracy: 0.9000\n",
      "Epoch 2478/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0806 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9000\n",
      "Epoch 2479/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1036 - accuracy: 0.9667 - val_loss: 0.2152 - val_accuracy: 0.9000\n",
      "Epoch 2480/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0906 - accuracy: 0.9667 - val_loss: 0.2110 - val_accuracy: 0.9000\n",
      "Epoch 2481/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1002 - accuracy: 0.9667 - val_loss: 0.2114 - val_accuracy: 0.9000\n",
      "Epoch 2482/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1114 - accuracy: 0.9333 - val_loss: 0.2109 - val_accuracy: 0.9000\n",
      "Epoch 2483/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0887 - accuracy: 0.9667 - val_loss: 0.2133 - val_accuracy: 0.9000\n",
      "Epoch 2484/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1121 - accuracy: 0.9667 - val_loss: 0.2192 - val_accuracy: 0.9000\n",
      "Epoch 2485/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1213 - accuracy: 0.9333 - val_loss: 0.2298 - val_accuracy: 0.9000\n",
      "Epoch 2486/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1134 - accuracy: 0.9667 - val_loss: 0.2437 - val_accuracy: 0.9000\n",
      "Epoch 2487/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0873 - accuracy: 0.9667 - val_loss: 0.2665 - val_accuracy: 0.9000\n",
      "Epoch 2488/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0991 - accuracy: 0.9667 - val_loss: 0.2881 - val_accuracy: 0.9000\n",
      "Epoch 2489/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.9000\n",
      "Epoch 2490/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1144 - accuracy: 0.9333 - val_loss: 0.3062 - val_accuracy: 0.9000\n",
      "Epoch 2491/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1035 - accuracy: 0.9667 - val_loss: 0.2940 - val_accuracy: 0.9000\n",
      "Epoch 2492/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9000\n",
      "Epoch 2493/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0815 - accuracy: 0.9667 - val_loss: 0.2508 - val_accuracy: 0.9000\n",
      "Epoch 2494/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0688 - accuracy: 0.9667 - val_loss: 0.2319 - val_accuracy: 0.9000\n",
      "Epoch 2495/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.1157 - accuracy: 0.9667 - val_loss: 0.2156 - val_accuracy: 0.9000\n",
      "Epoch 2496/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1584 - accuracy: 0.9333 - val_loss: 0.2057 - val_accuracy: 0.9000\n",
      "Epoch 2497/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1102 - accuracy: 0.9667 - val_loss: 0.2034 - val_accuracy: 0.9000\n",
      "Epoch 2498/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1901 - accuracy: 0.9000 - val_loss: 0.2043 - val_accuracy: 0.9000\n",
      "Epoch 2499/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0864 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9000\n",
      "Epoch 2500/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0782 - accuracy: 0.9667 - val_loss: 0.2097 - val_accuracy: 0.9000\n",
      "Epoch 2501/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.0842 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9000\n",
      "Epoch 2502/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1050 - accuracy: 0.9667 - val_loss: 0.2267 - val_accuracy: 0.9000\n",
      "Epoch 2503/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.0828 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9000\n",
      "Epoch 2504/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0870 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.9000\n",
      "Epoch 2505/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1041 - accuracy: 0.9667 - val_loss: 0.2682 - val_accuracy: 0.9000\n",
      "Epoch 2506/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9000\n",
      "Epoch 2507/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0741 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9000\n",
      "Epoch 2508/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1050 - accuracy: 0.9667 - val_loss: 0.2605 - val_accuracy: 0.9000\n",
      "Epoch 2509/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.0751 - accuracy: 0.9667 - val_loss: 0.2590 - val_accuracy: 0.9000\n",
      "Epoch 2510/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.0915 - accuracy: 0.9667 - val_loss: 0.2523 - val_accuracy: 0.9000\n",
      "Epoch 2511/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.0820 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 0.9000\n",
      "Epoch 2512/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1100 - accuracy: 0.9333 - val_loss: 0.2478 - val_accuracy: 0.9000\n",
      "Epoch 2513/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0858 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9000\n",
      "Epoch 2514/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.9000\n",
      "Epoch 2515/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1122 - accuracy: 0.9333 - val_loss: 0.2567 - val_accuracy: 0.9000\n",
      "Epoch 2516/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0894 - accuracy: 1.0000 - val_loss: 0.2545 - val_accuracy: 0.9000\n",
      "Epoch 2517/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0776 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.9000\n",
      "Epoch 2518/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1165 - accuracy: 0.9333 - val_loss: 0.2404 - val_accuracy: 0.9000\n",
      "Epoch 2519/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.9000\n",
      "Epoch 2520/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0804 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9000\n",
      "Epoch 2521/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1182 - accuracy: 0.9333 - val_loss: 0.2164 - val_accuracy: 0.9000\n",
      "Epoch 2522/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0559 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9000\n",
      "Epoch 2523/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1076 - accuracy: 0.9667 - val_loss: 0.2171 - val_accuracy: 0.9000\n",
      "Epoch 2524/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0734 - accuracy: 0.9667 - val_loss: 0.2154 - val_accuracy: 0.9000\n",
      "Epoch 2525/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1387 - accuracy: 0.9333 - val_loss: 0.2214 - val_accuracy: 0.9000\n",
      "Epoch 2526/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1200 - accuracy: 0.9333 - val_loss: 0.2303 - val_accuracy: 0.9000\n",
      "Epoch 2527/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1469 - accuracy: 0.9333 - val_loss: 0.2316 - val_accuracy: 0.9000\n",
      "Epoch 2528/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.1028 - accuracy: 0.9667 - val_loss: 0.2316 - val_accuracy: 0.9000\n",
      "Epoch 2529/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1295 - accuracy: 0.9333 - val_loss: 0.2297 - val_accuracy: 0.9000\n",
      "Epoch 2530/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1061 - accuracy: 0.9667 - val_loss: 0.2244 - val_accuracy: 0.9000\n",
      "Epoch 2531/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0895 - accuracy: 0.9667 - val_loss: 0.2200 - val_accuracy: 0.9000\n",
      "Epoch 2532/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0976 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9000\n",
      "Epoch 2533/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0889 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9000\n",
      "Epoch 2534/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0943 - accuracy: 0.9667 - val_loss: 0.2233 - val_accuracy: 0.9000\n",
      "Epoch 2535/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1160 - accuracy: 0.9333 - val_loss: 0.2182 - val_accuracy: 0.9000\n",
      "Epoch 2536/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1184 - accuracy: 0.9667 - val_loss: 0.2175 - val_accuracy: 0.9000\n",
      "Epoch 2537/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1161 - accuracy: 0.9667 - val_loss: 0.2201 - val_accuracy: 0.9000\n",
      "Epoch 2538/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1012 - accuracy: 0.9667 - val_loss: 0.2256 - val_accuracy: 0.9000\n",
      "Epoch 2539/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0770 - accuracy: 0.9667 - val_loss: 0.2302 - val_accuracy: 0.9000\n",
      "Epoch 2540/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0675 - accuracy: 0.9667 - val_loss: 0.2356 - val_accuracy: 0.9000\n",
      "Epoch 2541/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1180 - accuracy: 0.9333 - val_loss: 0.2448 - val_accuracy: 0.9000\n",
      "Epoch 2542/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0854 - accuracy: 0.9667 - val_loss: 0.2604 - val_accuracy: 0.9000\n",
      "Epoch 2543/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0590 - accuracy: 1.0000 - val_loss: 0.2724 - val_accuracy: 0.9000\n",
      "Epoch 2544/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0866 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.9000\n",
      "Epoch 2545/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0832 - accuracy: 1.0000 - val_loss: 0.2749 - val_accuracy: 0.9000\n",
      "Epoch 2546/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0703 - accuracy: 1.0000 - val_loss: 0.2709 - val_accuracy: 0.9000\n",
      "Epoch 2547/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.0882 - accuracy: 0.9667 - val_loss: 0.2663 - val_accuracy: 0.9000\n",
      "Epoch 2548/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0957 - accuracy: 0.9667 - val_loss: 0.2695 - val_accuracy: 0.9000\n",
      "Epoch 2549/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0986 - accuracy: 0.9333 - val_loss: 0.2706 - val_accuracy: 0.9000\n",
      "Epoch 2550/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0844 - accuracy: 0.9667 - val_loss: 0.2754 - val_accuracy: 0.9000\n",
      "Epoch 2551/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1264 - accuracy: 0.9333 - val_loss: 0.2713 - val_accuracy: 0.9000\n",
      "Epoch 2552/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0782 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.9000\n",
      "Epoch 2553/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1290 - accuracy: 0.9333 - val_loss: 0.2515 - val_accuracy: 0.9000\n",
      "Epoch 2554/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1288 - accuracy: 0.9333 - val_loss: 0.2428 - val_accuracy: 0.9000\n",
      "Epoch 2555/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0785 - accuracy: 0.9667 - val_loss: 0.2344 - val_accuracy: 0.9000\n",
      "Epoch 2556/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0849 - accuracy: 0.9667 - val_loss: 0.2294 - val_accuracy: 0.9000\n",
      "Epoch 2557/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1243 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9000\n",
      "Epoch 2558/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0900 - accuracy: 0.9667 - val_loss: 0.2349 - val_accuracy: 0.9000\n",
      "Epoch 2559/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.0807 - accuracy: 0.9667 - val_loss: 0.2401 - val_accuracy: 0.9000\n",
      "Epoch 2560/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0861 - accuracy: 0.9667 - val_loss: 0.2429 - val_accuracy: 0.9000\n",
      "Epoch 2561/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9000\n",
      "Epoch 2562/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1271 - accuracy: 0.9667 - val_loss: 0.2615 - val_accuracy: 0.9000\n",
      "Epoch 2563/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0658 - accuracy: 0.9667 - val_loss: 0.2693 - val_accuracy: 0.9000\n",
      "Epoch 2564/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1352 - accuracy: 0.9000 - val_loss: 0.2775 - val_accuracy: 0.9000\n",
      "Epoch 2565/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.9000\n",
      "Epoch 2566/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1900 - accuracy: 0.9333 - val_loss: 0.2599 - val_accuracy: 0.9000\n",
      "Epoch 2567/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.0773 - accuracy: 1.0000 - val_loss: 0.2341 - val_accuracy: 0.9000\n",
      "Epoch 2568/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1565 - accuracy: 0.9000 - val_loss: 0.1933 - val_accuracy: 0.9000\n",
      "Epoch 2569/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.1198 - accuracy: 0.9667 - val_loss: 0.1652 - val_accuracy: 1.0000\n",
      "Epoch 2570/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1474 - accuracy: 0.9333 - val_loss: 0.1504 - val_accuracy: 1.0000\n",
      "Epoch 2571/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.0884 - accuracy: 0.9333 - val_loss: 0.1468 - val_accuracy: 1.0000\n",
      "Epoch 2572/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1171 - accuracy: 0.9333 - val_loss: 0.1505 - val_accuracy: 1.0000\n",
      "Epoch 2573/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0935 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 1.0000\n",
      "Epoch 2574/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0993 - accuracy: 0.9667 - val_loss: 0.1824 - val_accuracy: 0.9000\n",
      "Epoch 2575/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.1323 - accuracy: 0.9667 - val_loss: 0.2033 - val_accuracy: 0.9000\n",
      "Epoch 2576/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.0957 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9000\n",
      "Epoch 2577/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.1108 - accuracy: 0.9667 - val_loss: 0.2492 - val_accuracy: 0.9000\n",
      "Epoch 2578/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1073 - accuracy: 0.9667 - val_loss: 0.2605 - val_accuracy: 0.9000\n",
      "Epoch 2579/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1399 - accuracy: 0.9667 - val_loss: 0.2673 - val_accuracy: 0.9000\n",
      "Epoch 2580/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0938 - accuracy: 0.9667 - val_loss: 0.2698 - val_accuracy: 0.9000\n",
      "Epoch 2581/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0970 - accuracy: 0.9333 - val_loss: 0.2649 - val_accuracy: 0.9000\n",
      "Epoch 2582/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0819 - accuracy: 0.9667 - val_loss: 0.2568 - val_accuracy: 0.9000\n",
      "Epoch 2583/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0908 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9000\n",
      "Epoch 2584/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1701 - accuracy: 0.9000 - val_loss: 0.2262 - val_accuracy: 0.9000\n",
      "Epoch 2585/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0986 - accuracy: 0.9667 - val_loss: 0.2173 - val_accuracy: 0.9000\n",
      "Epoch 2586/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1327 - accuracy: 0.9000 - val_loss: 0.2071 - val_accuracy: 0.9000\n",
      "Epoch 2587/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0995 - accuracy: 0.9333 - val_loss: 0.1994 - val_accuracy: 0.9000\n",
      "Epoch 2588/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0920 - accuracy: 0.9667 - val_loss: 0.1918 - val_accuracy: 0.9000\n",
      "Epoch 2589/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9000\n",
      "Epoch 2590/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.0745 - accuracy: 0.9667 - val_loss: 0.1870 - val_accuracy: 0.9000\n",
      "Epoch 2591/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1151 - accuracy: 0.9667 - val_loss: 0.1878 - val_accuracy: 0.9000\n",
      "Epoch 2592/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1171 - accuracy: 0.9333 - val_loss: 0.1951 - val_accuracy: 0.9000\n",
      "Epoch 2593/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1131 - accuracy: 0.9667 - val_loss: 0.2061 - val_accuracy: 0.9000\n",
      "Epoch 2594/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0664 - accuracy: 1.0000 - val_loss: 0.2189 - val_accuracy: 0.9000\n",
      "Epoch 2595/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1108 - accuracy: 0.9667 - val_loss: 0.2222 - val_accuracy: 0.9000\n",
      "Epoch 2596/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0974 - accuracy: 0.9667 - val_loss: 0.2291 - val_accuracy: 0.9000\n",
      "Epoch 2597/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0859 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9000\n",
      "Epoch 2598/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0882 - accuracy: 0.9667 - val_loss: 0.2086 - val_accuracy: 0.9000\n",
      "Epoch 2599/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1016 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9000\n",
      "Epoch 2600/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1000 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9000\n",
      "Epoch 2601/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0811 - accuracy: 0.9667 - val_loss: 0.1692 - val_accuracy: 0.9000\n",
      "Epoch 2602/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0950 - accuracy: 0.9667 - val_loss: 0.1587 - val_accuracy: 1.0000\n",
      "Epoch 2603/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1063 - accuracy: 0.9667 - val_loss: 0.1567 - val_accuracy: 1.0000\n",
      "Epoch 2604/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1186 - accuracy: 0.9667 - val_loss: 0.1570 - val_accuracy: 1.0000\n",
      "Epoch 2605/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1195 - accuracy: 0.9667 - val_loss: 0.1624 - val_accuracy: 1.0000\n",
      "Epoch 2606/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0725 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 0.9000\n",
      "Epoch 2607/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0718 - accuracy: 1.0000 - val_loss: 0.1797 - val_accuracy: 0.9000\n",
      "Epoch 2608/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1235 - accuracy: 0.9333 - val_loss: 0.1815 - val_accuracy: 0.9000\n",
      "Epoch 2609/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1396 - accuracy: 0.9000 - val_loss: 0.1893 - val_accuracy: 0.9000\n",
      "Epoch 2610/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 0.9000\n",
      "Epoch 2611/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1084 - accuracy: 0.9667 - val_loss: 0.1803 - val_accuracy: 0.9000\n",
      "Epoch 2612/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9000\n",
      "Epoch 2613/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 1.0000\n",
      "Epoch 2614/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0814 - accuracy: 0.9667 - val_loss: 0.1691 - val_accuracy: 1.0000\n",
      "Epoch 2615/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0948 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 1.0000\n",
      "Epoch 2616/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.0914 - accuracy: 0.9667 - val_loss: 0.1738 - val_accuracy: 1.0000\n",
      "Epoch 2617/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0909 - accuracy: 0.9667 - val_loss: 0.1813 - val_accuracy: 0.9000\n",
      "Epoch 2618/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1220 - accuracy: 0.9000 - val_loss: 0.1940 - val_accuracy: 0.9000\n",
      "Epoch 2619/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0787 - accuracy: 0.9667 - val_loss: 0.2093 - val_accuracy: 0.9000\n",
      "Epoch 2620/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.0844 - accuracy: 0.9667 - val_loss: 0.2279 - val_accuracy: 0.9000\n",
      "Epoch 2621/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0798 - accuracy: 0.9667 - val_loss: 0.2396 - val_accuracy: 0.9000\n",
      "Epoch 2622/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1180 - accuracy: 0.9667 - val_loss: 0.2509 - val_accuracy: 0.9000\n",
      "Epoch 2623/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.1098 - accuracy: 0.9333 - val_loss: 0.2469 - val_accuracy: 0.9000\n",
      "Epoch 2624/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1002 - accuracy: 0.9333 - val_loss: 0.2286 - val_accuracy: 0.9000\n",
      "Epoch 2625/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.0804 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9000\n",
      "Epoch 2626/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1130 - accuracy: 0.9667 - val_loss: 0.1818 - val_accuracy: 0.9000\n",
      "Epoch 2627/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1519 - accuracy: 0.9333 - val_loss: 0.1587 - val_accuracy: 1.0000\n",
      "Epoch 2628/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1071 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 1.0000\n",
      "Epoch 2629/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1119 - accuracy: 0.9667 - val_loss: 0.1327 - val_accuracy: 1.0000\n",
      "Epoch 2630/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0904 - accuracy: 0.9667 - val_loss: 0.1288 - val_accuracy: 1.0000\n",
      "Epoch 2631/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0963 - accuracy: 0.9333 - val_loss: 0.1294 - val_accuracy: 1.0000\n",
      "Epoch 2632/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1383 - accuracy: 0.9333 - val_loss: 0.1361 - val_accuracy: 1.0000\n",
      "Epoch 2633/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.1172 - accuracy: 0.9667 - val_loss: 0.1461 - val_accuracy: 1.0000\n",
      "Epoch 2634/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.0993 - accuracy: 0.9667 - val_loss: 0.1566 - val_accuracy: 1.0000\n",
      "Epoch 2635/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0750 - accuracy: 0.9667 - val_loss: 0.1596 - val_accuracy: 1.0000\n",
      "Epoch 2636/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1032 - accuracy: 0.9667 - val_loss: 0.1648 - val_accuracy: 1.0000\n",
      "Epoch 2637/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9000\n",
      "Epoch 2638/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1039 - accuracy: 0.9333 - val_loss: 0.1790 - val_accuracy: 0.9000\n",
      "Epoch 2639/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1074 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9000\n",
      "Epoch 2640/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0780 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9000\n",
      "Epoch 2641/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1281 - accuracy: 0.9000 - val_loss: 0.1786 - val_accuracy: 0.9000\n",
      "Epoch 2642/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.0747 - accuracy: 0.9667 - val_loss: 0.1726 - val_accuracy: 0.9000\n",
      "Epoch 2643/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0916 - accuracy: 1.0000 - val_loss: 0.1637 - val_accuracy: 1.0000\n",
      "Epoch 2644/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.0714 - accuracy: 1.0000 - val_loss: 0.1517 - val_accuracy: 1.0000\n",
      "Epoch 2645/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.0926 - accuracy: 0.9667 - val_loss: 0.1422 - val_accuracy: 1.0000\n",
      "Epoch 2646/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0733 - accuracy: 0.9667 - val_loss: 0.1358 - val_accuracy: 1.0000\n",
      "Epoch 2647/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1093 - accuracy: 0.9667 - val_loss: 0.1343 - val_accuracy: 1.0000\n",
      "Epoch 2648/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 1.0000\n",
      "Epoch 2649/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.0980 - accuracy: 0.9667 - val_loss: 0.1357 - val_accuracy: 1.0000\n",
      "Epoch 2650/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0875 - accuracy: 0.9667 - val_loss: 0.1375 - val_accuracy: 1.0000\n",
      "Epoch 2651/3000\n",
      "30/30 [==============================] - 0s 115us/step - loss: 0.1064 - accuracy: 0.9667 - val_loss: 0.1424 - val_accuracy: 1.0000\n",
      "Epoch 2652/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1004 - accuracy: 0.9667 - val_loss: 0.1557 - val_accuracy: 1.0000\n",
      "Epoch 2653/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9000\n",
      "Epoch 2654/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1206 - accuracy: 0.9333 - val_loss: 0.1854 - val_accuracy: 0.9000\n",
      "Epoch 2655/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0803 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.9000\n",
      "Epoch 2656/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.1193 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 0.9000\n",
      "Epoch 2657/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9000\n",
      "Epoch 2658/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.0671 - accuracy: 1.0000 - val_loss: 0.1732 - val_accuracy: 0.9000\n",
      "Epoch 2659/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.1677 - val_accuracy: 0.9000\n",
      "Epoch 2660/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0657 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 1.0000\n",
      "Epoch 2661/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1020 - accuracy: 0.9333 - val_loss: 0.1596 - val_accuracy: 1.0000\n",
      "Epoch 2662/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0568 - accuracy: 1.0000 - val_loss: 0.1568 - val_accuracy: 1.0000\n",
      "Epoch 2663/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0936 - accuracy: 1.0000 - val_loss: 0.1556 - val_accuracy: 1.0000\n",
      "Epoch 2664/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0684 - accuracy: 1.0000 - val_loss: 0.1562 - val_accuracy: 1.0000\n",
      "Epoch 2665/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0988 - accuracy: 0.9667 - val_loss: 0.1591 - val_accuracy: 1.0000\n",
      "Epoch 2666/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.0589 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9000\n",
      "Epoch 2667/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0727 - accuracy: 0.9667 - val_loss: 0.1740 - val_accuracy: 0.9000\n",
      "Epoch 2668/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1097 - accuracy: 0.9667 - val_loss: 0.1838 - val_accuracy: 0.9000\n",
      "Epoch 2669/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.0807 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9000\n",
      "Epoch 2670/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0871 - accuracy: 0.9667 - val_loss: 0.1932 - val_accuracy: 0.9000\n",
      "Epoch 2671/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0816 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9000\n",
      "Epoch 2672/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0705 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9000\n",
      "Epoch 2673/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0734 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9000\n",
      "Epoch 2674/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0950 - accuracy: 0.9333 - val_loss: 0.1892 - val_accuracy: 0.9000\n",
      "Epoch 2675/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0780 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9000\n",
      "Epoch 2676/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9000\n",
      "Epoch 2677/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1052 - accuracy: 0.9667 - val_loss: 0.2032 - val_accuracy: 0.9000\n",
      "Epoch 2678/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0517 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9000\n",
      "Epoch 2679/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.1063 - accuracy: 0.9667 - val_loss: 0.2148 - val_accuracy: 0.9000\n",
      "Epoch 2680/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0991 - accuracy: 0.9333 - val_loss: 0.2159 - val_accuracy: 0.9000\n",
      "Epoch 2681/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0850 - accuracy: 0.9667 - val_loss: 0.2160 - val_accuracy: 0.9000\n",
      "Epoch 2682/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0719 - accuracy: 0.9667 - val_loss: 0.2171 - val_accuracy: 0.9000\n",
      "Epoch 2683/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.0979 - accuracy: 0.9667 - val_loss: 0.2242 - val_accuracy: 0.9000\n",
      "Epoch 2684/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1242 - accuracy: 0.9667 - val_loss: 0.2309 - val_accuracy: 0.9000\n",
      "Epoch 2685/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0855 - accuracy: 0.9667 - val_loss: 0.2339 - val_accuracy: 0.9000\n",
      "Epoch 2686/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0992 - accuracy: 0.9667 - val_loss: 0.2379 - val_accuracy: 0.9000\n",
      "Epoch 2687/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.0672 - accuracy: 0.9667 - val_loss: 0.2408 - val_accuracy: 0.9000\n",
      "Epoch 2688/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1065 - accuracy: 0.9333 - val_loss: 0.2346 - val_accuracy: 0.9000\n",
      "Epoch 2689/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.0784 - accuracy: 0.9667 - val_loss: 0.2251 - val_accuracy: 0.9000\n",
      "Epoch 2690/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1170 - accuracy: 0.9667 - val_loss: 0.2047 - val_accuracy: 0.9000\n",
      "Epoch 2691/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0736 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.9000\n",
      "Epoch 2692/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1061 - accuracy: 0.9667 - val_loss: 0.1730 - val_accuracy: 0.9000\n",
      "Epoch 2693/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.1046 - accuracy: 0.9333 - val_loss: 0.1664 - val_accuracy: 1.0000\n",
      "Epoch 2694/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0844 - accuracy: 0.9667 - val_loss: 0.1597 - val_accuracy: 1.0000\n",
      "Epoch 2695/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0869 - accuracy: 0.9667 - val_loss: 0.1538 - val_accuracy: 1.0000\n",
      "Epoch 2696/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0706 - accuracy: 0.9667 - val_loss: 0.1501 - val_accuracy: 1.0000\n",
      "Epoch 2697/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0666 - accuracy: 0.9667 - val_loss: 0.1470 - val_accuracy: 1.0000\n",
      "Epoch 2698/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.1448 - val_accuracy: 1.0000\n",
      "Epoch 2699/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1070 - accuracy: 0.9333 - val_loss: 0.1482 - val_accuracy: 1.0000\n",
      "Epoch 2700/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.1567 - val_accuracy: 1.0000\n",
      "Epoch 2701/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1205 - accuracy: 0.9333 - val_loss: 0.1671 - val_accuracy: 0.9000\n",
      "Epoch 2702/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0902 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9000\n",
      "Epoch 2703/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0912 - accuracy: 0.9667 - val_loss: 0.2042 - val_accuracy: 0.9000\n",
      "Epoch 2704/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0891 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9000\n",
      "Epoch 2705/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0793 - accuracy: 0.9667 - val_loss: 0.2236 - val_accuracy: 0.9000\n",
      "Epoch 2706/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.1056 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9000\n",
      "Epoch 2707/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1015 - accuracy: 0.9667 - val_loss: 0.2071 - val_accuracy: 0.9000\n",
      "Epoch 2708/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1018 - accuracy: 0.9667 - val_loss: 0.1841 - val_accuracy: 0.9000\n",
      "Epoch 2709/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1050 - accuracy: 0.9667 - val_loss: 0.1673 - val_accuracy: 0.9000\n",
      "Epoch 2710/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1098 - accuracy: 0.9333 - val_loss: 0.1563 - val_accuracy: 1.0000\n",
      "Epoch 2711/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0938 - accuracy: 0.9667 - val_loss: 0.1486 - val_accuracy: 1.0000\n",
      "Epoch 2712/3000\n",
      "30/30 [==============================] - 0s 152us/step - loss: 0.1037 - accuracy: 0.9667 - val_loss: 0.1418 - val_accuracy: 1.0000\n",
      "Epoch 2713/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0826 - accuracy: 0.9667 - val_loss: 0.1358 - val_accuracy: 1.0000\n",
      "Epoch 2714/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.1050 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 1.0000\n",
      "Epoch 2715/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1047 - accuracy: 0.9333 - val_loss: 0.1355 - val_accuracy: 1.0000\n",
      "Epoch 2716/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0734 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 1.0000\n",
      "Epoch 2717/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1217 - accuracy: 0.9333 - val_loss: 0.1487 - val_accuracy: 1.0000\n",
      "Epoch 2718/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0598 - accuracy: 0.9667 - val_loss: 0.1594 - val_accuracy: 1.0000\n",
      "Epoch 2719/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1121 - accuracy: 0.9667 - val_loss: 0.1718 - val_accuracy: 0.9000\n",
      "Epoch 2720/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.1125 - accuracy: 0.9667 - val_loss: 0.1836 - val_accuracy: 0.9000\n",
      "Epoch 2721/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1074 - accuracy: 0.9667 - val_loss: 0.1978 - val_accuracy: 0.9000\n",
      "Epoch 2722/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0908 - accuracy: 0.9667 - val_loss: 0.2055 - val_accuracy: 0.9000\n",
      "Epoch 2723/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0759 - accuracy: 1.0000 - val_loss: 0.2179 - val_accuracy: 0.9000\n",
      "Epoch 2724/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0943 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9000\n",
      "Epoch 2725/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0985 - accuracy: 0.9667 - val_loss: 0.1995 - val_accuracy: 0.9000\n",
      "Epoch 2726/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1157 - accuracy: 0.9667 - val_loss: 0.1849 - val_accuracy: 0.9000\n",
      "Epoch 2727/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.1034 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 0.9000\n",
      "Epoch 2728/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1038 - accuracy: 0.9667 - val_loss: 0.1593 - val_accuracy: 1.0000\n",
      "Epoch 2729/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1494 - accuracy: 0.9000 - val_loss: 0.1498 - val_accuracy: 1.0000\n",
      "Epoch 2730/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 1.0000\n",
      "Epoch 2731/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0762 - accuracy: 0.9667 - val_loss: 0.1416 - val_accuracy: 1.0000\n",
      "Epoch 2732/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0885 - accuracy: 0.9333 - val_loss: 0.1427 - val_accuracy: 1.0000\n",
      "Epoch 2733/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 1.0000\n",
      "Epoch 2734/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 1.0000\n",
      "Epoch 2735/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0735 - accuracy: 0.9667 - val_loss: 0.1599 - val_accuracy: 0.9000\n",
      "Epoch 2736/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 0.1700 - val_accuracy: 0.9000\n",
      "Epoch 2737/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0773 - accuracy: 1.0000 - val_loss: 0.1770 - val_accuracy: 0.9000\n",
      "Epoch 2738/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0846 - accuracy: 0.9667 - val_loss: 0.1788 - val_accuracy: 0.9000\n",
      "Epoch 2739/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1134 - accuracy: 0.9667 - val_loss: 0.1735 - val_accuracy: 0.9000\n",
      "Epoch 2740/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.0862 - accuracy: 0.9667 - val_loss: 0.1757 - val_accuracy: 0.9000\n",
      "Epoch 2741/3000\n",
      "30/30 [==============================] - 0s 116us/step - loss: 0.0870 - accuracy: 0.9667 - val_loss: 0.1752 - val_accuracy: 0.9000\n",
      "Epoch 2742/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1416 - accuracy: 0.9333 - val_loss: 0.1717 - val_accuracy: 0.9000\n",
      "Epoch 2743/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.0749 - accuracy: 1.0000 - val_loss: 0.1666 - val_accuracy: 0.9000\n",
      "Epoch 2744/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1029 - accuracy: 0.9667 - val_loss: 0.1592 - val_accuracy: 0.9000\n",
      "Epoch 2745/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0749 - accuracy: 1.0000 - val_loss: 0.1596 - val_accuracy: 0.9000\n",
      "Epoch 2746/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.1016 - accuracy: 0.9667 - val_loss: 0.1642 - val_accuracy: 0.9000\n",
      "Epoch 2747/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9000\n",
      "Epoch 2748/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1306 - accuracy: 0.9000 - val_loss: 0.1676 - val_accuracy: 0.9000\n",
      "Epoch 2749/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0759 - accuracy: 0.9667 - val_loss: 0.1676 - val_accuracy: 0.9000\n",
      "Epoch 2750/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 0.9000\n",
      "Epoch 2751/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1235 - accuracy: 0.9333 - val_loss: 0.1708 - val_accuracy: 0.9000\n",
      "Epoch 2752/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1038 - accuracy: 0.9333 - val_loss: 0.1772 - val_accuracy: 0.9000\n",
      "Epoch 2753/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0802 - accuracy: 0.9667 - val_loss: 0.1835 - val_accuracy: 0.9000\n",
      "Epoch 2754/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0953 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9000\n",
      "Epoch 2755/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9000\n",
      "Epoch 2756/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0727 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9000\n",
      "Epoch 2757/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9000\n",
      "Epoch 2758/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9000\n",
      "Epoch 2759/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.0911 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9000\n",
      "Epoch 2760/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0738 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 0.9000\n",
      "Epoch 2761/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0672 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 0.9000\n",
      "Epoch 2762/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1023 - accuracy: 0.9667 - val_loss: 0.1670 - val_accuracy: 0.9000\n",
      "Epoch 2763/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0599 - accuracy: 1.0000 - val_loss: 0.1565 - val_accuracy: 1.0000\n",
      "Epoch 2764/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1017 - accuracy: 0.9667 - val_loss: 0.1480 - val_accuracy: 1.0000\n",
      "Epoch 2765/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0698 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 1.0000\n",
      "Epoch 2766/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0902 - accuracy: 0.9333 - val_loss: 0.1324 - val_accuracy: 1.0000\n",
      "Epoch 2767/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 1.0000\n",
      "Epoch 2768/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0713 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 1.0000\n",
      "Epoch 2769/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 1.0000\n",
      "Epoch 2770/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0763 - accuracy: 0.9667 - val_loss: 0.1167 - val_accuracy: 1.0000\n",
      "Epoch 2771/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0759 - accuracy: 0.9667 - val_loss: 0.1166 - val_accuracy: 1.0000\n",
      "Epoch 2772/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0893 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 1.0000\n",
      "Epoch 2773/3000\n",
      "30/30 [==============================] - 0s 140us/step - loss: 0.0984 - accuracy: 0.9667 - val_loss: 0.1204 - val_accuracy: 1.0000\n",
      "Epoch 2774/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.0802 - accuracy: 0.9333 - val_loss: 0.1214 - val_accuracy: 1.0000\n",
      "Epoch 2775/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.1251 - val_accuracy: 1.0000\n",
      "Epoch 2776/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1123 - accuracy: 0.9667 - val_loss: 0.1350 - val_accuracy: 1.0000\n",
      "Epoch 2777/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0816 - accuracy: 0.9667 - val_loss: 0.1433 - val_accuracy: 1.0000\n",
      "Epoch 2778/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0891 - accuracy: 0.9667 - val_loss: 0.1496 - val_accuracy: 1.0000\n",
      "Epoch 2779/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.1520 - val_accuracy: 1.0000\n",
      "Epoch 2780/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.1539 - val_accuracy: 1.0000\n",
      "Epoch 2781/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 1.0000\n",
      "Epoch 2782/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0684 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 1.0000\n",
      "Epoch 2783/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1090 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9000\n",
      "Epoch 2784/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0742 - accuracy: 0.9667 - val_loss: 0.1681 - val_accuracy: 0.9000\n",
      "Epoch 2785/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0757 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 0.9000\n",
      "Epoch 2786/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0887 - accuracy: 1.0000 - val_loss: 0.1763 - val_accuracy: 0.9000\n",
      "Epoch 2787/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0750 - accuracy: 1.0000 - val_loss: 0.1758 - val_accuracy: 0.9000\n",
      "Epoch 2788/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1045 - accuracy: 0.9333 - val_loss: 0.1668 - val_accuracy: 0.9000\n",
      "Epoch 2789/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0924 - accuracy: 0.9333 - val_loss: 0.1568 - val_accuracy: 1.0000\n",
      "Epoch 2790/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.0793 - accuracy: 0.9667 - val_loss: 0.1476 - val_accuracy: 1.0000\n",
      "Epoch 2791/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0627 - accuracy: 0.9667 - val_loss: 0.1419 - val_accuracy: 1.0000\n",
      "Epoch 2792/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 1.0000\n",
      "Epoch 2793/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0898 - accuracy: 0.9667 - val_loss: 0.1300 - val_accuracy: 1.0000\n",
      "Epoch 2794/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 0.1269 - val_accuracy: 1.0000\n",
      "Epoch 2795/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0952 - accuracy: 0.9667 - val_loss: 0.1245 - val_accuracy: 1.0000\n",
      "Epoch 2796/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 0.1231 - val_accuracy: 1.0000\n",
      "Epoch 2797/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0633 - accuracy: 0.9667 - val_loss: 0.1239 - val_accuracy: 1.0000\n",
      "Epoch 2798/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0831 - accuracy: 0.9667 - val_loss: 0.1288 - val_accuracy: 1.0000\n",
      "Epoch 2799/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1140 - accuracy: 0.9333 - val_loss: 0.1381 - val_accuracy: 1.0000\n",
      "Epoch 2800/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 1.0000\n",
      "Epoch 2801/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0623 - accuracy: 0.9667 - val_loss: 0.1593 - val_accuracy: 0.9000\n",
      "Epoch 2802/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.1715 - val_accuracy: 0.9000\n",
      "Epoch 2803/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.0819 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.9000\n",
      "Epoch 2804/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0772 - accuracy: 1.0000 - val_loss: 0.1788 - val_accuracy: 0.9000\n",
      "Epoch 2805/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0639 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 0.9000\n",
      "Epoch 2806/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0977 - accuracy: 0.9667 - val_loss: 0.1602 - val_accuracy: 0.9000\n",
      "Epoch 2807/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0699 - accuracy: 0.9667 - val_loss: 0.1516 - val_accuracy: 1.0000\n",
      "Epoch 2808/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0836 - accuracy: 0.9667 - val_loss: 0.1491 - val_accuracy: 1.0000\n",
      "Epoch 2809/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0837 - accuracy: 0.9667 - val_loss: 0.1483 - val_accuracy: 1.0000\n",
      "Epoch 2810/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 1.0000\n",
      "Epoch 2811/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1067 - accuracy: 0.9333 - val_loss: 0.1517 - val_accuracy: 1.0000\n",
      "Epoch 2812/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0678 - accuracy: 0.9667 - val_loss: 0.1548 - val_accuracy: 1.0000\n",
      "Epoch 2813/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0612 - accuracy: 0.9667 - val_loss: 0.1604 - val_accuracy: 0.9000\n",
      "Epoch 2814/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 0.1726 - val_accuracy: 0.9000\n",
      "Epoch 2815/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0957 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9000\n",
      "Epoch 2816/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.0988 - accuracy: 0.9333 - val_loss: 0.2087 - val_accuracy: 0.9000\n",
      "Epoch 2817/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0886 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9000\n",
      "Epoch 2818/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9000\n",
      "Epoch 2819/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9000\n",
      "Epoch 2820/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.0811 - accuracy: 0.9667 - val_loss: 0.1810 - val_accuracy: 0.9000\n",
      "Epoch 2821/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0670 - accuracy: 1.0000 - val_loss: 0.1758 - val_accuracy: 0.9000\n",
      "Epoch 2822/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 0.9000\n",
      "Epoch 2823/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.0658 - accuracy: 0.9667 - val_loss: 0.1679 - val_accuracy: 0.9000\n",
      "Epoch 2824/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.1015 - accuracy: 0.9667 - val_loss: 0.1632 - val_accuracy: 0.9000\n",
      "Epoch 2825/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0749 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 1.0000\n",
      "Epoch 2826/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 1.0000\n",
      "Epoch 2827/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0984 - accuracy: 0.9333 - val_loss: 0.1389 - val_accuracy: 1.0000\n",
      "Epoch 2828/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1125 - accuracy: 0.9333 - val_loss: 0.1359 - val_accuracy: 1.0000\n",
      "Epoch 2829/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1082 - accuracy: 0.9667 - val_loss: 0.1325 - val_accuracy: 1.0000\n",
      "Epoch 2830/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0738 - accuracy: 0.9667 - val_loss: 0.1312 - val_accuracy: 1.0000\n",
      "Epoch 2831/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.0778 - accuracy: 0.9667 - val_loss: 0.1298 - val_accuracy: 1.0000\n",
      "Epoch 2832/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.1009 - accuracy: 0.9333 - val_loss: 0.1338 - val_accuracy: 1.0000\n",
      "Epoch 2833/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 1.0000\n",
      "Epoch 2834/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0933 - accuracy: 0.9667 - val_loss: 0.1474 - val_accuracy: 1.0000\n",
      "Epoch 2835/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1177 - accuracy: 0.9000 - val_loss: 0.1490 - val_accuracy: 1.0000\n",
      "Epoch 2836/3000\n",
      "30/30 [==============================] - 0s 138us/step - loss: 0.1132 - accuracy: 0.9667 - val_loss: 0.1494 - val_accuracy: 1.0000\n",
      "Epoch 2837/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0763 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 1.0000\n",
      "Epoch 2838/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0742 - accuracy: 1.0000 - val_loss: 0.1458 - val_accuracy: 1.0000\n",
      "Epoch 2839/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0517 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 1.0000\n",
      "Epoch 2840/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 1.0000\n",
      "Epoch 2841/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0908 - accuracy: 0.9667 - val_loss: 0.1407 - val_accuracy: 1.0000\n",
      "Epoch 2842/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0582 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 1.0000\n",
      "Epoch 2843/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0815 - accuracy: 0.9667 - val_loss: 0.1375 - val_accuracy: 1.0000\n",
      "Epoch 2844/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0767 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 1.0000\n",
      "Epoch 2845/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0552 - accuracy: 0.9667 - val_loss: 0.1394 - val_accuracy: 1.0000\n",
      "Epoch 2846/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0896 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 1.0000\n",
      "Epoch 2847/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0929 - accuracy: 0.9333 - val_loss: 0.1428 - val_accuracy: 1.0000\n",
      "Epoch 2848/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0881 - accuracy: 0.9667 - val_loss: 0.1438 - val_accuracy: 1.0000\n",
      "Epoch 2849/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1088 - accuracy: 0.9333 - val_loss: 0.1454 - val_accuracy: 1.0000\n",
      "Epoch 2850/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0897 - accuracy: 0.9667 - val_loss: 0.1522 - val_accuracy: 1.0000\n",
      "Epoch 2851/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.0976 - accuracy: 0.9667 - val_loss: 0.1577 - val_accuracy: 0.9000\n",
      "Epoch 2852/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.1088 - accuracy: 0.9667 - val_loss: 0.1602 - val_accuracy: 0.9000\n",
      "Epoch 2853/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.1098 - accuracy: 0.9000 - val_loss: 0.1659 - val_accuracy: 0.9000\n",
      "Epoch 2854/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0727 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9000\n",
      "Epoch 2855/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.1744 - val_accuracy: 0.9000\n",
      "Epoch 2856/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9000\n",
      "Epoch 2857/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.0943 - accuracy: 0.9667 - val_loss: 0.1821 - val_accuracy: 0.9000\n",
      "Epoch 2858/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0906 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9000\n",
      "Epoch 2859/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0836 - accuracy: 0.9667 - val_loss: 0.1914 - val_accuracy: 0.9000\n",
      "Epoch 2860/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.1076 - accuracy: 0.9667 - val_loss: 0.1904 - val_accuracy: 0.9000\n",
      "Epoch 2861/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.9000\n",
      "Epoch 2862/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9000\n",
      "Epoch 2863/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0712 - accuracy: 1.0000 - val_loss: 0.1676 - val_accuracy: 0.9000\n",
      "Epoch 2864/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0694 - accuracy: 1.0000 - val_loss: 0.1649 - val_accuracy: 0.9000\n",
      "Epoch 2865/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0641 - accuracy: 0.9667 - val_loss: 0.1636 - val_accuracy: 0.9000\n",
      "Epoch 2866/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9000\n",
      "Epoch 2867/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0811 - accuracy: 0.9667 - val_loss: 0.1625 - val_accuracy: 0.9000\n",
      "Epoch 2868/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.0836 - accuracy: 0.9667 - val_loss: 0.1730 - val_accuracy: 0.9000\n",
      "Epoch 2869/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0799 - accuracy: 0.9667 - val_loss: 0.1851 - val_accuracy: 0.9000\n",
      "Epoch 2870/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0732 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9000\n",
      "Epoch 2871/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.1103 - accuracy: 0.9333 - val_loss: 0.1933 - val_accuracy: 0.9000\n",
      "Epoch 2872/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.0481 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9000\n",
      "Epoch 2873/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0838 - accuracy: 0.9667 - val_loss: 0.1843 - val_accuracy: 0.9000\n",
      "Epoch 2874/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0675 - accuracy: 0.9667 - val_loss: 0.1767 - val_accuracy: 0.9000\n",
      "Epoch 2875/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0828 - accuracy: 0.9667 - val_loss: 0.1652 - val_accuracy: 0.9000\n",
      "Epoch 2876/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 1.0000\n",
      "Epoch 2877/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 0.1486 - val_accuracy: 1.0000\n",
      "Epoch 2878/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 1.0000\n",
      "Epoch 2879/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0631 - accuracy: 0.9667 - val_loss: 0.1440 - val_accuracy: 1.0000\n",
      "Epoch 2880/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0970 - accuracy: 0.9333 - val_loss: 0.1449 - val_accuracy: 1.0000\n",
      "Epoch 2881/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0773 - accuracy: 0.9667 - val_loss: 0.1396 - val_accuracy: 1.0000\n",
      "Epoch 2882/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0751 - accuracy: 0.9667 - val_loss: 0.1350 - val_accuracy: 1.0000\n",
      "Epoch 2883/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0550 - accuracy: 0.9667 - val_loss: 0.1327 - val_accuracy: 1.0000\n",
      "Epoch 2884/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0785 - accuracy: 0.9667 - val_loss: 0.1331 - val_accuracy: 1.0000\n",
      "Epoch 2885/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.1151 - accuracy: 0.9333 - val_loss: 0.1351 - val_accuracy: 1.0000\n",
      "Epoch 2886/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1087 - accuracy: 0.9667 - val_loss: 0.1351 - val_accuracy: 1.0000\n",
      "Epoch 2887/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0720 - accuracy: 0.9667 - val_loss: 0.1378 - val_accuracy: 1.0000\n",
      "Epoch 2888/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0830 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 1.0000\n",
      "Epoch 2889/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.1468 - val_accuracy: 1.0000\n",
      "Epoch 2890/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0982 - accuracy: 0.9667 - val_loss: 0.1486 - val_accuracy: 1.0000\n",
      "Epoch 2891/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9000\n",
      "Epoch 2892/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.0539 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9000\n",
      "Epoch 2893/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0829 - accuracy: 0.9667 - val_loss: 0.1473 - val_accuracy: 1.0000\n",
      "Epoch 2894/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 1.0000\n",
      "Epoch 2895/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0839 - accuracy: 0.9667 - val_loss: 0.1356 - val_accuracy: 1.0000\n",
      "Epoch 2896/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0820 - accuracy: 0.9667 - val_loss: 0.1275 - val_accuracy: 1.0000\n",
      "Epoch 2897/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.0849 - accuracy: 0.9667 - val_loss: 0.1222 - val_accuracy: 1.0000\n",
      "Epoch 2898/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0815 - accuracy: 0.9667 - val_loss: 0.1219 - val_accuracy: 1.0000\n",
      "Epoch 2899/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0908 - accuracy: 0.9667 - val_loss: 0.1210 - val_accuracy: 1.0000\n",
      "Epoch 2900/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.1065 - accuracy: 0.9333 - val_loss: 0.1215 - val_accuracy: 1.0000\n",
      "Epoch 2901/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0693 - accuracy: 0.9667 - val_loss: 0.1228 - val_accuracy: 1.0000\n",
      "Epoch 2902/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0850 - accuracy: 0.9667 - val_loss: 0.1255 - val_accuracy: 1.0000\n",
      "Epoch 2903/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0791 - accuracy: 0.9667 - val_loss: 0.1359 - val_accuracy: 1.0000\n",
      "Epoch 2904/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0844 - accuracy: 0.9667 - val_loss: 0.1396 - val_accuracy: 1.0000\n",
      "Epoch 2905/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 1.0000\n",
      "Epoch 2906/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.1135 - accuracy: 0.9333 - val_loss: 0.1369 - val_accuracy: 1.0000\n",
      "Epoch 2907/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0869 - accuracy: 0.9667 - val_loss: 0.1380 - val_accuracy: 1.0000\n",
      "Epoch 2908/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0701 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 1.0000\n",
      "Epoch 2909/3000\n",
      "30/30 [==============================] - 0s 120us/step - loss: 0.0736 - accuracy: 0.9667 - val_loss: 0.1306 - val_accuracy: 1.0000\n",
      "Epoch 2910/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.1271 - val_accuracy: 1.0000\n",
      "Epoch 2911/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0447 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 1.0000\n",
      "Epoch 2912/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.0995 - accuracy: 0.9667 - val_loss: 0.1227 - val_accuracy: 1.0000\n",
      "Epoch 2913/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0807 - accuracy: 0.9667 - val_loss: 0.1232 - val_accuracy: 1.0000\n",
      "Epoch 2914/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0736 - accuracy: 0.9667 - val_loss: 0.1275 - val_accuracy: 1.0000\n",
      "Epoch 2915/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0665 - accuracy: 0.9667 - val_loss: 0.1335 - val_accuracy: 1.0000\n",
      "Epoch 2916/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 1.0000\n",
      "Epoch 2917/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0674 - accuracy: 0.9667 - val_loss: 0.1564 - val_accuracy: 0.9000\n",
      "Epoch 2918/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.0641 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9000\n",
      "Epoch 2919/3000\n",
      "30/30 [==============================] - 0s 139us/step - loss: 0.0779 - accuracy: 0.9667 - val_loss: 0.1726 - val_accuracy: 0.9000\n",
      "Epoch 2920/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9000\n",
      "Epoch 2921/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.1736 - val_accuracy: 0.9000\n",
      "Epoch 2922/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.9000\n",
      "Epoch 2923/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0870 - accuracy: 0.9667 - val_loss: 0.1630 - val_accuracy: 0.9000\n",
      "Epoch 2924/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0680 - accuracy: 1.0000 - val_loss: 0.1561 - val_accuracy: 0.9000\n",
      "Epoch 2925/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0968 - accuracy: 0.9333 - val_loss: 0.1420 - val_accuracy: 1.0000\n",
      "Epoch 2926/3000\n",
      "30/30 [==============================] - 0s 137us/step - loss: 0.0975 - accuracy: 0.9667 - val_loss: 0.1350 - val_accuracy: 1.0000\n",
      "Epoch 2927/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0902 - accuracy: 0.9667 - val_loss: 0.1274 - val_accuracy: 1.0000\n",
      "Epoch 2928/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0731 - accuracy: 0.9667 - val_loss: 0.1237 - val_accuracy: 1.0000\n",
      "Epoch 2929/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0721 - accuracy: 0.9667 - val_loss: 0.1243 - val_accuracy: 1.0000\n",
      "Epoch 2930/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0646 - accuracy: 0.9667 - val_loss: 0.1260 - val_accuracy: 1.0000\n",
      "Epoch 2931/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 1.0000\n",
      "Epoch 2932/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0741 - accuracy: 0.9667 - val_loss: 0.1350 - val_accuracy: 1.0000\n",
      "Epoch 2933/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 1.0000\n",
      "Epoch 2934/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 1.0000\n",
      "Epoch 2935/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0556 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 1.0000\n",
      "Epoch 2936/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0702 - accuracy: 1.0000 - val_loss: 0.1291 - val_accuracy: 1.0000\n",
      "Epoch 2937/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.0864 - accuracy: 0.9667 - val_loss: 0.1321 - val_accuracy: 1.0000\n",
      "Epoch 2938/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.0594 - accuracy: 0.9667 - val_loss: 0.1361 - val_accuracy: 1.0000\n",
      "Epoch 2939/3000\n",
      "30/30 [==============================] - 0s 117us/step - loss: 0.0684 - accuracy: 0.9667 - val_loss: 0.1415 - val_accuracy: 1.0000\n",
      "Epoch 2940/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0853 - accuracy: 0.9667 - val_loss: 0.1445 - val_accuracy: 1.0000\n",
      "Epoch 2941/3000\n",
      "30/30 [==============================] - 0s 134us/step - loss: 0.0708 - accuracy: 0.9667 - val_loss: 0.1502 - val_accuracy: 0.9000\n",
      "Epoch 2942/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9000\n",
      "Epoch 2943/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9000\n",
      "Epoch 2944/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0624 - accuracy: 0.9667 - val_loss: 0.1589 - val_accuracy: 0.9000\n",
      "Epoch 2945/3000\n",
      "30/30 [==============================] - 0s 131us/step - loss: 0.0839 - accuracy: 0.9667 - val_loss: 0.1612 - val_accuracy: 0.9000\n",
      "Epoch 2946/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0919 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9000\n",
      "Epoch 2947/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0563 - accuracy: 0.9667 - val_loss: 0.1644 - val_accuracy: 0.9000\n",
      "Epoch 2948/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0906 - accuracy: 0.9667 - val_loss: 0.1583 - val_accuracy: 0.9000\n",
      "Epoch 2949/3000\n",
      "30/30 [==============================] - 0s 133us/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9000\n",
      "Epoch 2950/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0780 - accuracy: 0.9667 - val_loss: 0.1462 - val_accuracy: 0.9000\n",
      "Epoch 2951/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.1412 - val_accuracy: 1.0000\n",
      "Epoch 2952/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0583 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 1.0000\n",
      "Epoch 2953/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0626 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 1.0000\n",
      "Epoch 2954/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0767 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 1.0000\n",
      "Epoch 2955/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0914 - accuracy: 0.9333 - val_loss: 0.1161 - val_accuracy: 1.0000\n",
      "Epoch 2956/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 0.1132 - val_accuracy: 1.0000\n",
      "Epoch 2957/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 1.0000\n",
      "Epoch 2958/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0842 - accuracy: 0.9667 - val_loss: 0.1021 - val_accuracy: 1.0000\n",
      "Epoch 2959/3000\n",
      "30/30 [==============================] - 0s 135us/step - loss: 0.1581 - accuracy: 0.9000 - val_loss: 0.1008 - val_accuracy: 1.0000\n",
      "Epoch 2960/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 1.0000\n",
      "Epoch 2961/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0524 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 1.0000\n",
      "Epoch 2962/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0899 - accuracy: 0.9333 - val_loss: 0.1086 - val_accuracy: 1.0000\n",
      "Epoch 2963/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 1.0000\n",
      "Epoch 2964/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0715 - accuracy: 1.0000 - val_loss: 0.1189 - val_accuracy: 1.0000\n",
      "Epoch 2965/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 1.0000\n",
      "Epoch 2966/3000\n",
      "30/30 [==============================] - 0s 119us/step - loss: 0.0814 - accuracy: 0.9667 - val_loss: 0.1147 - val_accuracy: 1.0000\n",
      "Epoch 2967/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0880 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 1.0000\n",
      "Epoch 2968/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0668 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 1.0000\n",
      "Epoch 2969/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0589 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 1.0000\n",
      "Epoch 2970/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0744 - accuracy: 0.9667 - val_loss: 0.1066 - val_accuracy: 1.0000\n",
      "Epoch 2971/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0611 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 1.0000\n",
      "Epoch 2972/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0813 - accuracy: 0.9667 - val_loss: 0.1151 - val_accuracy: 1.0000\n",
      "Epoch 2973/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0885 - accuracy: 0.9667 - val_loss: 0.1220 - val_accuracy: 1.0000\n",
      "Epoch 2974/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.0888 - accuracy: 0.9667 - val_loss: 0.1326 - val_accuracy: 1.0000\n",
      "Epoch 2975/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 1.0000\n",
      "Epoch 2976/3000\n",
      "30/30 [==============================] - 0s 132us/step - loss: 0.1108 - accuracy: 0.9667 - val_loss: 0.1430 - val_accuracy: 1.0000\n",
      "Epoch 2977/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0680 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 1.0000\n",
      "Epoch 2978/3000\n",
      "30/30 [==============================] - 0s 125us/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 1.0000\n",
      "Epoch 2979/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0742 - accuracy: 1.0000 - val_loss: 0.1428 - val_accuracy: 1.0000\n",
      "Epoch 2980/3000\n",
      "30/30 [==============================] - 0s 123us/step - loss: 0.0577 - accuracy: 0.9667 - val_loss: 0.1482 - val_accuracy: 1.0000\n",
      "Epoch 2981/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.9000\n",
      "Epoch 2982/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.0680 - accuracy: 0.9667 - val_loss: 0.1603 - val_accuracy: 0.9000\n",
      "Epoch 2983/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0961 - accuracy: 0.9667 - val_loss: 0.1676 - val_accuracy: 0.9000\n",
      "Epoch 2984/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0558 - accuracy: 0.9667 - val_loss: 0.1732 - val_accuracy: 0.9000\n",
      "Epoch 2985/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0725 - accuracy: 0.9667 - val_loss: 0.1737 - val_accuracy: 0.9000\n",
      "Epoch 2986/3000\n",
      "30/30 [==============================] - 0s 118us/step - loss: 0.0941 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9000\n",
      "Epoch 2987/3000\n",
      "30/30 [==============================] - 0s 126us/step - loss: 0.0737 - accuracy: 0.9667 - val_loss: 0.1710 - val_accuracy: 0.9000\n",
      "Epoch 2988/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 0.1639 - val_accuracy: 0.9000\n",
      "Epoch 2989/3000\n",
      "30/30 [==============================] - 0s 136us/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9000\n",
      "Epoch 2990/3000\n",
      "30/30 [==============================] - 0s 122us/step - loss: 0.0652 - accuracy: 0.9667 - val_loss: 0.1409 - val_accuracy: 1.0000\n",
      "Epoch 2991/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 1.0000\n",
      "Epoch 2992/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 1.0000\n",
      "Epoch 2993/3000\n",
      "30/30 [==============================] - 0s 130us/step - loss: 0.0610 - accuracy: 0.9667 - val_loss: 0.1255 - val_accuracy: 1.0000\n",
      "Epoch 2994/3000\n",
      "30/30 [==============================] - 0s 124us/step - loss: 0.0722 - accuracy: 0.9667 - val_loss: 0.1246 - val_accuracy: 1.0000\n",
      "Epoch 2995/3000\n",
      "30/30 [==============================] - 0s 121us/step - loss: 0.0881 - accuracy: 0.9667 - val_loss: 0.1224 - val_accuracy: 1.0000\n",
      "Epoch 2996/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0599 - accuracy: 0.9667 - val_loss: 0.1210 - val_accuracy: 1.0000\n",
      "Epoch 2997/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 1.0000\n",
      "Epoch 2998/3000\n",
      "30/30 [==============================] - 0s 128us/step - loss: 0.0643 - accuracy: 0.9667 - val_loss: 0.1216 - val_accuracy: 1.0000\n",
      "Epoch 2999/3000\n",
      "30/30 [==============================] - 0s 127us/step - loss: 0.0857 - accuracy: 0.9333 - val_loss: 0.1296 - val_accuracy: 1.0000\n",
      "Epoch 3000/3000\n",
      "30/30 [==============================] - 0s 129us/step - loss: 0.0548 - accuracy: 1.0000 - val_loss: 0.1367 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'historyData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6r/qjkmb3mx55l9vc9x538f6ypr0000gn/T/ipykernel_3679/1169731169.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m model_train = model.fit(train_X, train_label, epochs=3000, verbose=1,\n\u001b[1;32m     17\u001b[0m                         validation_data=(valid_X, valid_label))\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mloss_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistoryData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m#The above line will return a dictionary, access it's info like this:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mbest_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'historyData' is not defined"
     ]
    }
   ],
   "source": [
    "#TRAIN THE MODEL\n",
    "    \n",
    "loss_hist=0\n",
    "# Add an early stopping callback\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    mode='min', \n",
    "    patience = 2200, \n",
    "    restore_best_weights = True, \n",
    "    verbose=1)\n",
    "# Add a checkpoint where loss is minimum, and save that model\n",
    "mc = keras.callbacks.ModelCheckpoint('best_model.SB', monitor='loss', \n",
    "                     mode='min',  verbose=1, save_best_only=True)\n",
    "\n",
    "#COMPLETE THE model.fit STATEMENT BELOW\n",
    "model_train = model.fit(train_X, train_label, epochs=3000, verbose=1,\n",
    "                        validation_data=(valid_X, valid_label))\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(model_train.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f1d923a-37d5-4afd-89f5-c8e041eb2e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row [ 0 ] data:  Ta=  1.0 , ID=  200.0  RL=  0.8181818181818182\n",
      " pred Mmax=  [9.6876925e-01 3.1193426e-02 3.7338457e-05]  Mmaxint =  0  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 1 ] data:  Ta=  1.0 , ID=  200.0  RL=  1.7441077441077442\n",
      " pred Mmax=  [1.1869277e-22 8.0711824e-01 1.9288178e-01]  Mmaxint =  1  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 2 ] data:  Ta=  1.0 , ID=  200.0  RL=  3.239057239057239\n",
      " pred Mmax=  [0.000000e+00 1.588433e-15 1.000000e+00]  Mmaxint =  2  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 3 ] data:  Ta=  1.0 , ID=  200.0  RL=  4.484848484848484\n",
      " pred Mmax=  [0.0000000e+00 1.4216195e-28 1.0000000e+00]  Mmaxint =  2  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 4 ] data:  Ta=  1.0 , ID=  200.0  RL=  5.7272727272727275\n",
      " pred Mmax=  [0. 0. 1.]  Mmaxint =  2  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 5 ] data:  Ta=  1.0 , ID=  500.0  RL=  0.2356902356902357\n",
      " pred Mmax=  [9.9960715e-01 3.9256053e-04 3.0412411e-07]  Mmaxint =  0  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 6 ] data:  Ta=  1.0 , ID=  500.0  RL=  0.7138047138047138\n",
      " pred Mmax=  [0.00275448 0.99474156 0.00250404]  Mmaxint =  1  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 7 ] data:  Ta=  1.0 , ID=  500.0  RL=  1.4545454545454546\n",
      " pred Mmax=  [2.4662316e-23 3.9459519e-02 9.6054041e-01]  Mmaxint =  2  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 8 ] data:  Ta=  1.0 , ID=  500.0  RL=  2.0606060606060606\n",
      " pred Mmax=  [0.0000000e+00 2.3199403e-08 1.0000000e+00]  Mmaxint =  2  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 9 ] data:  Ta=  1.0 , ID=  500.0  RL=  2.663299663299663\n",
      " pred Mmax=  [0.0000000e+00 1.2066208e-14 1.0000000e+00]  Mmaxint =  2  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 10 ] data:  Ta=  1.0 , ID=  700.0  RL=  0.164983164983165\n",
      " pred Mmax=  [9.9923289e-01 7.6642516e-04 7.6399090e-07]  Mmaxint =  0  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 11 ] data:  Ta=  1.0 , ID=  700.0  RL=  0.4814814814814815\n",
      " pred Mmax=  [0.06577728 0.931677   0.00254568]  Mmaxint =  1  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 12 ] data:  Ta=  1.0 , ID=  700.0  RL=  1.0\n",
      " pred Mmax=  [8.4148493e-16 4.4027838e-01 5.5972159e-01]  Mmaxint =  2  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 13 ] data:  Ta=  1.0 , ID=  700.0  RL=  1.4444444444444444\n",
      " pred Mmax=  [2.4185364e-30 2.1126138e-05 9.9997890e-01]  Mmaxint =  2  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 14 ] data:  Ta=  1.0 , ID=  700.0  RL=  1.8619528619528618\n",
      " pred Mmax=  [0.0000000e+00 1.0296303e-09 1.0000000e+00]  Mmaxint =  2  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 15 ] data:  Ta=  1.0 , ID=  1000.0  RL=  0.13198653198653199\n",
      " pred Mmax=  [8.8155031e-01 1.1798465e-01 4.6499664e-04]  Mmaxint =  0  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 16 ] data:  Ta=  1.0 , ID=  1000.0  RL=  0.3939393939393939\n",
      " pred Mmax=  [5.072324e-07 9.150239e-01 8.497553e-02]  Mmaxint =  1  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 17 ] data:  Ta=  1.0 , ID=  1000.0  RL=  0.8484848484848485\n",
      " pred Mmax=  [1.2372587e-21 2.2639484e-04 9.9977356e-01]  Mmaxint =  2  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 18 ] data:  Ta=  1.0 , ID=  1000.0  RL=  1.1245791245791246\n",
      " pred Mmax=  [8.0858514e-31 3.2814697e-07 9.9999964e-01]  Mmaxint =  2  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 19 ] data:  Ta=  1.0 , ID=  1000.0  RL=  1.4006734006734007\n",
      " pred Mmax=  [0.000000e+00 4.663599e-10 1.000000e+00]  Mmaxint =  2  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 20 ] data:  Ta=  1.81 , ID=  500.0  RL=  0.2356902356902357\n",
      " pred Mmax=  [9.9974293e-01 2.5677294e-04 1.9665177e-07]  Mmaxint =  0  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 21 ] data:  Ta=  1.85 , ID=  500.0  RL=  0.7138047138047138\n",
      " pred Mmax=  [9.6545211e-04 9.9642724e-01 2.6073100e-03]  Mmaxint =  1  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 22 ] data:  Ta=  1.9 , ID=  500.0  RL=  1.4545454545454546\n",
      " pred Mmax=  [4.4481098e-24 2.5944965e-02 9.7405505e-01]  Mmaxint =  2  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 23 ] data:  Ta=  1.86 , ID=  500.0  RL=  2.0606060606060606\n",
      " pred Mmax=  [0.0000000e+00 1.8646944e-08 1.0000000e+00]  Mmaxint =  2  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 24 ] data:  Ta=  1.8800000000000001 , ID=  500.0  RL=  2.663299663299663\n",
      " pred Mmax=  [0.0000000e+00 1.1521652e-14 1.0000000e+00]  Mmaxint =  2  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 25 ] data:  Ta=  0.21000000000000002 , ID=  1000.0  RL=  0.13198653198653199\n",
      " pred Mmax=  [8.7674665e-01 1.2272085e-01 5.3249038e-04]  Mmaxint =  0  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 26 ] data:  Ta=  0.2 , ID=  1000.0  RL=  0.3939393939393939\n",
      " pred Mmax=  [5.2797765e-07 8.8900876e-01 1.1099073e-01]  Mmaxint =  1  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 27 ] data:  Ta=  0.19 , ID=  1000.0  RL=  0.8484848484848485\n",
      " pred Mmax=  [1.1214839e-21 1.4656599e-04 9.9985337e-01]  Mmaxint =  2  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 28 ] data:  Ta=  0.22999999999999998 , ID=  1000.0  RL=  1.1245791245791246\n",
      " pred Mmax=  [7.1543826e-31 2.0715007e-07 9.9999976e-01]  Mmaxint =  2  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 29 ] data:  Ta=  0.24 , ID=  1000.0  RL=  1.4006734006734007\n",
      " pred Mmax=  [0.0000000e+00 2.7831967e-10 1.0000000e+00]  Mmaxint =  2  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 30 ] data:  Ta=  0.05 , ID=  700.0  RL=  0.164983164983165\n",
      " pred Mmax=  [9.9857605e-01 1.4223813e-03 1.5244428e-06]  Mmaxint =  0  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 31 ] data:  Ta=  0.06999999999999999 , ID=  700.0  RL=  0.4814814814814815\n",
      " pred Mmax=  [0.05084118 0.94621164 0.00294721]  Mmaxint =  1  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 32 ] data:  Ta=  0.1 , ID=  700.0  RL=  1.0\n",
      " pred Mmax=  [6.970957e-16 2.933764e-01 7.066236e-01]  Mmaxint =  2  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 33 ] data:  Ta=  0.08 , ID=  700.0  RL=  1.4444444444444444\n",
      " pred Mmax=  [1.3440074e-30 9.5276064e-06 9.9999046e-01]  Mmaxint =  2  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 34 ] data:  Ta=  0.02 , ID=  700.0  RL=  1.8619528619528618\n",
      " pred Mmax=  [0.000000e+00 3.795726e-10 1.000000e+00]  Mmaxint =  2  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 35 ] data:  Ta=  1.52 , ID=  200.0  RL=  0.8181818181818182\n",
      " pred Mmax=  [9.6634525e-01 3.3614963e-02 3.9890925e-05]  Mmaxint =  0  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 36 ] data:  Ta=  1.54 , ID=  200.0  RL=  1.7441077441077442\n",
      " pred Mmax=  [6.2167806e-23 7.9607087e-01 2.0392914e-01]  Mmaxint =  1  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 37 ] data:  Ta=  2.12 , ID=  1000.0  RL=  0.13198653198653199\n",
      " pred Mmax=  [0.5360616  0.4615447  0.00239362]  Mmaxint =  0  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 38 ] data:  Ta=  1.94 , ID=  1000.0  RL=  0.3939393939393939\n",
      " pred Mmax=  [1.416889e-07 8.600739e-01 1.399260e-01]  Mmaxint =  1  data Mmax=  [1 0 0]\n",
      " \n",
      "row [ 39 ] data:  Ta=  1.92 , ID=  1000.0  RL=  0.8484848484848485\n",
      " pred Mmax=  [1.6957073e-22 1.2530244e-04 9.9987471e-01]  Mmaxint =  2  data Mmax=  [1 0 0]\n",
      " \n",
      " \n",
      "training versus validation comparisons\n",
      "30/30 [==============================] - 0s 39us/step\n",
      "train loss: 0.05040697008371353\n",
      "train accuracy: 1.0\n",
      "10/10 [==============================] - 0s 101us/step\n",
      "validation loss: 0.1366814225912094\n",
      "validation accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "\n",
    "#first point (data row [0]) comparison of data and prediction\n",
    "\n",
    "#=====================\n",
    "#example code to convert one hot output to predicted Mmax integer\n",
    "for i in range(len(xarray)):\n",
    "    test = [] #specifies a test input data set\n",
    "    outpt=[] #output of model for test input\n",
    "    test = [[ xarray[i][0] , xarray[i][1] , xarray[i][2] ]]\n",
    "    testarray = np.array(test)\n",
    "    outpt = model.predict(testarray)\n",
    "    Mmaxint = np.argmax(np.round(outpt[0]))  # np.argmax returns the index of the maximum values along an axis\n",
    "    #first input data row:  normalized Air temp (degC), ID (W/sqm), load resistance (ohms)\n",
    "    print ('row [',i,'] data:  Ta= ', xarray[i][0]*Tamed, ', ID= ', xarray[i][1]*IDmed, \\\n",
    "    ' RL= ', xarray[i][2]*RLmed)\n",
    "    print (' pred Mmax= ', outpt[0],' Mmaxint = ', Mmaxint,' data Mmax= ', ydataCatOHEarray[0])\n",
    "    print (' ')\n",
    "'''#Predict Mmaxint for arbitray specified input data: \n",
    "print ('arbitrary input data:  Ta= ', 10., ', ID= ', 1000., ' RL= ', 41.6)\n",
    "test = [[ 10.0/Tamed, 1000.0/IDmed, 41.6/RLmed ]]\n",
    "testarray = np.array(test)\n",
    "outpt = model.predict(testarray)\n",
    "Mmaxint = np.argmax(np.round(outpt[0]))\n",
    "print (' pred Mmax= ', outpt[0],' Mmaxint = ', Mmaxint,)\n",
    "'''\n",
    "#=====================\n",
    "print (' ')\n",
    "print('training versus validation comparisons')\n",
    "\n",
    "#Model Evaluation on the Training Set\n",
    "train_eval = model.evaluate(train_X, train_label, verbose=1)  #changed to verbose=1 to show progress\n",
    "print('train loss:', train_eval[0])\n",
    "print('train accuracy:', train_eval[1])\n",
    "\n",
    "#Model Evaluation on the Validation Set\n",
    "test_eval = model.evaluate(valid_X, valid_label, verbose=1)  #changed to verbose=1 to show progress\n",
    "print('validation loss:', test_eval[0])\n",
    "print('validation accuracy:', test_eval[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced3d153-99ad-4077-b056-54a15bd4293a",
   "metadata": {},
   "source": [
    "#### k)\n",
    "##### 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8f3498f-a5c1-45b1-b483-3c5dfa03fb03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ta \t ID \t RL \t Mmaxint\n",
      "10.0 \t 200.0 \t 50.0 \t 2\n",
      "20 \t 200 \t 130 \t 2\n",
      "10 \t 500 \t 40 \t 2\n",
      "20 \t 500 \t 80 \t 2\n",
      "20 \t 700 \t 30 \t 2\n",
      "20 \t 700 \t 55 \t 2\n",
      "10 \t 1000 \t 12 \t 2\n",
      "20 \t 1000 \t 25 \t 2\n",
      "20 \t 1000 \t 39 \t 2\n"
     ]
    }
   ],
   "source": [
    "#Predict Mmaxint for arbitray specified input data: \n",
    "Arb_xdata=[] #input array containing the combnations of perating conditions to find the mode number\n",
    "Arb_xdata=[[10.0, 200.0, 50.0],\n",
    "           [20, 200, 130],\n",
    "           [10, 500, 40],\n",
    "           [20, 500, 80],\n",
    "           [20, 700, 30],\n",
    "           [20, 700, 55],\n",
    "           [10, 1000, 12],\n",
    "           [20, 1000, 25],\n",
    "           [20, 1000, 39]]\n",
    "print('Ta \\t ID \\t RL \\t Mmaxint')\n",
    "for i in range(len(Arb_xdata)):\n",
    "    test = [] #specifies a test input data set\n",
    "    outpt=[] #output of model for test input\n",
    "    test = [[ Arb_xdata[i][0]/Tamed , Arb_xdata[i][1]/IDmed , Arb_xdata[i][2]/RLmed ]]\n",
    "    testarray = np.array(test)\n",
    "    outpt = model.predict(testarray)\n",
    "    Mmaxint = np.argmax(np.round(outpt[0]))  # np.argmax returns the index of the maximum values along an axis\n",
    "    #first input data row:  normalized Air temp (degC), ID (W/sqm), load resistance (ohms)\n",
    "    print(Arb_xdata[i][0], '\\t', Arb_xdata[i][1], '\\t', Arb_xdata[i][2], '\\t', Mmaxint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5c0ef01-5d28-41ca-93a9-62763688579a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ta \t ID \t RL \t W\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'taskmode_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6r/qjkmb3mx55l9vc9x538f6ypr0000gn/T/ipykernel_3679/3970860783.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mArb_xdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mTamed\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mArb_xdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mIDmed\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mArb_xdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mRLmed\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtestarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moutpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtaskmode_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m#first input data row:  normalized Air temp (degC), ID (W/sqm), load resistance (ohms)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mArb_xdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mArb_xdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mArb_xdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'taskmode_model' is not defined"
     ]
    }
   ],
   "source": [
    "#predict the power output for mode 0\n",
    "print('Ta \\t ID \\t RL \\t W')\n",
    "for i in range(len(Arb_xdata)):\n",
    "    test = [] #specifies a test input data set\n",
    "    outpt=[] #output of model for test input\n",
    "    test = [[ 0.0, Arb_xdata[i][0]/Tamed , Arb_xdata[i][1]/IDmed , Arb_xdata[i][2]/RLmed ]]\n",
    "    testarray = np.array(test)\n",
    "    outpt = taskmode_model.predict(testarray)\n",
    "    #first input data row:  normalized Air temp (degC), ID (W/sqm), load resistance (ohms)\n",
    "    print(Arb_xdata[i][0], '\\t', Arb_xdata[i][1], '\\t', Arb_xdata[i][2], '\\t', outpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1afc2792-384d-4a0d-8a76-bed238d78adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ta \t ID \t RL \t W\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'taskmode_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6r/qjkmb3mx55l9vc9x538f6ypr0000gn/T/ipykernel_3679/4038765172.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mArb_xdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mTamed\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mArb_xdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mIDmed\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mArb_xdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mRLmed\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtestarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moutpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtaskmode_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m#first input data row:  normalized Air temp (degC), ID (W/sqm), load resistance (ohms)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mArb_xdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mArb_xdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mArb_xdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'taskmode_model' is not defined"
     ]
    }
   ],
   "source": [
    "#predict the power output for mode 1\n",
    "print('Ta \\t ID \\t RL \\t W')\n",
    "for i in range(len(Arb_xdata)):\n",
    "    test = [] #specifies a test input data set\n",
    "    outpt=[] #output of model for test input\n",
    "    test = [[ 1.0, Arb_xdata[i][0]/Tamed , Arb_xdata[i][1]/IDmed , Arb_xdata[i][2]/RLmed ]]\n",
    "    testarray = np.array(test)\n",
    "    outpt = taskmode_model.predict(testarray)\n",
    "    #first input data row:  normalized Air temp (degC), ID (W/sqm), load resistance (ohms)\n",
    "    print(Arb_xdata[i][0], '\\t', Arb_xdata[i][1], '\\t', Arb_xdata[i][2], '\\t', outpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "479d3f0c-6498-4354-9dac-8a757b293b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ta \t ID \t RL \t W\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'taskmode_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6r/qjkmb3mx55l9vc9x538f6ypr0000gn/T/ipykernel_3679/4248299517.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mArb_xdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mTamed\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mArb_xdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mIDmed\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mArb_xdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mRLmed\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtestarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moutpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtaskmode_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m#first input data row:  normalized Air temp (degC), ID (W/sqm), load resistance (ohms)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mArb_xdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mArb_xdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mArb_xdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'taskmode_model' is not defined"
     ]
    }
   ],
   "source": [
    "#predict the power output for mode 2\n",
    "print('Ta \\t ID \\t RL \\t W')\n",
    "for i in range(len(Arb_xdata)):\n",
    "    test = [] #specifies a test input data set\n",
    "    outpt=[] #output of model for test input\n",
    "    test = [[ 2.0, Arb_xdata[i][0]/Tamed , Arb_xdata[i][1]/IDmed , Arb_xdata[i][2]/RLmed ]]\n",
    "    testarray = np.array(test)\n",
    "    outpt = taskmode_model.predict(testarray)\n",
    "    #first input data row:  normalized Air temp (degC), ID (W/sqm), load resistance (ohms)\n",
    "    print(Arb_xdata[i][0], '\\t', Arb_xdata[i][1], '\\t', Arb_xdata[i][2], '\\t', outpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34d296f-4bd8-40d8-8d94-dbdf6496404c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
