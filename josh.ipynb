{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ee5c5d6-0541-4c9c-affc-f4284de506d4",
   "metadata": {},
   "source": [
    "# Project Three\n",
    "\n",
    "## Part One\n",
    "\n",
    "Part 1 of this project considers the performance of the solar panel design show above. The panel  \n",
    "contains 72 solar cells connected in series, each with an area of 173 cm2. Performance test data for   \n",
    "this type of unit is provided as a dataset that includes the following performance parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfcd957-f18d-41d0-bc4d-f3b512b223cc",
   "metadata": {},
   "source": [
    "### Task 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7d64ca-5110-4993-85b3-027a03ea09a2",
   "metadata": {},
   "source": [
    "#### Data Set 3.1.1 Low Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15df584-2276-4784-aada-4004a9e8c099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, numpy\n",
    "#Part 1 input data: Air temp (degC), ID (W/sqm), load resistance (ohms)\n",
    "# - split into training set and a randomly slected small validation set\n",
    "xdata = [[-10.0, 350, 4.464], \n",
    "  [-10.0, 650, 4.464], \n",
    "  [-10.0, 950, 4.464], \n",
    "  [-10.0, 1250, 4.464], \n",
    "  [10.0, 350, 4.464], \n",
    "  [10.0, 650, 4.464], \n",
    "  [10.0, 950, 4.464], \n",
    "  [10.0, 1250, 4.464], \n",
    "  [30.0, 350, 4.464], \n",
    "  [30.0, 650, 4.464], \n",
    "  [30.0, 950, 4.464], \n",
    "  [30.0, 1250, 4.464], \n",
    "  [-10.0, 350, 6.696], \n",
    "  [-10.0, 650, 6.696], \n",
    "  [-10.0, 950, 6.696], \n",
    "  [-10.0, 1250, 6.696], \n",
    "  [10.0, 350, 6.696], \n",
    "  [10.0, 650, 6.696], \n",
    "  [10.0, 950, 6.696], \n",
    "  [10.0, 1250, 6.696], \n",
    "  [30.0, 350, 6.696], \n",
    "  [30.0, 650, 6.696], \n",
    "  [30.0, 950, 6.696], \n",
    "  [30.0, 1250, 6.696], \n",
    "  [-10.0, 350, 8.928], \n",
    "  [-10.0, 650, 8.928], \n",
    "  [-10.0, 950, 8.928], \n",
    "  [-10.0, 1250, 8.928], \n",
    "  [10.0, 350, 8.928], \n",
    "  [10.0, 650, 8.928], \n",
    "  [10.0, 950, 8.928], \n",
    "  [10.0, 1250, 8.928], \n",
    "  [30.0, 350, 8.928], \n",
    "  [30.0, 650, 8.928], \n",
    "  [30.0, 950, 8.928], \n",
    "  [30.0, 1250, 8.928]] \n",
    "\n",
    "\n",
    "#Part 1 output data: VL (V) and Power out (W)\n",
    "ydata = [[18.9, 80.3], \n",
    " [23.5, 124.6], \n",
    " [24.8, 138.6], \n",
    " [25.6, 146.9], \n",
    " [19.2, 83.1], \n",
    " [25.0, 140.5], \n",
    " [26.5, 157.6], \n",
    " [27.3, 167.5],  \n",
    " [19.4, 84.7], \n",
    " [26.4, 156.7], \n",
    " [28.1, 177.7], \n",
    " [29.0, 189.4],\n",
    " [22.4, 75.2], \n",
    " [24.8, 92.2], \n",
    " [25.8, 99.7], \n",
    " [26.4, 104.6], \n",
    " [23.6, 83.7], \n",
    " [26.5, 104.9], \n",
    " [27.6, 113.8], \n",
    " [28.3, 119.6], \n",
    " [24.8, 92.0], \n",
    " [28.1, 118.2], \n",
    " [29.3, 128.8], \n",
    " [30.1, 135.5],  \n",
    " [23.5, 62.2], \n",
    " [25.4, 72.5], \n",
    " [26.3, 77.6], \n",
    " [26.9, 81.1],  \n",
    " [25.0, 70.3], \n",
    " [27.1, 82.7], \n",
    " [28.1, 88.7], \n",
    " [28.7, 92.8],  \n",
    " [26.5, 78.6], \n",
    " [28.8, 93.5], \n",
    " [29.9, 100.5], \n",
    " [30.6, 105.2]] \n",
    "\n",
    "\n",
    "xarray= numpy.array(xdata)\n",
    "yarray= numpy.array(ydata)\n",
    "print (xdata)\n",
    "print (xarray)\n",
    "print (ydata)\n",
    "print (yarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906d4ffb-4ce8-40e2-89cb-8fe7439ec4bf",
   "metadata": {},
   "source": [
    "#### Task 1.1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c4b8c1d-4713-4633-83ad-061542dba912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Script that computes the mean and standard deviation for the three input variables (Tair, Id, Rl) within above data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec0bed1-23fd-44d0-ad11-958828210675",
   "metadata": {},
   "source": [
    "#### Task 1.1b & 1.1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38870c3-3d19-48c8-b892-d01ddee491ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next, you are to modify the P3pcaExampleF22 code to remove its section where\n",
    "#it subtracts the mean from its data, and replace its data set with the standardized\n",
    "#data set created from DS3.1.1LowfluxF22. Also change the names of the\n",
    "#variables to suitable choices for the parameters in your data [Tair , I\n",
    "#D , RL ]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49224081-7b49-4335-9745-92468ec7ac22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#P3pcaExampleF22\n",
    "#PCA example\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30de6de6-3c61-4547-80c9-4b701d74275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[7,4,3],[4,1,8],[6,3,5],[8,6,1],[8,5,7],[7,2,9],[5,3,3],[9,5,8],[7,4,5],[8,2,2]])#define array\n",
    "print (X)\n",
    "print (X.T)  #print the transpose\n",
    "Xmean = np.mean(X,0)  # compute mean vector\n",
    "print (Xmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bdc365-afdb-41e7-b9ff-8587bd431319",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.cov(X.T)  #transpose is matrix we want to work with - compute covariance matrix\n",
    "print (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9614740b-1a14-49c2-8d9b-30eaf71a0d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, v = LA.eig(C)  # get the eigenvalues w and the eigenvectors \n",
    "print (w)\n",
    "print (v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6996002-fd49-488a-8525-03c311f12d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "A  = np.array([v[:,2],v[:,1]])  # form the transformation matrix using eigenvectors\n",
    "# for the top two eigenvalues\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd13ae6-c9ac-4f1c-a636-0c63d513b1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.matmul(A,(X-Xmean).T) # Apply transformation to obtain new   \n",
    "                             # data representation in 2-D\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87427233-7a2a-4cc9-b405-c1cdfad469fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xhat = np.matmul(A.T,Y).T + Xmean  #recover the original data using the inverse transform\n",
    "print(xhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24210b10-354f-4e8b-919e-668478fd0268",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.sum((X - xhat)**2)/10  #mean squared error\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6a0658-1bf7-4eef-9cbd-3f7e069f73f6",
   "metadata": {},
   "source": [
    "#### Task 1.1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58fc5ab-f970-47fb-9186-f2fd5aeb8c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarize the eigenvalues in a table and include it and the 3D P3pcaPlot1F22\n",
    "#scatter plot of the standardized data created by the code in your summary report.\n",
    "#Based on them, provide in your report a discussion of the relative importance of\n",
    "#these three variables (are they all important, is one most important, is one of lesser\n",
    "#importance than the other two, etc.?)\n",
    "\n",
    "#P3pcaPlot1F22\n",
    "# imports\n",
    "\n",
    "%matplotlib notebook\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.gca(projection='3d')\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "X = np.array([[7,4,3],[4,1,8],[6,3,5],[8,6,1],[8,5,7],[7,2,9],[5,3,3],[9,5,8],[7,4,5],[8,2,2]])#define array\n",
    "x=X[:,0]\n",
    "y=X[:,1]\n",
    "z=X[:,2]\n",
    "\n",
    "# these are data transformed back in P3pcaExampleF21 \n",
    "# - they can be added to plot with a bit of extra code\n",
    "xhat = np.array([[7.07495606, 3.92443193, 2.99101016],\n",
    " [4.35818659, 0.63888882, 7.95704095],\n",
    " [6.18905239, 2.80940399, 4.97732603],\n",
    " [8.45730172, 5.53896441, 0.94515359],\n",
    " [8.31521059, 4.68221571, 6.96219527],\n",
    " [6.43642293, 2.56817868, 9.06759253],\n",
    " [5.56335682, 2.43204338, 2.93243389],\n",
    " [8.88184769, 5.11911702, 8.01417058],\n",
    " [7.19307301, 3.80535054, 4.97684382],\n",
    " [6.53059219, 3.48140552, 2.17623319]])\n",
    "xh=xhat[:,0]\n",
    "yh=xhat[:,1]\n",
    "zh=xhat[:,2]\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x,y,z, c='red', s=60)\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z');\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f36894b-1495-444f-b1ee-9934cd8ca06c",
   "metadata": {},
   "source": [
    "### Task 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abb4853-bb50-40c4-bfb0-cefce0695886",
   "metadata": {},
   "source": [
    "#### Task 1.2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f6ff7-c047-4af7-8285-b56e9edd546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) For the original data set DS3.1.1LowfluxF22, determine the median value for\n",
    "# each parameter and normalize the data by dividing each parameter value by its\n",
    "# median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5596601-2186-4fde-a50e-8f600e611303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, numpy\n",
    "#Part 1 input data: Air temp (degC), ID (W/sqm), load resistance (ohms)\n",
    "# - split into training set and a randomly slected small validation set\n",
    "xdata = [[-10.0, 350, 4.464], \n",
    "  [-10.0, 650, 4.464], \n",
    "  [-10.0, 950, 4.464], \n",
    "  [-10.0, 1250, 4.464], \n",
    "  [10.0, 350, 4.464], \n",
    "  [10.0, 650, 4.464], \n",
    "  [10.0, 950, 4.464], \n",
    "  [10.0, 1250, 4.464], \n",
    "  [30.0, 350, 4.464], \n",
    "  [30.0, 650, 4.464], \n",
    "  [30.0, 950, 4.464], \n",
    "  [30.0, 1250, 4.464], \n",
    "  [-10.0, 350, 6.696], \n",
    "  [-10.0, 650, 6.696], \n",
    "  [-10.0, 950, 6.696], \n",
    "  [-10.0, 1250, 6.696], \n",
    "  [10.0, 350, 6.696], \n",
    "  [10.0, 650, 6.696], \n",
    "  [10.0, 950, 6.696], \n",
    "  [10.0, 1250, 6.696], \n",
    "  [30.0, 350, 6.696], \n",
    "  [30.0, 650, 6.696], \n",
    "  [30.0, 950, 6.696], \n",
    "  [30.0, 1250, 6.696], \n",
    "  [-10.0, 350, 8.928], \n",
    "  [-10.0, 650, 8.928], \n",
    "  [-10.0, 950, 8.928], \n",
    "  [-10.0, 1250, 8.928], \n",
    "  [10.0, 350, 8.928], \n",
    "  [10.0, 650, 8.928], \n",
    "  [10.0, 950, 8.928], \n",
    "  [10.0, 1250, 8.928], \n",
    "  [30.0, 350, 8.928], \n",
    "  [30.0, 650, 8.928], \n",
    "  [30.0, 950, 8.928], \n",
    "  [30.0, 1250, 8.928]] \n",
    "\n",
    "\n",
    "#Part 1 output data: VL (V) and Power out (W)\n",
    "ydata = [[18.9, 80.3], \n",
    " [23.5, 124.6], \n",
    " [24.8, 138.6], \n",
    " [25.6, 146.9], \n",
    " [19.2, 83.1], \n",
    " [25.0, 140.5], \n",
    " [26.5, 157.6], \n",
    " [27.3, 167.5],  \n",
    " [19.4, 84.7], \n",
    " [26.4, 156.7], \n",
    " [28.1, 177.7], \n",
    " [29.0, 189.4],\n",
    " [22.4, 75.2], \n",
    " [24.8, 92.2], \n",
    " [25.8, 99.7], \n",
    " [26.4, 104.6], \n",
    " [23.6, 83.7], \n",
    " [26.5, 104.9], \n",
    " [27.6, 113.8], \n",
    " [28.3, 119.6], \n",
    " [24.8, 92.0], \n",
    " [28.1, 118.2], \n",
    " [29.3, 128.8], \n",
    " [30.1, 135.5],  \n",
    " [23.5, 62.2], \n",
    " [25.4, 72.5], \n",
    " [26.3, 77.6], \n",
    " [26.9, 81.1],  \n",
    " [25.0, 70.3], \n",
    " [27.1, 82.7], \n",
    " [28.1, 88.7], \n",
    " [28.7, 92.8],  \n",
    " [26.5, 78.6], \n",
    " [28.8, 93.5], \n",
    " [29.9, 100.5], \n",
    " [30.6, 105.2]] \n",
    "\n",
    "\n",
    "xarray= numpy.array(xdata)\n",
    "yarray= numpy.array(ydata)\n",
    "print (xdata)\n",
    "print (xarray)\n",
    "print (ydata)\n",
    "print (yarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b7efbe-0188-4dc0-a56e-5c0180e6fb87",
   "metadata": {},
   "source": [
    "#### Task 1.2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9991a10e-4eda-49ac-83fb-d34d07a544af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b) Take the normalized original data created in part (a) and separate it randomly into\n",
    "# two data sets: a training set with 2/3rds of the data and a second validation set\n",
    "# with 1/3rd of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84a3c93-d5d9-42c2-a935-9eee238dd5ec",
   "metadata": {},
   "source": [
    "#### Task 1.2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7be08d-3d11-44db-a829-5f2d3443587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c) Substitute the normalized training set data into the skeleton code and convert it to a\n",
    "# neural network model that can be trained using the training data set. For this first\n",
    "# model, use a keras.sequential network with having these specs:\n",
    "# - specify a RandomUniform initializer (see skeleton code)\n",
    "# - an inlet layer having 6 neurons with activation=K.elu, input_shape=[3]\n",
    "# - 3 hidden layers with 8, 16, and 8 neurons\n",
    "# - an outlet layer with 2 neurons with no activation function\n",
    "# - set activation=K.elu for all the neurons except the outlet layer, and use the\n",
    "#  RMSprop optimizer, as configured in the skeleton program.\n",
    "# Using the model.fit routine as configured in the skeleton program is recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0646fb-91e5-4e67-9c24-86df0b5e5838",
   "metadata": {},
   "source": [
    "#### Task 1.2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dac419c-8029-4518-b554-e0034ef75c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (d) Train the neural network model constructed in part (c) using the training data.\n",
    "# Try to get the mean absolute error below 0.025 if possible. You can adjust the\n",
    "# initialization and/or the learning parameter a bit to try to improve convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd6ee65-94f0-4073-8733-8ec77efe8ff9",
   "metadata": {},
   "source": [
    "#### Task 1.2e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40596d9f-fd57-4757-959d-9999de23f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (e) Compare the trained model predictions to the training data set, report the mean\n",
    "# absolute error for the fit, and create a log-log plot of predicted power output vs.\n",
    "# data value power output for each set of data point operating conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ecce10-8890-48d4-b2e2-d4b110d07d88",
   "metadata": {},
   "source": [
    "#### Task 1.2f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ad96d9-3487-4683-99d0-1ba057844493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (f) Repeat the steps of part (e), comparing the model predictions this time to the\n",
    "# normalized validation data. Report the mean absolution error and include the loglog plot specified in \n",
    "#(e) for these data in the summary report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fdb252-e239-4830-bb29-54e96ac2a965",
   "metadata": {},
   "source": [
    "#### Task 1.2g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84cca5e-e7fa-47af-b28c-eb71b3e19fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (g) Normalize the limited data for ID > 1300 W/m2 provided in data set\n",
    "# DS3.1.2HifluxF22 in the same way as the DS3.1.1LowfluxF22 data. Repeat the\n",
    "# steps of part (e), comparing the model predictions, this time to the normalized\n",
    "# limited data for ID > 1300 W/m2\n",
    "# . Report the mean absolution error and include\n",
    "# the log-log plot specified in (e) for these data in the summary report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6673a93-ae4f-4c7a-b663-7e9ea1510337",
   "metadata": {},
   "source": [
    "#### Task 1.2h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba100428-45b9-4035-917e-fd5d471e880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (h) Taking the air temperature to be fixed at 20 Â°C, use the trained model created in\n",
    "# this task to create predictions of the solar power output for 4 Ohms < RL < 8 Ohms\n",
    "# and 500 < ID < 1800 W/m2\n",
    "# , and create a surface plot of the power delivered (W! ) to\n",
    "# the load as a function of these two variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4ef98a-5836-4213-9c06-1dfc0cd13222",
   "metadata": {},
   "source": [
    "### Task 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604d85c8-6c76-42f0-8281-ee001fbac2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat steps (a)-(h) in Task 1.2 to construct and train a neural network model with the\n",
    "# same specs as Task 1.2, except for the following changes to the network design:\n",
    "# Use 4 hidden layers (instead of 3) having 8, 12, 16, and 8 neurons\n",
    "# With this new model, repeats steps (a)-(h) in Task 1.2, and do this additional step (i):\n",
    "# (i) Compare the results for this task with those for Task 1.2, and assess whether (1) this\n",
    "# model better matches the data, and (2) whether there are any signs of overfitting.\n",
    "# Summarize your conclusions in your report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226013bf-29aa-401c-9252-c2d4f10c68de",
   "metadata": {},
   "source": [
    "## Part Two"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608b5d10-168b-4886-8dba-f384acf0bfd8",
   "metadata": {},
   "source": [
    "### Task 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e0ac68-8e1e-4dd9-bd7b-da0c1e099d62",
   "metadata": {},
   "source": [
    "#### Task 2.1a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772895f4-a38e-4bb2-94fb-62d47a561a1f",
   "metadata": {},
   "source": [
    "#### Task 2.1b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c8ef7c-d0ee-4b18-9d2c-18c2530727f0",
   "metadata": {},
   "source": [
    "#### Task 2.1c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a376e47-0819-448e-b081-84028870767e",
   "metadata": {},
   "source": [
    "#### Task 2.1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d2879f-ef87-4cd9-92cd-25721f721b73",
   "metadata": {},
   "source": [
    "#### Task 2.1e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618ec95f-ca13-460f-9147-ec3faf951835",
   "metadata": {},
   "source": [
    "#### Task 2.1f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9af254b-7eea-40ca-bc4f-ad0b2908464b",
   "metadata": {},
   "source": [
    "### Task 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31196d37-2759-4f85-859d-f47bae1d9add",
   "metadata": {},
   "source": [
    "#### Task 2.2a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078283db-6683-459e-acda-abddda6a9334",
   "metadata": {},
   "source": [
    "#### Task 2.2b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1296a53f-c117-4265-bba0-21ab60eb4d8f",
   "metadata": {},
   "source": [
    "#### Task 2.2c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b169d-f810-409d-b4c3-397d0eeab7d5",
   "metadata": {},
   "source": [
    "#### Task 2.2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43f31ad-02a6-4518-bc65-33e09d9b6d03",
   "metadata": {},
   "source": [
    "#### Task 2.2e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e637f29c-43a8-4dbb-92cf-835586761383",
   "metadata": {},
   "source": [
    "#### Task 2.2f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3b00b4-9092-4f99-aad5-b03591714703",
   "metadata": {},
   "source": [
    "#### Task 2.2g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a92ba6-5020-4424-89e9-664392f29109",
   "metadata": {},
   "source": [
    "#### Task 2.2h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94520ac1-fb70-423a-ae40-19a125c4cb48",
   "metadata": {},
   "source": [
    "#### Task 2.2i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d84246-c9d7-4230-a891-9672e1707a08",
   "metadata": {},
   "source": [
    "#### Task 2.2j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3800c239-7275-483f-b288-b20be099c20e",
   "metadata": {},
   "source": [
    "#### Task 2.2k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f417eb-8229-47e9-a4ba-a7cb2d575e78",
   "metadata": {},
   "source": [
    "#### Task 2.2k.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e469de-b5bf-4529-a8ca-05116c2295b6",
   "metadata": {},
   "source": [
    "#### Task 2.2k.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9619b7-8720-45d0-bc9e-780b85919d34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
